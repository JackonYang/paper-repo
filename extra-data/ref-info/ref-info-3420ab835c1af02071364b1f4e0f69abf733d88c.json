{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1880661"
                        ],
                        "name": "F. Wahl",
                        "slug": "F.-Wahl",
                        "structuredName": {
                            "firstName": "Friedrich",
                            "lastName": "Wahl",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145470231"
                        ],
                        "name": "Kwan Y. Wong",
                        "slug": "Kwan-Y.-Wong",
                        "structuredName": {
                            "firstName": "Kwan",
                            "lastName": "Wong",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kwan Y. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34896449"
                        ],
                        "name": "R. Casey",
                        "slug": "R.-Casey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Casey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Casey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 41585742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4947ddbda627747c9b13da81514f0129597e91de",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Block-segmentation-and-text-extraction-in-mixed-Wahl-Wong",
            "title": {
                "fragments": [],
                "text": "Block segmentation and text extraction in mixed text/image documents"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Image Process."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266621"
                        ],
                        "name": "M. Viswanathan",
                        "slug": "M.-Viswanathan",
                        "structuredName": {
                            "firstName": "Mahesh",
                            "lastName": "Viswanathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Viswanathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "Second, strokes are extracted from the segmented text regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2530196,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62a53caea5213ea177298d7b2aff292b1386c37a",
            "isKey": false,
            "numCitedBy": 434,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Gobbledoc, a system providing remote access to stored documents, which is based on syntactic document analysis and optical character recognition (OCR), is discussed. In Gobbledoc, image processing, document analysis, and OCR operations take place in batch mode when the documents are acquired. The document image acquisition process and the knowledge base that must be entered into the system to process a family of page images are described. The process by which the X-Y tree data structure converts a 2-D page-segmentation problem into a series of 1-D string-parsing problems that can be tackled using conventional compiler tools is also described. Syntactic analysis is used in Gobbledoc to divide each page into labeled rectangular blocks. Blocks labeled text are converted by OCR to obtain a secondary (ASCII) document representation. Since such symbolic files are better suited for computerized search than for human access to the document content and because too many visual layout clues are lost in the OCR process (including some special characters), Gobbledoc preserves the original block images for human browsing. Storage, networking, and display issues specific to document images are also discussed.<<ETX>>"
            },
            "slug": "A-prototype-document-image-analysis-system-for-Nagy-Seth",
            "title": {
                "fragments": [],
                "text": "A prototype document image analysis system for technical journals"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The document image acquisition process and the knowledge base that must be entered into the system to process a family of page images are described, and the process by which the X-Y tree data structure converts a 2-D page-segmentation problem into a series of 1-D string-parsing problems that can be tackled using conventional compiler tools."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111216375"
                        ],
                        "name": "Dacheng Wang",
                        "slug": "Dacheng-Wang",
                        "structuredName": {
                            "firstName": "Dacheng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dacheng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26685555,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "873fa0ca7454bd1ca4de25128c522e088b635ddc",
            "isKey": false,
            "numCitedBy": 250,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Classification-of-newspaper-image-blocks-using-Wang-Srihari",
            "title": {
                "fragments": [],
                "text": "Classification of newspaper image blocks using texture analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47260288"
                        ],
                        "name": "L. Fletcher",
                        "slug": "L.-Fletcher",
                        "structuredName": {
                            "firstName": "Lloyd",
                            "lastName": "Fletcher",
                            "middleNames": [
                                "Alan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Fletcher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "In this paper, a four-step system which automaticnlly detects and extracts text in images i& proposed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2685456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b08e547ba4edb60902d1708a5593d71f075aa7f1",
            "isKey": false,
            "numCitedBy": 657,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described. It is intended for use in an automated system for document analysis. The principal parts of the algorithm are the generation of connected components and the application of the Hough transform in order to group components into logical character strings that can then be separated from the graphics. The algorithm outputs two images, one containing text strings and the other graphics. These images can then be processed by suitable character recognition and graphics recognition systems. The performance of the algorithm, both in terms of its effectiveness and computational efficiency, was evaluated using several test images and showed superior performance compared to other techniques. >"
            },
            "slug": "A-Robust-Algorithm-for-Text-String-Separation-from-Fletcher-Kasturi",
            "title": {
                "fragments": [],
                "text": "A Robust Algorithm for Text String Separation from Mixed Text/Graphics Images"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described and showed superior performance compared to other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144851973"
                        ],
                        "name": "M. Kamel",
                        "slug": "M.-Kamel",
                        "structuredName": {
                            "firstName": "Mohamed",
                            "lastName": "Kamel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kamel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1500387699"
                        ],
                        "name": "A. Zhao",
                        "slug": "A.-Zhao",
                        "structuredName": {
                            "firstName": "Aiguo",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zhao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 33047782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b786be0f6e167d58a9da67eca864113efbf6b01",
            "isKey": false,
            "numCitedBy": 221,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The extraction of binary character/graphics images from gray-scale document images with background pictures, shadows, highlight, smear, and smudge is a common critical image processing operation, particularly for document image analysis, optical character recognition, check image processing, image transmission, and videoconferencing. After a brief review of previous work with emphasis on five published extraction techniques, viz., a global thresholding technique, YDH technique, a nonlinear adaptive technique, an integrated function technique, and a local contrast technique, this paper presents two new extraction techniques: a logical level technique and a mask-based subtraction technique. With experiments on images of a typical check and a poor-quality text document, this paper systematically evaluates and analyses both new and published techniques with respect to six aspects, viz., speed, memory requirement, stroke width restriction, parameter number, parameter setting, and human subjective evaluation of result images. Experiments and evaluations have shown that one new technique is superior to the rest, suggesting its suitability for high-speed low-cost applications."
            },
            "slug": "Extraction-of-Binary-Character/Graphics-Images-from-Kamel-Zhao",
            "title": {
                "fragments": [],
                "text": "Extraction of Binary Character/Graphics Images from Grayscale Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents two new extraction techniques: a logical level technique and a mask-based subtraction technique, suggesting its suitability for high-speed low-cost applications."
            },
            "venue": {
                "fragments": [],
                "text": "CVGIP Graph. Model. Image Process."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145470231"
                        ],
                        "name": "Kwan Y. Wong",
                        "slug": "Kwan-Y.-Wong",
                        "structuredName": {
                            "firstName": "Kwan",
                            "lastName": "Wong",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kwan Y. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34896449"
                        ],
                        "name": "R. Casey",
                        "slug": "R.-Casey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Casey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Casey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1880661"
                        ],
                        "name": "F. Wahl",
                        "slug": "F.-Wahl",
                        "structuredName": {
                            "firstName": "Friedrich",
                            "lastName": "Wahl",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wahl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15921038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7abca302c74d2f5adfd323a28e26d40b019df2b5",
            "isKey": false,
            "numCitedBy": 594,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper outlines the requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing. Several critical functions have been investigated and the technical approaches are discussed. The first is the segmentation and classification of digitized printed documents into regions of text and images. A nonlinear, run-length smoothing algorithm has been used for this purpose. By using the regular features of text lines, a linear adaptive classification scheme discriminates text regions from others. The second technique studied is an adaptive approach to the recognition of the hundreds of font styles and sizes that can occur on printed documents. A preclassifier is constructed during the input process and used to speed up a well-known pattern-matching method for clustering characters from an arbitrary print source into a small sample of prototypes. Experimental results are included."
            },
            "slug": "Document-Analysis-System-Wong-Casey",
            "title": {
                "fragments": [],
                "text": "Document Analysis System"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "The requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing, are outlined and several critical functions have been investigated and the technical approaches are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IBM J. Res. Dev."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2461436"
                        ],
                        "name": "Jiangying Zhou",
                        "slug": "Jiangying-Zhou",
                        "structuredName": {
                            "firstName": "Jiangying",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiangying Zhou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 255
                            }
                        ],
                        "text": "Classic top-down techniques are based on the run length smoothing (RLS) algorithm [15, 17] to smooth the image rst, then, horizontal and vertical projection pro les [16] are commonly used to cut the page into smaller blocks such as columns and paragraphs [9, 13, 16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 23410608,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "999e76f9115af2741b0cd973d875163ae714d5da",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Page-segmentation-and-classification-Pavlidis-Zhou",
            "title": {
                "fragments": [],
                "text": "Page segmentation and classification"
            },
            "venue": {
                "fragments": [],
                "text": "CVGIP Graph. Model. Image Process."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398550688"
                        ],
                        "name": "L. O'Gorman",
                        "slug": "L.-O'Gorman",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "O'Gorman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. O'Gorman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22995244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d85097da36118fbccfeb7802abf89bf4b4c63a3e",
            "isKey": false,
            "numCitedBy": 728,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Page layout analysis is a document processing technique used to determine the format of a page. This paper describes the document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components. The method yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks. It is advantageous over many other methods in three main ways: independence from skew angle, independence from different text spacings, and the ability to process local regions of different text orientations within the same image. Results of the method shown for several different page formats and for randomly oriented subpages on the same image illustrate the versatility of the method. We also discuss the differences, advantages, and disadvantages of the docstrum with respect to other lay-out methods. >"
            },
            "slug": "The-Document-Spectrum-for-Page-Layout-Analysis-O'Gorman",
            "title": {
                "fragments": [],
                "text": "The Document Spectrum for Page Layout Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components, yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398550688"
                        ],
                        "name": "L. O'Gorman",
                        "slug": "L.-O'Gorman",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "O'Gorman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. O'Gorman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44674932,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2a5b702aec0aa01946f02d190bf9418000559bd",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Thresholding is a common image processing operation applied to gray-scale images to obtain binary or multilevel images. Traditionally, one of two approaches is used: global or locally adaptive processing. However, each of these approaches has a disadvantage: the global approach neglects local information, and the locally adaptive approach neglects global information. A thresholding method is described here that is global in approach, but uses a measure of local information, namely connectivity. Thresholds are found at the intensity levels that best preserve the connectivity of regions within the image. Thus, this method has advantages of both global and locally adaptive approaches. This method is applied here to document images. Experimental comparisons against other thresholding methods show that the connectivity-preserving method yields much improved results. On binary images, this method has been shown to improve subsequent OCR recognition rates from about 95% to 97,5%. More importantly, the new method has been shown to reduce the number of binarization failures (where text is so poorly binarized as to be totally unrecognizable by a commercial OCR system) from 33% to 6% on difficult images. For multilevel document images, as well, the results show similar improvement."
            },
            "slug": "Binarization-and-Multithresholding-of-Document-O'Gorman",
            "title": {
                "fragments": [],
                "text": "Binarization and Multithresholding of Document Images Using Connectivity"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This method has been shown to reduce the number of binarization failures from 33% to 6% on difficult images and to improve subsequent OCR recognition rates from about 95% to 97,5% on binary images."
            },
            "venue": {
                "fragments": [],
                "text": "CVGIP Graph. Model. Image Process."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102213388"
                        ],
                        "name": "K. Thompson",
                        "slug": "K.-Thompson",
                        "structuredName": {
                            "firstName": "Kendall",
                            "lastName": "Thompson",
                            "middleNames": [
                                "Milar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Thompson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 264
                            }
                        ],
                        "text": "However, most such schemes require clean binary input [3, 15, 16, 17]; some assume speci c document layouts such as newspapers [6] and technical journals [9]; others utilize domain-speci c knowledge such as mail address blocks [12] or con gurations of chess games [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "Other systems utilize domain-speci c knowledge such as mail address blocks [12] or con gurations of chess games [1]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 26523155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5298e5b0a3c18f4ef4b3f09eb8bdc2f7e5f3e22f",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "By applying semantic analysis to images of extended passages of text, several volumes of a chess encyclopedia have been read with high accuracy. Although carefully proofread, the books were poorly printed and posed a severe challenge to conventional page-layout analysis and character-recognition methods. An experimental page-reader system performed strictly top-down layout analysis for identification of columns, lines, words, and characters. This proceeded rapidly and reliably thanks to a recently developed skew-estimation technique. Resegmentation of broken, touching, and dirty characters was handled in an efficient and integrated manner by a heuristic search operating on isolated words. By analyzing the syntax of game descriptions and applying the rules of chess, the error rate was reduced by a factor of 30 from what was achievable through shape analysis alone. Several computer vision systems integration issues suggested by this experience are discussed. >"
            },
            "slug": "Reading-Chess-Baird-Thompson",
            "title": {
                "fragments": [],
                "text": "Reading Chess"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "By applying semantic analysis to images of extended passages of text, several volumes of a chess encyclopedia have been read with high accuracy and the error rate was reduced by a factor of 30 from what was achievable through shape analysis alone."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3141168"
                        ],
                        "name": "P. W. Palumbo",
                        "slug": "P.-W.-Palumbo",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Palumbo",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. W. Palumbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064971340"
                        ],
                        "name": "Jung Soh",
                        "slug": "Jung-Soh",
                        "structuredName": {
                            "firstName": "Jung",
                            "lastName": "Soh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jung Soh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145912825"
                        ],
                        "name": "R. Sridhar",
                        "slug": "R.-Sridhar",
                        "structuredName": {
                            "firstName": "Ramalingam",
                            "lastName": "Sridhar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sridhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3145150"
                        ],
                        "name": "V. Demjanenko",
                        "slug": "V.-Demjanenko",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Demjanenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Demjanenko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Using reasonable heuristics on text strings such as height similarity, spacing and alignment, the extracted strokes are then processed to form rectangular boxes surrounding the corresponding ttzt strings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16249736,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "3a9e7bd7f8911d5b2d7b4a5a755dfd4f6770589b",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The CEDAR real-time address block location system, which determines candidates for the location of the destination address from a scanned mail piece image, is described. For each candidate destination address block (DAB), the address block location (ABL) system determines the line segmentation, global orientation, block skew, an indication of whether the address appears to be handwritten or machine printed, and a value indicating the degree of confidence that the block actually contains the destination address. With 20-MHz Sparc processors, the average time per mail piece for the combined hardware and software system components is 0.210 seconds. The system located 89.0% of the addresses as the top choice. Recent developments in the system include the use of a top-down segmentation tool, address syntax analysis using only connected component data, and improvements to the segmentation refinement routines. This has increased top choice performance to 91.4%.<<ETX>>"
            },
            "slug": "Postal-address-block-location-in-real-time-Palumbo-Srihari",
            "title": {
                "fragments": [],
                "text": "Postal address block location in real time"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "Recent developments in the CEDAR real-time address block location system include the use of a top-down segmentation tool, address syntax analysis using only connected component data, and improvements to the segmentation refinement routines."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258400"
                        ],
                        "name": "\u00d8. Trier",
                        "slug": "\u00d8.-Trier",
                        "structuredName": {
                            "firstName": "\u00d8ivind",
                            "lastName": "Trier",
                            "middleNames": [
                                "Due"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00d8. Trier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48717516"
                        ],
                        "name": "T. Taxt",
                        "slug": "T.-Taxt",
                        "structuredName": {
                            "firstName": "Torfinn",
                            "lastName": "Taxt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Taxt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17374833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66126ec1fe61b833ae695db9c5bac54641fab482",
            "isKey": false,
            "numCitedBy": 451,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an evaluation of eleven locally adaptive binarization methods for gray scale images with low contrast, variable background intensity and noise. Niblack's method (1986) with the addition of the postprocessing step of Yanowitz and Bruckstein's method (1989) added performed the best and was also one of the fastest binarization methods. >"
            },
            "slug": "Evaluation-of-Binarization-Methods-for-Document-Trier-Taxt",
            "title": {
                "fragments": [],
                "text": "Evaluation of Binarization Methods for Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This paper presents an evaluation of eleven locally adaptive binarization methods for gray scale images with low contrast, variable background intensity and noise and Niblack's method with the addition of the postprocessing step of Yanowitz and Bruckstein's method (1989) performed the best and was also one of the fastest binarized methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3151920"
                        ],
                        "name": "C. Glasbey",
                        "slug": "C.-Glasbey",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Glasbey",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Glasbey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10342664,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f013f6dbf26efd35392fb4272f88ac17a53ee92",
            "isKey": false,
            "numCitedBy": 594,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Eleven histogram-based global thresholding algorithms are presented in a common notational framework. Relationships among them are identified from 654 mixtures of two Gaussian distributions, plus effects of mixed pixels. The iterated version of Kittler and Illingworth\u2032s minimum error algorithm ( Pattern Recognition , 19, 1986, 41-47) is found to be best."
            },
            "slug": "An-Analysis-of-Histogram-Based-Thresholding-Glasbey",
            "title": {
                "fragments": [],
                "text": "An Analysis of Histogram-Based Thresholding Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "Eleven histogram-based global thresholding algorithms are presented in a common notational framework and the iterated version of Kittler and Illingworth\u2032s minimum error algorithm is found to be best."
            },
            "venue": {
                "fragments": [],
                "text": "CVGIP Graph. Model. Image Process."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153312185"
                        ],
                        "name": "S. Mori",
                        "slug": "S.-Mori",
                        "structuredName": {
                            "firstName": "Shunji",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143686714"
                        ],
                        "name": "Kazuhiko Yamamoto",
                        "slug": "Kazuhiko-Yamamoto",
                        "structuredName": {
                            "firstName": "Kazuhiko",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuhiko Yamamoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58021636,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0627cb9872115ea4c4d3484538a2f440923d8f13",
            "isKey": false,
            "numCitedBy": 940,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "Research and development of OCR systems are considered from a historical point of view. The historical development of commercial systems is included. Both template matching and structure analysis approaches to R&D are considered. It is noted that the two approaches are coming closer and tending to merge. Commercial products are divided into three generations, for each of which some representative OCR systems are chosen and described in some detail. Some comments are made on recent techniques applied to OCR, such as expert systems and neural networks, and some open problems are indicated. The authors' views and hopes regarding future trends are presented. >"
            },
            "slug": "Historical-review-of-OCR-research-and-development-Mori-Suen",
            "title": {
                "fragments": [],
                "text": "Historical review of OCR research and development"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Both template matching and structure analysis approaches to R&D are considered and it is noted that the two approaches are coming closer and tending to merge."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065554001"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5601682,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "29cb9c230d999a2175c31969f0d90fcae3fb4efe",
            "isKey": false,
            "numCitedBy": 1083,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a model of human preattentive texture perception. This model consists of three stages: (1) convolution of the image with a bank of even-symmetric linear filters followed by half-wave rectification to give a set of responses modeling outputs of V1 simple cells, (2) inhibition, localized in space, within and among the neural-response profiles that results in the suppression of weak responses when there are strong responses at the same or nearby locations, and (3) texture-boundary detection by using wide odd-symmetric mechanisms. Our model can predict the salience of texture boundaries in any arbitrary gray-scale image. A computer implementation of this model has been tested on many of the classic stimuli from psychophysical literature. Quantitative predictions of the degree of discriminability of different texture pairs match well with experimental measurements of discriminability in human observers."
            },
            "slug": "Preattentive-texture-discrimination-with-early-Malik-Perona",
            "title": {
                "fragments": [],
                "text": "Preattentive texture discrimination with early vision mechanisms."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A model of human preattentive texture perception that can predict the salience of texture boundaries in any arbitrary gray-scale image and Quantitative predictions of the degree of discriminability of different texture pairs match well with experimental measurements of discriminateability in human observers."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 236467906,
            "fieldsOfStudy": [],
            "id": "0945840c6ca76f2a011b460581ce39072585b4af",
            "isKey": false,
            "numCitedBy": 1198,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Proceedings-of-the-IEEE",
            "title": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document Analysis System. IBM Journal Res. Dev"
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis System. IBM Journal Res. Dev"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classiication of Newspaper Image Blocks Using Texture Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision, Graphics and Image Processing"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 82
                            }
                        ],
                        "text": "Classic top-down techniques are based on the run length smoothing (RLS) algorithm [15, 17] to smooth the image rst, then, horizontal and vertical projection pro les [16] are commonly used to cut the page into smaller blocks such as columns and paragraphs [9, 13, 16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 54
                            }
                        ],
                        "text": "However, most such schemes require clean binary input [3, 15, 16, 17]; some assume speci c document layouts such as newspapers [6] and technical journals [9]; others utilize domain-speci c knowledge such as mail address blocks [12] or con gurations of chess games [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Block Seg-  mentation and Text Extraction in Mixed Text/Image Docu-  ments"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Graphics and Image Processing, 20:375{  390"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An Analysis of HistogramBased Thresholding Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Tbu & a & ons on Pattern Analysis \u2019 Ani Machine Intelligence"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Page Segmentation and Classification. CVGZP: Gmphical Models and Image Processing"
            },
            "venue": {
                "fragments": [],
                "text": "Page Segmentation and Classification. CVGZP: Gmphical Models and Image Processing"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classification of No \\ vspap ~ r Image Blocks Using Texture Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision , Gmphics ond Image Processing"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Example 1. (a) Original image (adsll); (b) Extracted text; (c) The OCR result using Caere's WordScan Plus 4"
            },
            "venue": {
                "fragments": [],
                "text": "Example 1. (a) Original image (adsll); (b) Extracted text; (c) The OCR result using Caere's WordScan Plus 4"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 32
                            }
                        ],
                        "text": "However, current OCR technology [2, 8] is largely restricted to nding text printed against clean backgrounds, and cannot handle text printed against shaded or textured backgrounds, and/or embedded in images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Omnidocument Technoligies"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of  The IEEE,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pattern Anal. Mach. Intell"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Anal. Mach. Intell"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 82
                            }
                        ],
                        "text": "Classic top-down techniques are based on the run length smoothing (RLS) algorithm [15, 17] to smooth the image rst, then, horizontal and vertical projection pro les [16] are commonly used to cut the page into smaller blocks such as columns and paragraphs [9, 13, 16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 54
                            }
                        ],
                        "text": "However, most such schemes require clean binary input [3, 15, 16, 17]; some assume speci c document layouts such as newspapers [6] and technical journals [9]; others utilize domain-speci c knowledge such as mail address blocks [12] or con gurations of chess games [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document Anal-  ysis System"
            },
            "venue": {
                "fragments": [],
                "text": "IBM Journal Res. Dev., 26(6):647{656"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 165
                            }
                        ],
                        "text": "Classic top-down techniques are based on the run length smoothing (RLS) algorithm [15, 17] to smooth the image rst, then, horizontal and vertical projection pro les [16] are commonly used to cut the page into smaller blocks such as columns and paragraphs [9, 13, 16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 54
                            }
                        ],
                        "text": "However, most such schemes require clean binary input [3, 15, 16, 17]; some assume speci c document layouts such as newspapers [6] and technical journals [9]; others utilize domain-speci c knowledge such as mail address blocks [12] or con gurations of chess games [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classi cation of Newspaper  Image Blocks Using Texture Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision,  Graphics and Image Processing, 47:327{352"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": "First, a texture segmentation scheme is used to focus attention on regions where text may occur."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classification of No\\vspap~r Image Blocks Using Texture Analysis Computer Vision, Gmphics ond Image Processing"
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis System. IBM Journal Res. Dev"
            },
            "year": 1982
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 6,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 28,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Finding-text-in-images-Wu-Manmatha/3420ab835c1af02071364b1f4e0f69abf733d88c?sort=total-citations"
}