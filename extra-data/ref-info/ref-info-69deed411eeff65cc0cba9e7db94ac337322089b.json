{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6382669,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be305b0684f1a6ec8407c107187d28502b48f993",
            "isKey": false,
            "numCitedBy": 464,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Edge detection is one of the most studied problems in computer vision, yet it remains a very challenging task. It is difficult since often the decision for an edge cannot be made purely based on low level cues such as gradient, instead we need to engage all levels of information, low, middle, and high, in order to decide where to put edges. In this paper we propose a novel supervised learning algorithm for edge and object boundary detection which we refer to as Boosted Edge Learning or BEL for short. A decision of an edge point is made independently at each location in the image; a very large aperture is used providing significant context for each decision. In the learning stage, the algorithm selects and combines a large number of features across different scales in order to learn a discriminative model using an extended version of the Probabilistic Boosting Tree classification algorithm. The learning based framework is highly adaptive and there are no parameters to tune. We show applications for edge detection in a number of specific image domains as well as on natural images. We test on various datasets including the Berkeley dataset and the results obtained are very good."
            },
            "slug": "Supervised-Learning-of-Edges-and-Object-Boundaries-Doll\u00e1r-Tu",
            "title": {
                "fragments": [],
                "text": "Supervised Learning of Edges and Object Boundaries"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper proposes a novel supervised learning algorithm for edge and object boundary detection which it refers to as Boosted Edge Learning or BEL for short and shows applications for edge detection in a number of specific image domains as well as on natural images."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2919518"
                        ],
                        "name": "S. Munder",
                        "slug": "S.-Munder",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Munder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Munder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "\u2026methods can be divided into three types [2]: (1) wrapper methods that judge the quality of a subset of features by the performance of a trained classifier, (2) filter methods which assign a score to each feature, and (3) embedded methods where feature selection is a natural part of the learning\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10769792,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ebbf3ec461f9b347937e4a5b993f12940558934",
            "isKey": false,
            "numCitedBy": 636,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting people in images is key for several important application domains in computer vision. This paper presents an in-depth experimental study on pedestrian classification; multiple feature-classifier combinations are examined with respect to their ROC performance and efficiency. We investigate global versus local and adaptive versus nonadaptive features, as exemplified by PCA coefficients, Haar wavelets, and local receptive fields (LRFs). In terms of classifiers, we consider the popular support vector machines (SVMs), feedforward neural networks, and k-nearest neighbor classifier. Experiments are performed on a large data set consisting of 4,000 pedestrian and more than 25,000 nonpedestrian (labeled) images captured in outdoor urban environments. Statistically meaningful results are obtained by analyzing performance variances caused by varying training and test sets. Furthermore, we investigate how classification performance and training sample size are correlated. Sample size is adjusted by increasing the number of manually labeled training data or by employing automatic bootstrapping or cascade techniques. Our experiments show that the novel combination of SVMs with LRF features performs best. A boosted cascade of Haar wavelets can, however, reach quite competitive results, at a fraction of computational cost. The data set used in this paper is made public, establishing a benchmark for this important problem"
            },
            "slug": "An-Experimental-Study-on-Pedestrian-Classification-Munder-Gavrila",
            "title": {
                "fragments": [],
                "text": "An Experimental Study on Pedestrian Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "An in-depth experimental study on pedestrian classification; multiple feature-classifier combinations are examined with respect to their ROC performance and efficiency and show that the novel combination of SVMs with LRF features performs best."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34745271"
                        ],
                        "name": "Y. Abramson",
                        "slug": "Y.-Abramson",
                        "structuredName": {
                            "firstName": "Yotam",
                            "lastName": "Abramson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Abramson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748488"
                        ],
                        "name": "F. Moutarde",
                        "slug": "F.-Moutarde",
                        "structuredName": {
                            "firstName": "Fabien",
                            "lastName": "Moutarde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Moutarde"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2593406"
                        ],
                        "name": "B. Stanciulescu",
                        "slug": "B.-Stanciulescu",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Stanciulescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Stanciulescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2953005"
                        ],
                        "name": "B. Steux",
                        "slug": "B.-Steux",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Steux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Steux"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16939835,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c02d470580379faebbcb4c6a2d46b329f9fd313",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an efficient method for automatic training of performant visual object detectors, and its successful application to training of a back-view car detec- tor. Our method for training detectors is adaBoost applied to a very general family of visual features (called \u201ccontrol-point\u201d features), with a specific feature-selection weak-learner: evo-HC, which is a hybrid of Hill-Climbing and evolutionary-search. Very good results are obtained for the car-detection application: 95% positive car detection rate with less than one false positive per image frame, computed on an independant validation video. It is also shown that our original hybrid evo-HC weak-learner allows to obtain detection performances that are unreachable in rea- sonable training time with a crude random search. Finally our method seems to be potentially efficient for training detectors of very different kinds of objects, as it was already previously shown to provide state-of-art performance for pedestrian-detection tasks."
            },
            "slug": "COMBINING-ADABOOST-WITH-A-HILL-CLIMBING-FEATURE-FOR-Abramson-Moutarde",
            "title": {
                "fragments": [],
                "text": "COMBINING ADABOOST WITH A HILL-CLIMBING EVOLUTIONARY FEATURE SEARCH FOR EFFICIENT TRAINING OF PERFORMANT VISUAL OBJECT DETECTORS"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "An efficient method for automatic training of performant visual object detectors, with a specific feature-selection weak-learner: evo-HC, which is a hybrid of Hill-Climbing and evolutionary-search, and its successful application to training of a back-view cardetection task."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144889914"
                        ],
                        "name": "M. Jiang",
                        "slug": "M.-Jiang",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49725994"
                        ],
                        "name": "T. Choy",
                        "slug": "T.-Choy",
                        "structuredName": {
                            "firstName": "Tat-Sang",
                            "lastName": "Choy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Choy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145640180"
                        ],
                        "name": "S. Mehta",
                        "slug": "S.-Mehta",
                        "structuredName": {
                            "firstName": "Sameep",
                            "lastName": "Mehta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mehta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1919727"
                        ],
                        "name": "M. Coatney",
                        "slug": "M.-Coatney",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "Coatney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Coatney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40080782"
                        ],
                        "name": "S. Barr",
                        "slug": "S.-Barr",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Barr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Barr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "19046845"
                        ],
                        "name": "K. Hazzard",
                        "slug": "K.-Hazzard",
                        "structuredName": {
                            "firstName": "Kaden",
                            "lastName": "Hazzard",
                            "middleNames": [
                                "R.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hazzard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33309233"
                        ],
                        "name": "D. Richie",
                        "slug": "D.-Richie",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Richie",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Richie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022640"
                        ],
                        "name": "S. Parthasarathy",
                        "slug": "S.-Parthasarathy",
                        "structuredName": {
                            "firstName": "Srinivasan",
                            "lastName": "Parthasarathy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Parthasarathy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707285"
                        ],
                        "name": "R. Machiraju",
                        "slug": "R.-Machiraju",
                        "structuredName": {
                            "firstName": "Raghu",
                            "lastName": "Machiraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Machiraju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145748772"
                        ],
                        "name": "D. Thompson",
                        "slug": "D.-Thompson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Thompson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060707441"
                        ],
                        "name": "J. Wilkins",
                        "slug": "J.-Wilkins",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wilkins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wilkins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862251"
                        ],
                        "name": "B. Gatlin",
                        "slug": "B.-Gatlin",
                        "structuredName": {
                            "firstName": "Boyd",
                            "lastName": "Gatlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatlin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3242735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd3f81ebd13ae2078f4300a5e040672bb3a66679",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Numerical simulation is replacing experimentation as a means to gain insight into complex physical phenomena. Analyzing the data produced by such simulations is extremely challenging, given the enormous sizes of the datasets involved. In order to make efficient progress, analyzing such data must advance from current techniques that only visualize static images of the data, to novel techniques that can mine, track, and visualize the important features in the data. In this paper, we present our research on a unified framework that addresses this critical challenge in two science domains: computational fluid dynamics and molecular dynamics. We offer a systematic approach to detect the significant features in both domains, characterize and track them, and formulate hypotheses with regard to their complex evolution. Our framework includes two paradigms for feature mining, and the choice of one over the other, for a given application, can be determined based on local or global influence of relevant features in the data."
            },
            "slug": "Feature-Mining-Paradigms-for-Scientific-Data-Jiang-Choy",
            "title": {
                "fragments": [],
                "text": "Feature Mining Paradigms for Scientific Data"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper offers a systematic approach to detect the significant features in both domains, characterize and track them, and formulate hypotheses with regard to their complex evolution, and includes two paradigms for feature mining."
            },
            "venue": {
                "fragments": [],
                "text": "SDM"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764547"
                        ],
                        "name": "M. Sahami",
                        "slug": "M.-Sahami",
                        "structuredName": {
                            "firstName": "Mehran",
                            "lastName": "Sahami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sahami"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "Note that in this terminology the popular AdaBoost algorithm [7] can be used as an embedded method for feature selection [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1455429,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ed4e1dbe10c0ac9fa00b30d1882cae1249a5a6a",
            "isKey": false,
            "numCitedBy": 1746,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we examine a method for feature subset selection based on Information Theory. Initially, a framework for defining the theoretically optimal, but computationally intractable, method for feature subset selection is presented. We show that our goal should be to eliminate a feature if it gives us little or no additional information beyond that subsumed by the remaining features. In particular, this will be the case for both irrelevant and redundant features. We then give an efficient algorithm for feature selection which computes an approximation to the optimal feature selection criterion. The conditions under which the approximate algorithm is successful are examined. Empirical results are given on a number of data sets, showing that the algorithm effectively handles datasets with a very large number of features."
            },
            "slug": "Toward-Optimal-Feature-Selection-Koller-Sahami",
            "title": {
                "fragments": [],
                "text": "Toward Optimal Feature Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An efficient algorithm for feature selection which computes an approximation to the optimal feature selection criterion is given, showing that the algorithm effectively handles datasets with a very large number of features."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2804442"
                        ],
                        "name": "Andr\u00e9 Treptow",
                        "slug": "Andr\u00e9-Treptow",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Treptow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9 Treptow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144625394"
                        ],
                        "name": "A. Zell",
                        "slug": "A.-Zell",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Zell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3015107,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "061acafe052199439a483ebf61a1a30a41217be6",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, P. Viola and M.J. Jones (2001) presented a method for real-time object detection in images using a boosted cascade of simple features. In This work we show how an evolutionary algorithm can be used within the Adaboost framework to find new features providing better classifiers. The evolutionary algorithm replaces the exhaustive search over all features so that even very large feature sets can be searched in reasonable time. Experiments on two different sets of images prove that by the use of evolutionary search we are able to find object detectors that are faster and have higher detection rates."
            },
            "slug": "Combining-Adaboost-learning-and-evolutionary-search-Treptow-Zell",
            "title": {
                "fragments": [],
                "text": "Combining Adaboost learning and evolutionary search to select features for real-time object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work shows how an evolutionary algorithm can be used within the Adaboost framework to find new features providing better classifiers to find object detectors that are faster and have higher detection rates."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No.04TH8753)"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 144
                            }
                        ],
                        "text": "\u2026methods can be divided into three types [2]: (1) wrapper methods that judge the quality of a subset of features by the performance of a trained classifier, (2) filter methods which assign a score to each feature, and (3) embedded methods where feature selection is a natural part of the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "Such \u2018expert design\u2019 can require significant domain knowledge and insight to the problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 29
                            }
                        ],
                        "text": "Another trend is to learn features automatically from training samples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": false,
            "numCitedBy": 29258,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076499"
                        ],
                        "name": "K. Krawiec",
                        "slug": "K.-Krawiec",
                        "structuredName": {
                            "firstName": "Krzysztof",
                            "lastName": "Krawiec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Krawiec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144452270"
                        ],
                        "name": "B. Bhanu",
                        "slug": "B.-Bhanu",
                        "structuredName": {
                            "firstName": "Bir",
                            "lastName": "Bhanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Bhanu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "We use the term feature mining to refer to the task of organizing and exploring large, possibly infinite, spaces of heterogeneous features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7638667,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9a842c6af0f9cb7fb5ff0e25d2640119088842a",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a novel method for learning complex concepts/hypotheses directly from raw training data. The task addressed here concerns data-driven synthesis of recognition procedures for real-world object recognition task. The method uses linear genetic programming to encode potential solutions expressed in terms of elementary operations, and handles the complexity of the learning task by applying cooperative coevolution to decompose the problem automatically. The training consists in coevolving feature extraction procedures, each being a sequence of elementary image processing and feature extraction operations. Extensive experimental results show that the approach attains competitive performance for 3-D object recognition in real synthetic aperture radar (SAR) imagery."
            },
            "slug": "Visual-Learning-by-Evolutionary-Feature-Synthesis-Krawiec-Bhanu",
            "title": {
                "fragments": [],
                "text": "Visual Learning by Evolutionary Feature Synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A novel method for learning complex concepts/hypotheses directly from raw training data that handles the complexity of the learning task by applying cooperative coevolution to decompose the problem automatically."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766703"
                        ],
                        "name": "A. Elisseeff",
                        "slug": "A.-Elisseeff",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Elisseeff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Elisseeff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 293
                            }
                        ],
                        "text": "\u2026can be divided into three types [2]: (1) wrapper methods that judge the quality of a subset of features by the performance of a trained classifier, (2) filter methods which assign a score to each feature, and (3) embedded methods where feature selection is a natural part of the learning method."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 379259,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8384f7ef288d2d5cb267128471c5427fc98b54b",
            "isKey": false,
            "numCitedBy": 14051,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods."
            },
            "slug": "An-Introduction-to-Variable-and-Feature-Selection-Guyon-Elisseeff",
            "title": {
                "fragments": [],
                "text": "An Introduction to Variable and Feature Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The contributions of this special issue cover a wide range of aspects of variable selection: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143980462"
                        ],
                        "name": "R. Collins",
                        "slug": "R.-Collins",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Collins",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152672156"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "Such \u2018expert design\u2019 can require significant domain knowledge and insight to the problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195884819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f51cb4be6e22f7e2b7126c9f2e250071a2351e08",
            "isKey": false,
            "numCitedBy": 366,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for evaluating multiple feature spaces while tracking, and for adjusting the set of features used to improve tracking performance. Our hypothesis is that the features that best discriminate between object and background are also best for tracking the object. We develop an online feature selection mechanism based on the two-class variance ratio measure, applied to log likelihood distributions computed with respect to a given feature from samples of object and background pixels. This feature selection mechanism is embedded in a tracking system that adaptively selects the top-ranked discriminative features for tracking. Examples are presented to illustrate how the method adapts to changing appearances of both tracked object and scene background."
            },
            "slug": "On-line-selection-of-discriminative-tracking-Collins-Liu",
            "title": {
                "fragments": [],
                "text": "On-line selection of discriminative tracking features"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An online feature selection mechanism based on the two-class variance ratio measure, applied to log likelihood distributions computed with respect to a given feature from samples of object and background pixels, is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "These methods, while promising, often tend to have restricted forms for learned features (typically linear) and\n1-4244-1180-7/07/$25.00 \u00a92007 IEEE\nhave not proven to be universally applicable."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": true,
            "numCitedBy": 35236,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076499"
                        ],
                        "name": "K. Krawiec",
                        "slug": "K.-Krawiec",
                        "structuredName": {
                            "firstName": "Krzysztof",
                            "lastName": "Krawiec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Krawiec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144452270"
                        ],
                        "name": "B. Bhanu",
                        "slug": "B.-Bhanu",
                        "structuredName": {
                            "firstName": "Bir",
                            "lastName": "Bhanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Bhanu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6041698,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28ec8cafe4d714b415aba263acbd072fda2ff4cd",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a novel genetically inspired visual learning method is proposed. Given the training raster images, this general approach induces a sophisticated feature-based recognition system. It employs the paradigm of cooperative coevolution to handle the computational difficulty of this task. To represent the feature extraction agents, the linear genetic programming is used. The paper describes the learning algorithm and provides a firm rationale for its design. Different architectures of recognition systems are considered that employ the proposed feature synthesis method. An extensive experimental evaluation on the demanding real-world task of object recognition in synthetic aperture radar (SAR) imagery shows the ability of the proposed approach to attain high recognition performance in different operating conditions."
            },
            "slug": "Visual-learning-by-coevolutionary-feature-synthesis-Krawiec-Bhanu",
            "title": {
                "fragments": [],
                "text": "Visual learning by coevolutionary feature synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An extensive experimental evaluation on the demanding real-world task of object recognition in synthetic aperture radar (SAR) imagery shows the ability of the proposed approach to attain high recognition performance in different operating conditions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144238410"
                        ],
                        "name": "Qiang Zhu",
                        "slug": "Qiang-Zhu",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39369497"
                        ],
                        "name": "Mei-Chen Yeh",
                        "slug": "Mei-Chen-Yeh",
                        "structuredName": {
                            "firstName": "Mei-Chen",
                            "lastName": "Yeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mei-Chen Yeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766349"
                        ],
                        "name": "K. Cheng",
                        "slug": "K.-Cheng",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815078"
                        ],
                        "name": "S. Avidan",
                        "slug": "S.-Avidan",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Avidan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Avidan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7800101,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05fe01b57b3ba58dc5029c068a48567b55018ea5",
            "isKey": false,
            "numCitedBy": 1568,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We integrate the cascade-of-rejectors approach with the Histograms of Oriented Gradients (HoG) features to achieve a fast and accurate human detection system. The features used in our system are HoGs of variable-size blocks that capture salient features of humans automatically. Using AdaBoost for feature selection, we identify the appropriate set of blocks, from a large set of possible blocks. In our system, we use the integral image representation and a rejection cascade which significantly speed up the computation. For a 320 \u00d7 280 image, the system can process 5 to 30 frames per second depending on the density in which we scan the image, while maintaining an accuracy level similar to existing methods."
            },
            "slug": "Fast-Human-Detection-Using-a-Cascade-of-Histograms-Zhu-Yeh",
            "title": {
                "fragments": [],
                "text": "Fast Human Detection Using a Cascade of Histograms of Oriented Gradients"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This work integrates the cascade-of-rejectors approach with the Histograms of Oriented Gradients features to achieve a fast and accurate human detection system that can process 5 to 30 frames per second depending on the density in which the image is scanned, while maintaining an accuracy level similar to existing methods."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690967"
                        ],
                        "name": "A. Blum",
                        "slug": "A.-Blum",
                        "structuredName": {
                            "firstName": "Avrim",
                            "lastName": "Blum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713919"
                        ],
                        "name": "P. Langley",
                        "slug": "P.-Langley",
                        "structuredName": {
                            "firstName": "Pat",
                            "lastName": "Langley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Langley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 289
                            }
                        ],
                        "text": "\u2026can be divided into three types [2]: (1) wrapper methods that judge the quality of a subset of features by the performance of a trained classifier, (2) filter methods which assign a score to each feature, and (3) embedded methods where feature selection is a natural part of the learning method."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7055940,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f04029d1d83f41eaebf5a216ebecf2a61ff6dc0",
            "isKey": false,
            "numCitedBy": 3269,
            "numCiting": 197,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Selection-of-Relevant-Features-and-Examples-in-Blum-Langley",
            "title": {
                "fragments": [],
                "text": "Selection of Relevant Features and Examples in Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "Finally, [9] used the term feature mining in reference to search for evolving physical phenomenon in scientific data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In this section we elaborate on the concept of feature mining, in which our goal is to minimize the human effort needed to explore and organize the vast space of possible features for image classification."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15810545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "548ab5770b89650158f99caee1bed3a986b0dcdf",
            "isKey": false,
            "numCitedBy": 724,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract This paper extends the face detection framework proposedby Viola and Jones 2001 to handle pro\ufb01le views and rotatedfaces. As in the work of Rowley et al 1998. and Schneider-man et al. 2000, we build different detectors for differentviews of the face. A decision tree is then trained to deter-mine the viewpoint class (such as right pro\ufb01le or rotated60 degrees) for a given window of the image being exam-ined. This is similar to the approach of Rowley et al. 1998.The appropriate detector for that viewpoint can then be runinstead of running all detectors on all windows. This tech-niqueyields goodresults and maintainsthe speed advantageof the Viola-Jones detector. 1. Introduction There are a number of techniques that can successfullydetect frontal upright faces in a wide variety of images[11, 7, 10, 12, 3, 6]. While the de\ufb01nition of \u201cfrontal\u201d and\u201cupright\u201dmayvaryfromsystem to system, the reality is thatmany natural images contain rotated or pro\ufb01le faces thatare not reliably detected. There are a small number of sys-tems which explicitly address non-frontal, or non-uprightface detection [8, 10, 2]. This paper describes progress to-ward a system which can detect faces regardless of posereliably and in real-time.This paperextendsthe frameworkproposedby Viola andJones [12]. This approach is selected because of its compu-tational ef\ufb01ciency and simplicity.One observation which is shared among all previous re-lated work is that a multi-view detector must be carefullyconstructed by combining a collection of detectors eachtrained for a single viewpoint. It appears that a monolithicapproach, where a single classi\ufb01er is trained to detect allposes of a face, is unlearnable with existing classi\ufb01ers. Ourinformal experiments lend support to this conclusion, sincea classi\ufb01er trained on all poses appears to be hopelessly in-accurate.This paper addresses two types of pose variation: non-frontal faces, which are rotated out of the image plane, andnon-upright faces, which are rotated in the image plane.In both cases the multi-view detector presented in this pa-per is a combination of Viola-Jones detectors, each detectortrained on face data taken from a single viewpoint.Reliable non-upright face detection was \ufb01rst presentedin a paper by Rowley, Baluja and Kanade [8]. They traintwo neural network classi\ufb01ers. The \ufb01rst estimates the poseof a face in the detection window. The second is a conven-tional face detector. Faces are detected in three steps: foreach image window the pose of \u201cface\u201d is \ufb01rst estimated; thepose estimate is then used to de-rotate the image window;the window is then classi\ufb01ed by the second detector. Fornon-face windows, the poses estimate must be consideredrandom. Nevertheless, a rotated non-faceshouldbe rejectedby the conventional detector. One potential \ufb02aw of such asystem is that the \ufb01nal detection rate is roughly the productof the correct classi\ufb01cation rates of the two classi\ufb01ers (sincethe errors of the two classi\ufb01ers are somewhat independent).One could adopt the Rowley et al. three step approachwhile replacingthe classi\ufb01ers with those of Viola andJones.The \ufb01nal system would be more ef\ufb01cient, but not signi\ufb01-cantly. Classi\ufb01cation by the Viola-Jones system is so ef\ufb01-cient, that derotation would dominate the computational ex-pense. In principle derotation is not strictly necessary sinceit should be possible to construct a detector for rotated facesdirectly. Detection becomes a two stage process. First thepose of the window is estimated and then one ofrotationspeci\ufb01c detectors is called upon to classify the window.In this paper detection of non-upright faces is handledusing the two stage approach. In the \ufb01rst stage the pose ofeach window is estimated using a decision tree constructedusing features like those described by Viola and Jones. Inthe second stage one ofpose speci\ufb01c Viola-Jones dete-tectors are used to classify the window.Oncepose speci\ufb01c detectors are trained and available,an alternative detection process can be tested as well. In thiscase alldetectors are evaluated and the union of their de-"
            },
            "slug": "Fast-Multi-view-Face-Detection-Jones-Viola",
            "title": {
                "fragments": [],
                "text": "Fast Multi-view Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A multi-view detector presented in this pa-per is a combination of Viola-Jones detectors, each detectortrained on face data taken from a single viewpoint, which appears that a monolithic approach to face detection is unlearnable with existing classi\ufb01er trained on all poses."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Arguably, feature mining would be even more significant for techniques that for computational or theoretical reasons do not deal well with large feature sets, e.g. support vector machines [21] or neural networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "Finally, [9] used the term feature mining in reference to search for evolving physical phenomenon in scientific data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6644398,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccf5208521cb8c35f50ee8873df89294b8ed7292",
            "isKey": false,
            "numCitedBy": 13115,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line."
            },
            "slug": "A-decision-theoretic-generalization-of-on-line-and-Freund-Schapire",
            "title": {
                "fragments": [],
                "text": "A decision-theoretic generalization of on-line learning and an application to boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The model studied can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting, and it is shown that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems."
            },
            "venue": {
                "fragments": [],
                "text": "EuroCOLT"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "These methods, while promising, often tend to have restricted forms for learned features (typically linear) and\n1-4244-1180-7/07/$25.00 \u00a92007 IEEE\nhave not proven to be universally applicable."
                    },
                    "intents": []
                }
            ],
            "corpusId": 4358477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8012c4a1e2ca663f1a04e80cbb19631a00cbab27",
            "isKey": true,
            "numCitedBy": 5639,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "THE receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented1\u20134 and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms5,6. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding7\u201312. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties13\u201318, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal8,12 that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs."
            },
            "slug": "Emergence-of-simple-cell-receptive-field-properties-Olshausen-Field",
            "title": {
                "fragments": [],
                "text": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40403107"
                        ],
                        "name": "X. Zhou",
                        "slug": "X.-Zhou",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Zhou",
                            "middleNames": [
                                "Sean"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829720"
                        ],
                        "name": "L. Bogoni",
                        "slug": "L.-Bogoni",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Bogoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bogoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144719476"
                        ],
                        "name": "Adrian Barbu",
                        "slug": "Adrian-Barbu",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Barbu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adrian Barbu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1923723,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce42ccc5a25ac999a24e2e646c8f1c29e03d56b2",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic polyp detection is an increasingly important task in medical imaging with virtual colonoscopy [15] being widely used. In this paper, we present a 3D object detection algorithm and show its application on polyp detection from CT images. We make the following contributions: (1) The system adopts Probabilistic Boosting Tree (PBT) to probabilistically detect polyps. Integral volume and 3D Haar filters are introduced to achieve fast feature computation. (2) We give an explicit convergence rate analysis for the AdaBoost algorithm [2] and prove that the error at each step \\in t+1. is tightly bounded by the previous error \\in t. (3) For a 3D polyp template, a generative model is defined. Given the bound and convergence analysis, we analyze the role of \"sample alignment\" in the template design and devise a robust and efficient algorithm for polyp detection. The overall system has been tested on 150 volumes and the results obtained are very encouraging."
            },
            "slug": "Probabilistic-3D-Polyp-Detection-in-CT-Images:-The-Tu-Zhou",
            "title": {
                "fragments": [],
                "text": "Probabilistic 3D Polyp Detection in CT Images: The Role of Sample Alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a 3D object detection algorithm that adopts Probabilistic Boosting Tree (PBT) to probabilistically detect polyps and analyzes the role of \"sample alignment\" in the template design and devise a robust and efficient algorithm for polyp detection."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "One still needs to spend a considerable amount of time adapting and combining these features to specific problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "Another trend is to learn features automatically from training samples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8571961,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "9c7a96155f10f152cae0866102c061cdf6da02e8",
            "isKey": false,
            "numCitedBy": 1683,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images."
            },
            "slug": "An-Affine-Invariant-Interest-Point-Detector-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "An Affine Invariant Interest Point Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel approach for detecting affine invariant interest points that can deal with significant affine transformations including large scale changes and shows an excellent performance in the presence of large perspective transformations including significant scale changes."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022386739"
                        ],
                        "name": "Peter Barlett",
                        "slug": "Peter-Barlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Barlett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Barlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740222"
                        ],
                        "name": "Wee Sun Lee",
                        "slug": "Wee-Sun-Lee",
                        "structuredName": {
                            "firstName": "Wee",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wee Sun Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "The VC dimension [21] of a classifier H , V C(H), can be used to derive a loose upper bound on the expected test error of H ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 573509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d19272112b50547614479a0c409fca66e3b05f7",
            "isKey": false,
            "numCitedBy": 2844,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the surprising recurring phenomena observed in experiments with boosting is that the test error of the generated classifier usually does not increase as its size becomes very large, and often is observed to decrease even after the training error reaches zero. In this paper, we show that this phenomenon is related to the distribution of margins of the training examples with respect to the generated voting classification rule, where the margin of an example is simply the difference between the number of correct votes and the maximum number of votes received by any incorrect label. We show that techniques used in the analysis of Vapnik's support vector classifiers and of neural networks with small weights can be applied to voting methods to relate the margin distribution to the test error. We also show theoretically and experimentally that boosting is especially effective at increasing the margins of the training examples. Finally, we compare our explanation to those based on the bias-variance"
            },
            "slug": "Boosting-the-margin:-A-new-explanation-for-the-of-Schapire-Freund",
            "title": {
                "fragments": [],
                "text": "Boosting the margin: A new explanation for the effectiveness of voting methods"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that techniques used in the analysis of Vapnik's support vector classifiers and of neural networks with small weights can be applied to voting methods to relate the margin distribution to the test error."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743073"
                        ],
                        "name": "L. Kuncheva",
                        "slug": "L.-Kuncheva",
                        "structuredName": {
                            "firstName": "Ludmila",
                            "lastName": "Kuncheva",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kuncheva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117879414"
                        ],
                        "name": "C. J. Whitaker",
                        "slug": "C.-J.-Whitaker",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Whitaker",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Whitaker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14317314,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2642e2ddaf39596405369f7c61e74aa95e836694",
            "isKey": false,
            "numCitedBy": 2211,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Diversity among the members of a team of classifiers is deemed to be a key issue in classifier combination. However, measuring diversity is not straightforward because there is no generally accepted formal definition. We have found and studied ten statistics which can measure diversity among binary classifier outputs (correct or incorrect vote for the class label): four averaged pairwise measures (the Q statistic, the correlation, the disagreement and the double fault) and six non-pairwise measures (the entropy of the votes, the difficulty index, the Kohavi-Wolpert variance, the interrater agreement, the generalized diversity, and the coincident failure diversity). Four experiments have been designed to examine the relationship between the accuracy of the team and the measures of diversity, and among the measures themselves. Although there are proven connections between diversity and accuracy in some special cases, our results raise some doubts about the usefulness of diversity measures in building classifier ensembles in real-life pattern recognition problems."
            },
            "slug": "Measures-of-Diversity-in-Classifier-Ensembles-and-Kuncheva-Whitaker",
            "title": {
                "fragments": [],
                "text": "Measures of Diversity in Classifier Ensembles and Their Relationship with the Ensemble Accuracy"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Although there are proven connections between diversity and accuracy in some special cases, the results raise some doubts about the usefulness of diversity measures in building classifier ensembles in real-life pattern recognition problems."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "One still needs to spend a considerable amount of time adapting and combining these features to specific problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "Another trend is to learn features automatically from training samples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": false,
            "numCitedBy": 25497,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Arguably, feature mining would be even more significant for techniques that for computational or theoretical reasons do not deal well with large feature sets, e.g. support vector machines [21] or neural networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 229
                            }
                        ],
                        "text": "The training error train =\u2211\ni D1(i)1(yi 6= H(xi)) is bounded by\nt = X\ni\nDt(i)1(yi 6= ht(xi)) (1)\ntrain \u2264 TY\nt=1\nZt =\nTY\nt=1\n2 p t(1\u2212 t), (2)\nwhere T is the number of weak classifiers, t is the error of each weak classifier on the distribution Dt it was trained on, and 1 is an indicator function."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28637672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "385197d4c02593e2823c71e4f90a0993b703620e",
            "isKey": false,
            "numCitedBy": 26320,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "slug": "Statistical-learning-theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "Statistical learning theory"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For the remainder of this paper we will use Discrete Ada- Boost [ 7 ] as our classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We begin with a brief review of AdaBoost [ 7 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Note that in this terminology the popular AdaBoost algorithm [ 7 ] can be used as an embedded method for feature selection [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11742444,
            "fieldsOfStudy": [],
            "id": "4ba566223e426677d12a9a18418c023a4deec77e",
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting"
            },
            "venue": {
                "fragments": [],
                "text": "COLT 1997"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "Given an image, for example of a face, there are a plethora of ways to extract features, e.g. mean, variance, edges, gradients, filter responses, color features, geometric features, etc. and each can be computed at every position in the image with different sized windows, or pooled locally or\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "CBCL Face Database #1, MIT Center For Biological and Computation Learning http://cbcl"
            },
            "venue": {
                "fragments": [],
                "text": "CBCL Face Database #1, MIT Center For Biological and Computation Learning http://cbcl"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 25,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Feature-Mining-for-Image-Classification-Doll\u00e1r-Tu/69deed411eeff65cc0cba9e7db94ac337322089b?sort=total-citations"
}