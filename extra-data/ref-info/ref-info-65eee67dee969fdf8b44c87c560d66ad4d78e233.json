{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2308463"
                        ],
                        "name": "Salah El Hihi",
                        "slug": "Salah-El-Hihi",
                        "structuredName": {
                            "firstName": "Salah",
                            "lastName": "Hihi",
                            "middleNames": [
                                "El"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Salah El Hihi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2843869,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b13813b49f160e1a2010c44bd4fb3d09a28446e3",
            "isKey": false,
            "numCitedBy": 332,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We have already shown that extracting long-term dependencies from sequential data is difficult, both for determimstic dynamical systems such as recurrent networks, and probabilistic models such as hidden Markov models (HMMs) or input/output hidden Markov models (IOHMMs). In practice, to avoid this problem, researchers have used domain specific a-priori knowledge to give meaning to the hidden or state variables representing past context. In this paper, we propose to use a more general type of a-priori knowledge, namely that the temporal dependencies are structured hierarchically. This implies that long-term dependencies are represented by variables with a long time scale. This principle is applied to a recurrent network which includes delays and multiple time scales. Experiments confirm the advantages of such structures. A similar approach is proposed for HMMs and IOHMMs."
            },
            "slug": "Hierarchical-Recurrent-Neural-Networks-for-Hihi-Bengio",
            "title": {
                "fragments": [],
                "text": "Hierarchical Recurrent Neural Networks for Long-Term Dependencies"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes to use a more general type of a-priori knowledge, namely that the temporal dependencies are structured hierarchically, which implies that long-term dependencies are represented by variables with a long time scale."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143913738"
                        ],
                        "name": "Santiago Fern\u00e1ndez",
                        "slug": "Santiago-Fern\u00e1ndez",
                        "structuredName": {
                            "firstName": "Santiago",
                            "lastName": "Fern\u00e1ndez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Santiago Fern\u00e1ndez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 104
                            }
                        ],
                        "text": "Hierarchical RNN architectures have also been used to discover the segmentation structure in sequences (Fern\u00e1ndez et al., 2007; Kong et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 89
                            }
                        ],
                        "text": "We find that this model tends to learn fine timescales for low-level layers and coarse timescales for high-level layers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1668634,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12496bf48ebdb5ab3c92bc911d6ee42369fa70bc",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Modelling data in structured domains requires establishing the relations among patterns at multiple scales. When these patterns arise from sequential data, the multiscale structure also contains a dynamic component that must be modelled, particularly, as is often the case, if the data is unsegmented. Probabilistic graphical models are the predominant framework for labelling unsegmented sequential data in structured domains. Their use requires a certain degree of a priori knowledge about the relations among patterns and about the patterns themselves. This paper presents a hierarchical system, based on the connectionist temporal classification algorithm, for labelling unsegmented sequential data at multiple scales with recurrent neural networks only. Experiments on the recognition of sequences of spoken digits show that the system outperforms hidden Markov models, while making fewer assumptions about the domain."
            },
            "slug": "Sequence-Labelling-in-Structured-Domains-with-Fern\u00e1ndez-Graves",
            "title": {
                "fragments": [],
                "text": "Sequence Labelling in Structured Domains with Hierarchical Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper presents a hierarchical system, based on the connectionist temporal classification algorithm, for labelling unsegmented sequential data at multiple scales with recurrent neural networks only and shows that the system outperforms hidden Markov models, while making fewer assumptions about the domain."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 221
                            }
                        ],
                        "text": "The most popular approach is to set the timescales as hyperparameters (El Hihi & Bengio, 1995; Koutn\u00edk et al., 2014; Bahdanau et al., 2016) instead of treating them as dynamic variables that can be learned from the data (Schmidhuber, 1991; 1992; Chung et al., 2015; 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "In these works, it is advocated to stack multiple layers of RNNs in a decreasing order of update frequency for computational and learning efficiency."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "However, unlike the spatial data, learning both hierarchical and temporal representation has been among the long-standing challenges of RNNs in spite of the fact that hierarchical multiscale structures naturally exist in many temporal data (Schmidhuber, 1991; Mozer, 1993; El Hihi & Bengio, 1995; Lin et al., 1996; Koutn\u00edk et al., 2014)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "In the biscale RNNs (Chung et al., 2016), the authors proposed to model layer-wise timescales adaptively by having additional gating units, however this approach still relies on the soft gating mechanism like LSTMs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 51
                            }
                        ],
                        "text": "Two notable early attempts inspiring our model are Schmidhuber (1992) and El Hihi & Bengio (1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 3
                            }
                        ],
                        "text": "In Schmidhuber (1992), the author shows a model that can self-organize a hierarchical multiscale structure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "There have been various approaches to implementing the multiscale RNNs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "Hence, the UPDATE operation is executed sparsely unlike the standard RNNs where it is executed at every time step, making it computationally inefficient."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 100
                            }
                        ],
                        "text": "A promising approach to model such hierarchical and temporal representation is the multiscale RNNs (Schmidhuber, 1992; El Hihi & Bengio, 1995; Koutn\u00edk et al., 2014)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 229
                            }
                        ],
                        "text": "Based on the observation that high-level abstraction changes slowly with temporal coherency while low-level abstraction has quickly changing features sensitive to the precise local timing (El Hihi & Bengio, 1995), the multiscale RNNs group hidden units into multiple modules of different timescales."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 228
                            }
                        ],
                        "text": "In addition to the fact that the architecture fits naturally to the latent hierarchical structures in many temporal data, the multiscale approach provides the following advantages that resolve some inherent problems of standard RNNs: (a) computational efficiency obtained by updating the high-level layers less frequently, (b) efficiently delivering long-term dependencies with fewer updates at the high-level layers, which mitigates the vanishing gradient problem, (c) flexible resource allocation (e.g., more hidden units to the higher layers that focus on modelling long-term dependencies and less hidden units to the lower layers which are in charge of learning short-term dependencies)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18271205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50c770b425a5bb25c77387f687a9910a9d130722",
            "isKey": true,
            "numCitedBy": 428,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous neural network learning algorithms for sequence processing are computationally expensive and perform poorly when it comes to long time lags. This paper first introduces a simple principle for reducing the descriptions of event sequences without loss of information. A consequence of this principle is that only unexpected inputs can be relevant. This insight leads to the construction of neural architectures that learn to divide and conquer by recursively decomposing sequences. I describe two architectures. The first functions as a self-organizing multilevel hierarchy of recurrent networks. The second, involving only two recurrent networks, tries to collapse a multilevel predictor hierarchy into a single recurrent net. Experiments show that the system can require less computation per time step and many fewer training sequences than conventional training algorithms for recurrent nets."
            },
            "slug": "Learning-Complex,-Extended-Sequences-Using-the-of-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Learning Complex, Extended Sequences Using the Principle of History Compression"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A simple principle for reducing the descriptions of event sequences without loss of information is introduced and this insight leads to the construction of neural architectures that learn to divide and conquer by recursively decomposing sequences."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35097114"
                        ],
                        "name": "Saizheng Zhang",
                        "slug": "Saizheng-Zhang",
                        "structuredName": {
                            "firstName": "Saizheng",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saizheng Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3374063"
                        ],
                        "name": "Yuhuai Wu",
                        "slug": "Yuhuai-Wu",
                        "structuredName": {
                            "firstName": "Yuhuai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuhuai Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47828117"
                        ],
                        "name": "Tong Che",
                        "slug": "Tong-Che",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Che",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Che"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3146592"
                        ],
                        "name": "Zhouhan Lin",
                        "slug": "Zhouhan-Lin",
                        "structuredName": {
                            "firstName": "Zhouhan",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhouhan Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710604"
                        ],
                        "name": "R. Memisevic",
                        "slug": "R.-Memisevic",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Memisevic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Memisevic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14499411,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6fda11d2b31ad66dd008a65f7e708aa64a27703",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we systematically analyze the connecting architectures of recurrent neural networks (RNNs). Our main contribution is twofold: first, we present a rigorous graph-theoretic framework describing the connecting architectures of RNNs in general. Second, we propose three architecture complexity measures of RNNs: (a) the recurrent depth, which captures the RNN's over-time nonlinear complexity, (b) the feedforward depth, which captures the local input-output nonlinearity (similar to the \"depth\" in feedforward neural networks (FNNs)), and (c) the recurrent skip coefficient which captures how rapidly the information propagates over time. We rigorously prove each measure's existence and computability. Our experimental results show that RNNs might benefit from larger recurrent depth and feedforward depth. We further demonstrate that increasing recurrent skip coefficient offers performance boosts on long term dependency problems."
            },
            "slug": "Architectural-Complexity-Measures-of-Recurrent-Zhang-Wu",
            "title": {
                "fragments": [],
                "text": "Architectural Complexity Measures of Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes three architecture complexity measures of RNNs and rigorously proves each measure's existence and computability, and demonstrates that increasing recurrent skip coefficient offers performance boosts on long term dependency problems."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8270717"
                        ],
                        "name": "Junyoung Chung",
                        "slug": "Junyoung-Chung",
                        "structuredName": {
                            "firstName": "Junyoung",
                            "lastName": "Chung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junyoung Chung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1854385"
                        ],
                        "name": "\u00c7aglar G\u00fcl\u00e7ehre",
                        "slug": "\u00c7aglar-G\u00fcl\u00e7ehre",
                        "structuredName": {
                            "firstName": "\u00c7aglar",
                            "lastName": "G\u00fcl\u00e7ehre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c7aglar G\u00fcl\u00e7ehre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 246
                            }
                        ],
                        "text": "The most popular approach is to set the timescales as hyperparameters (El Hihi & Bengio, 1995; Koutn\u00edk et al., 2014; Bahdanau et al., 2016) instead of treating them as dynamic variables that can be learned from the data (Schmidhuber, 1991; 1992; Chung et al., 2015; 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8577750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d14c7e5f5cace4c925abc74c88baa474e9f31a28",
            "isKey": false,
            "numCitedBy": 647,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, we propose a novel recurrent neural network (RNN) architecture. The proposed RNN, gated-feedback RNN (GF-RNN), extends the existing approach of stacking multiple recurrent layers by allowing and controlling signals flowing from upper recurrent layers to lower layers using a global gating unit for each pair of layers. The recurrent signals exchanged between layers are gated adaptively based on the previous hidden states and the current input. We evaluated the proposed GF-RNN with different types of recurrent units, such as tanh, long short-term memory and gated recurrent units, on the tasks of character-level language modeling and Python program evaluation. Our empirical evaluation of different RNN units, revealed that in both tasks, the GF-RNN outperforms the conventional approaches to build deep stacked RNNs. We suggest that the improvement arises because the GFRNN can adaptively assign different layers to different timescales and layer-to-layer interactions (including the top-down ones which are not usually present in a stacked RNN) by learning to gate these interactions."
            },
            "slug": "Gated-Feedback-Recurrent-Neural-Networks-Chung-G\u00fcl\u00e7ehre",
            "title": {
                "fragments": [],
                "text": "Gated Feedback Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The empirical evaluation of different RNN units revealed that the proposed gated-feedback RNN outperforms the conventional approaches to build deep stacked RNNs in the tasks of character-level language modeling and Python program evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3374063"
                        ],
                        "name": "Yuhuai Wu",
                        "slug": "Yuhuai-Wu",
                        "structuredName": {
                            "firstName": "Yuhuai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuhuai Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35097114"
                        ],
                        "name": "Saizheng Zhang",
                        "slug": "Saizheng-Zhang",
                        "structuredName": {
                            "firstName": "Saizheng",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saizheng Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48379623"
                        ],
                        "name": "Y. Zhang",
                        "slug": "Y.-Zhang",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 115
                            }
                        ],
                        "text": "From this simple example, we can see the advantages of having a hierarchical multiscale structure: (1) as the W2P-RNN is updated at a much slower update rate than the C2W-RNN, a considerable amount of computation can be saved, (2) gradients are backpropagated through a much smaller number of time\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 305,
                                "start": 300
                            }
                        ],
                        "text": "In Figure 1 (a), we depict a hierarchical RNN (HRNN) for language modelling with two layers: the first layer receives characters as inputs and generates word-level representations (C2W-RNN), and the second layer takes the word-level representations as inputs and yields phrase-level representations (W2P-RNN)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 124
                            }
                        ],
                        "text": "When the C2W-RNN starts to process the next word, its hidden states are reinitialized using the latest hidden states of the W2P-RNN, which contain summarized representation of all the words that have been processed by that time step, in that phrase."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 198
                            }
                        ],
                        "text": "As shown, by means of the provided end-of-word labels, the C2W-RNN obtains word-level representation after processing the last character of each word and passes the word-level representation to the W2P-RNN."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 35
                            }
                        ],
                        "text": "Note that the hidden states of the W2P-RNN remains unchanged while all the characters of a word are processed by the C2W-RNN."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 10
                            }
                        ],
                        "text": "Then, the W2P-RNN performs an update of the phrase-level representation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 110
                            }
                        ],
                        "text": "From this simple example, we can see the advantages of having a hierarchical multiscale structure: (1) as the W2P-RNN is updated at a much slower update rate than the C2W-RNN, a considerable amount of computation can be saved, (2) gradients are backpropagated through a much smaller number of time steps, and (3) layer-wise capacity control becomes possible (e.g., use a smaller number of hidden units in the first layer which models short-term dependencies but whose updates are invoked much more often)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7386147,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "136cf66392f1d6bf42da4cc070888996dc472b91",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a general and simple structural design called Multiplicative Integration (MI) to improve recurrent neural networks (RNNs). MI changes the way in which information from difference sources flows and is integrated in the computational building block of an RNN, while introducing almost no extra parameters. The new structure can be easily embedded into many popular RNN models, including LSTMs and GRUs. We empirically analyze its learning behaviour and conduct evaluations on several tasks using different RNN models. Our experimental results demonstrate that Multiplicative Integration can provide a substantial performance boost over many of the existing RNN models."
            },
            "slug": "On-Multiplicative-Integration-with-Recurrent-Neural-Wu-Zhang",
            "title": {
                "fragments": [],
                "text": "On Multiplicative Integration with Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "This work introduces a general and simple structural design called Multiplicative Integration, which changes the way in which information from difference sources flows and is integrated in the computational building block of an RNN, while introducing almost no extra parameters."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115356552"
                        ],
                        "name": "Tsungnan Lin",
                        "slug": "Tsungnan-Lin",
                        "structuredName": {
                            "firstName": "Tsungnan",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsungnan Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35216199"
                        ],
                        "name": "B. Horne",
                        "slug": "B.-Horne",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Horne",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4023505"
                        ],
                        "name": "P. Ti\u0148o",
                        "slug": "P.-Ti\u0148o",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Ti\u0148o",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ti\u0148o"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 143
                            }
                        ],
                        "text": "A more recent model, the clockwork RNN (CW-RNN) (Koutn\u00edk et al., 2014) extends the hierarchical RNN (El Hihi & Bengio, 1995) and the NARX RNN (Lin et al., 1996)1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 271,
                                "start": 255
                            }
                        ],
                        "text": "\u2026both hierarchical and temporal representation has been among the long-standing challenges of RNNs in spite of the fact that hierarchical multiscale structures naturally exist in many temporal data (Schmidhuber, 1991; Mozer, 1993; El Hihi & Bengio, 1995; Lin et al., 1996; Koutn\u00edk et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 129
                            }
                        ],
                        "text": "In addition to the fact that the architecture fits naturally to the latent hierarchical structures in many temporal data, the multiscale approach provides the following advantages that resolve some inherent problems of standard RNNs: (a) computational efficiency obtained by updating the high-level\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6638216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6e91c9e7e8f8a577a98ecfcfa998212a683195a",
            "isKey": false,
            "numCitedBy": 630,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "It has previously been shown that gradient-descent learning algorithms for recurrent neural networks can perform poorly on tasks that involve long-term dependencies, i.e. those problems for which the desired output depends on inputs presented at times far in the past. We show that the long-term dependencies problem is lessened for a class of architectures called nonlinear autoregressive models with exogenous (NARX) recurrent neural networks, which have powerful representational capabilities. We have previously reported that gradient descent learning can be more effective in NARX networks than in recurrent neural network architectures that have \"hidden states\" on problems including grammatical inference and nonlinear system identification. Typically, the network converges much faster and generalizes better than other networks. The results in this paper are consistent with this phenomenon. We present some experimental results which show that NARX networks can often retain information for two to three times as long as conventional recurrent neural networks. We show that although NARX networks do not circumvent the problem of long-term dependencies, they can greatly improve performance on long-term dependency problems. We also describe in detail some of the assumptions regarding what it means to latch information robustly and suggest possible ways to loosen these assumptions."
            },
            "slug": "Learning-long-term-dependencies-in-NARX-recurrent-Lin-Horne",
            "title": {
                "fragments": [],
                "text": "Learning long-term dependencies in NARX recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that the long-term dependencies problem is lessened for a class of architectures called nonlinear autoregressive models with exogenous (NARX) recurrent neural networks, which have powerful representational capabilities."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360589"
                        ],
                        "name": "Julian G. Zilly",
                        "slug": "Julian-G.-Zilly",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Zilly",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julian G. Zilly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2100612"
                        ],
                        "name": "R. Srivastava",
                        "slug": "R.-Srivastava",
                        "structuredName": {
                            "firstName": "Rupesh",
                            "lastName": "Srivastava",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2865775"
                        ],
                        "name": "J. Koutn\u00edk",
                        "slug": "J.-Koutn\u00edk",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koutn\u00edk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koutn\u00edk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1101453,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dba53e72c182e25e98e8f73a99d75ff69dda0c2",
            "isKey": false,
            "numCitedBy": 350,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Many sequential processing tasks require complex nonlinear transition functions from one step to the next. However, recurrent neural networks with 'deep' transition functions remain difficult to train, even when using Long Short-Term Memory (LSTM) networks. We introduce a novel theoretical analysis of recurrent networks based on Gersgorin's circle theorem that illuminates several modeling and optimization issues and improves our understanding of the LSTM cell. Based on this analysis we propose Recurrent Highway Networks, which extend the LSTM architecture to allow step-to-step transition depths larger than one. Several language modeling experiments demonstrate that the proposed architecture results in powerful and efficient models. On the Penn Treebank corpus, solely increasing the transition depth from 1 to 10 improves word-level perplexity from 90.6 to 65.4 using the same number of parameters. On the larger Wikipedia datasets for character prediction (text8 and enwik8), RHNs outperform all previous results and achieve an entropy of 1.27 bits per character."
            },
            "slug": "Recurrent-Highway-Networks-Zilly-Srivastava",
            "title": {
                "fragments": [],
                "text": "Recurrent Highway Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel theoretical analysis of recurrent networks based on Gersgorin's circle theorem is introduced that illuminates several modeling and optimization issues and improves the understanding of the LSTM cell."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150165387"
                        ],
                        "name": "J. Urgen Schmidhuber",
                        "slug": "J.-Urgen-Schmidhuber",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Urgen Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Urgen Schmidhuber"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 221
                            }
                        ],
                        "text": "The most popular approach is to set the timescales as hyperparameters (El Hihi & Bengio, 1995; Koutn\u00edk et al., 2014; Bahdanau et al., 2016) instead of treating them as dynamic variables that can be learned from the data (Schmidhuber, 1991; 1992; Chung et al., 2015; 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 199
                            }
                        ],
                        "text": "\u2026both hierarchical and temporal representation has been among the long-standing challenges of RNNs in spite of the fact that hierarchical multiscale structures naturally exist in many temporal data (Schmidhuber, 1991; Mozer, 1993; El Hihi & Bengio, 1995; Lin et al., 1996; Koutn\u00edk et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14510132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c69201d091dd92699fd90a17b9e3407319726791",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of learning t\u00f2divide and conquer' by meaningful hierarchical adaptive decomposition of temporal sequences. This problem is relevant for time-series analysis as well as for goal-directed learning, particularily if event sequences tend to have hierarchical temporal structure. The rst neural systems for recursively chunking sequences are described. These systems are based on a principle called th\u00e8principle of history compression'. This principle essentially says: As long as a predictor is able to predict future environmental inputs from previous ones, no additional knowledge can be obtained by observing these inputs in reality. Only unexpected inputs deserve attention. A focus is on a class of 2-network systems which try to collapse a self-organizing (possibly multi-level) hierarchy of temporal predictors into a single recurrent network. Only those input events that were not expected by the rst recurrent net are transferred to the second recurrent net. Therefore the second net receives a reduced discription of the input history. It tries to develop internal representations for`higher-level' temporal structure. These internal representations in turn serve to create additional training signals for the rst net, thus helping the rst net to create longer and longer`chunks' for the second net. Experiments show that chunking systems can be superior to the conventional training algorithms for recurrent nets. 1 OUTLINE Section 2 motivates the search for sequence-composing systems by describing major drawbacks of`conventional' learning algorithms for recurrent networks with time-varying inputs and outputs. Section 3 describes a simple observation which is essential for the rest of this paper: It describes th\u00e8principle of history compression'. This principle essentially says: As long as a predictor is able to predict future environmental inputs from previous ones, no additional knowledge can be obtained by observing these inputs in reality. Only unexpected inputs deserve attention. This principle is of particular interest if typical event sequences have hierarchical temporal structure. Basic schemes for constructing sequence chunking systems based on the principle of history compression are described. Section 4 then describes on-line and o-line versions of a particular 2-network chunking system which tries to collapse a self-organizing (possibly multi-level) predictor hierarchy into a single recurrent network (the automatizer). The idea is to feed everything that is unexpected into a `higher-level' recurrent net (the chunker). Since the expected things can be derived from the unexpected things by the automatizer, the chunker is fed with a reduced description of the input history. The chunker has a \u2026"
            },
            "slug": "Neural-Sequence-Chunkers-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Neural Sequence Chunkers"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experiments show that chunking systems can be superior to the conventional training algorithms for recurrent nets, and a focus is on a class of 2-network systems which try to collapse a self-organizing hierarchy of temporal predictors into a single recurrent network."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996134"
                        ],
                        "name": "Razvan Pascanu",
                        "slug": "Razvan-Pascanu",
                        "structuredName": {
                            "firstName": "Razvan",
                            "lastName": "Pascanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Razvan Pascanu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 81
                            }
                        ],
                        "text": "The norm of the gradient is clipped with a threshold of 1 (Mikolov et al., 2010; Pascanu et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 43
                            }
                        ],
                        "text": "Using the boundary states, at each time step, each layer selects one of the following operations: UPDATE, COPY or FLUSH."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14650762,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84069287da0a6b488b8c933f3cb5be759cb6237e",
            "isKey": false,
            "numCitedBy": 3803,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "There are two widely known issues with properly training recurrent neural networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section."
            },
            "slug": "On-the-difficulty-of-training-recurrent-neural-Pascanu-Mikolov",
            "title": {
                "fragments": [],
                "text": "On the difficulty of training recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper proposes a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem and validates empirically the hypothesis and proposed solutions."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47648549"
                        ],
                        "name": "Lingpeng Kong",
                        "slug": "Lingpeng-Kong",
                        "structuredName": {
                            "firstName": "Lingpeng",
                            "lastName": "Kong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lingpeng Kong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745899"
                        ],
                        "name": "Chris Dyer",
                        "slug": "Chris-Dyer",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Dyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Dyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144365875"
                        ],
                        "name": "Noah A. Smith",
                        "slug": "Noah-A.-Smith",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noah A. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 128
                            }
                        ],
                        "text": "Hierarchical RNN architectures have also been used to discover the segmentation structure in sequences (Fern\u00e1ndez et al., 2007; Kong et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 113
                            }
                        ],
                        "text": "We find that this model tends to learn fine timescales for low-level layers and coarse timescales for high-level layers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5519195,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b904d6e84c98c6ce22ce6923224b205a2a24ee1",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce segmental recurrent neural networks (SRNNs) which define, given an input sequence, a joint probability distribution over segmentations of the input and labelings of the segments. Representations of the input segments (i.e., contiguous subsequences of the input) are computed by encoding their constituent tokens using bidirectional recurrent neural nets, and these \"segment embeddings\" are used to define compatibility scores with output labels. These local compatibility scores are integrated using a global semi-Markov conditional random field. Both fully supervised training -- in which segment boundaries and labels are observed -- as well as partially supervised training -- in which segment boundaries are latent -- are straightforward. Experiments on handwriting recognition and joint Chinese word segmentation/POS tagging show that, compared to models that do not explicitly represent segments such as BIO tagging schemes and connectionist temporal classification (CTC), SRNNs obtain substantially higher accuracies."
            },
            "slug": "Segmental-Recurrent-Neural-Networks-Kong-Dyer",
            "title": {
                "fragments": [],
                "text": "Segmental Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experiments on handwriting recognition and joint Chinese word segmentation/POS tagging show that segmental recurrent neural networks obtain substantially higher accuracies compared to models that do not explicitly represent segments."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145704247"
                        ],
                        "name": "James Martens",
                        "slug": "James-Martens",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Martens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Martens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8843166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de",
            "isKey": false,
            "numCitedBy": 1255,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent Neural Networks (RNNs) are very powerful sequence models that do not enjoy widespread use because it is extremely difficult to train them properly. Fortunately, recent advances in Hessian-free optimization have been able to overcome the difficulties associated with training RNNs, making it possible to apply them successfully to challenging sequence problems. In this paper we demonstrate the power of RNNs trained with the new Hessian-Free optimizer (HF) by applying them to character-level language modeling tasks. The standard RNN architecture, while effective, is not ideally suited for such tasks, so we introduce a new RNN variant that uses multiplicative (or \"gated\") connections which allow the current input character to determine the transition matrix from one hidden state vector to the next. After training the multiplicative RNN with the HF optimizer for five days on 8 high-end Graphics Processing Units, we were able to surpass the performance of the best previous single method for character-level language modeling \u2013 a hierarchical non-parametric sequence model. To our knowledge this represents the largest recurrent neural network application to date."
            },
            "slug": "Generating-Text-with-Recurrent-Neural-Networks-Sutskever-Martens",
            "title": {
                "fragments": [],
                "text": "Generating Text with Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The power of RNNs trained with the new Hessian-Free optimizer by applying them to character-level language modeling tasks is demonstrated, and a new RNN variant that uses multiplicative connections which allow the current input character to determine the transition matrix from one hidden state vector to the next is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35030998"
                        ],
                        "name": "Adam Santoro",
                        "slug": "Adam-Santoro",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Santoro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Santoro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258504"
                        ],
                        "name": "Sergey Bartunov",
                        "slug": "Sergey-Bartunov",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Bartunov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergey Bartunov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46378362"
                        ],
                        "name": "M. Botvinick",
                        "slug": "M.-Botvinick",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Botvinick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Botvinick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542999"
                        ],
                        "name": "T. Lillicrap",
                        "slug": "T.-Lillicrap",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Lillicrap",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lillicrap"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16660179,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbd0e204f48a45735e1065c8b90b298077b73192",
            "isKey": false,
            "numCitedBy": 459,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of \u201cone-shot learning.\u201d Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory locationbased focusing mechanisms."
            },
            "slug": "One-shot-Learning-with-Memory-Augmented-Neural-Santoro-Bartunov",
            "title": {
                "fragments": [],
                "text": "One-shot Learning with Memory-Augmented Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1993475"
                        ],
                        "name": "K. Rocki",
                        "slug": "K.-Rocki",
                        "structuredName": {
                            "firstName": "Kamil",
                            "lastName": "Rocki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rocki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5063280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca9d174c70c9102d88f2707bc395d6a384e1de1d",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent neural nets are widely used for predicting temporal data. Their inherent deep feedforward structure allows learning complex sequential patterns. It is believed that top-down feedback might be an important missing ingredient which in theory could help disambiguate similar patterns depending on broader context. In this paper we introduce surprisal-driven recurrent networks, which take into account past error information when making new predictions. This is achieved by continuously monitoring the discrepancy between most recent predictions and the actual observations. Furthermore, we show that it outperforms other stochastic and fully deterministic approaches on enwik8 character level prediction task achieving 1.37 BPC on the test portion of the text."
            },
            "slug": "Surprisal-Driven-Feedback-in-Recurrent-Networks-Rocki",
            "title": {
                "fragments": [],
                "text": "Surprisal-Driven Feedback in Recurrent Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper introduces surprisal-driven recurrent networks, which take into account past error information when making new predictions, which outperforms other stochastic and fully deterministic approaches on enwik8 character level prediction task."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 208
                            }
                        ],
                        "text": "One of the key principles of learning in deep neural networks as well as in the human brain is to obtain a hierarchical representation with increasing levels of abstraction (Bengio, 2009; LeCun et al., 2015; Schmidhuber, 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11715509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "193edd20cae92c6759c18ce93eeea96afd9528eb",
            "isKey": false,
            "numCitedBy": 11786,
            "numCiting": 1174,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Deep-learning-in-neural-networks:-An-overview-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Deep learning in neural networks: An overview"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144473519"
                        ],
                        "name": "M. Mozer",
                        "slug": "M.-Mozer",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Mozer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mozer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 218
                            }
                        ],
                        "text": "\u2026both hierarchical and temporal representation has been among the long-standing challenges of RNNs in spite of the fact that hierarchical multiscale structures naturally exist in many temporal data (Schmidhuber, 1991; Mozer, 1993; El Hihi & Bengio, 1995; Lin et al., 1996; Koutn\u00edk et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 357,
                                "start": 240
                            }
                        ],
                        "text": "However, unlike the spatial data, learning both hierarchical and temporal representation has been among the long-standing challenges of RNNs in spite of the fact that hierarchical multiscale structures naturally exist in many temporal data (Schmidhuber, 1991; Mozer, 1993; El Hihi and Bengio, 1995; Kleinberg, 2003; Koutn\u00edk et al., 2014; Chung et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5355536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e141d68065ce638f9fc4f006eab2f66711e89768",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning structure in temporally-extended sequences is a difficult computational problem because only a fraction of the relevant information is available at any instant. Although variants of back propagation can in principle be used to find structure in sequences, in practice they are not sufficiently powerful to discover arbitrary contingencies, especially those spanning long temporal intervals or involving high order statistics. For example, in designing a connectionist network for music composition, we have encountered the problem that the net is able to learn musical structure that occurs locally in time--e.g., relations among notes within a musical phrase--but not structure that occurs over longer time periods--e.g., relations among phrases. To address this problem, we require a means of constructing a reduced description of the sequence that makes global aspects more explicit or more readily detectable. I propose to achieve this using hidden units that operate with different time constants. Simulation experiments indicate that slower time-scale hidden units are able to pick up global structure, structure that simply can not be learned by standard back propagation."
            },
            "slug": "Induction-of-Multiscale-Temporal-Structure-Mozer",
            "title": {
                "fragments": [],
                "text": "Induction of Multiscale Temporal Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Simulation experiments indicate that slower time-scale hidden units are able to pick up global structure, structure that simply can not be learned by standard back propagation, using hidden units that operate with different time constants."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2865775"
                        ],
                        "name": "J. Koutn\u00edk",
                        "slug": "J.-Koutn\u00edk",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koutn\u00edk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koutn\u00edk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3035541"
                        ],
                        "name": "Klaus Greff",
                        "slug": "Klaus-Greff",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Greff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klaus Greff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145842938"
                        ],
                        "name": "Faustino J. Gomez",
                        "slug": "Faustino-J.-Gomez",
                        "structuredName": {
                            "firstName": "Faustino",
                            "lastName": "Gomez",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Faustino J. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 95
                            }
                        ],
                        "text": "The most popular approach is to set the timescales as hyperparameters (El Hihi & Bengio, 1995; Koutn\u00edk et al., 2014; Bahdanau et al., 2016) instead of treating them as dynamic variables that can be learned from the data (Schmidhuber, 1991; 1992; Chung et al., 2015; 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 35
                            }
                        ],
                        "text": "In addition to the fact that the architecture fits naturally to the latent hierarchical structures in many temporal data, the multiscale approach provides the following advantages that resolve some inherent problems of standard RNNs: (a) computational efficiency obtained by updating the high-level\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 49
                            }
                        ],
                        "text": "A more recent model, the clockwork RNN (CW-RNN) (Koutn\u00edk et al., 2014) extends the hierarchical RNN (El Hihi & Bengio, 1995) and the NARX RNN (Lin et al., 1996)1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 4
                            }
                        ],
                        "text": "The CW-RNN is computationally more efficient than the standard RNN including the LSTM since hidden units are updated only at the assigned clock rates."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2022 We propose the slope annealing trick to improve the training procedure based on the\nstraight-through estimator."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 204
                            }
                        ],
                        "text": "In Section 2, we discussed the limitations of the existing RNN models under this setting, which either have to update all units at every time step or use fixed update frequencies (El Hihi & Bengio, 1995; Koutn\u00edk et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 7
                            }
                        ],
                        "text": "In the CW-RNN, hidden units are partitioned into several modules, and different timescales are assigned to the modules such that a module i updates its hidden units at every 2(i\u22121)-th time step."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 42
                            }
                        ],
                        "text": "However, finding proper timescales in the CW-RNN remains as a challenge whereas our model learns the intrinsic timescales from the data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 143
                            }
                        ],
                        "text": "A promising approach to model such hierarchical and temporal representation is the multiscale RNNs (Schmidhuber, 1992; El Hihi & Bengio, 1995; Koutn\u00edk et al., 2014)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 4
                            }
                        ],
                        "text": "The CW-RNN tries to solve the issue of using soft timescales in the LSTM, by explicitly assigning hard timescales."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 273
                            }
                        ],
                        "text": "\u2026both hierarchical and temporal representation has been among the long-standing challenges of RNNs in spite of the fact that hierarchical multiscale structures naturally exist in many temporal data (Schmidhuber, 1991; Mozer, 1993; El Hihi & Bengio, 1995; Lin et al., 1996; Koutn\u00edk et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14936429,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5522764282c85aea422f1c4dc92ff7e0ca6987bc",
            "isKey": true,
            "numCitedBy": 376,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequence prediction and classification are ubiquitous and challenging problems in machine learning that can require identifying complex dependencies between temporally distant inputs. Recurrent Neural Networks (RNNs) have the ability, in theory, to cope with these temporal dependencies by virtue of the short-term memory implemented by their recurrent (feedback) connections. However, in practice they are difficult to train successfully when long-term memory is required. This paper introduces a simple, yet powerful modification to the simple RNN (SRN) architecture, the Clockwork RNN (CW-RNN), in which the hidden layer is partitioned into separate modules, each processing inputs at its own temporal granularity, making computations only at its prescribed clock rate. Rather than making the standard RNN models more complex, CW-RNN reduces the number of SRN parameters, improves the performance significantly in the tasks tested, and speeds up the network evaluation. The network is demonstrated in preliminary experiments involving three tasks: audio signal generation, TIMIT spoken word classification, where it outperforms both SRN and LSTM networks, and online handwriting recognition, where it outperforms SRNs."
            },
            "slug": "A-Clockwork-RNN-Koutn\u00edk-Greff",
            "title": {
                "fragments": [],
                "text": "A Clockwork RNN"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper introduces a simple, yet powerful modification to the simple RNN architecture, the Clockwork RNN (CW-RNN), in which the hidden layer is partitioned into separate modules, each processing inputs at its own temporal granularity, making computations only at its prescribed clock rate."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2583391"
                        ],
                        "name": "Nal Kalchbrenner",
                        "slug": "Nal-Kalchbrenner",
                        "structuredName": {
                            "firstName": "Nal",
                            "lastName": "Kalchbrenner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nal Kalchbrenner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1841008"
                        ],
                        "name": "Ivo Danihelka",
                        "slug": "Ivo-Danihelka",
                        "structuredName": {
                            "firstName": "Ivo",
                            "lastName": "Danihelka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivo Danihelka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7823468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b791cd374c7109693aaddee2c12d659ae4e3ec0",
            "isKey": false,
            "numCitedBy": 311,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces Grid Long Short-Term Memory, a network of LSTM cells arranged in a multidimensional grid that can be applied to vectors, sequences or higher dimensional data such as images. The network differs from existing deep LSTM architectures in that the cells are connected between network layers as well as along the spatiotemporal dimensions of the data. The network provides a unified way of using LSTM for both deep and sequential computation. We apply the model to algorithmic tasks such as 15-digit integer addition and sequence memorization, where it is able to significantly outperform the standard LSTM. We then give results for two empirical tasks. We find that 2D Grid LSTM achieves 1.47 bits per character on the Wikipedia character prediction benchmark, which is state-of-the-art among neural approaches. In addition, we use the Grid LSTM to define a novel two-dimensional translation model, the Reencoder, and show that it outperforms a phrase-based reference system on a Chinese-to-English translation task."
            },
            "slug": "Grid-Long-Short-Term-Memory-Kalchbrenner-Danihelka",
            "title": {
                "fragments": [],
                "text": "Grid Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Grid LSTM is used to define a novel two-dimensional translation model, the Reencoder, and it is shown that it outperforms a phrase-based reference system on a Chinese-to-English translation task."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714004"
                        ],
                        "name": "A. Mnih",
                        "slug": "A.-Mnih",
                        "structuredName": {
                            "firstName": "Andriy",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144717963"
                        ],
                        "name": "Karol Gregor",
                        "slug": "Karol-Gregor",
                        "structuredName": {
                            "firstName": "Karol",
                            "lastName": "Gregor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karol Gregor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 113
                            }
                        ],
                        "text": "Among a few methods for training a neural network with discrete variables such as the REINFORCE (Williams, 1992; Mnih & Gregor, 2014) and the straight-through estimator (Hinton, 2012; Bengio et al., 2013), we use the straightthrough estimator to train our model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Although the main goal of our proposed model is not regularization, we found that our model also shows very good generalization performance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1981188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "018300f5f0e679cee5241d9c69c8d88e00e8bf31",
            "isKey": false,
            "numCitedBy": 624,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Highly expressive directed latent variable models, such as sigmoid belief networks, are difficult to train on large datasets because exact inference in them is intractable and none of the approximate inference methods that have been applied to them scale well. We propose a fast non-iterative approximate inference method that uses a feedforward network to implement efficient exact sampling from the variational posterior. The model and this inference network are trained jointly by maximizing a variational lower bound on the log-likelihood. Although the naive estimator of the inference network gradient is too high-variance to be useful, we make it practical by applying several straightforward model-independent variance reduction techniques. Applying our approach to training sigmoid belief networks and deep autoregressive networks, we show that it outperforms the wake-sleep algorithm on MNIST and achieves state-of-the-art results on the Reuters RCV1 document dataset."
            },
            "slug": "Neural-Variational-Inference-and-Learning-in-Belief-Mnih-Gregor",
            "title": {
                "fragments": [],
                "text": "Neural Variational Inference and Learning in Belief Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a fast non-iterative approximate inference method that uses a feedforward network to implement efficient exact sampling from the variational posterior and shows that it outperforms the wake-sleep algorithm on MNIST and achieves state-of-the-art results on the Reuters RCV1 document dataset."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8270717"
                        ],
                        "name": "Junyoung Chung",
                        "slug": "Junyoung-Chung",
                        "structuredName": {
                            "firstName": "Junyoung",
                            "lastName": "Chung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junyoung Chung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2182706"
                        ],
                        "name": "Kyle Kastner",
                        "slug": "Kyle-Kastner",
                        "structuredName": {
                            "firstName": "Kyle",
                            "lastName": "Kastner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyle Kastner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46573521"
                        ],
                        "name": "Laurent Dinh",
                        "slug": "Laurent-Dinh",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Dinh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurent Dinh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2957685"
                        ],
                        "name": "Kratarth Goel",
                        "slug": "Kratarth-Goel",
                        "structuredName": {
                            "firstName": "Kratarth",
                            "lastName": "Goel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kratarth Goel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 246
                            }
                        ],
                        "text": "The most popular approach is to set the timescales as hyperparameters (El Hihi & Bengio, 1995; Koutn\u00edk et al., 2014; Bahdanau et al., 2016) instead of treating them as dynamic variables that can be learned from the data (Schmidhuber, 1991; 1992; Chung et al., 2015; 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "k rates. However, \ufb01nding proper timescales in CW-RNN remains as a challenge, unlike our model, which learns the intrinsic timescales from the data. More recently, in the Gated-Feedback RNNs (GF-RNN) (Chung et al., 2015a) and the Biscale RNNs (BiS-RNN) (Chung et al., 2016), the authors proposed to model layer-wise timescales more explicitly by having additional gating units to stacked RNN architecture. While the GF-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": " of the (x;y) coordinates of each sequence by dividing with a factor of 100. Note that this process makes our numbers in Table 4 to become not directly comparable to the previous works (Graves, 2013; Chung et al., 2015b). However, we train both the baseline model and proposed 10 IAM-OnDB Model Average Log-Likelihood Standard LSTM 2285 HM-LSTM 2332 Table 4: Average log-likelihood per sequence on the IAM-OnDB test se"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "-LSTM 1.30 Table 2: Bits-per-character on the Text8 test set. Hutter Prize Wikipedia Model BPC SF-LSTM (Rocki, 2016b) 1.39 Stacked LSTM (Graves, 2013) 1.67 MRNN (Sutskever et al., 2011) 1.60 GF-LSTM (Chung et al., 2015a) 1.58 Grid-LSTM (Kalchbrenner et al., 2015) 1.47 Layer-normalized LSTM (Ba et al., 2016)y 1.46 MI-LSTM (Wu et al., 2016) 1.44 Recurrent Highway Networks (Zilly et al., 2016) 1.42 Recurrent Memory Ar"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "es as hyperparameters (El Hihi and Bengio, 1995; Koutn\u00edk et al., 2014; Bahdanau et al., 2016) instead of treating them as dynamic variables that can be learned from the data (Schmidhuber, 1991, 1992; Chung et al., 2015a, 2016). However, considering the fact that non-stationarity is prevalent in temporal data and that many entities of abstraction such as words and sentences are in variable-length, we claim that it i"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1594370,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c3b69b5247ef18fd5bab1109d87a04184ea8f4b",
            "isKey": false,
            "numCitedBy": 875,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we explore the inclusion of latent random variables into the hidden state of a recurrent neural network (RNN) by combining the elements of the variational autoencoder. We argue that through the use of high-level latent random variables, the variational RNN (VRNN)1 can model the kind of variability observed in highly structured sequential data such as natural speech. We empirically evaluate the proposed model against other related sequential models on four speech datasets and one handwriting dataset. Our results show the important roles that latent random variables can play in the RNN dynamics."
            },
            "slug": "A-Recurrent-Latent-Variable-Model-for-Sequential-Chung-Kastner",
            "title": {
                "fragments": [],
                "text": "A Recurrent Latent Variable Model for Sequential Data"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is argued that through the use of high-level latent random variables, the variational RNN (VRNN)1 can model the kind of variability observed in highly structured sequential data such as natural speech."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713801"
                        ],
                        "name": "Anoop Deoras",
                        "slug": "Anoop-Deoras",
                        "structuredName": {
                            "firstName": "Anoop",
                            "lastName": "Deoras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anoop Deoras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784529"
                        ],
                        "name": "H. Le",
                        "slug": "H.-Le",
                        "structuredName": {
                            "firstName": "Hai",
                            "lastName": "Le",
                            "middleNames": [
                                "Son"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2675251"
                        ],
                        "name": "Stefan Kombrink",
                        "slug": "Stefan-Kombrink",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Kombrink",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan Kombrink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1899242"
                        ],
                        "name": "J. Cernock\u00fd",
                        "slug": "J.-Cernock\u00fd",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Cernock\u00fd",
                            "middleNames": [
                                "Honza"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cernock\u00fd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 46542477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fd7fc06653723b05abe5f3d1de393ddcf6bdddb",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore the performance of several types of language mode ls on the word-level and the character-level language modelin g tasks. This includes two recently proposed recurrent neural netwo rk architectures, a feedforward neural network model, a maximum ent ropy model and the usual smoothed n-gram models. We then propose a simple technique for learning sub-word level units from th e data, and show that it combines advantages of both character and wo rdlevel models. Finally, we show that neural network based lan gu ge models can be order of magnitude smaller than compressed n-g ram models, at the same level of performance when applied to a Bro dcast news RT04 speech recognition task. By using sub-word un its, the size can be reduced even more."
            },
            "slug": "SUBWORD-LANGUAGE-MODELING-WITH-NEURAL-NETWORKS-Mikolov-Sutskever",
            "title": {
                "fragments": [],
                "text": "SUBWORD LANGUAGE MODELING WITH NEURAL NETWORKS"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A simple technique for learning sub-word level units from data is proposed, and it is shown that neural network based models can be order of magnitude smaller than compressed n-g ram models, at the same level of performance when applied to a Bro dcast news RT04 speech recognition task."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 65
                            }
                        ],
                        "text": "We use the mixture density network as the output layer following Graves (2013), and use 400 units for each HM-LSTM layer and for the output embedding layer."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 34
                            }
                        ],
                        "text": "We follow the data splits used in Graves (2013) where the first 90M characters are used to train the model, the next 5M characters for validation, and the remainders for the test set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 140
                            }
                        ],
                        "text": "For modelling temporal data, the recent resurgence of recurrent neural networks (RNN) has led to remarkable advances (Mikolov et al., 2010; Graves, 2013; Cho et al., 2014; Sutskever et al., 2014; Vinyals et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1697424,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89b1f4740ae37fd04f6ac007577bdd34621f0861",
            "isKey": false,
            "numCitedBy": 3153,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles."
            },
            "slug": "Generating-Sequences-With-Recurrent-Neural-Networks-Graves",
            "title": {
                "fragments": [],
                "text": "Generating Sequences With Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 95
                            }
                        ],
                        "text": "The UPDATE operation is similar to the usual update rule of the long short-term memory (LSTM) (Hochreiter & Schmidhuber, 1997), except that it is executed sparsely according to the detected boundaries."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 119
                            }
                        ],
                        "text": "The authors propose an RNN architecture that updates each layer with a fixed but different rate, called a hierarchical RNN.\nLSTMs (Hochreiter & Schmidhuber, 1997) employ the multiscale update concept, where the hidden units have different forget and update rates and thus can operate with different timescales."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 131
                            }
                        ],
                        "text": "The authors propose an RNN architecture that updates each layer with a fixed but different rate, called a hierarchical RNN.\nLSTMs (Hochreiter & Schmidhuber, 1997) employ the multiscale update concept, where the hidden units have different forget and update rates and thus can operate with different\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 160
                            }
                        ],
                        "text": "The remarkable recent successes of the deep convolutional neural networks are particularly based on this ability to learn hierarchical representation for spatial data (Krizhevsky et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1915014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
            "isKey": true,
            "numCitedBy": 51722,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms."
            },
            "slug": "Long-Short-Term-Memory-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3090784"
                        ],
                        "name": "Marius Pachitariu",
                        "slug": "Marius-Pachitariu",
                        "structuredName": {
                            "firstName": "Marius",
                            "lastName": "Pachitariu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marius Pachitariu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2283363"
                        ],
                        "name": "M. Sahani",
                        "slug": "M.-Sahani",
                        "structuredName": {
                            "firstName": "Maneesh",
                            "lastName": "Sahani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sahani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14444765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ef03716945bd3907458efbe1bbf8928dafc1efc",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural language models (LMs) based on recurrent neural networks (RNN) are some of the most successful word and character-level LMs. Why do they work so well, in particular better than linear neural LMs? Possible explanations are that RNNs have an implicitly better regularization or that RNNs have a higher capacity for storing patterns due to their nonlinearities or both. Here we argue for the first explanation in the limit of little training data and the second explanation for large amounts of text data. We show state-of-the-art performance on the popular and small Penn dataset when RNN LMs are regularized with random dropout. Nonetheless, we show even better performance from a simplified, much less expressive linear RNN model without off-diagonal entries in the recurrent matrix. We call this model an impulse-response LM (IRLM). Using random dropout, column normalization and annealed learning rates, IRLMs develop neurons that keep a memory of up to 50 words in the past and achieve a perplexity of 102.5 on the Penn dataset. On two large datasets however, the same regularization methods are unsuccessful for both models and the RNN's expressivity allows it to overtake the IRLM by 10 and 20 percent perplexity, respectively. Despite the perplexity gap, IRLMs still outperform RNNs on the Microsoft Research Sentence Completion (MRSC) task. We develop a slightly modified IRLM that separates long-context units (LCUs) from short-context units and show that the LCUs alone achieve a state-of-the-art performance on the MRSC task of 60.8%. Our analysis indicates that a fruitful direction of research for neural LMs lies in developing more accessible internal representations, and suggests an optimization regime of very high momentum terms for effectively training such models."
            },
            "slug": "Regularization-and-nonlinearities-for-neural-when-Pachitariu-Sahani",
            "title": {
                "fragments": [],
                "text": "Regularization and nonlinearities for neural language models: when are they needed?"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The analysis indicates that a fruitful direction of research for neural LMs lies in developing more accessible internal representations, and suggests an optimization regime of very high momentum terms for effectively training such models."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360972"
                        ],
                        "name": "Abdel-rahman Mohamed",
                        "slug": "Abdel-rahman-Mohamed",
                        "structuredName": {
                            "firstName": "Abdel-rahman",
                            "lastName": "Mohamed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel-rahman Mohamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206741496,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4177ec52d1b80ed57f2e72b0f9a42365f1a8598d",
            "isKey": false,
            "numCitedBy": 6901,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score."
            },
            "slug": "Speech-recognition-with-deep-recurrent-neural-Graves-Mohamed",
            "title": {
                "fragments": [],
                "text": "Speech recognition with deep recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2965424"
                        ],
                        "name": "J. Yosinski",
                        "slug": "J.-Yosinski",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Yosinski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yosinski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2552141"
                        ],
                        "name": "J. Clune",
                        "slug": "J.-Clune",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Clune",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Clune"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747909"
                        ],
                        "name": "Hod Lipson",
                        "slug": "Hod-Lipson",
                        "structuredName": {
                            "firstName": "Hod",
                            "lastName": "Lipson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hod Lipson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 269
                            }
                        ],
                        "text": "\u2026learned from the data in a way to optimize the target task, make deep neural networks entertain advantages such as generalization to unseen examples (Hoffman et al., 2013), sharing learned knowledge among multiple tasks, and discovering disentangling factors of variation (Kingma & Welling, 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 362467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "081651b38ff7533550a3adfc1c00da333a8fe86c",
            "isKey": false,
            "numCitedBy": 5779,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset."
            },
            "slug": "How-transferable-are-features-in-deep-neural-Yosinski-Clune",
            "title": {
                "fragments": [],
                "text": "How transferable are features in deep neural networks?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper quantifies the generality versus specificity of neurons in each layer of a deep convolutional neural network and reports a few surprising results, including that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 274
                            }
                        ],
                        "text": "\u2026learned from the data in a way to optimize the target task, make deep neural networks entertain advantages such as generalization to unseen examples (Hoffman et al., 2013), sharing learned knowledge among multiple tasks, and discovering disentangling factors of variation (Kingma & Welling, 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 216078090,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f5dc5b9a2ba710937e2c413b37b053cd673df02",
            "isKey": false,
            "numCitedBy": 16788,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract: How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results."
            },
            "slug": "Auto-Encoding-Variational-Bayes-Kingma-Welling",
            "title": {
                "fragments": [],
                "text": "Auto-Encoding Variational Bayes"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2348758"
                        ],
                        "name": "Tim Cooijmans",
                        "slug": "Tim-Cooijmans",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cooijmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cooijmans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2482072"
                        ],
                        "name": "Nicolas Ballas",
                        "slug": "Nicolas-Ballas",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Ballas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Ballas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40201308"
                        ],
                        "name": "C\u00e9sar Laurent",
                        "slug": "C\u00e9sar-Laurent",
                        "structuredName": {
                            "firstName": "C\u00e9sar",
                            "lastName": "Laurent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C\u00e9sar Laurent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "igure 4: Hierarchical multiscale structure in the Hutter Prize Wikipedia dataset captured by the HM-LSTM to compare with other previous works, we follow the data splits used in Mikolov et al. (2012); Cooijmans et al. (2016); Wu et al. (2016). We use 1024 units for each HM-LSTM layer and 2048 units for the embedding layer of the output module. The mini-batch size and the initial learning rate are set to 128 and 0:001, re"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "g rate. For the Penn Treebank dataset, we use 500 units in each layer of the HM-LSTM and 500 units for the embedding layer of the output module. We apply batch normalization (Ioffe and Szegedy, 2015; Cooijmans et al., 2016). In Table 1, we compare the test BPCs of four variants of our model to other baseline models. Note that the HM-LSTM using the step function for the hard boundary decision outperforms the other HM-LST"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "-LSTM (Zhang et al., 2016) 1.63 HF-MRNN (Mikolov et al., 2012) 1.54 MI-RNN (Wu et al., 2016) 1.52 Skipping-RNN (Pachitariu and Sahani, 2013) 1.48 MI-LSTM (Wu et al., 2016) 1.44 Batch-normalized LSTM (Cooijmans et al., 2016) 1.36 HM-LSTM 1.30 Table 2: Bits-per-character on the Text8 test set. Hutter Prize Wikipedia Model BPC SF-LSTM (Rocki, 2016b) 1.39 Stacked LSTM (Graves, 2013) 1.67 MRNN (Sutskever et al., 2011) 1.60 G"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "eger and Memisevic, 2015) 1.48 Clockwork RNN (Koutn\u00edk et al., 2014) 1.46 HF-MRNN (Mikolov et al., 2012) 1.41 MI-RNN (Wu et al., 2016) 1.39 ME n-gram (Mikolov et al., 2012) 1.37 Batch-normalized LSTM (Cooijmans et al., 2016) 1.32 Zoneout RNN (Krueger et al., 2016) 1.30 HM-LSTM Sampling 1.30 HM-LSTM Soft 1.29 HM-LSTM Step Fn. 1.28 HM-LSTM Step Fn. &amp; Slope Annealing 1.27 Table 1: Bits-per-character on the Penn Treebank"
                    },
                    "intents": []
                }
            ],
            "corpusId": 1107124,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "952454718139dba3aafc6b3b67c4f514ac3964af",
            "isKey": true,
            "numCitedBy": 341,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a reparameterization of LSTM that brings the benefits of batch normalization to recurrent neural networks. Whereas previous works only apply batch normalization to the input-to-hidden transformation of RNNs, we demonstrate that it is both possible and beneficial to batch-normalize the hidden-to-hidden transition, thereby reducing internal covariate shift between time steps. We evaluate our proposal on various sequential problems such as sequence classification, language modeling and question answering. Our empirical results show that our batch-normalized LSTM consistently leads to faster convergence and improved generalization."
            },
            "slug": "Recurrent-Batch-Normalization-Cooijmans-Ballas",
            "title": {
                "fragments": [],
                "text": "Recurrent Batch Normalization"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is demonstrated that it is both possible and beneficial to batch-normalize the hidden-to-hidden transition, thereby reducing internal covariate shift between time steps."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9948791"
                        ],
                        "name": "A. Vezhnevets",
                        "slug": "A.-Vezhnevets",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Vezhnevets",
                            "middleNames": [
                                "Sasha"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vezhnevets"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255983"
                        ],
                        "name": "Volodymyr Mnih",
                        "slug": "Volodymyr-Mnih",
                        "structuredName": {
                            "firstName": "Volodymyr",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volodymyr Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2217144"
                        ],
                        "name": "Simon Osindero",
                        "slug": "Simon-Osindero",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Osindero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Osindero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70495322"
                        ],
                        "name": "J. Agapiou",
                        "slug": "J.-Agapiou",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Agapiou",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Agapiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Although the main goal of our proposed model is not regularization, we found that our model also shows very good generalization performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 83
                            }
                        ],
                        "text": "The straight-through estimator has also been used in Courbariaux et al. (2016) and Vezhnevets et al. (2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 341469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ba25cb493ac7a03fc15d3b936257c9a6c689c1d",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel deep recurrent neural network architecture that learns to build implicit plans in an end-to-end manner by purely interacting with an environment in reinforcement learning setting. The network builds an internal plan, which is continuously updated upon observation of the next input from the environment. It can also partition this internal representation into contiguous sub- sequences by learning for how long the plan can be committed to - i.e. followed without re-planing. Combining these properties, the proposed model, dubbed STRategic Attentive Writer (STRAW) can learn high-level, temporally abstracted macro- actions of varying lengths that are solely learnt from data without any prior information. These macro-actions enable both structured exploration and economic computation. We experimentally demonstrate that STRAW delivers strong improvements on several ATARI games by employing temporally extended planning strategies (e.g. Ms. Pacman and Frostbite). It is at the same time a general algorithm that can be applied on any sequence data. To that end, we also show that when trained on text prediction task, STRAW naturally predicts frequent n-grams (instead of macro-actions), demonstrating the generality of the approach."
            },
            "slug": "Strategic-Attentive-Writer-for-Learning-Vezhnevets-Mnih",
            "title": {
                "fragments": [],
                "text": "Strategic Attentive Writer for Learning Macro-Actions"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A novel deep recurrent neural network architecture that learns to build implicit plans in an end-to-end manner by purely interacting with an environment in reinforcement learning setting, which is at the same time a general algorithm that can be applied on any sequence data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 172
                            }
                        ],
                        "text": "For modelling temporal data, the recent resurgence of recurrent neural networks (RNN) has led to remarkable advances (Mikolov et al., 2010; Graves, 2013; Cho et al., 2014; Sutskever et al., 2014; Vinyals et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7961699,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "isKey": false,
            "numCitedBy": 14882,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier."
            },
            "slug": "Sequence-to-Sequence-Learning-with-Neural-Networks-Sutskever-Vinyals",
            "title": {
                "fragments": [],
                "text": "Sequence to Sequence Learning with Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure, and finds that reversing the order of the words in all source sentences improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "r proposed model on character-level language modelling and handwriting sequence generation. 1 Introduction One of the key principles of learning in deep neural networks as well as in the human brain (Bengio, 2009; LeCun et al., 2015; Schmidhuber, 2015) is to obtain a hierarchical representation with increasing levels of abstraction. A stack of representation layers, learned from the data in a way to optimize "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 174
                            }
                        ],
                        "text": "One of the key principles of learning in deep neural networks as well as in the human brain is to obtain a hierarchical representation with increasing levels of abstraction (Bengio, 2009; LeCun et al., 2015; Schmidhuber, 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207178999,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e60ff004dde5c13ec53087872cfcdd12e85beb57",
            "isKey": false,
            "numCitedBy": 7558,
            "numCiting": 345,
            "paperAbstract": {
                "fragments": [],
                "text": "Theoretical results strongly suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one needs deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult optimization task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas. This paper discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks."
            },
            "slug": "Learning-Deep-Architectures-for-AI-Bengio",
            "title": {
                "fragments": [],
                "text": "Learning Deep Architectures for AI"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer modelssuch as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Found. Trends Mach. Learn."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38367242"
                        ],
                        "name": "Yoon Kim",
                        "slug": "Yoon-Kim",
                        "structuredName": {
                            "firstName": "Yoon",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoon Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2262249"
                        ],
                        "name": "Yacine Jernite",
                        "slug": "Yacine-Jernite",
                        "structuredName": {
                            "firstName": "Yacine",
                            "lastName": "Jernite",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yacine Jernite"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746662"
                        ],
                        "name": "D. Sontag",
                        "slug": "D.-Sontag",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Sontag",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sontag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2531268"
                        ],
                        "name": "Alexander M. Rush",
                        "slug": "Alexander-M.-Rush",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Rush",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander M. Rush"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 41
                            }
                        ],
                        "text": "D kernels are proposed in Kim (2014) and Kim et al. (2015) for language modelling and sentence classification."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 686481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "891ce1687e2befddd19f54e4eef1d3f39c8dbaf7",
            "isKey": false,
            "numCitedBy": 1428,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n We describe a simple neural language model that relies only on character-level inputs. Predictions are still made at the word-level. Our model employs a convolutional neural network (CNN) and a highway net work over characters, whose output is given to a long short-term memory (LSTM) recurrent neural network language model (RNN-LM). On the English Penn Treebank the model is on par with the existing state-of-the-art despite having 60% fewer parameters. On languages with rich morphology (Arabic, Czech, French, German, Spanish, Russian), the model outperforms word-level/morpheme-level LSTM baselines, again with fewer parameters. The results suggest that on many languages, character inputs are sufficient for language modeling. Analysis of word representations obtained from the character composition part of the model reveals that the model is able to encode, from characters only, both semantic and orthographic information.\n \n"
            },
            "slug": "Character-Aware-Neural-Language-Models-Kim-Jernite",
            "title": {
                "fragments": [],
                "text": "Character-Aware Neural Language Models"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A simple neural language model that relies only on character-level inputs that is able to encode, from characters only, both semantic and orthographic information and suggests that on many languages, character inputs are sufficient for language modeling."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2245567"
                        ],
                        "name": "M. Karafi\u00e1t",
                        "slug": "M.-Karafi\u00e1t",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Karafi\u00e1t",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Karafi\u00e1t"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1816892"
                        ],
                        "name": "L. Burget",
                        "slug": "L.-Burget",
                        "structuredName": {
                            "firstName": "Luk\u00e1\u0161",
                            "lastName": "Burget",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Burget"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1899242"
                        ],
                        "name": "J. Cernock\u00fd",
                        "slug": "J.-Cernock\u00fd",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Cernock\u00fd",
                            "middleNames": [
                                "Honza"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cernock\u00fd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2803071"
                        ],
                        "name": "S. Khudanpur",
                        "slug": "S.-Khudanpur",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Khudanpur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Khudanpur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 59
                            }
                        ],
                        "text": "The norm of the gradient is clipped with a threshold of 1 (Mikolov et al., 2010; Pascanu et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 21
                            }
                        ],
                        "text": "Using the boundary states, at each time step, each layer selects one of the following operations: UPDATE, COPY or FLUSH."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 118
                            }
                        ],
                        "text": "For modelling temporal data, the recent resurgence of recurrent neural networks (RNN) has led to remarkable advances (Mikolov et al., 2010; Graves, 2013; Cho et al., 2014; Sutskever et al., 2014; Vinyals et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17048224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9819b600a828a57e1cde047bbe710d3446b30da5",
            "isKey": false,
            "numCitedBy": 4902,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A new recurrent neural network based language model (RNN LM) with applications to speech recognition is presented. Results indicate that it is possible to obtain around 50% reduction of perplexity by using mixture of several RNN LMs, compared to a state of the art backoff language model. Speech recognition experiments show around 18% reduction of word error rate on the Wall Street Journal task when comparing models trained on the same amount of data, and around 5% on the much harder NIST RT05 task, even when the backoff model is trained on much more data than the RNN LM. We provide ample empirical evidence to suggest that connectionist language models are superior to standard n-gram techniques, except their high computational (training) complexity. Index Terms: language modeling, recurrent neural networks, speech recognition"
            },
            "slug": "Recurrent-neural-network-based-language-model-Mikolov-Karafi\u00e1t",
            "title": {
                "fragments": [],
                "text": "Recurrent neural network based language model"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results indicate that it is possible to obtain around 50% reduction of perplexity by using mixture of several RNN LMs, compared to a state of the art backoff language model."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3158246"
                        ],
                        "name": "Bart van Merrienboer",
                        "slug": "Bart-van-Merrienboer",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Merrienboer",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bart van Merrienboer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1854385"
                        ],
                        "name": "\u00c7aglar G\u00fcl\u00e7ehre",
                        "slug": "\u00c7aglar-G\u00fcl\u00e7ehre",
                        "structuredName": {
                            "firstName": "\u00c7aglar",
                            "lastName": "G\u00fcl\u00e7ehre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c7aglar G\u00fcl\u00e7ehre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335364"
                        ],
                        "name": "Dzmitry Bahdanau",
                        "slug": "Dzmitry-Bahdanau",
                        "structuredName": {
                            "firstName": "Dzmitry",
                            "lastName": "Bahdanau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dzmitry Bahdanau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076086"
                        ],
                        "name": "Fethi Bougares",
                        "slug": "Fethi-Bougares",
                        "structuredName": {
                            "firstName": "Fethi",
                            "lastName": "Bougares",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fethi Bougares"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518416"
                        ],
                        "name": "Holger Schwenk",
                        "slug": "Holger-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Holger Schwenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 199
                            }
                        ],
                        "text": "Note that the FLUSH operation is a hard reset in the sense that it completely erases all the previous states of the same layer, which is different from the soft reset or soft forget operation in the GRU or LSTM."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 76
                            }
                        ],
                        "text": "Unlike the leaky integration of the LSTM or the Gated Recurrent Unit (GRU) (Cho et al., 2014), the COPY operation retains the whole states without any loss of information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 154
                            }
                        ],
                        "text": "For modelling temporal data, the recent resurgence of recurrent neural networks (RNN) has led to remarkable advances (Mikolov et al., 2010; Graves, 2013; Cho et al., 2014; Sutskever et al., 2014; Vinyals et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5590763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b544dfe355a5070b60986319a3f51fb45d1348e",
            "isKey": false,
            "numCitedBy": 15055,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel neural network model called RNN Encoder\u2010 Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder\u2010Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases."
            },
            "slug": "Learning-Phrase-Representations-using-RNN-for-Cho-Merrienboer",
            "title": {
                "fragments": [],
                "text": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Qualitatively, the proposed RNN Encoder\u2010Decoder model learns a semantically and syntactically meaningful representation of linguistic phrases."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145055042"
                        ],
                        "name": "David Krueger",
                        "slug": "David-Krueger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Krueger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Krueger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422058"
                        ],
                        "name": "Tegan Maharaj",
                        "slug": "Tegan-Maharaj",
                        "structuredName": {
                            "firstName": "Tegan",
                            "lastName": "Maharaj",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tegan Maharaj"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064949280"
                        ],
                        "name": "J'anos Kram'ar",
                        "slug": "J'anos-Kram'ar",
                        "structuredName": {
                            "firstName": "J'anos",
                            "lastName": "Kram'ar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J'anos Kram'ar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145507036"
                        ],
                        "name": "M. Pezeshki",
                        "slug": "M.-Pezeshki",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Pezeshki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pezeshki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2482072"
                        ],
                        "name": "Nicolas Ballas",
                        "slug": "Nicolas-Ballas",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Ballas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Ballas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145604319"
                        ],
                        "name": "Nan Rosemary Ke",
                        "slug": "Nan-Rosemary-Ke",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Ke",
                            "middleNames": [
                                "Rosemary"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nan Rosemary Ke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996705"
                        ],
                        "name": "Anirudh Goyal",
                        "slug": "Anirudh-Goyal",
                        "structuredName": {
                            "firstName": "Anirudh",
                            "lastName": "Goyal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anirudh Goyal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98109738"
                        ],
                        "name": "Chris Pal",
                        "slug": "Chris-Pal",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Pal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Pal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 3
                            }
                        ],
                        "text": "In Zoneout, an identity transformation is randomly applied to each hidden unit at each time step according to a Bernoulli distribution."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 19
                            }
                        ],
                        "text": "While the focus of Zoneout is to propose a regularization technique similar to dropout (Srivastava et al., 2014) (where the regularization strength is controlled by a hyperparameter), our model learns (a) to dynamically determine when to copy from the context inputs and (b) to discover the hierarchical multiscale structure and representation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 37
                            }
                        ],
                        "text": "Using the hierarchical boundary states, we implement three operations, UPDATE, COPY and FLUSH, and choose one of them at each time step."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 64
                            }
                        ],
                        "text": "The COPY operation used in our model can be related to Zoneout (Krueger et al., 2016) which is a recurrent generalization of stochastic depth (Huang et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12200521,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f0687bcd0a7d7fc91b8c5d36c003a38b8853105",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose zoneout, a novel method for regularizing RNNs. At each timestep, zoneout stochastically forces some hidden units to maintain their previous values. Like dropout, zoneout uses random noise to train a pseudo-ensemble, improving generalization. But by preserving instead of dropping hidden units, gradient information and state information are more readily propagated through time, as in feedforward stochastic depth networks. We perform an empirical investigation of various RNN regularizers, and find that zoneout gives significant performance improvements across tasks. We achieve competitive results with relatively simple models in character- and word-level language modelling on the Penn Treebank and Text8 datasets, and combining with recurrent batch normalization yields state-of-the-art results on permuted sequential MNIST."
            },
            "slug": "Zoneout:-Regularizing-RNNs-by-Randomly-Preserving-Krueger-Maharaj",
            "title": {
                "fragments": [],
                "text": "Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This work proposes zoneout, a novel method for regularizing RNNs that uses random noise to train a pseudo-ensemble, improving generalization and performs an empirical investigation of various RNN regularizers, and finds that zoneout gives significant performance improvements across tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2897313"
                        ],
                        "name": "Nitish Srivastava",
                        "slug": "Nitish-Srivastava",
                        "structuredName": {
                            "firstName": "Nitish",
                            "lastName": "Srivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nitish Srivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 9
                            }
                        ],
                        "text": "Unlike the leaky integration of the LSTM or the Gated Recurrent Unit (GRU) (Cho et al., 2014), the COPY operation retains the whole states without any loss of information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 88
                            }
                        ],
                        "text": "While the focus of Zoneout is to propose a regularization technique similar to dropout (Srivastava et al., 2014) (where the regularization strength is controlled by a hyperparameter), our model learns (a) to dynamically determine when to copy from the context inputs and (b) to discover the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6844431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34f25a8704614163c4095b3ee2fc969b60de4698",
            "isKey": false,
            "numCitedBy": 28162,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "slug": "Dropout:-a-simple-way-to-prevent-neural-networks-Srivastava-Hinton",
            "title": {
                "fragments": [],
                "text": "Dropout: a simple way to prevent neural networks from overfitting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065623360"
                        ],
                        "name": "Nicholas L\u00e9onard",
                        "slug": "Nicholas-L\u00e9onard",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "L\u00e9onard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicholas L\u00e9onard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 184
                            }
                        ],
                        "text": "Among a few methods for training a neural network with discrete variables such as the REINFORCE (Williams, 1992; Mnih & Gregor, 2014) and the straight-through estimator (Hinton, 2012; Bengio et al., 2013), we use the straightthrough estimator to train our model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Although the main goal of our proposed model is not regularization, we found that our model also shows very good generalization performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 59
                            }
                        ],
                        "text": "We find that the straight-through estimator (Hinton, 2012; Bengio et al., 2013; Courbariaux et al., 2016) is efficient for training this model containing discrete variables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18406556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62c76ca0b2790c34e85ba1cce09d47be317c7235",
            "isKey": false,
            "numCitedBy": 1508,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Stochastic neurons and hard non-linearities can be useful for a number of reasons in deep learning models, but in many cases they pose a challenging problem: how to estimate the gradient of a loss function with respect to the input of such stochastic or non-smooth neurons? I.e., can we \"back-propagate\" through these stochastic neurons? We examine this question, existing approaches, and compare four families of solutions, applicable in different settings. One of them is the minimum variance unbiased gradient estimator for stochatic binary neurons (a special case of the REINFORCE algorithm). A second approach, introduced here, decomposes the operation of a binary stochastic neuron into a stochastic binary part and a smooth differentiable part, which approximates the expected effect of the pure stochatic binary neuron to first order. A third approach involves the injection of additive or multiplicative noise in a computational graph that is otherwise differentiable. A fourth approach heuristically copies the gradient with respect to the stochastic output directly as an estimator of the gradient with respect to the sigmoid argument (we call this the straight-through estimator). To explore a context where these estimators are useful, we consider a small-scale version of {\\em conditional computation}, where sparse stochastic units form a distributed representation of gaters that can turn off in combinatorially many ways large chunks of the computation performed in the rest of the neural network. In this case, it is important that the gating units produce an actual 0 most of the time. The resulting sparsity can be potentially be exploited to greatly reduce the computational cost of large deep networks for which conditional computation would be useful."
            },
            "slug": "Estimating-or-Propagating-Gradients-Through-Neurons-Bengio-L\u00e9onard",
            "title": {
                "fragments": [],
                "text": "Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work considers a small-scale version of {\\em conditional computation}, where sparse stochastic units form a distributed representation of gaters that can turn off in combinatorially many ways large chunks of the computation performed in the rest of the neural network."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1993475"
                        ],
                        "name": "K. Rocki",
                        "slug": "K.-Rocki",
                        "structuredName": {
                            "firstName": "Kamil",
                            "lastName": "Rocki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rocki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1782515,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dded890956b37df5ac4c42b8ffbc142725f2801",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The following report introduces ideas augmenting standard Long Short Term Memory (LSTM) architecture with multiple memory cells per hidden unit in order to improve its generalization capabilities. It considers both deterministic and stochastic variants of memory operation. It is shown that the nondeterministic Array-LSTM approach improves state-of-the-art performance on character level text prediction achieving 1.402 BPC on enwik8 dataset. Furthermore, this report estabilishes baseline neural-based results of 1.12 BPC and 1.19 BPC for enwik9 and enwik10 datasets respectively."
            },
            "slug": "Recurrent-Memory-Array-Structures-Rocki",
            "title": {
                "fragments": [],
                "text": "Recurrent Memory Array Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that the nondeterministic Array-LSTM approach improves state-of-the-art performance on character level text prediction achieving 1.402 BPC on enwik8 dataset."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335364"
                        ],
                        "name": "Dzmitry Bahdanau",
                        "slug": "Dzmitry-Bahdanau",
                        "structuredName": {
                            "firstName": "Dzmitry",
                            "lastName": "Bahdanau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dzmitry Bahdanau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2292403"
                        ],
                        "name": "J. Chorowski",
                        "slug": "J.-Chorowski",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Chorowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Chorowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1862138"
                        ],
                        "name": "Dmitriy Serdyuk",
                        "slug": "Dmitriy-Serdyuk",
                        "structuredName": {
                            "firstName": "Dmitriy",
                            "lastName": "Serdyuk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitriy Serdyuk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2616163"
                        ],
                        "name": "Philemon Brakel",
                        "slug": "Philemon-Brakel",
                        "structuredName": {
                            "firstName": "Philemon",
                            "lastName": "Brakel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philemon Brakel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 9
                            }
                        ],
                        "text": "This model, called a hierarchical multiscale recurrent neural network (HM-RNN), does not assign fixed update rates, but adaptively determines proper update times corresponding to different abstraction levels of the layers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 117
                            }
                        ],
                        "text": "The most popular approach is to set the timescales as hyperparameters (El Hihi & Bengio, 1995; Koutn\u00edk et al., 2014; Bahdanau et al., 2016) instead of treating them as dynamic variables that can be learned from the data (Schmidhuber, 1991; 1992; Chung et al., 2015; 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 32
                            }
                        ],
                        "text": "Also, in Chan et al. (2016) and Bahdanau et al. (2016), the authors proposed to obtain high-level representation of the sequences of reduced length by repeatedly merging or pooling the lower-level representation of the sequences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11760007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "878ba5458e9e51f0b341fd9117fa0b43ef4096d3",
            "isKey": false,
            "numCitedBy": 900,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Many state-of-the-art Large Vocabulary Continuous Speech Recognition (LVCSR) Systems are hybrids of neural networks and Hidden Markov Models (HMMs). Recently, more direct end-to-end methods have been investigated, in which neural architectures were trained to model sequences of characters [1,2]. To our knowledge, all these approaches relied on Connectionist Temporal Classification [3] modules. We investigate an alternative method for sequence modelling based on an attention mechanism that allows a Recurrent Neural Network (RNN) to learn alignments between sequences of input frames and output labels. We show how this setup can be applied to LVCSR by integrating the decoding RNN with an n-gram language model and by speeding up its operation by constraining selections made by the attention mechanism and by reducing the source sequence lengths by pooling information over time. Recognition accuracies similar to other HMM-free RNN-based approaches are reported for the Wall Street Journal corpus."
            },
            "slug": "End-to-end-attention-based-large-vocabulary-speech-Bahdanau-Chorowski",
            "title": {
                "fragments": [],
                "text": "End-to-end attention-based large vocabulary speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work investigates an alternative method for sequence modelling based on an attention mechanism that allows a Recurrent Neural Network (RNN) to learn alignments between sequences of input frames and output labels."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255983"
                        ],
                        "name": "Volodymyr Mnih",
                        "slug": "Volodymyr-Mnih",
                        "structuredName": {
                            "firstName": "Volodymyr",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volodymyr Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2228824"
                        ],
                        "name": "Andrei A. Rusu",
                        "slug": "Andrei-A.-Rusu",
                        "structuredName": {
                            "firstName": "Andrei",
                            "lastName": "Rusu",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrei A. Rusu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144056327"
                        ],
                        "name": "J. Veness",
                        "slug": "J.-Veness",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Veness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Veness"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792298"
                        ],
                        "name": "Marc G. Bellemare",
                        "slug": "Marc-G.-Bellemare",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Bellemare",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc G. Bellemare"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137672"
                        ],
                        "name": "Martin A. Riedmiller",
                        "slug": "Martin-A.-Riedmiller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Riedmiller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Riedmiller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145600108"
                        ],
                        "name": "A. Fidjeland",
                        "slug": "A.-Fidjeland",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Fidjeland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fidjeland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2273072"
                        ],
                        "name": "Georg Ostrovski",
                        "slug": "Georg-Ostrovski",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Ostrovski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Georg Ostrovski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48348688"
                        ],
                        "name": "Stig Petersen",
                        "slug": "Stig-Petersen",
                        "structuredName": {
                            "firstName": "Stig",
                            "lastName": "Petersen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stig Petersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50388928"
                        ],
                        "name": "Charlie Beattie",
                        "slug": "Charlie-Beattie",
                        "structuredName": {
                            "firstName": "Charlie",
                            "lastName": "Beattie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charlie Beattie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49813280"
                        ],
                        "name": "A. Sadik",
                        "slug": "A.-Sadik",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Sadik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sadik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2460849"
                        ],
                        "name": "Ioannis Antonoglou",
                        "slug": "Ioannis-Antonoglou",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Antonoglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ioannis Antonoglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143776287"
                        ],
                        "name": "Helen King",
                        "slug": "Helen-King",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "King",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helen King"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2106164"
                        ],
                        "name": "D. Kumaran",
                        "slug": "D.-Kumaran",
                        "structuredName": {
                            "firstName": "Dharshan",
                            "lastName": "Kumaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kumaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34313265"
                        ],
                        "name": "S. Legg",
                        "slug": "S.-Legg",
                        "structuredName": {
                            "firstName": "Shane",
                            "lastName": "Legg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Legg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48987704"
                        ],
                        "name": "D. Hassabis",
                        "slug": "D.-Hassabis",
                        "structuredName": {
                            "firstName": "Demis",
                            "lastName": "Hassabis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hassabis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "2013). The remarkable recent successes of the deep convolutional neural networks are particularly based on this ability to learn hierarchical representation for spatial data (Krizhevsky et al., 2012; Mnih et al., 2015; Silver et al., 2016). For modelling temporal data, the recent resurgence of recurrent neural networks (RNN) has led to remarkable advances (Graves et al., 2008, 2013; Cho et al., 2014; Sutskever et "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 205242740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d",
            "isKey": false,
            "numCitedBy": 16192,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks."
            },
            "slug": "Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu",
            "title": {
                "fragments": [],
                "text": "Human-level control through deep reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398996347"
                        ],
                        "name": "M. Costa-juss\u00e0",
                        "slug": "M.-Costa-juss\u00e0",
                        "structuredName": {
                            "firstName": "Marta",
                            "lastName": "Costa-juss\u00e0",
                            "middleNames": [
                                "Ruiz"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Costa-juss\u00e0"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779548"
                        ],
                        "name": "Jos\u00e9 A. R. Fonollosa",
                        "slug": "Jos\u00e9-A.-R.-Fonollosa",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Fonollosa",
                            "middleNames": [
                                "A.",
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 A. R. Fonollosa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 3
                            }
                        ],
                        "text": "In Ling et al. (2015), after obtaining the word boundary via tokenization, the HRNN architecture is used for neural machine translation by modelling the characters and words using the first and second RNN layers, respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 199
                            }
                        ],
                        "text": "For the character-level language modelling, the HM-RNN achieves the state-of-the-art results on the Text8 dataset, and comparable results to the state-of-the-art on the Penn Treebank and Hutter Prize Wikipedia datasets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Hutter Prize Wikipedia The Hutter Prize Wikipedia (enwik8) dataset (Hutter, 2012) contains 205 symbols including XML markups and special characters."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 267
                            }
                        ],
                        "text": "Visualizing Learned Hierarchical Multiscale Structure In Figure 3 and 4, we visualize the boundaries detected by the boundary detectors of the HM-LSTM while reading a character sequence of total length 270 taken from the validation set of either the Penn Treebank or Hutter Prize Wikipedia dataset."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 171
                            }
                        ],
                        "text": "On the character-level language modelling, the HM-LSTM achieved state-of-the-art result on the Text8 dataset and comparable results to the state-of-the-art results on the Penn Treebank and Hutter Prize Wikipedia datasets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 62
                            }
                        ],
                        "text": "There have been various approaches to implementing the multiscale RNNs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 92
                            }
                        ],
                        "text": "We evaluate our model on three benchmark text corpora: (1) Penn Treebank, (2) Text8 and (3) Hutter Prize Wikipedia."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 175
                            }
                        ],
                        "text": "To begin with, we provide an example of how a stacked RNN can model temporal data in an ideal setting, i.e., when the hierarchy of segments is provided (Sordoni et al., 2015; Ling et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1712853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d070993cb75407b285e14cb8aac0077624ef4d9",
            "isKey": true,
            "numCitedBy": 266,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural Machine Translation (MT) has reached state-of-the-art results. However, one of the main challenges that neural MT still faces is dealing with very large vocabularies and morphologically rich languages. In this paper, we propose a neural MT system using character-based embeddings in combination with convolutional and highway layers to replace the standard lookup-based word representations. The resulting unlimited-vocabulary and affix-aware source word embeddings are tested in a state-of-the-art neural MT based on an attention-based bidirectional recurrent neural network. The proposed MT scheme provides improved results even when the source language is not morphologically rich. Improvements up to 3 BLEU points are obtained in the German-English WMT task."
            },
            "slug": "Character-based-Neural-Machine-Translation-Costa-juss\u00e0-Fonollosa",
            "title": {
                "fragments": [],
                "text": "Character-based Neural Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A neural MT system using character-based embeddings in combination with convolutional and highway layers to replace the standard lookup-based word representations to provide improved results even when the source language is not morphologically rich is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143983679"
                        ],
                        "name": "Gao Huang",
                        "slug": "Gao-Huang",
                        "structuredName": {
                            "firstName": "Gao",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gao Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117103358"
                        ],
                        "name": "Yu Sun",
                        "slug": "Yu-Sun",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109168016"
                        ],
                        "name": "Zhuang Liu",
                        "slug": "Zhuang-Liu",
                        "structuredName": {
                            "firstName": "Zhuang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhuang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3371029"
                        ],
                        "name": "Daniel Sedra",
                        "slug": "Daniel-Sedra",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Sedra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Sedra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7446832"
                        ],
                        "name": "Kilian Q. Weinberger",
                        "slug": "Kilian-Q.-Weinberger",
                        "structuredName": {
                            "firstName": "Kilian",
                            "lastName": "Weinberger",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kilian Q. Weinberger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 116
                            }
                        ],
                        "text": "Using the hierarchical boundary states, we implement three operations, UPDATE, COPY and FLUSH, and choose one of them at each time step."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 143
                            }
                        ],
                        "text": "The COPY operation used in our model can be related to Zoneout (Krueger et al., 2016) which is a recurrent generalization of stochastic depth (Huang et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6773885,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51db1f3c8dfc7d4077da39c96bb90a6358128111",
            "isKey": false,
            "numCitedBy": 1426,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Very deep convolutional networks with hundreds of layers have led to significant reductions in error on competitive benchmarks. Although the unmatched expressiveness of the many layers can be highly desirable at test time, training very deep networks comes with its own set of challenges. The gradients can vanish, the forward flow often diminishes, and the training time can be painfully slow. To address these problems, we propose stochastic depth, a training procedure that enables the seemingly contradictory setup to train short networks and use deep networks at test time. We start with very deep networks but during training, for each mini-batch, randomly drop a subset of layers and bypass them with the identity function. This simple approach complements the recent success of residual networks. It reduces training time substantially and improves the test error significantly on almost all data sets that we used for evaluation. With stochastic depth we can increase the depth of residual networks even beyond 1200 layers and still yield meaningful improvements in test error (4.91 % on CIFAR-10)."
            },
            "slug": "Deep-Networks-with-Stochastic-Depth-Huang-Sun",
            "title": {
                "fragments": [],
                "text": "Deep Networks with Stochastic Depth"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Stochastic depth is proposed, a training procedure that enables the seemingly contradictory setup to train short networks and use deep networks at test time and reduces training time substantially and improves the test error significantly on almost all data sets that were used for evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2332513,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c915c1eecb217c123a36dc6d3ce52d12c742614",
            "isKey": false,
            "numCitedBy": 5181,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms."
            },
            "slug": "Simple-statistical-gradient-following-algorithms-Williams",
            "title": {
                "fragments": [],
                "text": "Simple statistical gradient-following algorithms for connectionist reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units that are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reInforcement tasks, and they do this without explicitly computing gradient estimates."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145055042"
                        ],
                        "name": "David Krueger",
                        "slug": "David-Krueger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Krueger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Krueger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710604"
                        ],
                        "name": "R. Memisevic",
                        "slug": "R.-Memisevic",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Memisevic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Memisevic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15194782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f84d5add20d4df0a6c89c47a920354c272cbdbd8",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We stabilize the activations of Recurrent Neural Networks (RNNs) by penalizing the squared distance between successive hidden states' norms. \nThis penalty term is an effective regularizer for RNNs including LSTMs and IRNNs, improving performance on character-level language modeling and phoneme recognition, and outperforming weight noise and dropout. \nWe achieve competitive performance (18.6\\% PER) on the TIMIT phoneme recognition task for RNNs evaluated without beam search or an RNN transducer. \nWith this penalty term, IRNN can achieve similar performance to LSTM on language modeling, although adding the penalty term to the LSTM results in superior performance. \nOur penalty term also prevents the exponential growth of IRNN's activations outside of their training horizon, allowing them to generalize to much longer sequences."
            },
            "slug": "Regularizing-RNNs-by-Stabilizing-Activations-Krueger-Memisevic",
            "title": {
                "fragments": [],
                "text": "Regularizing RNNs by Stabilizing Activations"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This penalty term is an effective regularizer for RNNs including LSTMs and IRNNs, improving performance on character-level language modeling and phoneme recognition, and outperforming weight noise and dropout."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51131802"
                        ],
                        "name": "J. Kiros",
                        "slug": "J.-Kiros",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Kiros",
                            "middleNames": [
                                "Ryan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kiros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 136
                            }
                        ],
                        "text": "However, considering the fact that non-stationarity is prevalent in temporal data, and that many entities of abstraction such as words and sentences are in variable length, we claim that it is important for an RNN to dynamically adapt its timescales to the particulars of the input entities of\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "3The plot function could be found at blog.otoro.net/2015/12/12/handwriting-generation-demo-in-tensorflow/."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The performance on real-valued sequences is tested on the handwriting sequence generation in which a relatively clear hierarchical multiscale structure exists compared to other data such as speech signals."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026kind of approach is not well suited to the case where different segments in the hierarchical decomposition have different lengths: for example, different words have different lengths, so a fixed hierarchy would not update its upper-level units in synchrony with the natural boundaries in the data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 35
                            }
                        ],
                        "text": "We also apply layer normalization (Ba et al., 2016) to our models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 198
                            }
                        ],
                        "text": "The UPDATE operation is performed to update the summary representation of the layer ` if the boundary z`\u22121t is detected from the layer below but the boundary z ` t\u22121 was not found at the previous time step."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8236317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97fb4e3d45bb098e27e0071448b6152217bd35a5",
            "isKey": true,
            "numCitedBy": 3051,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feedforward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques."
            },
            "slug": "Layer-Normalization-Ba-Kiros",
            "title": {
                "fragments": [],
                "text": "Layer Normalization"
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041695"
                        ],
                        "name": "Alessandro Sordoni",
                        "slug": "Alessandro-Sordoni",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sordoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Sordoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2507979"
                        ],
                        "name": "H. Vahabi",
                        "slug": "H.-Vahabi",
                        "structuredName": {
                            "firstName": "Hossein",
                            "lastName": "Vahabi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Vahabi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784800"
                        ],
                        "name": "C. Lioma",
                        "slug": "C.-Lioma",
                        "structuredName": {
                            "firstName": "Christina",
                            "lastName": "Lioma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lioma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707651"
                        ],
                        "name": "J. Simonsen",
                        "slug": "J.-Simonsen",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Simonsen",
                            "middleNames": [
                                "Grue"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Simonsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50204644"
                        ],
                        "name": "J. Nie",
                        "slug": "J.-Nie",
                        "structuredName": {
                            "firstName": "Jianyun",
                            "lastName": "Nie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 261
                            }
                        ],
                        "text": "The most popular approach is to set the timescales as hyperparameters (El Hihi & Bengio, 1995; Koutn\u00edk et al., 2014; Bahdanau et al., 2016) instead of treating them as dynamic variables that can be learned from the data (Schmidhuber, 1991; 1992; Chung et al., 2015; 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 177
                            }
                        ],
                        "text": "For the character-level language modelling, the HM-RNN achieves the state-of-the-art results on the Text8 dataset, and comparable results to the state-of-the-art on the Penn Treebank and Hutter Prize Wikipedia datasets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 258,
                                "start": 250
                            }
                        ],
                        "text": "Visualizing Learned Hierarchical Multiscale Structure In Figure 3 and 4, we visualize the boundaries detected by the boundary detectors of the HM-LSTM while reading a character sequence of total length 270 taken from the validation set of either the Penn Treebank or Hutter Prize Wikipedia dataset."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 171
                            }
                        ],
                        "text": "On the character-level language modelling, the HM-LSTM achieved state-of-the-art result on the Text8 dataset and comparable results to the state-of-the-art results on the Penn Treebank and Hutter Prize Wikipedia datasets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 47
                            }
                        ],
                        "text": "A similar HRNN architecture is also adopted in Sordoni et al. (2015) to model dialogue utterances."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 74
                            }
                        ],
                        "text": "While this is trivial if the hierarchical boundary structure is provided (Sordoni et al., 2015), it has been a challenge for an RNN to discover the latent hierarchical structure in temporal data without explicit boundary information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "Penn Treebank We process the Penn Treebank dataset (Marcus et al., 1993) by following the procedure introduced in Mikolov et al. (2012)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 59
                            }
                        ],
                        "text": "We evaluate our model on three benchmark text corpora: (1) Penn Treebank, (2) Text8 and (3) Hutter Prize Wikipedia."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 8
                            }
                        ],
                        "text": "For the Penn Treebank dataset, we use 512 units in each layer of the HM-LSTM and for the output embedding layer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 153
                            }
                        ],
                        "text": "To begin with, we provide an example of how a stacked RNN can model temporal data in an ideal setting, i.e., when the hierarchy of segments is provided (Sordoni et al., 2015; Ling et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215824871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb0d19804fd8d5be6deaf0059e0b7888e64205c3",
            "isKey": false,
            "numCitedBy": 424,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Users may strive to formulate an adequate textual query for their information need. Search engines assist the users by presenting query suggestions. To preserve the original search intent, suggestions should be context-aware and account for the previous queries issued by the user. Achieving context awareness is challenging due to data sparsity. We present a novel hierarchical recurrent encoder-decoder architecture that makes possible to account for sequences of previous queries of arbitrary lengths. As a result, our suggestions are sensitive to the order of queries in the context while avoiding data sparsity. Additionally, our model can suggest for rare, or long-tail, queries. The produced suggestions are synthetic and are sampled one word at a time, using computationally cheap decoding techniques. This is in contrast to current synthetic suggestion models relying upon machine learning pipelines and hand-engineered feature sets. Results show that our model outperforms existing context-aware approaches in a next query prediction setting. In addition to query suggestion, our architecture is general enough to be used in a variety of other applications."
            },
            "slug": "A-Hierarchical-Recurrent-Encoder-Decoder-for-Query-Sordoni-Bengio",
            "title": {
                "fragments": [],
                "text": "A Hierarchical Recurrent Encoder-Decoder for Generative Context-Aware Query Suggestion"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents a novel hierarchical recurrent encoder-decoder architecture that makes possible to account for sequences of previous queries of arbitrary lengths and is sensitive to the order of queries in the context while avoiding data sparsity."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 168
                            }
                        ],
                        "text": "The remarkable recent successes of the deep convolutional neural networks are particularly based on this ability to learn hierarchical representation for spatial data (Krizhevsky et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195908774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "isKey": false,
            "numCitedBy": 80976,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
            },
            "slug": "ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever",
            "title": {
                "fragments": [],
                "text": "ImageNet classification with deep convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5808102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d376d6978dad0374edfa6709c9556b42d3594d3",
            "isKey": false,
            "numCitedBy": 29251,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters."
            },
            "slug": "Batch-Normalization:-Accelerating-Deep-Network-by-Ioffe-Szegedy",
            "title": {
                "fragments": [],
                "text": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38367242"
                        ],
                        "name": "Yoon Kim",
                        "slug": "Yoon-Kim",
                        "structuredName": {
                            "firstName": "Yoon",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoon Kim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 26
                            }
                        ],
                        "text": "D kernels are proposed in Kim (2014) and Kim et al. (2015) for language modelling and sentence classification."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9672033,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba",
            "isKey": false,
            "numCitedBy": 10068,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks. We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks. Learning task-specific vectors through fine-tuning offers further gains in performance. We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors. The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification."
            },
            "slug": "Convolutional-Neural-Networks-for-Sentence-Kim",
            "title": {
                "fragments": [],
                "text": "Convolutional Neural Networks for Sentence Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification, and are proposed to allow for the use of both task-specific and static vectors."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": false,
            "numCitedBy": 90126,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726415"
                        ],
                        "name": "Alexander Toshev",
                        "slug": "Alexander-Toshev",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Toshev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Toshev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761978"
                        ],
                        "name": "D. Erhan",
                        "slug": "D.-Erhan",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Erhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Erhan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 196
                            }
                        ],
                        "text": "For modelling temporal data, the recent resurgence of recurrent neural networks (RNN) has led to remarkable advances (Mikolov et al., 2010; Graves, 2013; Cho et al., 2014; Sutskever et al., 2014; Vinyals et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1169492,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0",
            "isKey": false,
            "numCitedBy": 4511,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU-1 score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art."
            },
            "slug": "Show-and-tell:-A-neural-image-caption-generator-Vinyals-Toshev",
            "title": {
                "fragments": [],
                "text": "Show and tell: A neural image caption generator"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper presents a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388466"
                        ],
                        "name": "Matthieu Courbariaux",
                        "slug": "Matthieu-Courbariaux",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Courbariaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Courbariaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477463"
                        ],
                        "name": "Itay Hubara",
                        "slug": "Itay-Hubara",
                        "structuredName": {
                            "firstName": "Itay",
                            "lastName": "Hubara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Itay Hubara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1912398"
                        ],
                        "name": "Daniel Soudry",
                        "slug": "Daniel-Soudry",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Soudry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Soudry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387872181"
                        ],
                        "name": "Ran El-Yaniv",
                        "slug": "Ran-El-Yaniv",
                        "structuredName": {
                            "firstName": "Ran",
                            "lastName": "El-Yaniv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ran El-Yaniv"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Although the main goal of our proposed model is not regularization, we found that our model also shows very good generalization performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 53
                            }
                        ],
                        "text": "The straight-through estimator has also been used in Courbariaux et al. (2016) and Vezhnevets et al. (2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 80
                            }
                        ],
                        "text": "We find that the straight-through estimator (Hinton, 2012; Bengio et al., 2013; Courbariaux et al., 2016) is efficient for training this model containing discrete variables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14796162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6eecc808d4c74e7d0d7ef6b8a4112c985ced104d",
            "isKey": false,
            "numCitedBy": 1729,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a method to train Binarized Neural Networks (BNNs) - neural networks with binary weights and activations at run-time. At training-time the binary weights and activations are used for computing the parameters gradients. During the forward pass, BNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations, which is expected to substantially improve power-efficiency. To validate the effectiveness of BNNs we conduct two sets of experiments on the Torch7 and Theano frameworks. On both, BNNs achieved nearly state-of-the-art results over the MNIST, CIFAR-10 and SVHN datasets. Last but not least, we wrote a binary matrix multiplication GPU kernel with which it is possible to run our MNIST BNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The code for training and running our BNNs is available on-line."
            },
            "slug": "Binarized-Neural-Networks:-Training-Deep-Neural-and-Courbariaux-Hubara",
            "title": {
                "fragments": [],
                "text": "Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A binary matrix multiplication GPU kernel is written with which it is possible to run the MNIST BNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113861474"
                        ],
                        "name": "C. Bishop",
                        "slug": "C.-Bishop",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bishop"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "is experiment, we use the same model as the one used in the character-level language model, except that the output layer is modi\ufb01ed to predict real-valued outputs. We use the mixture density network (Bishop, 1994) as the output layer following Graves (2013), and use 400 units for each HM-LSTM layer and 800 units for the embedding layer of the output module. For comparison, we also evaluate a stacked LSTM which"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118227751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cf3569e045993dfe090749f26a55a768684ab86",
            "isKey": false,
            "numCitedBy": 407,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Minimization of a sum-of-squares or cross-entropy error function leads to network outputs which approximate the conditional averages of the target data, conditioned on the input vector. For classifications problems, with a suitably chosen target coding scheme, these averages represent the posterior probabilities of class membership, and so can be regarded as optimal. For problems involving the prediction of continuous variables, however, the conditional averages provide only a very limited description of the properties of the target variables. This is particularly true for problems in which the mapping to be learned is multi-valued, as often arises in the solution of inverse problems, since the average of several correct target values is not necessarily itself a correct value. In order to obtain a complete description of the data, for the purposes of predicting the outputs corresponding to new input vectors, we must model the conditional probability distribution of the target data, again conditioned on the input vector. In this paper we introduce a new class of network models obtained by combining a conventional neural network with a mixture density model. The complete system is called a Mixture Density Network, and can in principle represent arbitrary conditional probability distributions in the same way that a conventional neural network can represent arbitrary functions. We demonstrate the effectiveness of Mixture Density Networks using both a toy problem and a problem involving robot inverse kinematics."
            },
            "slug": "Mixture-density-networks-Bishop",
            "title": {
                "fragments": [],
                "text": "Mixture density networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper introduces a new class of network models obtained by combining a conventional neural network with a mixture density model, called a Mixture Density Network, which can in principle represent arbitrary conditional probability distributions in the same way that aventional neural network can represent arbitrary functions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50196944"
                        ],
                        "name": "Judy Hoffman",
                        "slug": "Judy-Hoffman",
                        "structuredName": {
                            "firstName": "Judy",
                            "lastName": "Hoffman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Judy Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368132"
                        ],
                        "name": "Eric Tzeng",
                        "slug": "Eric-Tzeng",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Tzeng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Tzeng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7408951"
                        ],
                        "name": "Jeff Donahue",
                        "slug": "Jeff-Donahue",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Donahue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Donahue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39978391"
                        ],
                        "name": "Yangqing Jia",
                        "slug": "Yangqing-Jia",
                        "structuredName": {
                            "firstName": "Yangqing",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangqing Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2903226"
                        ],
                        "name": "Kate Saenko",
                        "slug": "Kate-Saenko",
                        "structuredName": {
                            "firstName": "Kate",
                            "lastName": "Saenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kate Saenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 151
                            }
                        ],
                        "text": "\u2026learned from the data in a way to optimize the target task, make deep neural networks entertain advantages such as generalization to unseen examples (Hoffman et al., 2013), sharing learned knowledge among multiple tasks, and discovering disentangling factors of variation (Kingma & Welling, 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9747411,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6492351b7e6a33d7a06d6141572467acd8ee3051",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-of-the-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost."
            },
            "slug": "One-Shot-Adaptation-of-Supervised-Deep-Models-Hoffman-Tzeng",
            "title": {
                "fragments": [],
                "text": "One-Shot Adaptation of Supervised Deep Convolutional Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper shows that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias, and proposes several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3371403"
                        ],
                        "name": "J. Kleinberg",
                        "slug": "J.-Kleinberg",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Kleinberg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kleinberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "mong the long-standing challenges of RNNs in spite of the fact that hierarchical multiscale structures naturally exist in many temporal data (Schmidhuber, 1991; Mozer, 1993; El Hihi and Bengio, 1995; Kleinberg, 2003; Koutn\u00edk et al., 2014; Chung et al., 2016). For example, we can observe the following structures: (phone -&gt; phoneme -&gt; morpheme -&gt; sentence) from speech signals, (character -&gt; word -&gt; "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15539653,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a38468d0c7bc403581740324f229b61f85c2a706",
            "isKey": false,
            "numCitedBy": 1249,
            "numCiting": 86,
            "paperAbstract": {
                "fragments": [],
                "text": "A fundamental problem in text data mining is to extract meaningful structure from document streams that arrive continuously over time. E-mail and news articles are two natural examples of such streams, each characterized by topics that appear, grow in intensity for a period of time, and then fade away. The published literature in a particular research field can be seen to exhibit similar phenomena over a much longer time scale. Underlying much of the text mining work in this area is the following intuitive premise\u2014that the appearance of a topic in a document stream is signaled by a \u201cburst of activity,\u201d with certain features rising sharply in frequency as the topic emerges.The goal of the present work is to develop a formal approach for modeling such \u201cbursts,\u201d in such a way that they can be robustly and efficiently identified, and can provide an organizational framework for analyzing the underlying content. The approach is based on modeling the stream using an infinite-state automaton, in which bursts appear naturally as state transitions; it can be viewed as drawing an analogy with models from queueing theory for bursty network traffic. The resulting algorithms are highly efficient, and yield a nested representation of the set of bursts that imposes a hierarchical structure on the overall stream. Experiments with e-mail and research paper archives suggest that the resulting structures have a natural meaning in terms of the content that gave rise to them."
            },
            "slug": "Bursty-and-Hierarchical-Structure-in-Streams-Kleinberg",
            "title": {
                "fragments": [],
                "text": "Bursty and Hierarchical Structure in Streams"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The goal of the present work is to develop a formal approach for modeling such \u201cbursts,\u201d in such a way that they can be robustly and efficiently identified, and can provide an organizational framework for analyzing the underlying content."
            },
            "venue": {
                "fragments": [],
                "text": "Data Mining and Knowledge Discovery"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388360943"
                        ],
                        "name": "Rami Al-Rfou",
                        "slug": "Rami-Al-Rfou",
                        "structuredName": {
                            "firstName": "Rami",
                            "lastName": "Al-Rfou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rami Al-Rfou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815021"
                        ],
                        "name": "Guillaume Alain",
                        "slug": "Guillaume-Alain",
                        "structuredName": {
                            "firstName": "Guillaume",
                            "lastName": "Alain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guillaume Alain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2634674"
                        ],
                        "name": "Amjad Almahairi",
                        "slug": "Amjad-Almahairi",
                        "structuredName": {
                            "firstName": "Amjad",
                            "lastName": "Almahairi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amjad Almahairi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065022368"
                        ],
                        "name": "Christof Angerm\u00fcller",
                        "slug": "Christof-Angerm\u00fcller",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Angerm\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christof Angerm\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335364"
                        ],
                        "name": "Dzmitry Bahdanau",
                        "slug": "Dzmitry-Bahdanau",
                        "structuredName": {
                            "firstName": "Dzmitry",
                            "lastName": "Bahdanau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dzmitry Bahdanau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2482072"
                        ],
                        "name": "Nicolas Ballas",
                        "slug": "Nicolas-Ballas",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Ballas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Ballas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227028"
                        ],
                        "name": "Fr\u00e9d\u00e9ric Bastien",
                        "slug": "Fr\u00e9d\u00e9ric-Bastien",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Bastien",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fr\u00e9d\u00e9ric Bastien"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145040409"
                        ],
                        "name": "Justin Bayer",
                        "slug": "Justin-Bayer",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Bayer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Justin Bayer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144336979"
                        ],
                        "name": "A. Belikov",
                        "slug": "A.-Belikov",
                        "structuredName": {
                            "firstName": "Anatoly",
                            "lastName": "Belikov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Belikov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31984932"
                        ],
                        "name": "A. Belopolsky",
                        "slug": "A.-Belopolsky",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Belopolsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Belopolsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47944877"
                        ],
                        "name": "Arnaud Bergeron",
                        "slug": "Arnaud-Bergeron",
                        "structuredName": {
                            "firstName": "Arnaud",
                            "lastName": "Bergeron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnaud Bergeron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32837403"
                        ],
                        "name": "J. Bergstra",
                        "slug": "J.-Bergstra",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115295647"
                        ],
                        "name": "Valentin Bisson",
                        "slug": "Valentin-Bisson",
                        "structuredName": {
                            "firstName": "Valentin",
                            "lastName": "Bisson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Valentin Bisson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32308836"
                        ],
                        "name": "Josh Bleecher Snyder",
                        "slug": "Josh-Bleecher-Snyder",
                        "structuredName": {
                            "firstName": "Josh",
                            "lastName": "Snyder",
                            "middleNames": [
                                "Bleecher"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josh Bleecher Snyder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065828537"
                        ],
                        "name": "Nicolas Bouchard",
                        "slug": "Nicolas-Bouchard",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Bouchard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Bouchard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1395619597"
                        ],
                        "name": "Nicolas Boulanger-Lewandowski",
                        "slug": "Nicolas-Boulanger-Lewandowski",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Boulanger-Lewandowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Boulanger-Lewandowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2900675"
                        ],
                        "name": "Xavier Bouthillier",
                        "slug": "Xavier-Bouthillier",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Bouthillier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xavier Bouthillier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2346028"
                        ],
                        "name": "A. D. Br\u00e9bisson",
                        "slug": "A.-D.-Br\u00e9bisson",
                        "structuredName": {
                            "firstName": "Alexandre",
                            "lastName": "Br\u00e9bisson",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. D. Br\u00e9bisson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967465"
                        ],
                        "name": "Olivier Breuleux",
                        "slug": "Olivier-Breuleux",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Breuleux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olivier Breuleux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153921980"
                        ],
                        "name": "P. Carrier",
                        "slug": "P.-Carrier",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Carrier",
                            "middleNames": [
                                "Luc"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Carrier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2292403"
                        ],
                        "name": "J. Chorowski",
                        "slug": "J.-Chorowski",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Chorowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Chorowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145791315"
                        ],
                        "name": "P. Christiano",
                        "slug": "P.-Christiano",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Christiano",
                            "middleNames": [
                                "Francis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Christiano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2348758"
                        ],
                        "name": "Tim Cooijmans",
                        "slug": "Tim-Cooijmans",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cooijmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cooijmans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40638665"
                        ],
                        "name": "Marc-Alexandre C\u00f4t\u00e9",
                        "slug": "Marc-Alexandre-C\u00f4t\u00e9",
                        "structuredName": {
                            "firstName": "Marc-Alexandre",
                            "lastName": "C\u00f4t\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc-Alexandre C\u00f4t\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39977229"
                        ],
                        "name": "Myriam C\u00f4t\u00e9",
                        "slug": "Myriam-C\u00f4t\u00e9",
                        "structuredName": {
                            "firstName": "Myriam",
                            "lastName": "C\u00f4t\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Myriam C\u00f4t\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2921469"
                        ],
                        "name": "Yann Dauphin",
                        "slug": "Yann-Dauphin",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Dauphin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann Dauphin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2460212"
                        ],
                        "name": "Olivier Delalleau",
                        "slug": "Olivier-Delalleau",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Delalleau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olivier Delalleau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32604218"
                        ],
                        "name": "Julien Demouth",
                        "slug": "Julien-Demouth",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Demouth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julien Demouth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2755582"
                        ],
                        "name": "Guillaume Desjardins",
                        "slug": "Guillaume-Desjardins",
                        "structuredName": {
                            "firstName": "Guillaume",
                            "lastName": "Desjardins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guillaume Desjardins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48373216"
                        ],
                        "name": "S. Dieleman",
                        "slug": "S.-Dieleman",
                        "structuredName": {
                            "firstName": "Sander",
                            "lastName": "Dieleman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dieleman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46573521"
                        ],
                        "name": "Laurent Dinh",
                        "slug": "Laurent-Dinh",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Dinh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurent Dinh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812151"
                        ],
                        "name": "M\u00e9lanie Ducoffe",
                        "slug": "M\u00e9lanie-Ducoffe",
                        "structuredName": {
                            "firstName": "M\u00e9lanie",
                            "lastName": "Ducoffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M\u00e9lanie Ducoffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3074927"
                        ],
                        "name": "Vincent Dumoulin",
                        "slug": "Vincent-Dumoulin",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Dumoulin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Dumoulin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127597"
                        ],
                        "name": "S. Kahou",
                        "slug": "S.-Kahou",
                        "structuredName": {
                            "firstName": "Samira",
                            "lastName": "Kahou",
                            "middleNames": [
                                "Ebrahimi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kahou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761978"
                        ],
                        "name": "D. Erhan",
                        "slug": "D.-Erhan",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Erhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Erhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113846121"
                        ],
                        "name": "Ziye Fan",
                        "slug": "Ziye-Fan",
                        "structuredName": {
                            "firstName": "Ziye",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziye Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2345617"
                        ],
                        "name": "Orhan Firat",
                        "slug": "Orhan-Firat",
                        "structuredName": {
                            "firstName": "Orhan",
                            "lastName": "Firat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Orhan Firat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39844381"
                        ],
                        "name": "M. Germain",
                        "slug": "M.-Germain",
                        "structuredName": {
                            "firstName": "Mathieu",
                            "lastName": "Germain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Germain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3119801"
                        ],
                        "name": "Xavier Glorot",
                        "slug": "Xavier-Glorot",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Glorot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xavier Glorot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153440022"
                        ],
                        "name": "Ian J. Goodfellow",
                        "slug": "Ian-J.-Goodfellow",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Goodfellow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian J. Goodfellow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152130795"
                        ],
                        "name": "M. Graham",
                        "slug": "M.-Graham",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Graham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Graham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1854385"
                        ],
                        "name": "\u00c7aglar G\u00fcl\u00e7ehre",
                        "slug": "\u00c7aglar-G\u00fcl\u00e7ehre",
                        "structuredName": {
                            "firstName": "\u00c7aglar",
                            "lastName": "G\u00fcl\u00e7ehre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c7aglar G\u00fcl\u00e7ehre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144563741"
                        ],
                        "name": "P. Hamel",
                        "slug": "P.-Hamel",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Hamel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hamel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405640115"
                        ],
                        "name": "Iban Harlouchet",
                        "slug": "Iban-Harlouchet",
                        "structuredName": {
                            "firstName": "Iban",
                            "lastName": "Harlouchet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iban Harlouchet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114956664"
                        ],
                        "name": "J. Heng",
                        "slug": "J.-Heng",
                        "structuredName": {
                            "firstName": "Jean-Philippe",
                            "lastName": "Heng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Heng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2507883"
                        ],
                        "name": "Bal\u00e1zs Hidasi",
                        "slug": "Bal\u00e1zs-Hidasi",
                        "structuredName": {
                            "firstName": "Bal\u00e1zs",
                            "lastName": "Hidasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bal\u00e1zs Hidasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25056820"
                        ],
                        "name": "Sina Honari",
                        "slug": "Sina-Honari",
                        "structuredName": {
                            "firstName": "Sina",
                            "lastName": "Honari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sina Honari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49147969"
                        ],
                        "name": "Arjun Jain",
                        "slug": "Arjun-Jain",
                        "structuredName": {
                            "firstName": "Arjun",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arjun Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152857609"
                        ],
                        "name": "S\u00e9bastien Jean",
                        "slug": "S\u00e9bastien-Jean",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Jean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00e9bastien Jean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49104216"
                        ],
                        "name": "Kai Jia",
                        "slug": "Kai-Jia",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065766621"
                        ],
                        "name": "Mikhail Korobov",
                        "slug": "Mikhail-Korobov",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Korobov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikhail Korobov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144592382"
                        ],
                        "name": "Vivek Kulkarni",
                        "slug": "Vivek-Kulkarni",
                        "structuredName": {
                            "firstName": "Vivek",
                            "lastName": "Kulkarni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vivek Kulkarni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49071560"
                        ],
                        "name": "Alex Lamb",
                        "slug": "Alex-Lamb",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Lamb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Lamb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087941"
                        ],
                        "name": "Pascal Lamblin",
                        "slug": "Pascal-Lamblin",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Lamblin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Lamblin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065712703"
                        ],
                        "name": "Eric Larsen",
                        "slug": "Eric-Larsen",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Larsen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Larsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40201308"
                        ],
                        "name": "C\u00e9sar Laurent",
                        "slug": "C\u00e9sar-Laurent",
                        "structuredName": {
                            "firstName": "C\u00e9sar",
                            "lastName": "Laurent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C\u00e9sar Laurent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98258814"
                        ],
                        "name": "S. Lee",
                        "slug": "S.-Lee",
                        "structuredName": {
                            "firstName": "Sea",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118224452"
                        ],
                        "name": "S. Lefran\u00e7ois",
                        "slug": "S.-Lefran\u00e7ois",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lefran\u00e7ois",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lefran\u00e7ois"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066378869"
                        ],
                        "name": "S. Lemieux",
                        "slug": "S.-Lemieux",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lemieux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lemieux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065623360"
                        ],
                        "name": "Nicholas L\u00e9onard",
                        "slug": "Nicholas-L\u00e9onard",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "L\u00e9onard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicholas L\u00e9onard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3146592"
                        ],
                        "name": "Zhouhan Lin",
                        "slug": "Zhouhan-Lin",
                        "structuredName": {
                            "firstName": "Zhouhan",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhouhan Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3245814"
                        ],
                        "name": "J. Livezey",
                        "slug": "J.-Livezey",
                        "structuredName": {
                            "firstName": "Jesse",
                            "lastName": "Livezey",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Livezey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40532172"
                        ],
                        "name": "C. Lorenz",
                        "slug": "C.-Lorenz",
                        "structuredName": {
                            "firstName": "Cory",
                            "lastName": "Lorenz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lorenz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102472217"
                        ],
                        "name": "J. Lowin",
                        "slug": "J.-Lowin",
                        "structuredName": {
                            "firstName": "Jeremiah",
                            "lastName": "Lowin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lowin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087919644"
                        ],
                        "name": "Qianli Ma",
                        "slug": "Qianli-Ma",
                        "structuredName": {
                            "firstName": "Qianli",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qianli Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798462"
                        ],
                        "name": "Pierre-Antoine Manzagol",
                        "slug": "Pierre-Antoine-Manzagol",
                        "structuredName": {
                            "firstName": "Pierre-Antoine",
                            "lastName": "Manzagol",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre-Antoine Manzagol"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422889"
                        ],
                        "name": "Olivier Mastropietro",
                        "slug": "Olivier-Mastropietro",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Mastropietro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olivier Mastropietro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144431879"
                        ],
                        "name": "R. McGibbon",
                        "slug": "R.-McGibbon",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McGibbon",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McGibbon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710604"
                        ],
                        "name": "R. Memisevic",
                        "slug": "R.-Memisevic",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Memisevic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Memisevic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3158246"
                        ],
                        "name": "Bart van Merrienboer",
                        "slug": "Bart-van-Merrienboer",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Merrienboer",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bart van Merrienboer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748421"
                        ],
                        "name": "Vincent Michalski",
                        "slug": "Vincent-Michalski",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Michalski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Michalski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153583218"
                        ],
                        "name": "Mehdi Mirza",
                        "slug": "Mehdi-Mirza",
                        "structuredName": {
                            "firstName": "Mehdi",
                            "lastName": "Mirza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mehdi Mirza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40479190"
                        ],
                        "name": "A. Orlandi",
                        "slug": "A.-Orlandi",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Orlandi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Orlandi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1972076"
                        ],
                        "name": "C. Pal",
                        "slug": "C.-Pal",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Pal",
                            "middleNames": [
                                "Joseph"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Pal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996134"
                        ],
                        "name": "Razvan Pascanu",
                        "slug": "Razvan-Pascanu",
                        "structuredName": {
                            "firstName": "Razvan",
                            "lastName": "Pascanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Razvan Pascanu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145507036"
                        ],
                        "name": "M. Pezeshki",
                        "slug": "M.-Pezeshki",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Pezeshki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pezeshki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2402716"
                        ],
                        "name": "Colin Raffel",
                        "slug": "Colin-Raffel",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Raffel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Colin Raffel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49577546"
                        ],
                        "name": "D. Renshaw",
                        "slug": "D.-Renshaw",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Renshaw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Renshaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3146111"
                        ],
                        "name": "M. Rocklin",
                        "slug": "M.-Rocklin",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Rocklin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rocklin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144290131"
                        ],
                        "name": "Adriana Romero",
                        "slug": "Adriana-Romero",
                        "structuredName": {
                            "firstName": "Adriana",
                            "lastName": "Romero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adriana Romero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059592992"
                        ],
                        "name": "Markus Roth",
                        "slug": "Markus-Roth",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47696458"
                        ],
                        "name": "Peter Sadowski",
                        "slug": "Peter-Sadowski",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Sadowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Sadowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3373139"
                        ],
                        "name": "J. Salvatier",
                        "slug": "J.-Salvatier",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Salvatier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Salvatier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47918629"
                        ],
                        "name": "F. Savard",
                        "slug": "F.-Savard",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Savard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Savard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50764319"
                        ],
                        "name": "Jan Schl\u00fcter",
                        "slug": "Jan-Schl\u00fcter",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Schl\u00fcter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan Schl\u00fcter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47971768"
                        ],
                        "name": "J. Schulman",
                        "slug": "J.-Schulman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Schulman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schulman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116153"
                        ],
                        "name": "Gabriel Schwartz",
                        "slug": "Gabriel-Schwartz",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Schwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gabriel Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35224828"
                        ],
                        "name": "Iulian Serban",
                        "slug": "Iulian-Serban",
                        "structuredName": {
                            "firstName": "Iulian",
                            "lastName": "Serban",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iulian Serban"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1862138"
                        ],
                        "name": "Dmitriy Serdyuk",
                        "slug": "Dmitriy-Serdyuk",
                        "structuredName": {
                            "firstName": "Dmitriy",
                            "lastName": "Serdyuk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitriy Serdyuk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3197429"
                        ],
                        "name": "Samira Shabanian",
                        "slug": "Samira-Shabanian",
                        "structuredName": {
                            "firstName": "Samira",
                            "lastName": "Shabanian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samira Shabanian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060864166"
                        ],
                        "name": "\u00c9tienne Simon",
                        "slug": "\u00c9tienne-Simon",
                        "structuredName": {
                            "firstName": "\u00c9tienne",
                            "lastName": "Simon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c9tienne Simon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11115628"
                        ],
                        "name": "Sigurd Spieckermann",
                        "slug": "Sigurd-Spieckermann",
                        "structuredName": {
                            "firstName": "Sigurd",
                            "lastName": "Spieckermann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sigurd Spieckermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82487166"
                        ],
                        "name": "S. Subramanyam",
                        "slug": "S.-Subramanyam",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Subramanyam",
                            "middleNames": [
                                "Ramana"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Subramanyam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3407592"
                        ],
                        "name": "Jakub Sygnowski",
                        "slug": "Jakub-Sygnowski",
                        "structuredName": {
                            "firstName": "Jakub",
                            "lastName": "Sygnowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jakub Sygnowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66454233"
                        ],
                        "name": "J\u00e9r\u00e9mie Tanguay",
                        "slug": "J\u00e9r\u00e9mie-Tanguay",
                        "structuredName": {
                            "firstName": "J\u00e9r\u00e9mie",
                            "lastName": "Tanguay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J\u00e9r\u00e9mie Tanguay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51256193"
                        ],
                        "name": "Gijs van Tulder",
                        "slug": "Gijs-van-Tulder",
                        "structuredName": {
                            "firstName": "Gijs",
                            "lastName": "van Tulder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gijs van Tulder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153160559"
                        ],
                        "name": "Joseph P. Turian",
                        "slug": "Joseph-P.-Turian",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Turian",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph P. Turian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "19555508"
                        ],
                        "name": "S. Urban",
                        "slug": "S.-Urban",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Urban",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Urban"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120247189"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077146"
                        ],
                        "name": "Francesco Visin",
                        "slug": "Francesco-Visin",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Visin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francesco Visin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153559313"
                        ],
                        "name": "Harm de Vries",
                        "slug": "Harm-de-Vries",
                        "structuredName": {
                            "firstName": "Harm",
                            "lastName": "Vries",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harm de Vries"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393680089"
                        ],
                        "name": "David Warde-Farley",
                        "slug": "David-Warde-Farley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Warde-Farley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Warde-Farley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27358391"
                        ],
                        "name": "Dustin J. Webb",
                        "slug": "Dustin-J.-Webb",
                        "structuredName": {
                            "firstName": "Dustin",
                            "lastName": "Webb",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dustin J. Webb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117876053"
                        ],
                        "name": "M. Willson",
                        "slug": "M.-Willson",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Willson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Willson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36303818"
                        ],
                        "name": "Kelvin Xu",
                        "slug": "Kelvin-Xu",
                        "structuredName": {
                            "firstName": "Kelvin",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kelvin Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2954189"
                        ],
                        "name": "Lijun Xue",
                        "slug": "Lijun-Xue",
                        "structuredName": {
                            "firstName": "Lijun",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lijun Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2106357903"
                        ],
                        "name": "Li Yao",
                        "slug": "Li-Yao",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35097114"
                        ],
                        "name": "Saizheng Zhang",
                        "slug": "Saizheng-Zhang",
                        "structuredName": {
                            "firstName": "Saizheng",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saizheng Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153392903"
                        ],
                        "name": "Ying Zhang",
                        "slug": "Ying-Zhang",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8993325,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b570069f14c7588e066f7138e1f21af59d62e61",
            "isKey": false,
            "numCitedBy": 2076,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Theano is a Python library that allows to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. Since its introduction, it has been one of the most used CPU and GPU mathematical compilers - especially in the machine learning community - and has shown steady performance improvements. Theano is being actively and continuously developed since 2008, multiple frameworks have been built on top of it and it has been used to produce many state-of-the-art machine learning models. \nThe present article is structured as follows. Section I provides an overview of the Theano software and its community. Section II presents the principal features of Theano and how to use them, and compares them with other similar projects. Section III focuses on recently-introduced functionalities and improvements. Section IV compares the performance of Theano against Torch7 and TensorFlow on several machine learning models. Section V discusses current limitations of Theano and potential ways of improving it."
            },
            "slug": "Theano:-A-Python-framework-for-fast-computation-of-Al-Rfou-Alain",
            "title": {
                "fragments": [],
                "text": "Theano: A Python framework for fast computation of mathematical expressions"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The performance of Theano is compared against Torch7 and TensorFlow on several machine learning models and recently-introduced functionalities and improvements are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143913738"
                        ],
                        "name": "Santiago Fern\u00e1ndez",
                        "slug": "Santiago-Fern\u00e1ndez",
                        "structuredName": {
                            "firstName": "Santiago",
                            "lastName": "Fern\u00e1ndez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Santiago Fern\u00e1ndez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743758"
                        ],
                        "name": "M. Liwicki",
                        "slug": "M.-Liwicki",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Liwicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liwicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "r spatial data (Krizhevsky et al., 2012; Mnih et al., 2015; Silver et al., 2016). For modelling temporal data, the recent resurgence of recurrent neural networks (RNN) has led to remarkable advances (Graves et al., 2008, 2013; Cho et al., 2014; Sutskever et al., 2014; Vinyals et al., 2015). However, unlike the spatial data, learning both hierarchical and temporal representation has been among the long-standing chall"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14986843,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68db33b01ef82cbafb440e5f4bee30458cbb9871",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In online handwriting recognition the trajectory of the pen is recorded during writing. Although the trajectory provides a compact and complete representation of the written output, it is hard to transcribe directly, because each letter is spread over many pen locations. Most recognition systems therefore employ sophisticated preprocessing techniques to put the inputs into a more localised form. However these techniques require considerable human effort, and are specific to particular languages and alphabets. This paper describes a system capable of directly transcribing raw online handwriting data. The system consists of an advanced recurrent neural network with an output layer designed for sequence labelling, combined with a probabilistic language model. In experiments on an unconstrained online database, we record excellent results using either raw or preprocessed data, well outperforming a state-of-the-art HMM based system in both cases."
            },
            "slug": "Unconstrained-On-line-Handwriting-Recognition-with-Graves-Fern\u00e1ndez",
            "title": {
                "fragments": [],
                "text": "Unconstrained On-line Handwriting Recognition with Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A system capable of directly transcribing raw online handwriting data is described, consisting of an advanced recurrent neural network with an output layer designed for sequence labelling, combined with a probabilistic language model."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8270717"
                        ],
                        "name": "Junyoung Chung",
                        "slug": "Junyoung-Chung",
                        "structuredName": {
                            "firstName": "Junyoung",
                            "lastName": "Chung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junyoung Chung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 246
                            }
                        ],
                        "text": "The most popular approach is to set the timescales as hyperparameters (El Hihi & Bengio, 1995; Koutn\u00edk et al., 2014; Bahdanau et al., 2016) instead of treating them as dynamic variables that can be learned from the data (Schmidhuber, 1991; 1992; Chung et al., 2015; 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "In these works, it is advocated to stack multiple layers of RNNs in a decreasing order of update frequency for computational and learning efficiency."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "However, unlike the spatial data, learning both hierarchical and temporal representation has been among the long-standing challenges of RNNs in spite of the fact that hierarchical multiscale structures naturally exist in many temporal data (Schmidhuber, 1991; Mozer, 1993; El Hihi & Bengio, 1995; Lin et al., 1996; Koutn\u00edk et al., 2014)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 21
                            }
                        ],
                        "text": "In the biscale RNNs (Chung et al., 2016), the authors proposed to model layer-wise timescales adaptively by having additional gating units, however this approach still relies on the soft gating mechanism like LSTMs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "There have been various approaches to implementing the multiscale RNNs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 80
                            }
                        ],
                        "text": "In addition, the learned latent hierarchical structures can provide useful information to other downstream tasks such \u2217Yoshua Bengio is CIFAR Senior Fellow.\nar X\niv :1\n60 9."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "Hence, the UPDATE operation is executed sparsely unlike the standard RNNs where it is executed at every time step, making it computationally inefficient."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "A promising approach to model such hierarchical and temporal representation is the multiscale RNNs (Schmidhuber, 1992; El Hihi & Bengio, 1995; Koutn\u00edk et al., 2014)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 229
                            }
                        ],
                        "text": "Based on the observation that high-level abstraction changes slowly with temporal coherency while low-level abstraction has quickly changing features sensitive to the precise local timing (El Hihi & Bengio, 1995), the multiscale RNNs group hidden units into multiple modules of different timescales."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 228
                            }
                        ],
                        "text": "In addition to the fact that the architecture fits naturally to the latent hierarchical structures in many temporal data, the multiscale approach provides the following advantages that resolve some inherent problems of standard RNNs: (a) computational efficiency obtained by updating the high-level layers less frequently, (b) efficiently delivering long-term dependencies with fewer updates at the high-level layers, which mitigates the vanishing gradient problem, (c) flexible resource allocation (e.g., more hidden units to the higher layers that focus on modelling long-term dependencies and less hidden units to the lower layers which are in charge of learning short-term dependencies)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13495961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "acec46ffd3f6046af97529127d98f1d623816ea4",
            "isKey": false,
            "numCitedBy": 307,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "The existing machine translation systems, whether phrase-based or neural, have relied almost exclusively on word-level modelling with explicit segmentation. In this paper, we ask a fundamental question: can neural machine translation generate a character sequence without any explicit segmentation? To answer this question, we evaluate an attention-based encoder-decoder with a subword-level encoder and a character-level decoder on four language pairs--En-Cs, En-De, En-Ru and En-Fi-- using the parallel corpora from WMT'15. Our experiments show that the models with a character-level decoder outperform the ones with a subword-level decoder on all of the four language pairs. Furthermore, the ensembles of neural models with a character-level decoder outperform the state-of-the-art non-neural machine translation systems on En-Cs, En-De and En-Fi and perform comparably on En-Ru."
            },
            "slug": "A-Character-level-Decoder-without-Explicit-for-Chung-Cho",
            "title": {
                "fragments": [],
                "text": "A Character-level Decoder without Explicit Segmentation for Neural Machine Translation"
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1885349"
                        ],
                        "name": "Aja Huang",
                        "slug": "Aja-Huang",
                        "structuredName": {
                            "firstName": "Aja",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aja Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2772217"
                        ],
                        "name": "Chris J. Maddison",
                        "slug": "Chris-J.-Maddison",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Maddison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris J. Maddison"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35099444"
                        ],
                        "name": "A. Guez",
                        "slug": "A.-Guez",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Guez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Guez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2175946"
                        ],
                        "name": "L. Sifre",
                        "slug": "L.-Sifre",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Sifre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sifre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47568983"
                        ],
                        "name": "George van den Driessche",
                        "slug": "George-van-den-Driessche",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Driessche",
                            "middleNames": [
                                "van",
                                "den"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George van den Driessche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4337102"
                        ],
                        "name": "Julian Schrittwieser",
                        "slug": "Julian-Schrittwieser",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Schrittwieser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julian Schrittwieser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2460849"
                        ],
                        "name": "Ioannis Antonoglou",
                        "slug": "Ioannis-Antonoglou",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Antonoglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ioannis Antonoglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2749418"
                        ],
                        "name": "Vedavyas Panneershelvam",
                        "slug": "Vedavyas-Panneershelvam",
                        "structuredName": {
                            "firstName": "Vedavyas",
                            "lastName": "Panneershelvam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vedavyas Panneershelvam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1975889"
                        ],
                        "name": "Marc Lanctot",
                        "slug": "Marc-Lanctot",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Lanctot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Lanctot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48373216"
                        ],
                        "name": "S. Dieleman",
                        "slug": "S.-Dieleman",
                        "structuredName": {
                            "firstName": "Sander",
                            "lastName": "Dieleman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dieleman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2401609"
                        ],
                        "name": "Dominik Grewe",
                        "slug": "Dominik-Grewe",
                        "structuredName": {
                            "firstName": "Dominik",
                            "lastName": "Grewe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dominik Grewe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4111313"
                        ],
                        "name": "John Nham",
                        "slug": "John-Nham",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Nham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Nham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2583391"
                        ],
                        "name": "Nal Kalchbrenner",
                        "slug": "Nal-Kalchbrenner",
                        "structuredName": {
                            "firstName": "Nal",
                            "lastName": "Kalchbrenner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nal Kalchbrenner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542999"
                        ],
                        "name": "T. Lillicrap",
                        "slug": "T.-Lillicrap",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Lillicrap",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lillicrap"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40662181"
                        ],
                        "name": "M. Leach",
                        "slug": "M.-Leach",
                        "structuredName": {
                            "firstName": "Madeleine",
                            "lastName": "Leach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Leach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686971"
                        ],
                        "name": "T. Graepel",
                        "slug": "T.-Graepel",
                        "structuredName": {
                            "firstName": "Thore",
                            "lastName": "Graepel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Graepel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48987704"
                        ],
                        "name": "D. Hassabis",
                        "slug": "D.-Hassabis",
                        "structuredName": {
                            "firstName": "Demis",
                            "lastName": "Hassabis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hassabis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 167
                            }
                        ],
                        "text": "The remarkable recent successes of the deep convolutional neural networks are particularly based on this ability to learn hierarchical representation for spatial data (Krizhevsky et al., 2012; Mnih et al., 2015; Silver et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 515925,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "846aedd869a00c09b40f1f1f35673cb22bc87490",
            "isKey": false,
            "numCitedBy": 11398,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses \u2018value networks\u2019 to evaluate board positions and \u2018policy networks\u2019 to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away."
            },
            "slug": "Mastering-the-game-of-Go-with-deep-neural-networks-Silver-Huang",
            "title": {
                "fragments": [],
                "text": "Mastering the game of Go with deep neural networks and tree search"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Using this search algorithm, the program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0.5, the first time that a computer program has defeated a human professional player in the full-sized game of Go."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144333684"
                        ],
                        "name": "William Chan",
                        "slug": "William-Chan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Chan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Chan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3111912"
                        ],
                        "name": "Navdeep Jaitly",
                        "slug": "Navdeep-Jaitly",
                        "structuredName": {
                            "firstName": "Navdeep",
                            "lastName": "Jaitly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Navdeep Jaitly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 154
                            }
                        ],
                        "text": "In this paper, we propose a novel multiscale RNN model, which can learn the hierarchical multiscale structure from temporal data without explicit boundary information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18165915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3056add22b20e3361c38c0472d294a79d4031cb4",
            "isKey": false,
            "numCitedBy": 1524,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present Listen, Attend and Spell (LAS), a neural speech recognizer that transcribes speech utterances directly to characters without pronunciation models, HMMs or other components of traditional speech recognizers. In LAS, the neural network architecture subsumes the acoustic, pronunciation and language models making it not only an end-to-end trained system but an end-to-end model. In contrast to DNN-HMM, CTC and most other models, LAS makes no independence assumptions about the probability distribution of the output character sequences given the acoustic sequence. Our system has two components: a listener and a speller. The listener is a pyramidal recurrent network encoder that accepts filter bank spectra as inputs. The speller is an attention-based recurrent network decoder that emits each character conditioned on all previous characters, and the entire acoustic sequence. On a Google voice search task, LAS achieves a WER of 14.1% without a dictionary or an external language model and 10.3% with language model rescoring over the top 32 beams. In comparison, the state-of-the-art CLDNN-HMM model achieves a WER of 8.0% on the same set."
            },
            "slug": "Listen,-attend-and-spell:-A-neural-network-for-Chan-Jaitly",
            "title": {
                "fragments": [],
                "text": "Listen, attend and spell: A neural network for large vocabulary conversational speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "Listen, Attend and Spell (LAS), a neural speech recognizer that transcribes speech utterances directly to characters without pronunciation models, HMMs or other components of traditional speech recognizers is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35256019"
                        ],
                        "name": "M. Mahoney",
                        "slug": "M.-Mahoney",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Mahoney",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mahoney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17386893,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f758d8e6dee5348c2b5bf56f33994ad96e88a591",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Until recently the state of the art in lossless data compression was prediction by partial match (PPM). A PPM model estimates the next-symbol probabilit y distribution by combining statistics from the longest matching contiguous contexts in which each symbol value is found. We introduce a context mixing model which improves on PPM by allowing contexts which are arbitrary functions of the history. Each model independently estimates a probabilit y and confidence that the next bit of data will be 0 or 1. Predictions are combined by weighted averaging. After a bit is arithmetic coded, the weights are adjusted along the cost gradient in weight space to favor the most accurate models. Context mixing compressors, as implemented by the open source PAQ project, are now top ranked on several independent benchmarks."
            },
            "slug": "Adaptive-weighing-of-context-models-for-lossless-Mahoney",
            "title": {
                "fragments": [],
                "text": "Adaptive weighing of context models for lossless data compression"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "A context mixing model is introduced which improves on PPM by allowing contexts which are arbitrary functions of the history, and which is now top ranked on several independent benchmarks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388466"
                        ],
                        "name": "Matthieu Courbariaux",
                        "slug": "Matthieu-Courbariaux",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Courbariaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Courbariaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145719986"
                        ],
                        "name": "J. David",
                        "slug": "J.-David",
                        "structuredName": {
                            "firstName": "Jean-Pierre",
                            "lastName": "David",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. David"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "per operation at each time step and to detect the boundaries, the HM-RNN discovers the latent hierarchical structure of the sequences. We \ufb01nd that the straight-through estimator (Bengio et al., 2013; Courbariaux et al., 2015) is ef\ufb01cient for training this model containing discrete variables. We evaluate our model on two tasks: character-level language modelling and handwriting sequence generation. For the character-level "
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ator, however, is much simpler and often works more ef\ufb01ciently in practice than other unbiased but high-variance estimators such as the REINFORCE. The straight-through estimator has also been used in Courbariaux et al. (2015) and Mnih et al. (2016). The Slope Annealing Trick. In our experiment, we use the slope annealing trick to reduce the bias of the straight-through estimator. The idea is to reduce the discrepancy betw"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1518846,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5733ff08daff727af834345b9cfff1d0aa109ec",
            "isKey": false,
            "numCitedBy": 2113,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Neural Networks (DNN) have achieved state-of-the-art results in a wide range of tasks, with the best results obtained with large training sets and large models. In the past, GPUs enabled these breakthroughs because of their greater computational speed. In the future, faster computation at both training and test time is likely to be crucial for further progress and for consumer applications on low-power devices. As a result, there is much interest in research and development of dedicated hardware for Deep Learning (DL). Binary weights, i.e., weights which are constrained to only two possible values (e.g. -1 or 1), would bring great benefits to specialized DL hardware by replacing many multiply-accumulate operations by simple accumulations, as multipliers are the most space and power-hungry components of the digital implementation of neural networks. We introduce BinaryConnect, a method which consists in training a DNN with binary weights during the forward and backward propagations, while retaining precision of the stored weights in which gradients are accumulated. Like other dropout schemes, we show that BinaryConnect acts as regularizer and we obtain near state-of-the-art results with BinaryConnect on the permutation-invariant MNIST, CIFAR-10 and SVHN."
            },
            "slug": "BinaryConnect:-Training-Deep-Neural-Networks-with-Courbariaux-Bengio",
            "title": {
                "fragments": [],
                "text": "BinaryConnect: Training Deep Neural Networks with binary weights during propagations"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "BinaryConnect is introduced, a method which consists in training a DNN with binary weights during the forward and backward propagations, while retaining precision of the stored weights in which gradients are accumulated, and near state-of-the-art results with BinaryConnect are obtained on the permutation-invariant MNIST, CIFAR-10 and SVHN."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8536286"
                        ],
                        "name": "A. Bosselut",
                        "slug": "A.-Bosselut",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Bosselut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bosselut"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39455775"
                        ],
                        "name": "Omer Levy",
                        "slug": "Omer-Levy",
                        "structuredName": {
                            "firstName": "Omer",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omer Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14487640"
                        ],
                        "name": "Ari Holtzman",
                        "slug": "Ari-Holtzman",
                        "structuredName": {
                            "firstName": "Ari",
                            "lastName": "Holtzman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ari Holtzman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40479850"
                        ],
                        "name": "C. Ennis",
                        "slug": "C.-Ennis",
                        "structuredName": {
                            "firstName": "Corin",
                            "lastName": "Ennis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ennis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145197953"
                        ],
                        "name": "D. Fox",
                        "slug": "D.-Fox",
                        "structuredName": {
                            "firstName": "Dieter",
                            "lastName": "Fox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699545"
                        ],
                        "name": "Yejin Choi",
                        "slug": "Yejin-Choi",
                        "structuredName": {
                            "firstName": "Yejin",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yejin Choi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 51540074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcd857d75841aa3e92cd4284a8818aba9f6c0c3f",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Understanding procedural language requires anticipating the causal effects of actions, even when they are not explicitly stated. In this work, we introduce Neural Process Networks to understand procedural text through (neural) simulation of action dynamics. Our model complements existing memory architectures with dynamic entity tracking by explicitly modeling actions as state transformers. The model updates the states of the entities by executing learned action operators. Empirical results demonstrate that our proposed model can reason about the unstated causal effects of actions, allowing it to provide more accurate contextual information for understanding and generating procedural text, all while offering more interpretable internal representations than existing alternatives."
            },
            "slug": "Published-as-a-conference-paper-at-ICLR-2018-S-A-D-Bosselut-Levy",
            "title": {
                "fragments": [],
                "text": "Published as a conference paper at ICLR 2018 S IMULATING A CTION D YNAMICS WITH N EURAL P ROCESS N ETWORKS"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work introduces Neural Process Networks to understand procedural text through (neural) simulation of action dynamics, and complements existing memory architectures with dynamic entity tracking by explicitly modeling actions as state transformers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073603971"
                        ],
                        "name": "Vinod Nair",
                        "slug": "Vinod-Nair",
                        "structuredName": {
                            "firstName": "Vinod",
                            "lastName": "Nair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinod Nair"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 24
                            }
                        ],
                        "text": "When the C2W-RNN starts to process the next word, its hidden states are reinitialized using the latest hidden states of the W2P-RNN, which contain summarized representation of all the words that have been processed by that time step, in that phrase."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 118
                            }
                        ],
                        "text": "The output embedding het is computed by:\nhet = ReLU ( L\u2211 `=1 g`tW e `h ` t ) , (12)\nwhere L = 3 and ReLU(x) = max(0, x) (Nair & Hinton, 2010)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15539264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a538b05ebb01a40323997629e171c91aa28b8e2f",
            "isKey": false,
            "numCitedBy": 12813,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these \"Stepped Sigmoid Units\" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors."
            },
            "slug": "Rectified-Linear-Units-Improve-Restricted-Boltzmann-Nair-Hinton",
            "title": {
                "fragments": [],
                "text": "Rectified Linear Units Improve Restricted Boltzmann Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units that learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72270297"
                        ],
                        "name": "Parul Parashar",
                        "slug": "Parul-Parashar",
                        "structuredName": {
                            "firstName": "Parul",
                            "lastName": "Parashar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Parul Parashar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 170
                            }
                        ],
                        "text": "Among a few methods for training a neural network with discrete variables such as the REINFORCE (Williams, 1992; Mnih & Gregor, 2014) and the straight-through estimator (Hinton, 2012; Bengio et al., 2013), we use the straightthrough estimator to train our model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 44
                            }
                        ],
                        "text": "We find that the straight-through estimator (Hinton, 2012; Bengio et al., 2013; Courbariaux et al., 2015) is efficient for training this model containing discrete variables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 45
                            }
                        ],
                        "text": "We find that the straight-through estimator (Hinton, 2012; Bengio et al., 2013; Courbariaux et al., 2016) is efficient for training this model containing discrete variables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62529370,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5df0a0e9ceec70a9321b0555288222bf53216342",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine Learning is associated with the study and construction of systems that can learn on their own rather than following instructions. It is used in search engines, optical character recognition, computer vision etc. Neural networks are one of the several techniques used in machine learning. Here we are trying to discuss neural network approaches used in machine learning."
            },
            "slug": "Neural-Networks-in-Machine-Learning-Parashar",
            "title": {
                "fragments": [],
                "text": "Neural Networks in Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper discusses neural network approaches used in machine learning, which is used in search engines, optical character recognition, computer vision etc."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424234"
                        ],
                        "name": "Beatrice Santorini",
                        "slug": "Beatrice-Santorini",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Santorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Santorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063206"
                        ],
                        "name": "Mary Ann Marcinkiewicz",
                        "slug": "Mary-Ann-Marcinkiewicz",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Marcinkiewicz",
                            "middleNames": [
                                "Ann"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary Ann Marcinkiewicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 252796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
            "isKey": false,
            "numCitedBy": 8177,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant."
            },
            "slug": "Building-a-Large-Annotated-Corpus-of-English:-The-Marcus-Santorini",
            "title": {
                "fragments": [],
                "text": "Building a Large Annotated Corpus of English: The Penn Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "As a result of this grant, the researchers have now published on CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, which includes a fully hand-parsed version of the classic Brown corpus."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743758"
                        ],
                        "name": "M. Liwicki",
                        "slug": "M.-Liwicki",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Liwicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liwicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 96
                            }
                        ],
                        "text": "We extend the evaluation of the HM-LSTM to a real-valued sequence modelling task using IAMOnDB (Liwicki & Bunke, 2005) dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1745101,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9eb7daa88879f283ae05e359d6c502a320b833c9",
            "isKey": false,
            "numCitedBy": 179,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present IAM-OnDB - a new large online handwritten sentences database. It is publicly available and consists of text acquired via an electronic interface from a whiteboard. The database contains about 86 K word instances from an 11 K dictionary written by more than 200 writers. We also describe a recognizer for unconstrained English text that was trained and tested using this database. This recognizer is based on hidden Markov models (HMMs). In our experiments we show that by using larger training sets we can significantly increase the word recognition rate. This recognizer may serve as a benchmark reference for future research."
            },
            "slug": "IAM-OnDB-an-on-line-English-sentence-database-from-Liwicki-Bunke",
            "title": {
                "fragments": [],
                "text": "IAM-OnDB - an on-line English sentence database acquired from handwritten text on a whiteboard"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "IAM-OnDB is a new large online handwritten sentences database that consists of text acquired via an electronic interface from a whiteboard and a recognizer for unconstrained English text that was trained and tested using this database."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 208875690,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "8cf24826e5bbe8e9e3161bdb98c0523b3ace5443",
            "isKey": false,
            "numCitedBy": 25207,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "11. Brunck W: Die systematische untersuchung des sprachorgans bei angeborenen gaumendefekte. Diss Leipiz 1906 (from Meissner). 12. Commichau G, Oeken FW: Pneumatisationsverhaitnisse bel gaumenspaltentragem. HNO (Bed) 7:73-75, 1958 13. Compere WE, Jr: Tympanic cavity clearance studies. Trans AAOO 62:444-454, 1958 14. Compere WE, Jr: The radiologic evaluation of eustachian tube function. AMA Arch Otolaryngol 7 :386-389, 1960 15. Day KM: Management of deafness: Wherry Memorial Lecture. Trans AAOO 55: 22, 1950 16. Donaldson JA: The role of artificial Eustachian tube in cleft palate patients. Cleft Palate J 61-66, 1966 17. Drettner B: The nasal air way and hearing in patients with cleft palate. Acta Otolaryng 52: 131-142, 1960 18. Duncan RB: Positional otitis media. Arch Otolaryng 72:455-463, 1960"
            },
            "slug": "References",
            "title": {
                "fragments": [],
                "text": "References"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "11. Brunck W: Die systematische untersuchung des sprachorgans bei angeborenen gaumendefekte ist wirklich ein wirkliches Problem gegen \u00e2\u201a\u00ac\u201d Pneumatisationsverhaitnisse bel gaumenspaltentragem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 246
                            }
                        ],
                        "text": "The most popular approach is to set the timescales as hyperparameters (El Hihi & Bengio, 1995; Koutn\u00edk et al., 2014; Bahdanau et al., 2016) instead of treating them as dynamic variables that can be learned from the data (Schmidhuber, 1991; 1992; Chung et al., 2015; 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "In these works, it is advocated to stack multiple layers of RNNs in a decreasing order of update frequency for computational and learning efficiency."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "However, unlike the spatial data, learning both hierarchical and temporal representation has been among the long-standing challenges of RNNs in spite of the fact that hierarchical multiscale structures naturally exist in many temporal data (Schmidhuber, 1991; Mozer, 1993; El Hihi & Bengio, 1995; Lin et al., 1996; Koutn\u00edk et al., 2014)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 21
                            }
                        ],
                        "text": "In the biscale RNNs (Chung et al., 2016), the authors proposed to model layer-wise timescales adaptively by having additional gating units, however this approach still relies on the soft gating mechanism like LSTMs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "There have been various approaches to implementing the multiscale RNNs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "Hence, the UPDATE operation is executed sparsely unlike the standard RNNs where it is executed at every time step, making it computationally inefficient."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "A promising approach to model such hierarchical and temporal representation is the multiscale RNNs (Schmidhuber, 1992; El Hihi & Bengio, 1995; Koutn\u00edk et al., 2014)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 229
                            }
                        ],
                        "text": "Based on the observation that high-level abstraction changes slowly with temporal coherency while low-level abstraction has quickly changing features sensitive to the precise local timing (El Hihi & Bengio, 1995), the multiscale RNNs group hidden units into multiple modules of different timescales."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 228
                            }
                        ],
                        "text": "In addition to the fact that the architecture fits naturally to the latent hierarchical structures in many temporal data, the multiscale approach provides the following advantages that resolve some inherent problems of standard RNNs: (a) computational efficiency obtained by updating the high-level layers less frequently, (b) efficiently delivering long-term dependencies with fewer updates at the high-level layers, which mitigates the vanishing gradient problem, (c) flexible resource allocation (e.g., more hidden units to the higher layers that focus on modelling long-term dependencies and less hidden units to the lower layers which are in charge of learning short-term dependencies)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A characterlevel decoder without explicit segmentation for neural machine translation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113979381"
                        ],
                        "name": "Xing Hao",
                        "slug": "Xing-Hao",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Hao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Hao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8273966"
                        ],
                        "name": "Guigang Zhang",
                        "slug": "Guigang-Zhang",
                        "structuredName": {
                            "firstName": "Guigang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guigang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118869556"
                        ],
                        "name": "Shang Ma",
                        "slug": "Shang-Ma",
                        "structuredName": {
                            "firstName": "Shang",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shang Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 188
                            }
                        ],
                        "text": "One of the key principles of learning in deep neural networks as well as in the human brain is to obtain a hierarchical representation with increasing levels of abstraction (Bengio, 2009; LeCun et al., 2015; Schmidhuber, 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1779661,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "4f8d648c52edf74e41b0996128aa536e13cc7e82",
            "isKey": false,
            "numCitedBy": 30739,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Deep-Learning-Hao-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Semantic Comput."
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 68
                            }
                        ],
                        "text": "Hutter Prize Wikipedia The Hutter Prize Wikipedia (enwik8) dataset (Hutter, 2012) contains 205 symbols including XML markups and special characters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "3The plot function could be found at blog.otoro.net/2015/12/12/handwriting-generation-demo-in-tensorflow/."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The human knowledge compression contest"
            },
            "venue": {
                "fragments": [],
                "text": "The human knowledge compression contest"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Yoshua Bengio . Learning deep architectures for ai"
            },
            "venue": {
                "fragments": [],
                "text": "Foundations and trends R \u00a9 in Machine Learning"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Alex Graves . Generating sequences with recurrent neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "arXiv preprint arXiv"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 26
                            }
                        ],
                        "text": "A promising approach to model such hierarchical and temporal representation is the multiscale RNNs (Schmidhuber, 1992; El Hihi & Bengio, 1995; Koutn\u00edk et al., 2014)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 218
                            }
                        ],
                        "text": "\u2026both hierarchical and temporal representation has been among the long-standing challenges of RNNs in spite of the fact that hierarchical multiscale structures naturally exist in many temporal data (Schmidhuber, 1991; Mozer, 1993; El Hihi & Bengio, 1995; Lin et al., 1996; Koutn\u00edk et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Induction of multiscale temporal structure Advances in neural information processing systems"
            },
            "venue": {
                "fragments": [],
                "text": "Induction of multiscale temporal structure Advances in neural information processing systems"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 174
                            }
                        ],
                        "text": "One of the key principles of learning in deep neural networks as well as in the human brain is to obtain a hierarchical representation with increasing levels of abstraction (Bengio, 2009; LeCun et al., 2015; Schmidhuber, 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning deep architectures for ai. Foundations and trends"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 25
                            }
                        ],
                        "text": "Text8 The Text8 dataset (Mahoney, 2009) consists of 100M characters extracted from the Wikipedia corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 166
                            }
                        ],
                        "text": "Although the neural models, show remarkable performances, their compression performance is still behind the best models such as PAQ8hp12 (Mahoney, 2005) and decomp8 (Mahoney, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Large text compression benchmark"
            },
            "venue": {
                "fragments": [],
                "text": "URL: http://www. mattmahoney. net/text/text. html,"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "End - toend attentionbased large vocabulary speech recognition Yoshua Bengio . Learning deep architectures for ai"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 174
                            }
                        ],
                        "text": "One of the key principles of learning in deep neural networks as well as in the human brain is to obtain a hierarchical representation with increasing levels of abstraction (Bengio, 2009; LeCun et al., 2015; Schmidhuber, 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning deep architectures for ai. Foundations and trends R in Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Learning deep architectures for ai. Foundations and trends R in Machine Learning"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 170
                            }
                        ],
                        "text": "Among a few methods for training a neural network with discrete variables such as the REINFORCE (Williams, 1992; Mnih & Gregor, 2014) and the straight-through estimator (Hinton, 2012; Bengio et al., 2013), we use the straightthrough estimator to train our model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Although the main goal of our proposed model is not regularization, we found that our model also shows very good generalization performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 45
                            }
                        ],
                        "text": "We find that the straight-through estimator (Hinton, 2012; Bengio et al., 2013; Courbariaux et al., 2016) is efficient for training this model containing discrete variables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural networks for machine learning. Coursera, video lectures"
            },
            "venue": {
                "fragments": [],
                "text": "Neural networks for machine learning. Coursera, video lectures"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ", Yoshua Bengio , and Geoffrey Hinton . Deep learning"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 118
                            }
                        ],
                        "text": "The output embedding het is computed by:\nhet = ReLU ( L\u2211 `=1 g`tW e `h ` t ) , (12)\nwhere L = 3 and ReLU(x) = max(0, x) (Nair & Hinton, 2010)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Induction of multiscale temporal structure . Advances in neural information processing systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The human knowledge compression contest. 2012. URL http://prize"
            },
            "venue": {
                "fragments": [],
                "text": "The human knowledge compression contest. 2012. URL http://prize"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Induction of multiscale temporal structure Advances in neural information processing systems"
            },
            "venue": {
                "fragments": [],
                "text": "Induction of multiscale temporal structure Advances in neural information processing systems"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 26
                            }
                        ],
                        "text": "D kernels are proposed in Kim (2014) and Kim et al. (2015) for language modelling and sentence classification."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408"
            },
            "venue": {
                "fragments": [],
                "text": "Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Large text compression benchmark"
            },
            "venue": {
                "fragments": [],
                "text": "Large text compression benchmark"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Auto-encoding variational bayes. arXiv preprint arXiv:1312"
            },
            "venue": {
                "fragments": [],
                "text": "Auto-encoding variational bayes. arXiv preprint arXiv:1312"
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gated feedback recurrent neural networks A characterlevel decoder without explicit segmentation for neural machine translation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "End - toend attentionbased large vocabulary speech recognition Yoshua Bengio . Learning deep architectures for ai"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 46,
            "methodology": 31,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 88,
        "totalPages": 9
    },
    "page_url": "https://www.semanticscholar.org/paper/Hierarchical-Multiscale-Recurrent-Neural-Networks-Chung-Ahn/65eee67dee969fdf8b44c87c560d66ad4d78e233?sort=total-citations"
}