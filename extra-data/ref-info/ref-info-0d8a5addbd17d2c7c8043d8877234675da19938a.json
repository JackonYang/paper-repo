{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766489"
                        ],
                        "name": "M. Ryoo",
                        "slug": "M.-Ryoo",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ryoo",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ryoo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 204
                            }
                        ],
                        "text": "There is also an area of emerging research termed early recognition, where the task is to classify an incoming temporal sequence as early as possible while maintaining a level of detection accuracy [17], [18], [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9342979,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76be79c45335db6d08efcde7843ae298765d4d63",
            "isKey": false,
            "numCitedBy": 517,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a novel approach of human activity prediction. Human activity prediction is a probabilistic process of inferring ongoing activities from videos only containing onsets (i.e. the beginning part) of the activities. The goal is to enable early recognition of unfinished activities as opposed to the after-the-fact classification of completed activities. Activity prediction methodologies are particularly necessary for surveillance systems which are required to prevent crimes and dangerous activities from occurring. We probabilistically formulate the activity prediction problem, and introduce new methodologies designed for the prediction. We represent an activity as an integral histogram of spatio-temporal features, efficiently modeling how feature distributions change over time. The new recognition methodology named dynamic bag-of-words is developed, which considers sequential nature of human activities while maintaining advantages of the bag-of-words to handle noisy observations. Our experiments confirm that our approach reliably recognizes ongoing activities from streaming videos with a high accuracy."
            },
            "slug": "Human-activity-prediction:-Early-recognition-of-Ryoo",
            "title": {
                "fragments": [],
                "text": "Human activity prediction: Early recognition of ongoing activities from streaming videos"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The new recognition methodology named dynamic bag-of-words is developed, which considers sequential nature of human activities while maintaining advantages of the bag- of-words to handle noisy observations, and reliably recognizes ongoing activities from streaming videos with a high accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3190429"
                        ],
                        "name": "Bulent Tastan",
                        "slug": "Bulent-Tastan",
                        "structuredName": {
                            "firstName": "Bulent",
                            "lastName": "Tastan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bulent Tastan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727071"
                        ],
                        "name": "G. Sukthankar",
                        "slug": "G.-Sukthankar",
                        "structuredName": {
                            "firstName": "Gita",
                            "lastName": "Sukthankar",
                            "middleNames": [
                                "Reese"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sukthankar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7641152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52649f5f48bbeee641e1952a0ee96bc6b21221c0",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Leveraging-human-behavior-models-to-predict-paths-Tastan-Sukthankar",
            "title": {
                "fragments": [],
                "text": "Leveraging human behavior models to predict paths in indoor environments"
            },
            "venue": {
                "fragments": [],
                "text": "Pervasive Mob. Comput."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31458284"
                        ],
                        "name": "S. Pellegrini",
                        "slug": "S.-Pellegrini",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Pellegrini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pellegrini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433494"
                        ],
                        "name": "Andreas Ess",
                        "slug": "Andreas-Ess",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Ess",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Ess"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144810819"
                        ],
                        "name": "K. Schindler",
                        "slug": "K.-Schindler",
                        "structuredName": {
                            "firstName": "Konrad",
                            "lastName": "Schindler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Schindler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Previous work [11], [12], has shown that modeling the impact of the social environment, like actions of nearby pedestrians, can improve priors over pedestrian trajectories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7065547,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d7a98a81715e2d3747071722b2deeed8937d122",
            "isKey": false,
            "numCitedBy": 1042,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Object tracking typically relies on a dynamic model to predict the object's location from its past trajectory. In crowded scenarios a strong dynamic model is particularly important, because more accurate predictions allow for smaller search regions, which greatly simplifies data association. Traditional dynamic models predict the location for each target solely based on its own history, without taking into account the remaining scene objects. Collisions are resolved only when they happen. Such an approach ignores important aspects of human behavior: people are driven by their future destination, take into account their environment, anticipate collisions, and adjust their trajectories at an early stage in order to avoid them. In this work, we introduce a model of dynamic social behavior, inspired by models developed for crowd simulation. The model is trained with videos recorded from birds-eye view at busy locations, and applied as a motion model for multi-people tracking from a vehicle-mounted camera. Experiments on real sequences show that accounting for social interactions and scene knowledge improves tracking performance, especially during occlusions."
            },
            "slug": "You'll-never-walk-alone:-Modeling-social-behavior-Pellegrini-Ess",
            "title": {
                "fragments": [],
                "text": "You'll never walk alone: Modeling social behavior for multi-target tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A model of dynamic social behavior, inspired by models developed for crowd simulation, is introduced, trained with videos recorded from birds-eye view at busy locations, and applied as a motion model for multi-people tracking from a vehicle-mounted camera."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52224070"
                        ],
                        "name": "G. Zen",
                        "slug": "G.-Zen",
                        "structuredName": {
                            "firstName": "Gloria",
                            "lastName": "Zen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40811261"
                        ],
                        "name": "E. Ricci",
                        "slug": "E.-Ricci",
                        "structuredName": {
                            "firstName": "Elisa",
                            "lastName": "Ricci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ricci"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "We take a departure from traditional motion-based approaches [9], [10] and explore the interplay between features of the environment and pedestrian trajectories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4406344,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b583827ef9a05eb7609ab094d648de59324ba79f",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach for automatically discovering spatio-temporal patterns in complex dynamic scenes. Similarly to recent non-object centric methods, we use low level visual cues to detect atomic activities and then construct clip histograms. Differently from previous works, we formulate the task of discovering high level activity patterns as a prototype learning problem where the correlation among atomic activities is explicitly taken into account when grouping clip histograms. Interestingly at the core of our approach there is a convex optimization problem which allows us to efficiently extract patterns at multiple levels of detail. The effectiveness of our method is demonstrated on publicly available datasets."
            },
            "slug": "Earth-mover's-prototypes:-A-convex-learning-for-in-Zen-Ricci",
            "title": {
                "fragments": [],
                "text": "Earth mover's prototypes: A convex learning approach for discovering activity patterns in dynamic scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work forms the task of discovering high level activity patterns as a prototype learning problem where the correlation among atomic activities is explicitly taken into account when grouping clip histograms."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753269"
                        ],
                        "name": "Brian D. Ziebart",
                        "slug": "Brian-D.-Ziebart",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Ziebart",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian D. Ziebart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34961461"
                        ],
                        "name": "Andrew L. Maas",
                        "slug": "Andrew-L.-Maas",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Maas",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew L. Maas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756566"
                        ],
                        "name": "J. Bagnell",
                        "slug": "J.-Bagnell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Bagnell",
                            "middleNames": [
                                "Andrew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bagnell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144021446"
                        ],
                        "name": "A. Dey",
                        "slug": "A.-Dey",
                        "structuredName": {
                            "firstName": "Anind",
                            "lastName": "Dey",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": ", video games [7] and locations in road networks [6])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6] by incorporating visionbased physical scene features and noisy tracker observations, to forecast activities and destinations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "We build on the maximum entropy IOC approach in [6] and extend the model to deal with noisy observations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "We use the negative log-loss (NLL) of a trajectories, as in [6] as our probabilistic comparison metric."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6], we approximate the posterior over goals using a ratio of partition functions, one with and one without observations:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 336219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11b6bdfe36c48b11367b27187da11d95892f0361",
            "isKey": false,
            "numCitedBy": 1997,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent research has shown the benefit of framing problems of imitation learning as solutions to Markov Decision Problems. This approach reduces learning to the problem of recovering a utility function that makes the behavior induced by a near-optimal policy closely mimic demonstrated behavior. In this work, we develop a probabilistic approach based on the principle of maximum entropy. Our approach provides a well-defined, globally normalized distribution over decision sequences, while providing the same performance guarantees as existing methods. \n \nWe develop our technique in the context of modeling real-world navigation and driving behaviors where collected data is inherently noisy and imperfect. Our probabilistic approach enables modeling of route preferences as well as a powerful new approach to inferring destinations and routes based on partial trajectories."
            },
            "slug": "Maximum-Entropy-Inverse-Reinforcement-Learning-Ziebart-Maas",
            "title": {
                "fragments": [],
                "text": "Maximum Entropy Inverse Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A probabilistic approach based on the principle of maximum entropy that provides a well-defined, globally normalized distribution over decision sequences, while providing the same performance guarantees as existing methods is developed."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753269"
                        ],
                        "name": "Brian D. Ziebart",
                        "slug": "Brian-D.-Ziebart",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Ziebart",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian D. Ziebart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13693897"
                        ],
                        "name": "Nathan D. Ratliff",
                        "slug": "Nathan-D.-Ratliff",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Ratliff",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nathan D. Ratliff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1928874"
                        ],
                        "name": "G. Gallagher",
                        "slug": "G.-Gallagher",
                        "structuredName": {
                            "firstName": "Garratt",
                            "lastName": "Gallagher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gallagher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14045709"
                        ],
                        "name": "C. Mertz",
                        "slug": "C.-Mertz",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Mertz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mertz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2005495"
                        ],
                        "name": "K. Peterson",
                        "slug": "K.-Peterson",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Peterson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Peterson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756566"
                        ],
                        "name": "J. Bagnell",
                        "slug": "J.-Bagnell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Bagnell",
                            "middleNames": [
                                "Andrew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bagnell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144021446"
                        ],
                        "name": "A. Dey",
                        "slug": "A.-Dey",
                        "structuredName": {
                            "firstName": "Anind",
                            "lastName": "Dey",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752197"
                        ],
                        "name": "S. Srinivasa",
                        "slug": "S.-Srinivasa",
                        "structuredName": {
                            "firstName": "Siddhartha",
                            "lastName": "Srinivasa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srinivasa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 129
                            }
                        ],
                        "text": "Work in optimal control theory has shown that human behavior can be modeled successfully as a sequential decision-making process [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 216
                            }
                        ],
                        "text": "The problem of recovering a set of agent preferences (the reward or cost function) consistent with demonstrated activities, can be solved via Inverse Optimal Control (IOC) \u2013 also called Inverse Reinforcement Learning (IRL) [4] or inverse planning [5]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 113
                            }
                        ],
                        "text": "Various approaches using structured maximum margin prediction [21], feature matching [4] and maximum entropy IRL [3] have been proposed for recovering the cost function."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15354222,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36fb553aa996885017afe3489a8377eceddc08ee",
            "isKey": false,
            "numCitedBy": 447,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach for determining robot movements that efficiently accomplish the robot's tasks while not hindering the movements of people within the environment. Our approach models the goal-directed trajectories of pedestrians using maximum entropy inverse optimal control. The advantage of this modeling approach is the generality of its learned cost function to changes in the environment and to entirely different environments. We employ the predictions of this model of pedestrian trajectories in a novel incremental planner and quantitatively show the improvement in hindrance-sensitive robot trajectory planning provided by our approach."
            },
            "slug": "Planning-based-prediction-for-pedestrians-Ziebart-Ratliff",
            "title": {
                "fragments": [],
                "text": "Planning-based prediction for pedestrians"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A novel approach for determining robot movements that efficiently accomplish the robot's tasks while not hindering the movements of people within the environment is presented and improvement in hindrance-sensitive robot trajectory planning is quantitatively shown."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE/RSJ International Conference on Intelligent Robots and Systems"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13693897"
                        ],
                        "name": "Nathan D. Ratliff",
                        "slug": "Nathan-D.-Ratliff",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Ratliff",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nathan D. Ratliff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756566"
                        ],
                        "name": "J. Bagnell",
                        "slug": "J.-Bagnell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Bagnell",
                            "middleNames": [
                                "Andrew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bagnell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8195063"
                        ],
                        "name": "Martin A. Zinkevich",
                        "slug": "Martin-A.-Zinkevich",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Zinkevich",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Zinkevich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "Various approaches using structured maximum margin prediction [21], feature matching [4] and maximum entropy IRL [3] have been proposed for recovering the cost function."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1044953,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "117a50fbdfd473e43e550c6103733e6cb4aecb4c",
            "isKey": false,
            "numCitedBy": 628,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Imitation learning of sequential, goal-directed behavior by standard supervised techniques is often difficult. We frame learning such behaviors as a maximum margin structured prediction problem over a space of policies. In this approach, we learn mappings from features to cost so an optimal policy in an MDP with these cost mimics the expert's behavior. Further, we demonstrate a simple, provably efficient approach to structured maximum margin learning, based on the subgradient method, that leverages existing fast algorithms for inference. Although the technique is general, it is particularly relevant in problems where A* and dynamic programming approaches make learning policies tractable in problems beyond the limitations of a QP formulation. We demonstrate our approach applied to route planning for outdoor mobile robots, where the behavior a designer wishes a planner to execute is often clear, while specifying cost functions that engender this behavior is a much more difficult task."
            },
            "slug": "Maximum-margin-planning-Ratliff-Bagnell",
            "title": {
                "fragments": [],
                "text": "Maximum margin planning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work learns mappings from features to cost so an optimal policy in an MDP with these cost mimics the expert's behavior, and demonstrates a simple, provably efficient approach to structured maximum margin learning, based on the subgradient method, that leverages existing fast algorithms for inference."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689992"
                        ],
                        "name": "P. Abbeel",
                        "slug": "P.-Abbeel",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Abbeel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Abbeel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 223
                            }
                        ],
                        "text": "The problem of recovering a set of agent preferences (the reward or cost function) consistent with demonstrated activities, can be solved via Inverse Optimal Control (IOC) \u2013 also called Inverse Reinforcement Learning (IRL) [4] or inverse planning [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "Various approaches using structured maximum margin prediction [21], feature matching [4] and maximum entropy IRL [3] have been proposed for recovering the cost function."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207155342,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f65020fc3b1692d7989e099d6b6e698be5a50a93",
            "isKey": false,
            "numCitedBy": 2546,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider learning in a Markov decision process where we are not explicitly given a reward function, but where instead we can observe an expert demonstrating the task that we want to learn to perform. This setting is useful in applications (such as the task of driving) where it may be difficult to write down an explicit reward function specifying exactly how different desiderata should be traded off. We think of the expert as trying to maximize a reward function that is expressible as a linear combination of known features, and give an algorithm for learning the task demonstrated by the expert. Our algorithm is based on using \"inverse reinforcement learning\" to try to recover the unknown reward function. We show that our algorithm terminates in a small number of iterations, and that even though we may never recover the expert's reward function, the policy output by the algorithm will attain performance close to that of the expert, where here performance is measured with respect to the expert's unknown reward function."
            },
            "slug": "Apprenticeship-learning-via-inverse-reinforcement-Abbeel-Ng",
            "title": {
                "fragments": [],
                "text": "Apprenticeship learning via inverse reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work thinks of the expert as trying to maximize a reward function that is expressible as a linear combination of known features, and gives an algorithm for learning the task demonstrated by the expert, based on using \"inverse reinforcement learning\" to try to recover the unknown reward function."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21161348"
                        ],
                        "name": "Chris L. Baker",
                        "slug": "Chris-L.-Baker",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Baker",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris L. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276622"
                        ],
                        "name": "R. Saxe",
                        "slug": "R.-Saxe",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Saxe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Saxe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 247
                            }
                        ],
                        "text": "The problem of recovering a set of agent preferences (the reward or cost function) consistent with demonstrated activities, can be solved via Inverse Optimal Control (IOC) \u2013 also called Inverse Reinforcement Learning (IRL) [4] or inverse planning [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1560164,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "7dd51cef9bd43d495a12d10b7d0846f9bd60d9fa",
            "isKey": false,
            "numCitedBy": 680,
            "numCiting": 115,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Action-understanding-as-inverse-planning-Baker-Saxe",
            "title": {
                "fragments": [],
                "text": "Action understanding as inverse planning"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51505748"
                        ],
                        "name": "Daniel Munoz",
                        "slug": "Daniel-Munoz",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Munoz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Munoz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756566"
                        ],
                        "name": "J. Bagnell",
                        "slug": "J.-Bagnell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Bagnell",
                            "middleNames": [
                                "Andrew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bagnell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 167
                            }
                        ],
                        "text": "Recent semantic scene labeling approaches now provide a robust and reliable way of recognizing physical scene features such as pavement, grass, tree, building and car [1], [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15601601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "370308ad57aa43a29df1a9500c813c13254e16cd",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we propose a hierarchical approach for labeling semantic objects and regions in scenes. Our approach is reminiscent of early vision literature in that we use a decomposition of the image in order to encode relational and spatial information. In contrast to much existing work on structured prediction for scene understanding, we bypass a global probabilistic model and instead directly train a hierarchical inference procedure inspired by the message passing mechanics of some approximate inference procedures in graphical models. This approach mitigates both the theoretical and empirical difficulties of learning probabilistic models when exact inference is intractable. In particular, we draw from recent work in machine learning and break the complex inference process into a hierarchical series of simple machine learning subproblems. Each subproblem in the hierarchy is designed to capture the image and contextual statistics in the scene. This hierarchy spans coarse-to-fine regions and explicitly models the mixtures of semantic labels that may be present due to imperfect segmentation. To avoid cascading of errors and overfitting, we train the learning problems in sequence to ensure robustness to likely errors earlier in the inference sequence and leverage the stacking approach developed by Cohen et al."
            },
            "slug": "Stacked-Hierarchical-Labeling-Munoz-Bagnell",
            "title": {
                "fragments": [],
                "text": "Stacked Hierarchical Labeling"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work bypasses a global probabilistic model and instead directly train a hierarchical inference procedure inspired by the message passing mechanics of some approximate inference procedures in graphical models, which mitigates both the theoretical and empirical difficulties of learning Probabilistic models when exact inference is intractable."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760137"
                        ],
                        "name": "Haifeng Gong",
                        "slug": "Haifeng-Gong",
                        "structuredName": {
                            "firstName": "Haifeng",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haifeng Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1978562"
                        ],
                        "name": "Jack Sim",
                        "slug": "Jack-Sim",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Sim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jack Sim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145371551"
                        ],
                        "name": "M. Likhachev",
                        "slug": "M.-Likhachev",
                        "structuredName": {
                            "firstName": "Maxim",
                            "lastName": "Likhachev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Likhachev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[16] used potential goals and motion planning from homotopy classes to provide a prior for tracking under occlusion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9857913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73f84bfad5d3d6cd548ac43702802e2d244ad38d",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a long-term motion model for visual object tracking. In crowded street scenes, persistent occlusions are a frequent challenge for tracking algorithm and a robust, long-term motion model could help in these situations. Motivated by progresses in robot motion planning, we propose to construct a set of \u2018plausible\u2019 plans for each person, which are composed of multiple long-term motion prediction hypotheses that do not include redundancies, unnecessary loops or collisions with other objects. Constructing plausible plan is the key step in utilizing motion planning in object tracking, which has not been fully investigate in robot motion planning. We propose a novel method of efficiently constructing disjoint plans in different homotopy classes, based on winding numbers and winding angles of planned paths around all obstacles. As the goals can be specified by winding numbers and winding angles, we can avoid redundant plans in the same homotopy class and multiple whirls or loops around a single obstacle. We test our algorithm on a challenging, real-world dataset, and compare our algorithm with Linear Trajectory Avoidance and a simplified linear planning model. We find that our algorithm outperforms both algorithms in most sequences."
            },
            "slug": "Multi-hypothesis-motion-planning-for-visual-object-Gong-Sim",
            "title": {
                "fragments": [],
                "text": "Multi-hypothesis motion planning for visual object tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel method of efficiently constructing disjoint plans in differenthomotopy classes, based on winding numbers and winding angles of planned paths around all obstacles, which can avoid redundant plans in the same homotopy class and multiple whirls or loops around a single obstacle."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51505748"
                        ],
                        "name": "Daniel Munoz",
                        "slug": "Daniel-Munoz",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Munoz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Munoz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756566"
                        ],
                        "name": "J. Bagnell",
                        "slug": "J.-Bagnell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Bagnell",
                            "middleNames": [
                                "Andrew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bagnell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 172
                            }
                        ],
                        "text": "Recent semantic scene labeling approaches now provide a robust and reliable way of recognizing physical scene features such as pavement, grass, tree, building and car [1], [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9947256,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0415812484f68bfddf0710fc2c37749b41489cb",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of understanding scenes from multiple sources of sensor data (e.g., a camera and a laser scanner) in the case where there is no one-to-one correspondence across modalities (e.g., pixels and 3-D points). This is an important scenario that frequently arises in practice not only when two different types of sensors are used, but also when the sensors are not co-located and have different sampling rates. Previous work has addressed this problem by restricting interpretation to a single representation in one of the domains, with augmented features that attempt to encode the information from the other modalities. Instead, we propose to analyze all modalities simultaneously while propagating information across domains during the inference procedure. In addition to the immediate benefit of generating a complete interpretation in all of the modalities, we demonstrate that this co-inference approach also improves performance over the canonical approach."
            },
            "slug": "Co-inference-for-Multi-modal-Scene-Analysis-Munoz-Bagnell",
            "title": {
                "fragments": [],
                "text": "Co-inference for Multi-modal Scene Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes to analyze all modalities simultaneously while propagating information across domains during the inference procedure, and demonstrates that this co-inference approach also improves performance over the canonical approach."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737830"
                        ],
                        "name": "B. Morris",
                        "slug": "B.-Morris",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Morris",
                            "middleNames": [
                                "Tran"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Morris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713989"
                        ],
                        "name": "M. Trivedi",
                        "slug": "M.-Trivedi",
                        "structuredName": {
                            "firstName": "Mohan",
                            "lastName": "Trivedi",
                            "middleNames": [
                                "Manubhai"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Trivedi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "As a proof-of-concept, we focus on trajectory-based human activity analysis [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5755403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "770f736020c916e69c1e07252ba5f8473319f765",
            "isKey": false,
            "numCitedBy": 490,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a survey of trajectory-based activity analysis for visual surveillance. It describes techniques that use trajectory data to define a general set of activities that are applicable to a wide range of scenes and environments. Events of interest are detected by building a generic topographical scene description from underlying motion structure as observed over time. The scene topology is automatically learned and is distinguished by points of interest and motion characterized by activity paths. The methods we review are intended for real-time surveillance through definition of a diverse set of events for further analysis triggering, including virtual fencing, speed profiling, behavior classification, anomaly detection, and object interaction."
            },
            "slug": "A-Survey-of-Vision-Based-Trajectory-Learning-and-Morris-Trivedi",
            "title": {
                "fragments": [],
                "text": "A Survey of Vision-Based Trajectory Learning and Analysis for Surveillance"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The methods reviewed are intended for real-time surveillance through definition of a diverse set of events for further analysis triggering, including virtual fencing, speed profiling, behavior classification, anomaly detection, and object interaction."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Circuits and Systems for Video Technology"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2457612"
                        ],
                        "name": "Sangmin Oh",
                        "slug": "Sangmin-Oh",
                        "structuredName": {
                            "firstName": "Sangmin",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sangmin Oh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397590190"
                        ],
                        "name": "A. Hoogs",
                        "slug": "A.-Hoogs",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Hoogs",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hoogs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145895163"
                        ],
                        "name": "A. Perera",
                        "slug": "A.-Perera",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Perera",
                            "middleNames": [
                                "G.",
                                "Amitha"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Perera"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803047"
                        ],
                        "name": "Naresh P. Cuntoor",
                        "slug": "Naresh-P.-Cuntoor",
                        "structuredName": {
                            "firstName": "Naresh",
                            "lastName": "Cuntoor",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naresh P. Cuntoor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786891"
                        ],
                        "name": "Chia-Chih Chen",
                        "slug": "Chia-Chih-Chen",
                        "structuredName": {
                            "firstName": "Chia-Chih",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chia-Chih Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108613995"
                        ],
                        "name": "J. T. Lee",
                        "slug": "J.-T.-Lee",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Lee",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. T. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2972072"
                        ],
                        "name": "Saurajit Mukherjee",
                        "slug": "Saurajit-Mukherjee",
                        "structuredName": {
                            "firstName": "Saurajit",
                            "lastName": "Mukherjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saurajit Mukherjee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705627"
                        ],
                        "name": "J. Aggarwal",
                        "slug": "J.-Aggarwal",
                        "structuredName": {
                            "firstName": "Jake",
                            "lastName": "Aggarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aggarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2445131"
                        ],
                        "name": "Hyungtae Lee",
                        "slug": "Hyungtae-Lee",
                        "structuredName": {
                            "firstName": "Hyungtae",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyungtae Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2754027"
                        ],
                        "name": "E. Swears",
                        "slug": "E.-Swears",
                        "structuredName": {
                            "firstName": "Eran",
                            "lastName": "Swears",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Swears"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48631781"
                        ],
                        "name": "Xiaoyang Wang",
                        "slug": "Xiaoyang-Wang",
                        "structuredName": {
                            "firstName": "Xiaoyang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoyang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50426357"
                        ],
                        "name": "Q. Ji",
                        "slug": "Q.-Ji",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Ji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Ji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145096334"
                        ],
                        "name": "K. Reddy",
                        "slug": "K.-Reddy",
                        "structuredName": {
                            "firstName": "Kishore",
                            "lastName": "Reddy",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Reddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1856025"
                        ],
                        "name": "Carl Vondrick",
                        "slug": "Carl-Vondrick",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Vondrick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carl Vondrick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2367683"
                        ],
                        "name": "H. Pirsiavash",
                        "slug": "H.-Pirsiavash",
                        "structuredName": {
                            "firstName": "Hamed",
                            "lastName": "Pirsiavash",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Pirsiavash"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143738177"
                        ],
                        "name": "Jenny Yuen",
                        "slug": "Jenny-Yuen",
                        "structuredName": {
                            "firstName": "Jenny",
                            "lastName": "Yuen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jenny Yuen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145178895"
                        ],
                        "name": "Bi Song",
                        "slug": "Bi-Song",
                        "structuredName": {
                            "firstName": "Bi",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bi Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409113695"
                        ],
                        "name": "Anesco Fong",
                        "slug": "Anesco-Fong",
                        "structuredName": {
                            "firstName": "Anesco",
                            "lastName": "Fong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anesco Fong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404727582"
                        ],
                        "name": "A. Roy-Chowdhury",
                        "slug": "A.-Roy-Chowdhury",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Roy-Chowdhury",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Roy-Chowdhury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46988196"
                        ],
                        "name": "M. Desai",
                        "slug": "M.-Desai",
                        "structuredName": {
                            "firstName": "Mita",
                            "lastName": "Desai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Desai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "For our evaluation we use videos from the VIRAT ground dataset [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1826131,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c305fa65fed336e6be1d15a6567075c6ea6e51b",
            "isKey": false,
            "numCitedBy": 611,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new large-scale video dataset designed to assess the performance of diverse visual event recognition algorithms with a focus on continuous visual event recognition (CVER) in outdoor areas with wide coverage. Previous datasets for action recognition are unrealistic for real-world surveillance because they consist of short clips showing one action by one individual [15, 8]. Datasets have been developed for movies [11] and sports [12], but, these actions and scene conditions do not apply effectively to surveillance videos. Our dataset consists of many outdoor scenes with actions occurring naturally by non-actors in continuously captured videos of the real world. The dataset includes large numbers of instances for 23 event types distributed throughout 29 hours of video. This data is accompanied by detailed annotations which include both moving object tracks and event examples, which will provide solid basis for large-scale evaluation. Additionally, we propose different types of evaluation modes for visual recognition tasks and evaluation metrics along with our preliminary experimental results. We believe that this dataset will stimulate diverse aspects of computer vision research and help us to advance the CVER tasks in the years ahead."
            },
            "slug": "A-large-scale-benchmark-dataset-for-event-in-video-Oh-Hoogs",
            "title": {
                "fragments": [],
                "text": "A large-scale benchmark dataset for event recognition in surveillance video"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new large-scale video dataset designed to assess the performance of diverseVisual event recognition algorithms with a focus on continuous visual event recognition (CVER) in outdoor areas with wide coverage is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48908475"
                        ],
                        "name": "Chang Huang",
                        "slug": "Chang-Huang",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143847264"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 185
                            }
                        ],
                        "text": "Work exploring the impact of destinations, such as entrances and exits, of the environment on trajectories has shown that knowledge of goals yields better recognition of human activity [14], [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9088971,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce4331e3728100af129d849da6a954149946e816",
            "isKey": false,
            "numCitedBy": 539,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a detection-based three-level hierarchical association approach to robustly track multiple objects in crowded environments from a single camera. At the low level, reliable tracklets (i.e. short tracks for further analysis) are generated by linking detection responses based on conservative affinity constraints. At the middle level, these tracklets are further associated to form longer tracklets based on more complex affinity measures. The association is formulated as a MAP problem and solved by the Hungarian algorithm. At the high level, entries, exits and scene occluders are estimated using the already computed tracklets, which are used to refine the final trajectories. This approach is applied to the pedestrian class and evaluated on two challenging datasets. The experimental results show a great improvement in performance compared to previous methods."
            },
            "slug": "Robust-Object-Tracking-by-Hierarchical-Association-Huang-Wu",
            "title": {
                "fragments": [],
                "text": "Robust Object Tracking by Hierarchical Association of Detection Responses"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This work presents a detection-based three-level hierarchical association approach to robustly track multiple objects in crowded environments from a single camera and shows a great improvement in performance compared to previous methods."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698158"
                        ],
                        "name": "Minh Hoai Nguyen",
                        "slug": "Minh-Hoai-Nguyen",
                        "structuredName": {
                            "firstName": "Minh",
                            "lastName": "Nguyen",
                            "middleNames": [
                                "Hoai"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minh Hoai Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143867160"
                        ],
                        "name": "F. D. L. Torre",
                        "slug": "F.-D.-L.-Torre",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Torre",
                            "middleNames": [
                                "De",
                                "la"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. D. L. Torre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 210
                            }
                        ],
                        "text": "There is also an area of emerging research termed early recognition, where the task is to classify an incoming temporal sequence as early as possible while maintaining a level of detection accuracy [17], [18], [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8386677,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b72756c4d4237a857e1a764c876e82a82edd128c",
            "isKey": false,
            "numCitedBy": 311,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "The need for early detection of temporal events from sequential data arises in a wide spectrum of applications ranging from human-robot interaction to video security. While temporal event detection has been extensively studied, early detection is a relatively unexplored problem. This paper proposes a maximum-margin framework for training temporal event detectors to recognize partial events, enabling early detection. Our method is based on Structured Output SVM, but extends it to accommodate sequential data. Experiments on datasets of varying complexity, for detecting facial expressions, hand gestures, and human activities, demonstrate the benefits of our approach."
            },
            "slug": "Max-Margin-Early-Event-Detectors-Nguyen-Torre",
            "title": {
                "fragments": [],
                "text": "Max-Margin Early Event Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes a maximum-margin framework for training temporal event detectors to recognize partial events, enabling early detection, based on Structured Output SVM, but extends it to accommodate sequential data."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31997189"
                        ],
                        "name": "M. Turek",
                        "slug": "M.-Turek",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turek",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642913"
                        ],
                        "name": "A. Hoogs",
                        "slug": "A.-Hoogs",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Hoogs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hoogs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34265270"
                        ],
                        "name": "Roderic Collins",
                        "slug": "Roderic-Collins",
                        "structuredName": {
                            "firstName": "Roderic",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roderic Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "Other work uses trajectories to infer the functional features of the environment such as road, sidewalk and entrance [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 45373233,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78be49a8652dd9e233bbdad8ba8e588e41af319a",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Existing methods for video scene analysis are primarily concerned with learning motion patterns or models for anomaly detection. We present a novel form of video scene analysis where scene element categories such as roads, parking areas, sidewalks and entrances, can be segmented and categorized based on the behaviors of moving objects in and around them. We view the problem from the perspective of categorical object recognition, and present an approach for unsupervised learning of functional scene element categories. Our approach identifies functional regions with similar behaviors in the same scene and/or across scenes, by clustering histograms based on a trajectory-level, behavioral codebook. Experiments are conducted on two outdoor webcam video scenes with low frame rates and poor quality. Unsupervised classification results are presented for each scene independently, and also jointly where models learned on one scene are applied to the other."
            },
            "slug": "Unsupervised-Learning-of-Functional-Categories-in-Turek-Hoogs",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Functional Categories in Video Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work presents a novel form of video scene analysis where scene element categories such as roads, parking areas, sidewalks and entrances, can be segmented and categorized based on the behaviors of moving objects in and around them."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736651"
                        ],
                        "name": "S. Levine",
                        "slug": "S.-Levine",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Levine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1986848"
                        ],
                        "name": "Zoran Popovic",
                        "slug": "Zoran-Popovic",
                        "structuredName": {
                            "firstName": "Zoran",
                            "lastName": "Popovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoran Popovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145231047"
                        ],
                        "name": "V. Koltun",
                        "slug": "V.-Koltun",
                        "structuredName": {
                            "firstName": "Vladlen",
                            "lastName": "Koltun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Koltun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": ", video games [7] and locations in road networks [6])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12063228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e045f3447f69d9a7cac18ef23062ea8dd661285",
            "isKey": false,
            "numCitedBy": 292,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a probabilistic algorithm for nonlinear inverse reinforcement learning. The goal of inverse reinforcement learning is to learn the reward function in a Markov decision process from expert demonstrations. While most prior inverse reinforcement learning algorithms represent the reward as a linear combination of a set of features, we use Gaussian processes to learn the reward as a nonlinear function, while also determining the relevance of each feature to the expert's policy. Our probabilistic algorithm allows complex behaviors to be captured from suboptimal stochastic demonstrations, while automatically balancing the simplicity of the learned reward structure against its consistency with the observed actions."
            },
            "slug": "Nonlinear-Inverse-Reinforcement-Learning-with-Levine-Popovic",
            "title": {
                "fragments": [],
                "text": "Nonlinear Inverse Reinforcement Learning with Gaussian Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A probabilistic algorithm that allows complex behaviors to be captured from suboptimal stochastic demonstrations, while automatically balancing the simplicity of the learned reward structure against its consistency with the observed actions."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38245610"
                        ],
                        "name": "Saad Ali",
                        "slug": "Saad-Ali",
                        "structuredName": {
                            "firstName": "Saad",
                            "lastName": "Ali",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saad Ali"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "We take a departure from traditional motion-based approaches [9], [10] and explore the interplay between features of the environment and pedestrian trajectories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9560504,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4c5b3995f14fcb85affde0164addbbd4d962914",
            "isKey": false,
            "numCitedBy": 430,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an algorithm for tracking individual targets in high density crowd scenes containing hundreds of people. Tracking in such a scene is extremely challenging due to the small number of pixels on the target, appearance ambiguity resulting from the dense packing, and severe inter-object occlusions. The novel tracking algorithm, which is outlined in this paper, will overcome these challenges using a scene structure based force model. In this force model an individual, when moving in a particular scene, is subjected to global and local forces that are functions of the layout of that scene and the locomotive behavior of other individuals in the scene. The key ingredients of the force model are three floor fields, which are inspired by the research in the field of evacuation dynamics, namely Static Floor Field (SFF), Dynamic Floor Field (DFF), and Boundary Floor Field (BFF). These fields determine the probability of move from one location to another by converting the long-range forces into local ones. The SFF specifies regions of the scene which are attractive in nature (e.g. an exit location). The DFF specifies the immediate behavior of the crowd in the vicinity of the individual being tracked. The BFF specifies influences exhibited by the barriers in the scene (e.g. walls, no-go areas). By combining cues from all three fields with the available appearance information, we track individual targets in high density crowds."
            },
            "slug": "Floor-Fields-for-Tracking-in-High-Density-Crowd-Ali-Shah",
            "title": {
                "fragments": [],
                "text": "Floor Fields for Tracking in High Density Crowd Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An algorithm for tracking individual targets in high density crowd scenes containing hundreds of people using a scene structure based force model based on three floor fields, which are inspired by the research in the field of evacuation dynamics."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1885768"
                        ],
                        "name": "M. Chli",
                        "slug": "M.-Chli",
                        "structuredName": {
                            "firstName": "Margarita",
                            "lastName": "Chli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052135690"
                        ],
                        "name": "A. Davison",
                        "slug": "A.-Davison",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Davison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Davison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4518583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04554de05a3a9ebb1890d25aaa7e34544a0d32a7",
            "isKey": false,
            "numCitedBy": 1119,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In the matching tasks which form an integral part of all types of tracking and geometrical vision, there are invariably priors available on the absolute and/or relative image locations of features of interest. Usually, these priors are used post-hoc in the process of resolving feature matches and obtaining final scene estimates, via `first get candidate matches, then resolve' consensus algorithms such as RANSAC. In this paper we show that the dramatically different approach of using priors dynamically to guide a feature by feature matching search can achieve global matching with much fewer image processing operations and lower overall computational cost. Essentially, we put image processing into the loopof the search for global consensus. In particular, our approach is able to cope with significant image ambiguity thanks to a dynamic mixture of Gaussians treatment. In our fully Bayesian algorithm, the choice of the most efficient search action at each step is guided intuitively and rigorously by expected Shannon information gain. We demonstrate the algorithm in feature matching as part of a sequential SLAM system for 3D camera tracking. Robust, real-time matching can be achieved even in the previously unmanageable case of jerky, rapid motion necessitating weak motion modelling and large search regions."
            },
            "slug": "Active-Matching-Chli-Davison",
            "title": {
                "fragments": [],
                "text": "Active Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows that the dramatically different approach of using priors dynamically to guide a feature by feature matching search can achieve global matching with much fewer image processing operations and lower overall computational cost."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116931843"
                        ],
                        "name": "Shu Wang",
                        "slug": "Shu-Wang",
                        "structuredName": {
                            "firstName": "Shu",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shu Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153176123"
                        ],
                        "name": "Huchuan Lu",
                        "slug": "Huchuan-Lu",
                        "structuredName": {
                            "firstName": "Huchuan",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huchuan Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145338263"
                        ],
                        "name": "Fan Yang",
                        "slug": "Fan-Yang",
                        "structuredName": {
                            "firstName": "Fan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "In contrast, the trajectories of the SPT have no missing observations due to temporal filtering but have a tendency to drift away from the pedestrian."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "We run our experiments with a state-of-the-art super-pixel tracker (SPT) [23] and an in-house template-based tracker to show how the smoothing distribution improves the quality of estimated pedestrian trajectories."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "Despite that fact that our in-house tracker is not as robust as\n11\nSPT, the MHD after smoothing is actually better than the SPT post-smoothing."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "As such, the SPT has much better performance compared to our in-house tracker before smoothing."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9744463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b762ecb0624005831f2f3d8eb626d53e8eca4b6c",
            "isKey": true,
            "numCitedBy": 540,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "While numerous algorithms have been proposed for object tracking with demonstrated success, it remains a challenging problem for a tracker to handle large change in scale, motion, shape deformation with occlusion. One of the main reasons is the lack of effective image representation to account for appearance variation. Most trackers use high-level appearance structure or low-level cues for representing and matching target objects. In this paper, we propose a tracking method from the perspective of mid-level vision with structural information captured in superpixels. We present a discriminative appearance model based on superpixels, thereby facilitating a tracker to distinguish the target and the background with mid-level cues. The tracking task is then formulated by computing a target-background confidence map, and obtaining the best candidate by maximum a posterior estimate. Experimental results demonstrate that our tracker is able to handle heavy occlusion and recover from drifts. In conjunction with online update, the proposed algorithm is shown to perform favorably against existing methods for object tracking."
            },
            "slug": "Superpixel-tracking-Wang-Lu",
            "title": {
                "fragments": [],
                "text": "Superpixel tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents a discriminative appearance model based on superpixels, thereby facilitating a tracker to distinguish the target and the background with mid-level cues and is shown to perform favorably against existing methods for object tracking."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299436"
                        ],
                        "name": "R. Kaucic",
                        "slug": "R.-Kaucic",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Kaucic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kaucic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064442244"
                        ],
                        "name": "A. Perera",
                        "slug": "A.-Perera",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Perera",
                            "middleNames": [
                                "G.",
                                "Amitha"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Perera"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29416941"
                        ],
                        "name": "G. Brooksby",
                        "slug": "G.-Brooksby",
                        "structuredName": {
                            "firstName": "Glen",
                            "lastName": "Brooksby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Brooksby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781137"
                        ],
                        "name": "J. Kaufhold",
                        "slug": "J.-Kaufhold",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Kaufhold",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kaufhold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642913"
                        ],
                        "name": "A. Hoogs",
                        "slug": "A.-Hoogs",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Hoogs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hoogs"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 191
                            }
                        ],
                        "text": "Work exploring the impact of destinations, such as entrances and exits, of the environment on trajectories has shown that knowledge of goals yields better recognition of human activity [14], [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14178659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f77b0e931d6a1f22567cf6f532e843363660ba3",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A common difficulty encountered in tracking applications is how to track an object that becomes totally occluded, possibly for a significant period of time. Another problem is how to associate objects, or tracklets, across non-overlapping cameras, or between observations of a moving sensor that switches fields of regard. A third problem is how to update appearance models for tracked objects over time. As opposed to using a comprehensive multi-object tracker that must simultaneously deal with these tracking challenges, we present a novel, modular framework that handles each of these problems in a unified manner by the initialization, tracking, and linking of high-confidence tracklets. In this track/suspend/match paradigm, we first analyze the scene to identify areas where tracked objects are likely to become occluded. Tracking is then suspended on occluded objects and re-initiated when they emerge from behind the occlusion. We then associate, or match, suspended tracklets with the new tracklets using full kinematic models for object motion and Gibbsian distributions for object appearance in order to complete the track through the occlusion. Sensor gaps are handled in a similar manner, where tracking is suspended when the sensor looks away and then re-initiated when the sensor returns. Changes in object appearance and orientation during tracking are also seamlessly handled in this framework. Tracklets with low lock scores are terminated. Tracking then resumes on untracked movers with corresponding updated appearance models. These new tracklets are then linked back to the terminated ones as appropriate. Fully automatic tracking results from a moving sensor are presented."
            },
            "slug": "A-unified-framework-for-tracking-through-occlusions-Kaucic-Perera",
            "title": {
                "fragments": [],
                "text": "A unified framework for tracking through occlusions and across sensor gaps"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "This work presents a novel, modular framework that handles each of these problems in a unified manner by the initialization, tracking, and linking of high-confidence tracklets in a track/suspend/match paradigm."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2365442"
                        ],
                        "name": "B. Alexe",
                        "slug": "B.-Alexe",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Alexe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Alexe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879646"
                        ],
                        "name": "Thomas Deselaers",
                        "slug": "Thomas-Deselaers",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Deselaers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Deselaers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5611404,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d957ad316f7145c054d2dcbd47949869e46776b0",
            "isKey": false,
            "numCitedBy": 1007,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel method for unsupervised class segmentation on a set of images. It alternates between segmenting object instances and learning a class model. The method is based on a segmentation energy defined over all images at the same time, which can be optimized efficiently by techniques used before in interactive segmentation. Over iterations, our method progressively learns a class model by integrating observations over all images. In addition to appearance, this model captures the location and shape of the class with respect to an automatically determined coordinate frame common across images. This frame allows us to build stronger shape and location models, similar to those used in object class detection. Our method is inspired by interactive segmentation methods [1], but it is fully automatic and learns models characteristic for the object class rather than specific to one particular object/image. We experimentally demonstrate on the Caltech4, Caltech101, and Weizmann horses datasets that our method (a) transfers class knowledge across images and this improves results compared to segmenting every image independently; (b) outperforms Grabcut [1] for the task of unsupervised segmentation; (c) offers competitive performance compared to the state-of-the-art in unsupervised segmentation and in particular it outperforms the topic model [2]."
            },
            "slug": "ClassCut-for-Unsupervised-Class-Segmentation-Alexe-Deselaers",
            "title": {
                "fragments": [],
                "text": "ClassCut for Unsupervised Class Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A novel method for unsupervised class segmentation on a set of images that alternates between segmenting object instances and learning a class model based on a segmentation energy defined over all images at the same time, which can be optimized efficiently by techniques used before in interactive segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766188"
                        ],
                        "name": "Zhengzheng Xing",
                        "slug": "Zhengzheng-Xing",
                        "structuredName": {
                            "firstName": "Zhengzheng",
                            "lastName": "Xing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengzheng Xing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145525190"
                        ],
                        "name": "J. Pei",
                        "slug": "J.-Pei",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Pei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2147292665"
                        ],
                        "name": "Guozhu Dong",
                        "slug": "Guozhu-Dong",
                        "structuredName": {
                            "firstName": "Guozhu",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guozhu Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144019071"
                        ],
                        "name": "Philip S. Yu",
                        "slug": "Philip-S.-Yu",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Yu",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip S. Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 198
                            }
                        ],
                        "text": "There is also an area of emerging research termed early recognition, where the task is to classify an incoming temporal sequence as early as possible while maintaining a level of detection accuracy [17], [18], [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 589641,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1877cd39cc70f54b9222ea731abdba880babf1b4",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Supervised learning on sequence data, also known as sequence classification, has been well recognized as an important data mining task with many significant applications. Since temporal order is important in sequence data, in many critical applications of sequence classification such as medical diagnosis and disaster prediction, early prediction is a highly desirable feature of sequence classifiers. In early prediction, a sequence classifier should use a prefix of a sequence as short as possible to make a reasonably accurate prediction. To the best of our knowledge, early prediction on sequence data has not been studied systematically. In this paper, we identify the novel problem of mining sequence classifiers for early prediction. We analyze the problem and the challenges. As the first attempt to tackle the problem, we propose two interesting methods. The sequential classification rule (SCR) method mines a set of sequential classification rules as a classifier. A so-called early-prediction utility is defined and used to select features and rules. The generalized sequential decision tree (GSDT) method adopts a divide-and-conquer strategy to generate a classification model. We conduct an extensive empirical evaluation on several real data sets. Interestingly, our two methods achieve accuracy comparable to that of the stateof-the-art methods, but typically need to use only very short prefixes of the sequences. The results clearly indicate that early prediction is highly feasible and effective."
            },
            "slug": "Mining-Sequence-Classifiers-for-Early-Prediction-Xing-Pei",
            "title": {
                "fragments": [],
                "text": "Mining Sequence Classifiers for Early Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper identifies the novel problem of mining sequence classifiers for early prediction, and proposes two interesting methods that achieve accuracy comparable to that of the stateof-the-art methods, but typically need to use only very short prefixes of the sequences."
            },
            "venue": {
                "fragments": [],
                "text": "SDM"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144873562"
                        ],
                        "name": "R. Bellman",
                        "slug": "R.-Bellman",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Bellman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bellman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "Our work is also different from Partially Observable Markov Decision Process (POMDP) models because we assume that the observer has noisy observations of an actor, where the actor is fully aware of his own state."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "To this end, we propose a Hidden variable Markov Decision Process (hMDP) model which incorporates uncertainty (e.g., probabilistic physical scene features) and noisy observations (e.g., imperfect tracker) into the activity model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "In a POMDP, the actor is uncertain about his own state and the observer is not modeled."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "The MDP is defined by an initial state distribution p(s0), a transition model p(s\u2032|s, a) (shorthand ps\u2032s,a) and a cost function r(s)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "The Markov decision process (MDP) [20] is used to express the dynamics of a decision-making process (Figure 3b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "In deterministic MDPs, where the action decisions may be randomized but the state transitions follow deterministically from a state-action pair, we can invert the role of goal and start locations for an agent."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "In our hMDP model (Figure 3a), we add state observations u to represent the uncertainty of being in a state."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 63
                            }
                        ],
                        "text": "Further, the resulting formulation, based on a hidden variable MDP, provides a unified framework to support a range of operations in activity analysis: smoothing, path and destination forecasting, and transfer, which we validated both qualitatively and quantitatively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 166
                            }
                        ],
                        "text": "We summarize our contributions as follows: (1) we introduce the concept of inverse optimal control to the field of visionbased activity analysis, (2) we propose the hMDP model and a hidden variable inverse optimal control (HIOC) inference procedure to deal with uncertainty in observations and (3) we demonstrate the performance of forecasting, smoothing,\ndestination forecasting and knowledge transfer operations in a single framework on real image data."
                    },
                    "intents": []
                }
            ],
            "corpusId": 123329493,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "bff20fb30adad8d1c173963089df5fc9664304f0",
            "isKey": true,
            "numCitedBy": 1843,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The purpose of this paper is to discuss the asymptotic behavior of the sequence (f sub n(i)) generated by a nonlinear recurrence relation. This problem arises in connection with an equipment replacement problem, cf. S. Dreyfus, A Note on an Industrial Replacement Process."
            },
            "slug": "A-Markovian-Decision-Process-Bellman",
            "title": {
                "fragments": [],
                "text": "A Markovian Decision Process"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Max-margin early event detectors A Markovian decision process"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Mathematics and Mechanics"
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Superpixel tracking. In: ICCV"
            },
            "venue": {
                "fragments": [],
                "text": "Superpixel tracking. In: ICCV"
            },
            "year": 2011
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 15,
            "methodology": 10
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 27,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Activity-Forecasting-Kitani-Ziebart/0d8a5addbd17d2c7c8043d8877234675da19938a?sort=total-citations"
}