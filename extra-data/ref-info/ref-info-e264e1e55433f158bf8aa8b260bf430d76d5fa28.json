{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40538579"
                        ],
                        "name": "J. Vogel",
                        "slug": "J.-Vogel",
                        "structuredName": {
                            "firstName": "Julia",
                            "lastName": "Vogel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vogel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 92
                            }
                        ],
                        "text": "For a comparison between a k-nearest neighbor classifier and a SVM classifier also refer to Vogel (2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For more details, please refer to [42]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For a comparison between a k-nearest neighbor classifier and a SVM classifier also refer to [42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 34
                            }
                        ],
                        "text": "For more details, please refer to Vogel (2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18843968,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39e82f318df1f214809ea86bbccac860e899155d",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 130,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantics-based image retrieval has gained increasing interest in recent years. As an area in linguistics, semantics deals with the sense and the meaning of language. In the context of content-based image retrieval, the research goal is to access the meaning of images by naming or describing the most important image regions and their relationships. The topic of this dissertation is the semantic description, understanding, and mod-eling of natural scenes. The primary objective is to develop a computational image representation that reduces the semantic gap between the image understanding of humans and the computer. For humans, the most intuitive means of communications about images is image description. Image semantics and image description are thus closely interconnected. We propose a semantic modeling of natural scenes that is based on the classification of local semantic concepts. Image regions are extracted on a regular 10x10 grid. The resulting patches are classified into nine concept classes that subsume the main semantic content of the database images. Images are represented through the frequency of occurrence of the semantic concepts. This semantic modeling constitutes a compact, semantic image representation that allows to describe or search for specific image content, or, on a higher level, to model the semantic content of natural scene categories. The semantic modeling has been intensively studied for categorization and retrieval of natural scenes. Depending on the classification method and on the quality of the concept detectors, good to very good categorization and retrieval performance has been obtained. In particular, it is shown that the semantic modeling leads to considerably better categorization and retrieval performance compared to directly employing low-level features. Nevertheless, the analysis of the mis-categorized scenes reveals that the regular semantic ambiguity of the database images demands rather for a typicality ranking of images than for hard-decision categorization. This hypothesis is supported in two psychophysical experiments. Humans are able to consistently categorize images, but the employed database consists to a large degree of images that can be assigned to several scene categories. However, the human participants were very consistent in ranking the database images according to their semantic typicality. It is shown visually and quantitatively, that the proposed semantic modeling is also well-suited for semantic ranking of images. In particular, the typicality transition between two scene categories can be modeled. In addition, we propose a perceptually plausible distance measure that represents the most discriminant semantic concepts of each scene category. The typicality \u2026"
            },
            "slug": "Semantic-scene-modeling-and-retrieval-Vogel",
            "title": {
                "fragments": [],
                "text": "Semantic scene modeling and retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A semantic modeling of natural scenes that is based on the classification of local semantic concepts that constitutes a compact, semantic image representation that allows to describe or search for specific image content, or, on a higher level, to model the semantic content of natural scene categories."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144053687"
                        ],
                        "name": "A. Mojsilovic",
                        "slug": "A.-Mojsilovic",
                        "structuredName": {
                            "firstName": "Aleksandra",
                            "lastName": "Mojsilovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mojsilovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056191569"
                        ],
                        "name": "Jos\u00e9 Gomes",
                        "slug": "Jos\u00e9-Gomes",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Gomes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 Gomes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3112585"
                        ],
                        "name": "B. Rogowitz",
                        "slug": "B.-Rogowitz",
                        "structuredName": {
                            "firstName": "Bernice",
                            "lastName": "Rogowitz",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rogowitz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 44
                            }
                        ],
                        "text": "Influenced by the psychophysical studies of Mojsilovic et al. (2004) and through the analysis of the semantic similarities and dissimilarities of the employed images, nine local semantic concept si , i = 1 . . ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In addition, the natural, basic-level categories of Tversky and Hemenway [39] and the natural scene categories of Mojsilovic et al. [ 21 ] were combined and extended to the categories coasts, rivers/lakes, forests, plains, mountains and sky/ clouds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In\u221euenced by the psychophysical studies of Mojsilovic et al. [ 21 ] and through the analysis of the semantic similarities and dissimilarities of the employed images, nine local semantic concept si;i = 1:::M;M = 9 were determined as being discriminant for the desired retrieval tasks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "These semantic axes were further extended in [ 21 ] and resulted in the 20 mentioned scene categories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 45
                            }
                        ],
                        "text": "These semantic axes were further extended in Mojsilovic et al. (2004) and resulted in the 20 mentioned scene categories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Also through a set of psychophysical experiments, Mojsilovic et al. [ 21 ] obtain 20 semantic categories relevant for humans as well as verbal descriptions of these categories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 116
                            }
                        ],
                        "text": "In addition, the natural, basic-level categories of Tversky and Hemenway (1983) and the natural scene categories of Mojsilovic et al. (2004) were combined and extended to the categories coasts, rivers/lakes, forests, plains, mountains and sky/clouds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 50
                            }
                        ],
                        "text": "Also through a set of psychophysical experiments, Mojsilovic et al. (2004) obtain 20 semantic categories relevant for humans as well as verbal descriptions of these categories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2666403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4d165edae9e431a59993641d3b85c9bb640513a",
            "isKey": true,
            "numCitedBy": 77,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract image semantics resists all forms of modeling, very much like any kind of intelligence does. However, in order to develop more satisfying image navigation systems, we need tools to construct a semantic bridge between the user and the database. In this paper we present an image indexing scheme and a query language, which allow the user to introduce cognitive dimension to the search. At an abstract level, this approach consists of: (1) learning the \u201cnatural language\u201d that humans speak to communicate their semantic experience of images, (2) understanding the relationships between this language and objective measurable image attributes, and then (3) developing corresponding feature extraction schemes.More precisely, we have conducted a number of subjective experiments in which we asked human subjects to group images, and then explain verbally why they did so. The results of this study indicated that a part of the abstraction involved in image interpretation is often driven by semantic categories, which can be broken into more tangible semantic entities, i.e. objective semantic indicators. By analyzing our experimental data, we have identified some candidate semantic categories (i.e. portraits, people, crowds, cityscapes, landscapes, etc.) and their underlying semantic indicators (i.e. skin, sky, water, object, etc.). These experiments also helped us derive important low-level image descriptors, accounting for our perception of these indicators.We have then used these findings to develop an image feature extraction and indexing scheme. In particular, our feature set has been carefully designed to match the way humans communicate image meaning. This led us to the development of a \u201csemantic-friendly\u201d query language for browsing and searching diverse collections of images.We have implemented our approach into an Internet search engine, and tested it on a large number of images. The results we obtained are very promising."
            },
            "slug": "Semantic-Friendly-Indexing-and-Quering-of-Images-on-Mojsilovic-Gomes",
            "title": {
                "fragments": [],
                "text": "Semantic-Friendly Indexing and Quering of Images Based on the Extraction of the Objective Semantic Cues"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An image indexing scheme and a query language, which allow the user to introduce cognitive dimension to the search, and the development of a \u201csemantic-friendly\u201d query language for browsing and searching diverse collections of images."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277853"
                        ],
                        "name": "A. Vailaya",
                        "slug": "A.-Vailaya",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Vailaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vailaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34659351"
                        ],
                        "name": "M\u00e1rio A. T. Figueiredo",
                        "slug": "M\u00e1rio-A.-T.-Figueiredo",
                        "structuredName": {
                            "firstName": "M\u00e1rio",
                            "lastName": "Figueiredo",
                            "middleNames": [
                                "A.",
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M\u00e1rio A. T. Figueiredo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 282,
                                "start": 262
                            }
                        ],
                        "text": "Also in the early work on scene classification, semantics are often only found in the definition of the scene classes, e.g. indoor vs. outdoor, or waterfalls vs. mountains (Feng et al., 2003; Lipson et al., 1997; Maron and Ratan, 1998; Szummer and Picard, 1998; Vailaya et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: semantic scene understanding, content-based image retrieval, scene clasification, human scene preception, perceptually based techniques, computer vision"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9140319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "142f056a365dccd029c0897fcfa7833aecf2212f",
            "isKey": false,
            "numCitedBy": 868,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Grouping images into (semantically) meaningful categories using low-level visual features is a challenging and important problem in content-based image retrieval. Using binary Bayesian classifiers, we attempt to capture high-level concepts from low-level image features under the constraint that the test image does belong to one of the classes. Specifically, we consider the hierarchical classification of vacation images; at the highest level, images are classified as indoor or outdoor; outdoor images are further classified as city or landscape; finally, a subset of landscape images is classified into sunset, forest, and mountain classes. We demonstrate that a small vector quantizer (whose optimal size is selected using a modified MDL criterion) can be used to model the class-conditional densities of the features, required by the Bayesian methodology. The classifiers have been designed and evaluated on a database of 6931 vacation photographs. Our system achieved a classification accuracy of 90.5% for indoor/outdoor, 95.3% for city/landscape, 96.6% for sunset/forest and mountain, and 96% for forest/mountain classification problems. We further develop a learning method to incrementally train the classifiers as additional data become available. We also show preliminary results for feature reduction using clustering techniques. Our goal is to combine multiple two-class classifiers into a single hierarchical classifier."
            },
            "slug": "Image-classification-for-content-based-indexing-Vailaya-Figueiredo",
            "title": {
                "fragments": [],
                "text": "Image classification for content-based indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The goal is to combine multiple two-class classifiers into a single hierarchical classifier, and it is demonstrated that a small vector quantizer can be used to model the class-conditional densities of the features, required by the Bayesian methodology."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717056"
                        ],
                        "name": "M. Worring",
                        "slug": "M.-Worring",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Worring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Worring"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747647"
                        ],
                        "name": "S. Santini",
                        "slug": "S.-Santini",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Santini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Santini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722619"
                        ],
                        "name": "Amarnath Gupta",
                        "slug": "Amarnath-Gupta",
                        "structuredName": {
                            "firstName": "Amarnath",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amarnath Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: semantic scene understanding, content-based image retrieval, scene clasification, human scene preception, perceptually based techniques, computer vision"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 186
                            }
                        ],
                        "text": "Particularly, early retrieval systems have been based on the extraction of only low-level, often global pictorial features (for overviews see (Eakins and Graham, 1999; Rui et al., 1999; Smeulders et al., 2000; Veltkamp and Tanase, 2001))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2827898,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b7c4096ed697696a5f4fc8f3a6a750dc0cdecfe",
            "isKey": false,
            "numCitedBy": 6727,
            "numCiting": 410,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a review of 200 references in content-based image retrieval. The paper starts with discussing the working conditions of content-based retrieval: patterns of use, types of pictures, the role of semantics, and the sensory gap. Subsequent sections discuss computational steps for image retrieval systems. Step one of the review is image processing for retrieval sorted by color, texture, and local geometry. Features for retrieval are discussed next, sorted by: accumulative and global features, salient points, object and shape features, signs, and structural combinations thereof. Similarity of pictures and objects in pictures is reviewed for each of the feature types, in close connection to the types and means of feedback the user of the systems is capable of giving by interaction. We briefly discuss aspects of system engineering: databases, system architecture, and evaluation. In the concluding section, we present our view on: the driving force of the field, the heritage from computer vision, the influence on computer vision, the role of similarity and of interaction, the need for databases, the problem of evaluation, and the role of the semantic gap."
            },
            "slug": "Content-Based-Image-Retrieval-at-the-End-of-the-Smeulders-Worring",
            "title": {
                "fragments": [],
                "text": "Content-Based Image Retrieval at the End of the Early Years"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The working conditions of content-based retrieval: patterns of use, types of pictures, the role of semantics, and the sensory gap are discussed, as well as aspects of system engineering: databases, system architecture, and evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398547891"
                        ],
                        "name": "A. Gu\u00e9rin-Dugu\u00e9",
                        "slug": "A.-Gu\u00e9rin-Dugu\u00e9",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Gu\u00e9rin-Dugu\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gu\u00e9rin-Dugu\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798563"
                        ],
                        "name": "J. H\u00e9rault",
                        "slug": "J.-H\u00e9rault",
                        "structuredName": {
                            "firstName": "Jeanny",
                            "lastName": "H\u00e9rault",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H\u00e9rault"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Oliva et al. (1999) are among the first to bring a truly semantic component into the field of scene classification by proposing to organize images along three semantic axes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: semantic scene understanding, content-based image retrieval, scene clasification, human scene preception, perceptually based techniques, computer vision"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58152848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13d5e3104b902ad70bf4dc0564a4c336a4935475",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Scene recognition and content-based procedures are of great interest for image indexing applications processing very large databases. Knowing the context of a scene, a retrieval system may compute its semantic category in advance and filter out scenes belonging to irrelevant classes. \n \nIn this paper, we introduce a computational approach which classifies and organises real-world scenes along broad semantic axes. Fundamental to our approach is the computation of global spectral templates providing a continuous organisation of scenes between two categories. These templates encode the structure which is discriminant between two categories. We propose a hierarchical procedure of two stages, that organises images along three semantic axis. Firstly, all the scenes are classified according to an Artificial to Natural axis. Then, natural scenes are organised along the Open to Closed axis whereas artificial environments are classified according to the Expanded to Enclosed scenes axis."
            },
            "slug": "Global-semantic-classification-of-scenes-using-Oliva-Torralba",
            "title": {
                "fragments": [],
                "text": "Global semantic classification of scenes using power spectrum templates"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A computational approach which classifies and organises real-world scenes along broad semantic axes and proposes a hierarchical procedure of two stages, that organises images along three semantic axis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2446509"
                        ],
                        "name": "P. D. Sahin",
                        "slug": "P.-D.-Sahin",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Sahin",
                            "middleNames": [
                                "Duygulu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Sahin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 102
                            }
                        ],
                        "text": "Recently, several systems have been proposed that address a global as well as local image annotation (Barnard et al., 2002, 2003; Duygulu et al., 2002;\nFeng et al., 2004; Lavrenko et al., 2003; Oliva and Torralba, 2001, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 50
                            }
                        ],
                        "text": "First, the semantic modeling is compared to direct feature extraction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 106
                            }
                        ],
                        "text": "Also, the annotation accuracies are undesirably low as in approaches modeling word-region co-occurrences (Barnard et al., 2003; Lavrenko et al., 2003; Feng et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 868535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a26268d2ba9d34e5b59ae6e5c11a83cdca1a85e",
            "isKey": false,
            "numCitedBy": 1760,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text. Learning the joint distribution of image regions and words has many applications. We consider in detail predicting words associated with whole images (auto-annotation) and corresponding to particular image regions (region naming). Auto-annotation might help organize and access large collections of images. Region naming is a model of object recognition as a process of translating image regions to words, much as one might translate from one language to another. Learning the relationships between image regions and semantic correlates (words) is an interesting example of multi-modal data mining, particularly because it is typically hard to apply data mining techniques to collections of images. We develop a number of models for the joint distribution of image regions and words, including several which explicitly learn the correspondence between regions and words. We study multi-modal and correspondence extensions to Hofmann's hierarchical clustering/aspect model, a translation model adapted from statistical machine translation (Brown et al.), and a multi-modal extension to mixture of latent Dirichlet allocation (MoM-LDA). All models are assessed using a large collection of annotated images of real scenes. We study in depth the difficult problem of measuring performance. For the annotation task, we look at prediction performance on held out data. We present three alternative measures, oriented toward different types of task. Measuring the performance of correspondence methods is harder, because one must determine whether a word has been placed on the right region of an image. We can use annotation performance as a proxy measure, but accurate measurement requires hand labeled data, and thus must occur on a smaller scale. We show results using both an annotation proxy, and manually labeled data."
            },
            "slug": "Matching-Words-and-Pictures-Barnard-Sahin",
            "title": {
                "fragments": [],
                "text": "Matching Words and Pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text, is presented, and a number of models for the joint distribution of image regions and words are developed, including several which explicitly learn the correspondence between regions and Words."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 194
                            }
                        ],
                        "text": "Recently, several systems have been proposed that address a global as well as local image annotation (Barnard et al., 2002, 2003; Duygulu et al., 2002;\nFeng et al., 2004; Lavrenko et al., 2003; Oliva and Torralba, 2001, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: semantic scene understanding, content-based image retrieval, scene clasification, human scene preception, perceptually based techniques, computer vision"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11664336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "869171b2f56cfeaa9b81b2626cb4956fea590a57",
            "isKey": false,
            "numCitedBy": 6523,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a computational model of the recognition of real world scenes that bypasses the segmentation and the processing of individual objects or regions. The procedure is based on a very low dimensional representation of the scene, that we term the Spatial Envelope. We propose a set of perceptual dimensions (naturalness, openness, roughness, expansion, ruggedness) that represent the dominant spatial structure of a scene. Then, we show that these dimensions may be reliably estimated using spectral and coarsely localized information. The model generates a multidimensional space in which scenes sharing membership in semantic categories (e.g., streets, highways, coasts) are projected closed together. The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category."
            },
            "slug": "Modeling-the-Shape-of-the-Scene:-A-Holistic-of-the-Oliva-Torralba",
            "title": {
                "fragments": [],
                "text": "Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2123706"
                        ],
                        "name": "P. Lipson",
                        "slug": "P.-Lipson",
                        "structuredName": {
                            "firstName": "Pamela",
                            "lastName": "Lipson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lipson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 192
                            }
                        ],
                        "text": "Also in the early work on scene classification, semantics are often only found in the definition of the scene classes, e.g. indoor vs. outdoor, or waterfalls vs. mountains (Feng et al., 2003; Lipson et al., 1997; Maron and Ratan, 1998; Szummer and Picard, 1998; Vailaya et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: semantic scene understanding, content-based image retrieval, scene clasification, human scene preception, perceptually based techniques, computer vision"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206589454,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8cf3f0ea76961eca50bf26ab31e677037cab622",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Scene classification is a major open challenge in machine vision. Most solutions proposed so far such as those based on color histograms and local texture statistics cannot capture a scene's global configuration, which is critical in perceptual judgments of scene similarity. We present a novel approach, \"configural recognition\", for encoding scene class structure. The approach's main feature is its use of qualitative spatial and photometric relationships within and across regions in low resolution images. The emphasis on qualitative measures leads to enhanced generalization abilities and the use of low-resolution images renders the scheme computationally efficient. We present results on a large database of natural scenes. We also describe how qualitative scene concepts may be learned from examples."
            },
            "slug": "Configuration-based-scene-classification-and-image-Lipson-Grimson",
            "title": {
                "fragments": [],
                "text": "Configuration based scene classification and image indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel approach, \"configural recognition\", for encoding scene class structure using qualitative spatial and photometric relationships within and across regions in low resolution images and how qualitative scene concepts may be learned from examples is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757708"
                        ],
                        "name": "V. Lavrenko",
                        "slug": "V.-Lavrenko",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lavrenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lavrenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791802"
                        ],
                        "name": "J. Jeon",
                        "slug": "J.-Jeon",
                        "structuredName": {
                            "firstName": "Jiwoon",
                            "lastName": "Jeon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jeon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 1
                            }
                        ],
                        "text": "As visualized in the lower part of Fig."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 171
                            }
                        ],
                        "text": "Recently, several systems have been proposed that address a global as well as local image annotation (Barnard et al., 2002, 2003; Duygulu et al., 2002;\nFeng et al., 2004; Lavrenko et al., 2003; Oliva and Torralba, 2001, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 128
                            }
                        ],
                        "text": "Also, the annotation accuracies are undesirably low as in approaches modeling word-region co-occurrences (Barnard et al., 2003; Lavrenko et al., 2003; Feng et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: semantic scene understanding, content-based image retrieval, scene clasification, human scene preception, perceptually based techniques, computer vision"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 575890,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18f8820e2a5ca6273a39123c27c0745870cda057",
            "isKey": true,
            "numCitedBy": 798,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach to learning the semantics of images which allows us to automatically annotate an image with keywords and to retrieve images based on text queries. We do this using a formalism that models the generation of annotated images. We assume that every image is divided into regions, each described by a continuous-valued feature vector. Given a training set of images with annotations, we compute a joint probabilistic model of image features and words which allow us to predict the probability of generating a word given the image regions. This may be used to automatically annotate and retrieve images given a word as a query. Experiments show that our model significantly outperforms the best of the previously reported results on the tasks of automatic image annotation and retrieval."
            },
            "slug": "A-Model-for-Learning-the-Semantics-of-Pictures-Lavrenko-Manmatha",
            "title": {
                "fragments": [],
                "text": "A Model for Learning the Semantics of Pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "An approach to learning the semantics of images which allows us to automatically annotate an image with keywords and to retrieve images based on text queries using a formalism that models the generation of annotated images."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 317,
                                "start": 220
                            }
                        ],
                        "text": "An additional way to access semantic image information is to automatically attach a set of manually selected, semantically meaningful labels to local image regions that can be searched for in a subsequent retrieval step (Kumar and Hebert, 2003; Minka and Picard, 1997; Picard and Minka, 1995; Town and Sinclair, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 271,
                                "start": 249
                            }
                        ],
                        "text": "\u2026access semantic image information is to automatically attach a set of manually selected, semantically meaningful labels to local image regions that can be searched for in a subsequent retrieval step (Kumar and Hebert, 2003; Minka and Picard, 1997; Picard and Minka, 1995; Town and Sinclair, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2475363,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c183048cd41e47ffee77e19e0d198db5748b7d25",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper demonstrates a new application of computer vision to digital libraries \u2014 the use of texture forannotation, the description of content. Vision-based annotation assists the user in attaching descriptions to large sets of images and video. If a user labels a piece of an image aswater, a texture model can be used to propagate this label to other \u201cvisually similar\u201d regions. However, a serious problem is that no single model has been found that is good enough to match reliably human perception of similarity in pictures. Rather than using one model, the system described here knows several texture models, and is equipped with the ability to choose the one that \u201cbest explains\u201d the regions selected by the user for annotating. If none of these models suffices, then it creates new explanations by combining models. Examples of annotations propagated by the system on natural scenes are given. The system provides an average gain of four to one in label prediction for a set of 98 images."
            },
            "slug": "Vision-texture-for-annotation-Picard-Minka",
            "title": {
                "fragments": [],
                "text": "Vision texture for annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper demonstrates a new application of computer vision to digital libraries \u2014 the use of texture forotation, the description of content, and is equipped with the ability to choose the one that \u201cbest explains\u201d the regions selected by the user for annotating."
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Systems"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1857558"
                        ],
                        "name": "Shaolei Feng",
                        "slug": "Shaolei-Feng",
                        "structuredName": {
                            "firstName": "Shaolei",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaolei Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757708"
                        ],
                        "name": "V. Lavrenko",
                        "slug": "V.-Lavrenko",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lavrenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lavrenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 24
                            }
                        ],
                        "text": "As visualized in the lower part of Fig."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 152
                            }
                        ],
                        "text": "Recently, several systems have been proposed that address a global as well as local image annotation (Barnard et al., 2002, 2003; Duygulu et al., 2002;\nFeng et al., 2004; Lavrenko et al., 2003; Oliva and Torralba, 2001, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 151
                            }
                        ],
                        "text": "Also, the annotation accuracies are undesirably low as in approaches modeling word-region co-occurrences (Barnard et al., 2003; Lavrenko et al., 2003; Feng et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: semantic scene understanding, content-based image retrieval, scene clasification, human scene preception, perceptually based techniques, computer vision"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3829888,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba4e1089e2c5a1c12e9f6c2686e9c8d1870c718e",
            "isKey": true,
            "numCitedBy": 912,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Retrieving images in response to textual queries requires some knowledge of the semantics of the picture. Here, we show how we can do both automatic image annotation and retrieval (using one word queries) from images and videos using a multiple Bernoulli relevance model. The model assumes that a training set of images or videos along with keyword annotations is provided. Multiple keywords are provided for an image and the specific correspondence between a keyword and an image is not provided. Each image is partitioned into a set of rectangular regions and a real-valued feature vector is computed over these regions. The relevance model is a joint probability distribution of the word annotations and the image feature vectors and is computed using the training set. The word probabilities are estimated using a multiple Bernoulli model and the image feature probabilities using a non-parametric kernel density estimate. The model is then used to annotate images in a test set. We show experiments on both images from a standard Corel data set and a set of video key frames from NIST's video tree. Comparative experiments show that the model performs better than a model based on estimating word probabilities using the popular multinomial distribution. The results also show that our model significantly outperforms previously reported results on the task of image and video annotation."
            },
            "slug": "Multiple-Bernoulli-relevance-models-for-image-and-Feng-Manmatha",
            "title": {
                "fragments": [],
                "text": "Multiple Bernoulli relevance models for image and video annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work shows how it can do both automatic image annotation and retrieval (using one word queries) from images and videos using a multiple Bernoulli relevance model, which significantly outperforms previously reported results on the task of image and video annotation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703601"
                        ],
                        "name": "N. Sebe",
                        "slug": "N.-Sebe",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sebe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731570"
                        ],
                        "name": "M. Lew",
                        "slug": "M.-Lew",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lew",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lew"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40403107"
                        ],
                        "name": "X. Zhou",
                        "slug": "X.-Zhou",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Zhou",
                            "middleNames": [
                                "Sean"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143866184"
                        ],
                        "name": "E. Bakker",
                        "slug": "E.-Bakker",
                        "structuredName": {
                            "firstName": "Erwin",
                            "lastName": "Bakker",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bakker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 92
                            }
                        ],
                        "text": "Some even argue that there is an \u201curgent need\u201d to gain access to the content of still images (Sebe et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 74
                            }
                        ],
                        "text": "Based on human ranking data, we learn a perceptually plausible distance measure that leads to a high correlation between the human and the automatically obtained typicality ranking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5371770,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "408d4796b821fb00fe81802c5538710d242c018d",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Image and video retrieval continues to be one of the most exciting and fastest-growing research areas in the field of multimedia technology. What are the main challenges in image and video retrieval? Despite the sustained efforts in the last years, we think that the paramount challenge remains bridging the semantic gap. By this we mean that low level features are easily measured and computed, but the starting point of the retrieval process is typically the high level query from a human. Translating or converting the question posed by a human to the low level features seen by the computer illustrates the problem in bridging the semantic gap. However, the semantic gap is not merely translating high level features to low level features. The essence of a semantic query is understanding the meaning behind the query. This can involve understanding both the intellectual and emotional sides of the human, not merely the distilled logical portion of the query but also the personal preferences and emotional subtons of the query and the preferential form of the results."
            },
            "slug": "The-State-of-the-Art-in-Image-and-Video-Retrieval-Sebe-Lew",
            "title": {
                "fragments": [],
                "text": "The State of the Art in Image and Video Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work thinks that the paramount challenge in image and video retrieval remains bridging the semantic gap, which means that low level features are easily measured and computed, but the starting point of the retrieval process is typically the high level query from a human."
            },
            "venue": {
                "fragments": [],
                "text": "CIVR"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739867"
                        ],
                        "name": "R. Veltkamp",
                        "slug": "R.-Veltkamp",
                        "structuredName": {
                            "firstName": "Remco",
                            "lastName": "Veltkamp",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Veltkamp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36736177"
                        ],
                        "name": "H. Burkhardt",
                        "slug": "H.-Burkhardt",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Burkhardt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Burkhardt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688561"
                        ],
                        "name": "H. Kriegel",
                        "slug": "H.-Kriegel",
                        "structuredName": {
                            "firstName": "Hans-Peter",
                            "lastName": "Kriegel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kriegel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16149311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d363add027a6140d89ebfef9105c8fa765b3faca",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface. 1. Image Content Analysis and Description X. Zabulis, S.C. Orphanoudakis. 2. Local Features for Image Retrieval L. Van Gool, et al. 3. Fast Invariant Feature Extraction for Image Retrieval S. Siggelkow, H. Burkhardt. 4. Shape Description and Search for Similar Objects in Image Databases L.J. Latecki, R. Lakaemper. 5. Features in Content-based Image Retrieval Systems: a Survey R.C. Veltkamp, et al. 6. Probablistic Image Models for Object Recognition and Pose Estimation J. Hornegger, H. Niemann. 7. Distribution-based Image Similarity J. Puzicha. 8. Distribution Free Statistics for Segmentation G. Frederix, E.J. Pauwels. 9. Information Retrieval Methods for Multimedia Objects N. Fuhr. 10. New descriptors for image and video indexing P. Gros, et al. 11. Facial and Motion Analysis for Image and Video Retrieval M. Tistarelli, E. Grosso. 12. Asymmetric Similarity Measures for Video Summarisation S.M. Iacob, et al. 13. Video Retrieval using Semantic Data A. Del Bimbo. 14. Adaptable Similarity Search in Large Image Databases T. Seidl, H.-P. Kriegel. 15. Parallel NN-search for large multimedia repositories R. Weber, et al."
            },
            "slug": "State-of-the-Art-in-Content-Based-Image-and-Video-Veltkamp-Burkhardt",
            "title": {
                "fragments": [],
                "text": "State-of-the-Art in Content-Based Image and Video Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author confirmed that parallel NN-search for large multimedia repositories R. Weber, et al. is a viable option for image and video Retrieval methods for Multimedia Objects, and has shown its utility in solving the challenge of image recognition and description problems."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Imaging and Vision"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46995592"
                        ],
                        "name": "Pinar Duygulu",
                        "slug": "Pinar-Duygulu",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Duygulu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pinar Duygulu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121068894"
                        ],
                        "name": "David Forsyth",
                        "slug": "David-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 102
                            }
                        ],
                        "text": "Recently, several systems have been proposed that address a global as well as local image annotation (Barnard et al., 2002, 2003; Duygulu et al., 2002;\nFeng et al., 2004; Lavrenko et al., 2003; Oliva and Torralba, 2001, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 426654,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0db3310660bc45303a625c2bd89167c59c9ee6d",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We treat object recognition as a process of attaching words to images and image regions. To accomplish this we exploit clustering methods which learn the joint statistics of words and image regions. We show how these models can then be used to attach words to images outside the training set. This \u201cauto-annotation\u201d process has applications such as image indexing, as well as being related to object recognition. Predicted words can be compared to actual words associated with images in a held out set, and we introduce several performance measures based on this observation. These measures are then used to make principled comparisons of model variants, and proposed enhancements. Word prediction is most simply done as a function of the entire image. However, for recognition we need to learn the correspondence between words and specific image regions. Here we first show that the existing models can be used for this purpose, and then we propose modifications to improve performance based on this goal. Finally, we propose word prediction performance as a segmentation measure and report the results for two segmentation approaches."
            },
            "slug": "Object-Recognition-as-Machine-Translation-\u2013-Part-2:-Barnard-Duygulu",
            "title": {
                "fragments": [],
                "text": "Object Recognition as Machine Translation \u2013 Part 2: Exploiting Image Database Clustering Models"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This work shows how clustering methods which learn the joint statistics of words and image regions can be used to attach words to images outside the training set, and proposes word prediction performance as a segmentation measure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 93
                            }
                        ],
                        "text": "This is especially true for the correspondence between category labels and category members (Li and Wang, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: semantic scene understanding, content-based image retrieval, scene clasification, human scene preception, perceptually based techniques, computer vision"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3028284,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f39d3e88cce063ccd3ca01100efd44dcabc9d3b4",
            "isKey": false,
            "numCitedBy": 1187,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic linguistic indexing of pictures is an important but highly challenging problem for researchers in computer vision and content-based image retrieval. In this paper, we introduce a statistical modeling approach to this problem. Categorized images are used to train a dictionary of hundreds of statistical models each representing a concept. Images of any given concept are regarded as instances of a stochastic process that characterizes the concept. To measure the extent of association between an image and the textual description of a concept, the likelihood of the occurrence of the image based on the characterizing stochastic process is computed. A high likelihood indicates a strong association. In our experimental implementation, we focus on a particular group of stochastic processes, that is, the two-dimensional multiresolution hidden Markov models (2D MHMMs). We implemented and tested our ALIP (Automatic Linguistic Indexing of Pictures) system on a photographic image database of 600 different concepts, each with about 40 training images. The system is evaluated quantitatively using more than 4,600 images outside the training database and compared with a random annotation scheme. Experiments have demonstrated the good accuracy of the system and its high potential in linguistic indexing of photographic images."
            },
            "slug": "Automatic-Linguistic-Indexing-of-Pictures-by-a-Li-Wang",
            "title": {
                "fragments": [],
                "text": "Automatic Linguistic Indexing of Pictures by a Statistical Modeling Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper implemented and tested the ALIP (Automatic Linguistic Indexing of Pictures) system on a photographic image database of 600 different concepts, each with about 40 training images and demonstrated the good accuracy of the system and its high potential in linguistic indexing of photographic images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071789671"
                        ],
                        "name": "Navid Serrano",
                        "slug": "Navid-Serrano",
                        "structuredName": {
                            "firstName": "Navid",
                            "lastName": "Serrano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Navid Serrano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32219349"
                        ],
                        "name": "A. Savakis",
                        "slug": "A.-Savakis",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Savakis",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Savakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33642939"
                        ],
                        "name": "Jiebo Luo",
                        "slug": "Jiebo-Luo",
                        "structuredName": {
                            "firstName": "Jiebo",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiebo Luo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34599572,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99262bd7eb13c4b430e5fe180519887ac71df28b",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Improved-scene-classification-using-efficient-and-Serrano-Savakis",
            "title": {
                "fragments": [],
                "text": "Improved scene classification using efficient low-level features and semantic cues"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388249"
                        ],
                        "name": "A. Schwaninger",
                        "slug": "A.-Schwaninger",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Schwaninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Schwaninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40538579"
                        ],
                        "name": "J. Vogel",
                        "slug": "J.-Vogel",
                        "structuredName": {
                            "firstName": "Julia",
                            "lastName": "Vogel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vogel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48623104"
                        ],
                        "name": "F. Hofer",
                        "slug": "F.-Hofer",
                        "structuredName": {
                            "firstName": "Franziska",
                            "lastName": "Hofer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hofer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13924679,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d28d9acf053d4dea42a0b611eea7a15aec5d5cef",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural scenes constitute a very heterogeneous stimulus class. Each semantic category contains exemplars of varying typicality. It is, therefore, an interesting question whether humans can categorize natural scenes consistently into a relatively small number of categories, such as, coasts, rivers/lakes, forests, plains, and mountains. This is particularly important for applications, such as, image retrieval systems. Only if typicality is consistently perceived across different individuals, a general image-retrieval system makes sense. In this study, we use psychophysics and computational modeling to gain a deeper understanding of scene typicality. In the first psychophysical experiment, we used a forced-choice categorization task in which each of 250 natural scenes had to be classified into one of the following five categories: coasts, rivers/lakes, forests, plains, and mountains. In the second experiment, the typicality of each scene had to be rated on a 50-point scale for each of the five categories. The psychophysical results show high consistency between participants not only in the categorization of natural scenes, but also in the typicality ratings. In order to model human perception, we then employ a computational approach that uses an intermediate semantic modeling step by extracting local semantic concepts, such as, rock, water, and sand. Based on the human typicality ratings, we learn a psychophysically plausible distance measure that leads to a high correlation between the computational and the human ranking of natural scenes. Interestingly, model comparisons without a semantic-modeling step correlated much less with human performance, suggesting that our model is psychophysically very plausible."
            },
            "slug": "A-psychophysically-plausible-model-for-typicality-Schwaninger-Vogel",
            "title": {
                "fragments": [],
                "text": "A psychophysically plausible model for typicality ranking of natural scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A psychophysically plausible distance measure is learned that leads to a high correlation between the computational and the human ranking of natural scenes, and Interestingly, model comparisons without a semantic-modeling step correlated much less with human performance, suggesting that the model is Psychophysically very plausible."
            },
            "venue": {
                "fragments": [],
                "text": "TAP"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2446509"
                        ],
                        "name": "P. D. Sahin",
                        "slug": "P.-D.-Sahin",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Sahin",
                            "middleNames": [
                                "Duygulu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Sahin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059257793"
                        ],
                        "name": "Jo\u00e3o Freitas",
                        "slug": "Jo\u00e3o-Freitas",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Freitas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00e3o Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 130
                            }
                        ],
                        "text": "Recently, several systems have been proposed that address a global as well as local image annotation (Barnard et al., 2002, 2003; Duygulu et al., 2002;\nFeng et al., 2004; Lavrenko et al., 2003; Oliva and Torralba, 2001, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12561212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d9f55b445f36578802e7eef4393cfa914b11620",
            "isKey": false,
            "numCitedBy": 1765,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a model of object recognition as machine translation. In this model, recognition is a process of annotating image regions with words. Firstly, images are segmented into regions, which are classified into region types using a variety of features. A mapping between region types and keywords supplied with the images, is then learned, using a method based around EM. This process is analogous with learning a lexicon from an aligned bitext. For the implementation we describe, these words are nouns taken from a large vocabulary. On a large test set, the method can predict numerous words with high accuracy. Simple methods identify words that cannot be predicted well. We show how to cluster words that individually are difficult to predict into clusters that can be predicted well -- for example, we cannot predict the distinction between train and locomotive using the current set of features, but we can predict the underlying concept. The method is trained on a substantial collection of images. Extensive experimental results illustrate the strengths and weaknesses of the approach."
            },
            "slug": "Object-Recognition-as-Machine-Translation:-Learning-Sahin-Barnard",
            "title": {
                "fragments": [],
                "text": "Object Recognition as Machine Translation: Learning a Lexicon for a Fixed Image Vocabulary"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work shows how to cluster words that individually are difficult to predict into clusters that can be predicted well, and cannot predict the distinction between train and locomotive using the current set of features, but can predict the underlying concept."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739867"
                        ],
                        "name": "R. Veltkamp",
                        "slug": "R.-Veltkamp",
                        "structuredName": {
                            "firstName": "Remco",
                            "lastName": "Veltkamp",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Veltkamp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49247824"
                        ],
                        "name": "M. Tanase",
                        "slug": "M.-Tanase",
                        "structuredName": {
                            "firstName": "Mirela",
                            "lastName": "Tanase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tanase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3298177"
                        ],
                        "name": "D. Sent",
                        "slug": "D.-Sent",
                        "structuredName": {
                            "firstName": "Danielle",
                            "lastName": "Sent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2025369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5de0d5bf48b6e0d2c42bc36760e3729b4daedf69",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This article provides a framework to describe and compare content-based image retrieval systems. Sixteen contemporary systems are described in detail, in terms of the following technical aspects: querying, relevance feedback, result presentation, features, and matching. For a total of 44 systems we list the features that are used. Of these systems, 35 use any kind of color features, 28 use texture, and only 25 use shape features."
            },
            "slug": "Features-in-Content-based-Image-Retrieval-Systems:-Veltkamp-Tanase",
            "title": {
                "fragments": [],
                "text": "Features in Content-based Image Retrieval Systems: a Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This article provides a framework to describe and compare content-based image retrieval systems, in terms of the following technical aspects: querying, relevance feedback, result presentation, features, and matching."
            },
            "venue": {
                "fragments": [],
                "text": "State-of-the-Art in Content-Based Image and Video Retrieval"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1840551"
                        ],
                        "name": "M. Boutell",
                        "slug": "M.-Boutell",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Boutell",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Boutell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33642939"
                        ],
                        "name": "Jiebo Luo",
                        "slug": "Jiebo-Luo",
                        "structuredName": {
                            "firstName": "Jiebo",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiebo Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111112811"
                        ],
                        "name": "Xipeng Shen",
                        "slug": "Xipeng-Shen",
                        "structuredName": {
                            "firstName": "Xipeng",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xipeng Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48726084"
                        ],
                        "name": "Christopher M. Brown",
                        "slug": "Christopher-M.-Brown",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Brown",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher M. Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Boutell et al. (2004) propose a framework for describing natural scenes by multiple labels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: semantic scene understanding, content-based image retrieval, scene clasification, human scene preception, perceptually based techniques, computer vision"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9404152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "896b9c1551b7ffa347baed144582ec3b5d88f703",
            "isKey": false,
            "numCitedBy": 1923,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-multi-label-scene-classification-Boutell-Luo",
            "title": {
                "fragments": [],
                "text": "Learning multi-label scene classification"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739867"
                        ],
                        "name": "R. Veltkamp",
                        "slug": "R.-Veltkamp",
                        "structuredName": {
                            "firstName": "Remco",
                            "lastName": "Veltkamp",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Veltkamp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49247824"
                        ],
                        "name": "M. Tanase",
                        "slug": "M.-Tanase",
                        "structuredName": {
                            "firstName": "Mirela",
                            "lastName": "Tanase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tanase"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 282,
                                "start": 262
                            }
                        ],
                        "text": "Also in the early work on scene classification, semantics are often only found in the definition of the scene classes, e.g. indoor vs. outdoor, or waterfalls vs. mountains (Feng et al., 2003; Lipson et al., 1997; Maron and Ratan, 1998; Szummer and Picard, 1998; Vailaya et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10757073,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34d4d87dd3569309938058adfa44d824d06bfe08",
            "isKey": false,
            "numCitedBy": 651,
            "numCiting": 107,
            "paperAbstract": {
                "fragments": [],
                "text": "In many areas of commerce, government, academia, and hospitals, large collections of digital im- \nages are being created. Many of these collections are the product of digitizing existing collections of \nanalogue photographs, diagrams, drawings, paintings, and prints. Usually, the only way of search- \ning these collections was by keyword indexing, or simply by browsing. Digital images databases \nhowever, open the way to content-based searching. In this paper we survey some technical aspects \nof current content-based image retrieval systems."
            },
            "slug": "Content-based-image-retrieval-systems:-A-survey-Veltkamp-Tanase",
            "title": {
                "fragments": [],
                "text": "Content-based image retrieval systems: A survey"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "In this paper, some technical aspects of current content-based image retrieval systems are surveyed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145459057"
                        ],
                        "name": "Y. Rui",
                        "slug": "Y.-Rui",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Rui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2910032,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6fa15f525a9814247ecd7cd93636f278d6d9ab3b",
            "isKey": false,
            "numCitedBy": 2521,
            "numCiting": 220,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper provides a comprehensive survey of the technical achievements in the research area of image retrieval, especially content-based image retrieval, an area that has been so active and prosperous in the past few years. The survey includes 100+ papers covering the research aspects of image feature representation and extraction, multidimensional indexing, and system design, three of the fundamental bases of content-based image retrieval. Furthermore, based on the state-of-the-art technology available now and the demand from real-world applications, open research issues are identified and future promising research directions are suggested."
            },
            "slug": "Image-Retrieval:-Current-Techniques,-Promising-and-Rui-Huang",
            "title": {
                "fragments": [],
                "text": "Image Retrieval: Current Techniques, Promising Directions, and Open Issues"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The survey includes 100+ papers covering the research aspects of image feature representation and extraction, multidimensional indexing, and system design, three of the fundamental bases of content-based image retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis. Commun. Image Represent."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "segmentation-free Image segmentation algorithms such as the mean-shift algorithm [6] or the NCuts algorithm [ 35 ] still lead to undesirable over- and undersegmentation of semantically contiguous regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 114
                            }
                        ],
                        "text": "Image segmentation algorithms such as the mean-shift algorithm (Comaniciu and Meer, 2002) or the NCuts algorithm (Shi and Malik, 1997) still lead to undesirable over- and undersegmentation of semantically contiguous regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14848918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b94c7ff9532ab26c3aedbee3988ec4c7a237c173",
            "isKey": false,
            "numCitedBy": 12814,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging."
            },
            "slug": "Normalized-cuts-and-image-segmentation-Shi-Malik",
            "title": {
                "fragments": [],
                "text": "Normalized cuts and image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work treats image segmentation as a graph partitioning problem and proposes a novel global criterion, the normalized cut, for segmenting the graph, which measures both the total dissimilarity between the different groups as well as the total similarity within the groups."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 194
                            }
                        ],
                        "text": "Recently, several systems have been proposed that address a global as well as local image annotation (Barnard et al., 2002, 2003; Duygulu et al., 2002;\nFeng et al., 2004; Lavrenko et al., 2003; Oliva and Torralba, 2001, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 101
                            }
                        ],
                        "text": "Recently, several systems have been proposed that address a global as well as local image annotation [1,2, 7,9,16,23,24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3146850,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9a21604e6db8020b9e76d89064f2b63fb875b67a",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a scene-centered representation able to provide a meaningful description of real world images at multiple levels of categorization (from superordinate to subordinate levels). The scene-centered representation is based upon the estimation of spatial envelope properties describing the shape of a scene (e.g. size, perspective, mean depth) and the nature of its content. The approach is holistic and free of segmentation phase, grouping mechanisms, 3D construction and object-centered analysis."
            },
            "slug": "Scene-Centered-Description-from-Spatial-Envelope-Oliva-Torralba",
            "title": {
                "fragments": [],
                "text": "Scene-Centered Description from Spatial Envelope Properties"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The scene-centered representation is based upon the estimation of spatial envelope properties describing the shape of a scene and the nature of its content and is holistic and free of segmentation phase, grouping mechanisms, 3D construction and object-centered analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Biologically Motivated Computer Vision"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778989"
                        ],
                        "name": "M. Szummer",
                        "slug": "M.-Szummer",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Szummer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Szummer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 236
                            }
                        ],
                        "text": "Also in the early work on scene classification, semantics are often only found in the definition of the scene classes, e.g. indoor vs. outdoor, or waterfalls vs. mountains (Feng et al., 2003; Lipson et al., 1997; Maron and Ratan, 1998; Szummer and Picard, 1998; Vailaya et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: semantic scene understanding, content-based image retrieval, scene clasification, human scene preception, perceptually based techniques, computer vision"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14254507,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f45a46dedadf599c12874b22645d596205ed8d5",
            "isKey": false,
            "numCitedBy": 774,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how high-level scene properties can be inferred from classification of low-level image features, specifically for the indoor-outdoor scene retrieval problem. We systematically studied the features of: histograms in the Ohta color space; multiresolution, simultaneous autoregressive model parameters; and coefficients of a shift-invariant DCT. We demonstrate that performance is improved by computing features on subblocks, classifying these subblocks, and then combining these results in a way reminiscent of stacking. State of the art single-feature methods are shown to result in about 75-86% performance, while the new method results in 90.3% correct classification, when evaluated on a diverse database of over 1300 consumer images provided by Kodak."
            },
            "slug": "Indoor-outdoor-image-classification-Szummer-Picard",
            "title": {
                "fragments": [],
                "text": "Indoor-outdoor image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work systematically studied the features of: histograms in the Ohta color space; multiresolution, simultaneous autoregressive model parameters; and coefficients of a shift-invariant DCT to show how high-level scene properties can be inferred from classification of low-level image features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1998 IEEE International Workshop on Content-Based Access of Image and Video Database"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 317,
                                "start": 220
                            }
                        ],
                        "text": "An additional way to access semantic image information is to automatically attach a set of manually selected, semantically meaningful labels to local image regions that can be searched for in a subsequent retrieval step (Kumar and Hebert, 2003; Minka and Picard, 1997; Picard and Minka, 1995; Town and Sinclair, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 225
                            }
                        ],
                        "text": "\u2026access semantic image information is to automatically attach a set of manually selected, semantically meaningful labels to local image regions that can be searched for in a subsequent retrieval step (Kumar and Hebert, 2003; Minka and Picard, 1997; Picard and Minka, 1995; Town and Sinclair, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14646846,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dccf7738dcfd578f023f4831fb5eca7e1449c753",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital library access is driven by features but features are often context dependent and noisy and their relevance for a query is not always obvious This paper describes an approach for utilizing many data dependent user dependent and task dependent features in a semi automated tool Instead of requiring universal similarity measures or manual selection of relevant features the approach provides a learning algorithm for selecting and combining groupings of the data where groupings can be induced by highly spe cialized and context dependent features The se lection process is guided by a rich example based interaction with the user The inherent com binatorics of using multiple features is reduced by a multistage grouping generation weighting and collection process The stages closest to the user are trained fastest and slowly propagate their adaptations back to earlier stages The weighting stage adapts the collection stage s search space across uses so that in later interactions good groupings are found given few examples from the user Described is an interactive time imple mentation of this architecture for semi automatic within image segmentation and across image la beling driven by concurrently active color mod els texture models or manually provided group ings Issues for digital libraries Digital libraries of images video and sound are a rich area for pattern recognition research They also introduce a host of new problems and requirements since the range of possible queries is immense and requires the utilization of many spe cialized features Also systems for retrieval browsing and annotation i e classifying regions often must perform with only a small number of examples from a user i e an insuf cient amount of training data by traditional requirements Thus the area is doubly exciting since it presents the eld of pattern recognition with new challenges while beckoning in new applications One important issue for digital libraries is nding good models and similarity measures for comparing database en tries A part of this di culty is that feature extraction and comparison methods are highly data dependent see Figure This work was supported in part by BT PLC Hewlett Packard Labs and NEC for an example with texture Similarity measures are also user and task dependent as demonstrated by Figure Un fortunately these dependencies are not at this point under stood well enough especially by the typical digital library user to permit careful selection of the optimal measure be forehand Note that the multi resolution simultaneous auto regressive MRSAR model of which fares poorly com pared to the shift invariant eigenvector EV model in the above two examples scores clearly above the EV model on the standard Brodatz database On the same test data but for a perceptually motivated similarity criteria based on periodicity directionality and randomness both the EV and MRSAR models are beat by a new Wold based model Attempts to use intuitive texture features like coarseness contrast and directionality are appropri ate in some cases but do not fully determine all the qualities people might use in judging similarity Thus an a priori opti mal context dependent selection among similarity measures either by human or computer seems unlikely Next the scope of queries that databases need to address is immense Current computational solutions attempt to of fer location of perceptual content nd round red objects and objective content nd pictures of people in Boston Desirable queries also extend to subjective content give me a scene of a romantic forest task speci c content I need something with open space to place text collaborative con tent show me pictures children like and more An swering such queries requires a variety of features or meta data to be attached to the data in a digital library some of which may not be computable directly from the data The implication for algorithms is that they cannot rely on one model or one small set of carefully picked features but will have to drink from a veritable feature hydrant from which only a few drops may be relevant for the query Finally there is a signi cant need for semi automated ver sus fully automated tools Human computer synergy can make ill de ned tasks manageable and has the power to over come many of the problems of current pattern recognition tools An important application of semi automated tools is to assist the population of a database viz the creation of metadata A crucial technical issue for such tools is the selec tion and combination of existing features which features are most useful for a given query or annotation how should they be combined and which combinations are useful for the sys tem to remember so that it gets smarter with increased use This last point is important since not only are the queries immensely variable but the amount of training data i e ex amples provided by a user of what they do and don t want available at any instant is usually limited Hence a tool should strive to improve its generalization ability"
            },
            "slug": "Interactive-Learning-Using-a-\"Society-of-Models\"-Minka-Picard",
            "title": {
                "fragments": [],
                "text": "Interactive Learning Using a \"Society of Models\""
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This paper describes an approach for utilizing many data dependent user dependent and task dependent features in a semi automated tool instead of requiring universal similarity measures or manual selection of relevant features the approach provides a learning algorithm for selecting and combining groupings of the data."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 1996"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149116586"
                        ],
                        "name": "Xia Feng",
                        "slug": "Xia-Feng",
                        "structuredName": {
                            "firstName": "Xia",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xia Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34790329"
                        ],
                        "name": "Jianzhong Fang",
                        "slug": "Jianzhong-Fang",
                        "structuredName": {
                            "firstName": "Jianzhong",
                            "lastName": "Fang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianzhong Fang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143740671"
                        ],
                        "name": "G. Qiu",
                        "slug": "G.-Qiu",
                        "structuredName": {
                            "firstName": "Guoping",
                            "lastName": "Qiu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Qiu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 173
                            }
                        ],
                        "text": "Also in the early work on scene classification, semantics are often only found in the definition of the scene classes, e.g. indoor vs. outdoor, or waterfalls vs. mountains (Feng et al., 2003; Lipson et al., 1997; Maron and Ratan, 1998; Szummer and Picard, 1998; Vailaya et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: semantic scene understanding, content-based image retrieval, scene clasification, human scene preception, perceptually based techniques, computer vision"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6641597,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31fc216782779549a507c0c1e7d97c6289962d18",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, an efficient method using various histogram-based (high-dimensional) image content descriptors for automatically classifying general color photos into relevant categories is presented. Principal component analysis (PCA) is used to project the original high dimensional histograms onto their eigenspaces. Lower dimensional eigenfeatures are then used to train support vector machines (SVMs) to classify images into their categories. Experimental results show that even though different descriptors perform differently, they are all highly redundant. It is shown that the dimensionality of all these descriptors, regardless of their performances, can be significantly reduced without affecting classification accuracy. Such scheme would be useful when it is used in an interactive setting for relevant feedback in content-based image retrieval, where low dimensional content descriptors enable fast online learning and reclassification of results."
            },
            "slug": "Color-photo-categorization-using-compressed-and-Feng-Fang",
            "title": {
                "fragments": [],
                "text": "Color photo categorization using compressed histograms and support vector machines"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that the dimensionality of all these descriptors, regardless of their performances, can be significantly reduced without affecting classification accuracy in content-based image retrieval, where low dimensional content descriptors enable fast online learning and reclassification of results."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2003 International Conference on Image Processing (Cat. No.03CH37429)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731570"
                        ],
                        "name": "M. Lew",
                        "slug": "M.-Lew",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lew",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lew"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703601"
                        ],
                        "name": "N. Sebe",
                        "slug": "N.-Sebe",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sebe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2021608"
                        ],
                        "name": "J. Eakins",
                        "slug": "J.-Eakins",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Eakins",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eakins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14732345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3579e7915c3af4868ccd7fbaa71c02d00d1753a",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "What use is the sum of human knowledge if nothing can be found? Although significant advances have been made in text searching, only preliminary work has been done in finding images and videos in large digital collections. In fact, if we examine the most frequently used image and video retrieval systems (i.e. www.google.com) we find that they are typically oriented around text searches where manual annotation was already performed."
            },
            "slug": "Challenges-of-Image-and-Video-Retrieval-Lew-Sebe",
            "title": {
                "fragments": [],
                "text": "Challenges of Image and Video Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The most frequently used image and video retrieval systems are typically oriented around text searches where manual annotation was already performed, which indicates that images and videos in large digital collections are being searched for through text searches."
            },
            "venue": {
                "fragments": [],
                "text": "CIVR"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743610"
                        ],
                        "name": "B. Tversky",
                        "slug": "B.-Tversky",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Tversky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Tversky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141671"
                        ],
                        "name": "K. Hemenway",
                        "slug": "K.-Hemenway",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "Hemenway",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hemenway"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 12
                            }
                        ],
                        "text": "The following sections discuss those results in detail."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 52
                            }
                        ],
                        "text": "In addition, the natural, basic-level categories of Tversky and Hemenway (1983) and the natural scene categories of Mojsilovic et al. (2004) were combined and extended to the categories coasts, rivers/lakes, forests, plains, mountains and sky/clouds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 115
                            }
                        ],
                        "text": "Tversky and Hemenway were the first to construct a taxonomy of abstract categories such as\nenvironments or scenes (Tversky and Hemenway, 1983)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 54413901,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "1c87ac834e820b029c9c4248916520fed0fb4a57",
            "isKey": false,
            "numCitedBy": 302,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Categories-of-environmental-scenes-Tversky-Hemenway",
            "title": {
                "fragments": [],
                "text": "Categories of environmental scenes"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143413355"
                        ],
                        "name": "Yongmei Wang",
                        "slug": "Yongmei-Wang",
                        "structuredName": {
                            "firstName": "Yongmei",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongmei Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 232
                            }
                        ],
                        "text": "A discriminative and thus very different approach to scene categorization is the use of SVMs. SVMs have been widely used in recent years and have been shown to be capable tools for classification and categorization (Joachims, 2002; Wang and Zhang, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In fact, the results indicate quite clearly that the extraction of the nine local semantic concepts and the image representation based on concept-occurrence vectors model the important semantic image details that are needed for a meaningful typicality ranking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17854873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "763ee06c511c8940f0d82f3690ef29ed009e748e",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Accurate and automatic image orientation detection is of great importance in image libraries. We present automatic image orientation detection algorithms by adopting both the illuminance (structural) and chrominance (color) low-level content features. Statistical learning support vector machines (SVMs) are used in our approach as the classifiers. The different sources of the extracted image features, as well as the binary classification nature of SVM, require our system to be able to integrate the outputs from multiple classifiers. Both static combiner (averaging) and trainable combiner (also based on SVMs) are proposed and evaluated. In addition, two rejection options (regular and reinforced ambiguity rejections) are employed to improve orientation detection accuracy by sieving out images with low confidence values during the classification. A number of experiments on a database of more than 14000 images were performed to validate our approaches."
            },
            "slug": "Content-based-image-orientation-detection-with-Wang-Zhang",
            "title": {
                "fragments": [],
                "text": "Content-based image orientation detection with support vector machines"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This work presents automatic image orientation detection algorithms by adopting both the illuminance (structural) and chrominance (color) low-level content features, using Statistical learning support vector machines (SVMs) as classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Workshop on Content-Based Access of Image and Video Libraries (CBAIVL 2001)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 225
                            }
                        ],
                        "text": "\u2026access semantic image information is to automatically attach a set of manually selected, semantically meaningful labels to local image regions that can be searched for in a subsequent retrieval step (Kumar and Hebert, 2003; Minka and Picard, 1997; Picard and Minka, 1995; Town and Sinclair, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28597667,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85881e5e636412751e9e35eb76868e1a6a71d9c7",
            "isKey": false,
            "numCitedBy": 242,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital library access is driven by features, but the relevance of a feature for a query is not always obvious. This paper describes an approach for integrating a large number of context-dependent features into a semi-automated tool. Instead of requiring universal similarity measures or manual selection of relevant features, the approach provides a learning algorithm for selecting and combining groupings of the data, where groupings can be induced by highly specialized features. The selection process is guided by positive and negative examples from the user. The inherent combinatorics of using multiple features is reduced by a multistage grouping generation, weighting, and collection process. The stages closest to the user are trained fastest and slowly propagate their adaptations back to earlier stages. The weighting stage adapts the collection stage's search space across uses, so that, in later interactions, good groupings are found given few examples from the user."
            },
            "slug": "Interactive-learning-with-a-\"Society-of-Models\"-Minka-Picard",
            "title": {
                "fragments": [],
                "text": "Interactive learning with a \"society of models\""
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper describes an approach for integrating a large number of context-dependent features into a semi-automated tool that provides a learning algorithm for selecting and combining groupings of the data, where groupings can be induced by highly specialized features."
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145349582"
                        ],
                        "name": "Sanjiv Kumar",
                        "slug": "Sanjiv-Kumar",
                        "structuredName": {
                            "firstName": "Sanjiv",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjiv Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 163
                            }
                        ],
                        "text": "The averaged rank correlation between participants between 0.65 (mountains) and 0.81 (forests) is very high for these kind of psychophysical experiments (see e.g. Kline ( 2000))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3189198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "746aacd99a2d9650f4fb03df5d71655b351b6680",
            "isKey": true,
            "numCitedBy": 146,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a generative model based approach to man-made structure detection in 2D (two-dimensional) natural images. The proposed approach uses a causal multiscale random field suggested by Bouman and Shapiro (1994) as a prior model on the class labels on the image sites. However, instead of assuming the conditional independence of the observed data, we propose to capture the local dependencies in the data using a multiscale feature vector. The distribution of the multiscale feature vectors is modeled as mixture of Gaussians. A set of robust multi-scale features is presented that captures the general statistical properties of man-made structures at multiple scales without relying on explicit edge detection. The proposed approach was validated on real-world images from the Corel data set, and a performance comparison with other techniques is presented."
            },
            "slug": "Man-made-structure-detection-in-natural-images-a-Kumar-Hebert",
            "title": {
                "fragments": [],
                "text": "Man-made structure detection in natural images using a causal multiscale random field"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A generative model based approach to man-made structure detection in 2D (two-dimensional) natural images by using a causal multiscale random field as a prior model on the class labels on the image sites to capture the local dependencies in the data using a multiscales feature vector."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3112585"
                        ],
                        "name": "B. Rogowitz",
                        "slug": "B.-Rogowitz",
                        "structuredName": {
                            "firstName": "Bernice",
                            "lastName": "Rogowitz",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rogowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50485519"
                        ],
                        "name": "T. Frese",
                        "slug": "T.-Frese",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Frese",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Frese"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47088868"
                        ],
                        "name": "Joshua R. Smith",
                        "slug": "Joshua-R.-Smith",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745655"
                        ],
                        "name": "C. Bouman",
                        "slug": "C.-Bouman",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bouman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bouman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3438026"
                        ],
                        "name": "Edward B. Kalin",
                        "slug": "Edward-B.-Kalin",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Kalin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward B. Kalin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 57
                            }
                        ],
                        "text": "The result for 1, 2, 3, 5, and 10 image areas is depicted in Fig."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 34
                            }
                        ],
                        "text": "The psychophysical experiments of Rogowitz et al. (1997) revealed two main axes in which humans sort photographic images: human vs. nonhuman and natural vs. artificial."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9665828,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "712e571497d41c3a569e011649d998ae3fc0d916",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we study how human observers judge image similarity. To do so, we have conducted two psychophysical scaling experiments and have compared the results to two algorithmic image similarity metrics. For these experiments, we selected a set of 97 digitized photographic images which represent a range of semantic categories, viewing distances, and colors. We then used the two perceptual and the two algorithmic methods to measure the similarity of each image to every other image in the data set, producing four similarity matrices. These matrices were analyzed using multidimensional scaling techniques to gain insight into the dimensions human observers use for judging image similarity, and how these dimensions differ from the results of algorithmic methods. This paper also describes and validates a new technique for collecting similarity judgments which can provide meaningful results with a factor of four fewer judgments, as compared with the paired comparisons method."
            },
            "slug": "Perceptual-image-similarity-experiments-Rogowitz-Frese",
            "title": {
                "fragments": [],
                "text": "Perceptual image similarity experiments"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new technique for collecting similarity judgments which can provide meaningful results with a factor of four fewer judgments, as compared with the paired comparisons method is described and validates."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33696979"
                        ],
                        "name": "G. Murphy",
                        "slug": "G.-Murphy",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Murphy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Murphy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 80
                            }
                        ],
                        "text": "Rather, some sort of semantic typicality ranking as discussed in psychophysics (Murphy, 2002) and aimed for in content-based image retrieval should be performed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 108
                            }
                        ],
                        "text": "In Section 4, it was already shown that the categorization performance is better when employing the semantic modeling instead of directly extracting lowlevel features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 108
                            }
                        ],
                        "text": "The relevance of prototypes for categorization has been discussed in detail in the psychophysics community (Murphy, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 145167098,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "8c3edb92cd6d0f2b6490dc6a8719dd6fa2fb4116",
            "isKey": true,
            "numCitedBy": 2433,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Concepts embody our knowledge of the kinds of things there are in the world. Tying our past experiences to our present interactions with the environment, they enable us to recognize and understand new objects and events. Concepts are also relevant to understanding domains such as social situations, personality types, and even artistic styles. Yet like other phenomenologically simple cognitive processes such as walking or understanding speech, concept formation and use are maddeningly complex. Research since the 1970s and the decline of the \"classical view\" of concepts have greatly illuminated the psychology of concepts. But persistent theoretical disputes have sometimes obscured this progress. The Big Book of Concepts goes beyond those disputes to reveal the advances that have been made, focusing on the major empirical discoveries. By reviewing and evaluating research on diverse topics such as category learning, word meaning, conceptual development in infants and children, and the basic level of categorization, the book develops a much broader range of criteria than is usual for evaluating theories of concepts."
            },
            "slug": "The-Big-Book-of-Concepts-Murphy",
            "title": {
                "fragments": [],
                "text": "The Big Book of Concepts"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5737624"
                        ],
                        "name": "E. Rosch",
                        "slug": "E.-Rosch",
                        "structuredName": {
                            "firstName": "Eleanor",
                            "lastName": "Rosch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rosch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3050353"
                        ],
                        "name": "C. Mervis",
                        "slug": "C.-Mervis",
                        "structuredName": {
                            "firstName": "Carolyn",
                            "lastName": "Mervis",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mervis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Rosch and Mervis (1975) propose that a category prototype is not a single best example for the category but rather a summary representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Rosch and Mervis [ 29 ] propose that a category prototype is not a single best example for the category but rather a summary representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17258322,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "93aecb20183cd5e561bb0b6b961702a0798cbee2",
            "isKey": false,
            "numCitedBy": 5118,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Family-resemblances:-Studies-in-the-internal-of-Rosch-Mervis",
            "title": {
                "fragments": [],
                "text": "Family resemblances: Studies in the internal structure of categories"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 64
                            }
                        ],
                        "text": "Image segmentation algorithms such as the mean-shift algorithm (Comaniciu and Meer, 2002) or the NCuts algorithm (Shi and Malik, 1997) still lead to undesirable over- and undersegmentation of semantically contiguous regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 64
                            }
                        ],
                        "text": "The purpose of the concept classifiers is the semantic classification of local image regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 691081,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74f4ecc3e4e5b91fbb54330b285ed5214afe2001",
            "isKey": false,
            "numCitedBy": 11481,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance."
            },
            "slug": "Mean-Shift:-A-Robust-Approach-Toward-Feature-Space-Comaniciu-Meer",
            "title": {
                "fragments": [],
                "text": "Mean Shift: A Robust Approach Toward Feature Space Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is proved the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 216
                            }
                        ],
                        "text": "A discriminative and thus very different approach to scene categorization is the use of SVMs. SVMs have been widely used in recent years and have been shown to be capable tools for classification and categorization (Joachims, 2002; Wang and Zhang, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In fact, the results indicate quite clearly that the extraction of the nine local semantic concepts and the image representation based on concept-occurrence vectors model the important semantic image details that are needed for a meaningful typicality ranking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60532258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "248a297d786228a183fcae64023092660550fcd2",
            "isKey": false,
            "numCitedBy": 1753,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Based on ideas from Support Vector Machines (SVMs), Learning To Classify Text Using Support Vector Machines presents a new approach to generating text classifiers from examples. The approach combines high performance and efficiency with theoretical understanding and improved robustness. In particular, it is highly effective without greedy heuristic components. The SVM approach is computationally efficient in training and classification, and it comes with a learning theory that can guide real-world applications. Learning To Classify Text Using Support Vector Machines gives a complete and detailed description of the SVM approach to learning text classifiers, including training algorithms, transductive text classification, efficient performance estimation, and a statistical learning model of text classification. In addition, it includes an overview of the field of text classification, making it self-contained even for newcomers to the field. This book gives a concise introduction to SVMs for pattern recognition, and it includes a detailed description of how to formulate text-classification tasks for machine learning."
            },
            "slug": "Learning-to-classify-text-using-support-vector-and-Joachims",
            "title": {
                "fragments": [],
                "text": "Learning to classify text using support vector machines - methods, theory and algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This book gives a concise introduction to SVMs for pattern recognition, and it includes a detailed description of how to formulate text-classification tasks for machine learning."
            },
            "venue": {
                "fragments": [],
                "text": "The Kluwer international series in engineering and computer science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110551642"
                        ],
                        "name": "Chih-Wei Hsu",
                        "slug": "Chih-Wei-Hsu",
                        "structuredName": {
                            "firstName": "Chih-Wei",
                            "lastName": "Hsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Wei Hsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711460"
                        ],
                        "name": "Chih-Jen Lin",
                        "slug": "Chih-Jen-Lin",
                        "structuredName": {
                            "firstName": "Chih-Jen",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Jen Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "The package offers an efficient multi-class support using internally a oneagainst-one approach [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 95
                            }
                        ],
                        "text": "The package offers an efficient multiclass support using internally a one-against-one approach Hsu and Lin (2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15874442,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f755d620b57acf27a16ff95923c5677ff8198bb",
            "isKey": false,
            "numCitedBy": 6346,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Support vector machines (SVMs) were originally designed for binary classification. How to effectively extend it for multiclass classification is still an ongoing research issue. Several methods have been proposed where typically we construct a multiclass classifier by combining several binary classifiers. Some authors also proposed methods that consider all classes at once. As it is computationally more expensive to solve multiclass problems, comparisons of these methods using large-scale problems have not been seriously conducted. Especially for methods solving multiclass SVM in one step, a much larger optimization problem is required so up to now experiments are limited to small data sets. In this paper we give decomposition implementations for two such \"all-together\" methods. We then compare their performance with three methods based on binary classifications: \"one-against-all,\" \"one-against-one,\" and directed acyclic graph SVM (DAGSVM). Our experiments indicate that the \"one-against-one\" and DAG methods are more suitable for practical use than the other methods. Results also show that for large problems methods by considering all data at once in general need fewer support vectors."
            },
            "slug": "A-comparison-of-methods-for-multiclass-support-Hsu-Lin",
            "title": {
                "fragments": [],
                "text": "A comparison of methods for multiclass support vector machines"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Decomposition implementations for two \"all-together\" multiclass SVM methods are given and it is shown that for large problems methods by considering all data at once in general need fewer support vectors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717435"
                        ],
                        "name": "B. G. Schunck",
                        "slug": "B.-G.-Schunck",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Schunck",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. G. Schunck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 128
                            }
                        ],
                        "text": "The figures illustrate that with the concept-occurrence vectors of the semantic modeling, a semantic ordering of natural scenes can\nbe obtained."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 282,
                                "start": 265
                            }
                        ],
                        "text": "\u2026intensity: 16 bins), a 72-bin edge direction histogram, and the 24 features of the gray-level co-occurrence matrix (32 gray levels): contrast, energy, entropy, homogeneity, inverse difference moment and correlation for the displacements \u2212\u2192 1, 0, \u2212\u2192 1, 1, \u2212\u2192 0, 1 and\n\u2212\u2212\u2192\u22121, 1 (Jain et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28142344,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b471764b7bb35abbcacb3e9f585d2031f4fddff9",
            "isKey": false,
            "numCitedBy": 2454,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This text is intended to provide a balanced introduction to machine vision. Basic concepts are introduced with only essential mathematical elements. The details to allow implementation and use of vision algorithm in practical application are provided, and engineering aspects of techniques are emphasized. This text intentionally omits theories of machine vision that do not have sufficient practical applications at the time."
            },
            "slug": "Machine-vision-Jain-Kasturi",
            "title": {
                "fragments": [],
                "text": "Machine vision"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This text intentionally omits theories of machine vision that do not have sufficient practical applications at the time, and basic concepts are introduced with only essential mathematical elements."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5737624"
                        ],
                        "name": "E. Rosch",
                        "slug": "E.-Rosch",
                        "structuredName": {
                            "firstName": "Eleanor",
                            "lastName": "Rosch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rosch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 65
                            }
                        ],
                        "text": "It has been found through psychophysical experiments (especially [28,30]) that the basic level, a middle level of specificity, is the most natural, preferred level when for example naming particular objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 65
                            }
                        ],
                        "text": "It has been found through psychophysical experiments (especially Rosch (1978) and Rosch et al. (1976)) that the basic level, a middle level of specificity, is the most natural, preferred level when for example naming particular objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15633758,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "3f3421a27033ea4e7112024fc60d85efd12192f3",
            "isKey": false,
            "numCitedBy": 5721,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Principles-of-Categorization-Rosch",
            "title": {
                "fragments": [],
                "text": "Principles of Categorization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143790482"
                        ],
                        "name": "J. Bortz",
                        "slug": "J.-Bortz",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Bortz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bortz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 181645654,
            "fieldsOfStudy": [],
            "id": "e796fadbbab76889045491ee57727ededdb6a475",
            "isKey": false,
            "numCitedBy": 740,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Das erfolgreiche Statistik-Lehrbuch liegt jetzt in der 3. Auflage vor. Das Lehrbuch, das sich inzwischen zu einem Standardwerk in den Sozialwissenschaften, der Medizin und der Biologie entwickelt hat, fuhrt auch den mathematisch wenig geschulten Leser an komplizierte Verfahren heran. Dem fortgeschrittenen Studenten eroffnet es die Moglichkeit, den mathematischen Hintergrund einzelner Verfahren zu vertiefen und neue Ansatze kennenzulernen. Aus den Besprechungen der fruheren Auflagen: \"Das durch seinen didaktischen Aufbau, seine Verstandlichkeit sowie durch seine Gliederung in Elementar-Statistik, varianzanalytische Methoden und multivariate Methoden sich auszeichnende Buch eignet sich sowohl als Lehrbuch als auch als Nachschlagewerk... . Bestimmte Kapitel, die dem Anfanger als Erstlekture empfohlen werden, sind besonders gekennzeichnet.\" \"Die \" \"Naturwissenschaften\"#1\""
            },
            "slug": "Statistik:-Fur-Sozialwissenschaftler-Bortz",
            "title": {
                "fragments": [],
                "text": "Statistik: Fur Sozialwissenschaftler"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 148
                            }
                        ],
                        "text": "Since the absolute ranking score is meaningless for the task, Spearman\u2019s rank correlation has to be employed instead of the correlation coefficient [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 22
                            }
                        ],
                        "text": "In this equation, r = [1, 2, 3, 5, 10] refers to the number of image areas and N(r) = [9, 18, 27, 45, 90] to the corresponding length of the concept-occurrence vector (compare Section 2)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 100
                            }
                        ],
                        "text": "We obtain a semi-local, spatial image representation by computing and concatenating the COVs of r = [1, 2, 3, 5, 10] horizontally-layered image regions resulting in a feature vector of length N(r) = [9, 18, 27, 45, 90]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 148
                            }
                        ],
                        "text": "Since the absolute ranking score is meaningless for the task, Spearman\u2019s rank correlation has to be employed instead of the correlation coefficient (Bortz, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 22
                            }
                        ],
                        "text": "In each category, r = [1, 2, 3, 5, 10] horizontally-layered image areas have been tested."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistik f\u00fcr Sozialwissenschaftler, 5 edn"
            },
            "venue": {
                "fragments": [],
                "text": "Springer"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 163
                            }
                        ],
                        "text": "The averaged rank correlation between participants between 0.65 (mountains) and 0.81 (forests) is very high for these kind of psychophysical experiments (see e.g. Kline ( 2000))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Handbook of Psychological Testing, 2nd edn"
            },
            "venue": {
                "fragments": [],
                "text": "Routledge"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 163
                            }
                        ],
                        "text": "The averaged rank correlation between participants between 0.65 (mountains) and 0.81 (forests) is very high for these kind of psychophysical experiments (see e.g. Kline ( 2000))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Handbook of Psychological Testing, 2nd edition"
            },
            "venue": {
                "fragments": [],
                "text": "Routledge."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144785829"
                        ],
                        "name": "P. Kline",
                        "slug": "P.-Kline",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Kline",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kline"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 221974685,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "582a14edd81aebf156b72f6514aa5b1bdfeeed9e",
            "isKey": false,
            "numCitedBy": 1560,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-handbook-of-psychological-testing,-2nd-ed.-Kline",
            "title": {
                "fragments": [],
                "text": "The handbook of psychological testing, 2nd ed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5737624"
                        ],
                        "name": "E. Rosch",
                        "slug": "E.-Rosch",
                        "structuredName": {
                            "firstName": "Eleanor",
                            "lastName": "Rosch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rosch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30488219"
                        ],
                        "name": "C. Simpson",
                        "slug": "C.-Simpson",
                        "structuredName": {
                            "firstName": "Carolyn",
                            "lastName": "Simpson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Simpson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144370935"
                        ],
                        "name": "R. S. Miller",
                        "slug": "R.-S.-Miller",
                        "structuredName": {
                            "firstName": "R",
                            "lastName": "Miller",
                            "middleNames": [
                                "S"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. S. Miller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 65
                            }
                        ],
                        "text": "It has been found through psychophysical experiments (especially [28,30]) that the basic level, a middle level of specificity, is the most natural, preferred level when for example naming particular objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 82
                            }
                        ],
                        "text": "It has been found through psychophysical experiments (especially Rosch (1978) and Rosch et al. (1976)) that the basic level, a middle level of specificity, is the most natural, preferred level when for example naming particular objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 145675134,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "64a5379e98ea882ac189c8a77837d1a4b1274ba3",
            "isKey": false,
            "numCitedBy": 503,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Structural-bases-of-typicality-effects.-Rosch-Simpson",
            "title": {
                "fragments": [],
                "text": "Structural bases of typicality effects."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3331580"
                        ],
                        "name": "O. Maron",
                        "slug": "O.-Maron",
                        "structuredName": {
                            "firstName": "Oded",
                            "lastName": "Maron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Maron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2578809"
                        ],
                        "name": "A. L. Ratan",
                        "slug": "A.-L.-Ratan",
                        "structuredName": {
                            "firstName": "Aparna",
                            "lastName": "Ratan",
                            "middleNames": [
                                "Lakshmi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. L. Ratan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 213
                            }
                        ],
                        "text": "Also in the early work on scene classification, semantics are often only found in the definition of the scene classes, e.g. indoor vs. outdoor, or waterfalls vs. mountains (Feng et al., 2003; Lipson et al., 1997; Maron and Ratan, 1998; Szummer and Picard, 1998; Vailaya et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: semantic scene understanding, content-based image retrieval, scene clasification, human scene preception, perceptually based techniques, computer vision"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39240439,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "6e0616e65727c7ab9c185c92e15ccd405cfc2a0b",
            "isKey": false,
            "numCitedBy": 654,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multiple-Instance-Learning-for-Natural-Scene-Maron-Ratan",
            "title": {
                "fragments": [],
                "text": "Multiple-Instance Learning for Natural Scene Classification"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "20 Prototype Approach with PPD, annotated image regions: Top 10 ranked coasts-images"
            },
            "venue": {
                "fragments": [],
                "text": "20 Prototype Approach with PPD, annotated image regions: Top 10 ranked coasts-images"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "23 Prototype Approach with PPD, annotated image regions: Top 10 ranked rivers/lakes-images"
            },
            "venue": {
                "fragments": [],
                "text": "23 Prototype Approach with PPD, annotated image regions: Top 10 ranked rivers/lakes-images"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 114
                            }
                        ],
                        "text": "Image segmentation algorithms such as the mean-shift algorithm (Comaniciu and Meer, 2002) or the NCuts algorithm (Shi and Malik, 1997) still lead to undesirable over- and undersegmentation of semantically contiguous regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Normalised cuts and image"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 148
                            }
                        ],
                        "text": "Since the absolute ranking score is meaningless for the task, Spearman\u2019s rank correlation has to be employed instead of the correlation coefficient (Bortz, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistik f\u00fcr Sozialwissenschaftler, 5th edition"
            },
            "venue": {
                "fragments": [],
                "text": "Statistik f\u00fcr Sozialwissenschaftler, 5th edition"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "24 Prototype Approach with PPD, classified image regions: Top 10 ranked rivers/lakes-images"
            },
            "venue": {
                "fragments": [],
                "text": "24 Prototype Approach with PPD, classified image regions: Top 10 ranked rivers/lakes-images"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "21 Prototype Approach with PPD, classified image regions: Top 10 ranked coasts-images"
            },
            "venue": {
                "fragments": [],
                "text": "21 Prototype Approach with PPD, classified image regions: Top 10 ranked coasts-images"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 92
                            }
                        ],
                        "text": "For a comparison between a k-nearest neighbor classifier and a SVM classifier also refer to Vogel (2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 34
                            }
                        ],
                        "text": "For more details, please refer to Vogel (2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semantic Scene Modeling and Retrieval. No. 33 in Selected Readings in Vision and Graphics"
            },
            "venue": {
                "fragments": [],
                "text": "Semantic Scene Modeling and Retrieval. No. 33 in Selected Readings in Vision and Graphics"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 282,
                                "start": 262
                            }
                        ],
                        "text": "Also in the early work on scene classification, semantics are often only found in the definition of the scene classes, e.g. indoor vs. outdoor, or waterfalls vs. mountains (Feng et al., 2003; Lipson et al., 1997; Maron and Ratan, 1998; Szummer and Picard, 1998; Vailaya et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "age classi fi cation for content - based indexing"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: semantic scene understanding, content-based image retrieval, scene clasification, human scene preception, perceptually based techniques, computer vision"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 143
                            }
                        ],
                        "text": "Particularly, early retrieval systems have been based on the extraction of only low-level, often global pictorial features (for overviews see (Eakins and Graham, 1999; Rui et al., 1999; Smeulders et al., 2000; Veltkamp and Tanase, 2001))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Content-based image retrieval, a report to the JISC Technology Applications programme"
            },
            "venue": {
                "fragments": [],
                "text": "Content-based image retrieval, a report to the JISC Technology Applications programme"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Boutell et al. (2004) propose a framework for describing natural scenes by multiple labels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[4] propose a framework for describing natural scenes by multiple labels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning multilabel scene classification"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition 37(9), 1757\u20131771"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 168
                            }
                        ],
                        "text": "Particularly, early retrieval systems have been based on the extraction of only low-level, often global pictorial features (for overviews see (Eakins and Graham, 1999; Rui et al., 1999; Smeulders et al., 2000; Veltkamp and Tanase, 2001))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semantic Modeling of Natural Scenes for Content-Based Image Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 92
                            }
                        ],
                        "text": "For a comparison between a k-nearest neighbor classifier and a SVM classifier also refer to Vogel (2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 34
                            }
                        ],
                        "text": "For more details, please refer to Vogel (2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semantic Scene Modeling and Retrieval. Number 33 in Selected Readings in Vision and Graphics"
            },
            "venue": {
                "fragments": [],
                "text": "Semantic Scene Modeling and Retrieval. Number 33 in Selected Readings in Vision and Graphics"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 65
                            }
                        ],
                        "text": "It has been found through psychophysical experiments (especially Rosch (1978) and Rosch et al. (1976)) that the basic level, a middle level of specificity, is the most natural, preferred level when for example naming particular objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Principles of categorization Cognition and categorization"
            },
            "venue": {
                "fragments": [],
                "text": "Erlbaum"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 317,
                                "start": 220
                            }
                        ],
                        "text": "An additional way to access semantic image information is to automatically attach a set of manually selected, semantically meaningful labels to local image regions that can be searched for in a subsequent retrieval step (Kumar and Hebert, 2003; Minka and Picard, 1997; Picard and Minka, 1995; Town and Sinclair, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 273
                            }
                        ],
                        "text": "\u2026access semantic image information is to automatically attach a set of manually selected, semantically meaningful labels to local image regions that can be searched for in a subsequent retrieval step (Kumar and Hebert, 2003; Minka and Picard, 1997; Picard and Minka, 1995; Town and Sinclair, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Content based image retrieval using semantic visual categories"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 236
                            }
                        ],
                        "text": "Also in the early work on scene classification, semantics are often only found in the definition of the scene classes, e.g. indoor vs. outdoor, or waterfalls vs. mountains (Feng et al., 2003; Lipson et al., 1997; Maron and Ratan, 1998; Szummer and Picard, 1998; Vailaya et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Indoor-outdoor image classification In: Workshop on Content-based Access of Image and Video Databases"
            },
            "venue": {
                "fragments": [],
                "text": "Indoor-outdoor image classification In: Workshop on Content-based Access of Image and Video Databases"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Serrano et al. (2004) employ semantic features in addition to low-level features in order to increase indoor-outdoor classification performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improved scene classifi"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 114
                            }
                        ],
                        "text": "Image segmentation algorithms such as the mean-shift algorithm (Comaniciu and Meer, 2002) or the NCuts algorithm (Shi and Malik, 1997) still lead to undesirable over- and undersegmentation of semantically contiguous regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 20
                            }
                        ],
                        "text": "The image regions are extracted on a regular grid of 10 \u00d7 10 regions with size 48 \u00d7 72 or 72 \u00d7 48 pixels (see Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Normalised cuts and image segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "Conference on Computer Vision and Pattern Recognition CVPR'97"
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 46,
            "methodology": 14
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 64,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/Semantic-Modeling-of-Natural-Scenes-for-Image-Vogel-Schiele/e264e1e55433f158bf8aa8b260bf430d76d5fa28?sort=total-citations"
}