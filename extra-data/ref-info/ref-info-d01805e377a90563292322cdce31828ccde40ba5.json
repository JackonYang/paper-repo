{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277853"
                        ],
                        "name": "A. Vailaya",
                        "slug": "A.-Vailaya",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Vailaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vailaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34659351"
                        ],
                        "name": "M\u00e1rio A. T. Figueiredo",
                        "slug": "M\u00e1rio-A.-T.-Figueiredo",
                        "structuredName": {
                            "firstName": "M\u00e1rio",
                            "lastName": "Figueiredo",
                            "middleNames": [
                                "A.",
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M\u00e1rio A. T. Figueiredo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A second method relies on a successful grouping of the database images into semantically meaningful classes which will greatly enhance the performance of content-based image retrieval systems by filtering out images from irrelevant classes during matching [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "These classes were designed to match human perception, so that a database organized according to these classes would be highly effective for browsing and retrieval purposes [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The optimal codebook size, b q, is estimated by minimizing the following modified MDL (MMDL) criterion (see [10] for details), bq = argmin"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "addressed in detail in [10]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The qualitative attributes of city and landscape images have been previously described in [10]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Outdoor images are further classified into city and landscape images [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A 2-stage classifier was constructed (see [10])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Based on a similar analysis (see [10]), 20 codebook vectors were extracted for each of the city and landscape classes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1817614,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ba7cbd1bc3efbb97548f4e10861361206185d11",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Grouping images into (semantically) meaningful categories using low-level visual features is still a challenging and important problem in content-based image retrieval. Based on these groupings, effective indices can be built for an image database. In this paper, we cast the image classification problem in a Bayesian framework. Specifically, we consider city vs. landscape classification, and further, classification of landscape into sunset, forest, and mountain classes. We demonstrate how high-level concepts can be understood from specific low-level image features, under the constraint that the test images do belong to one of the delineated classes. We further demonstrate that a small codebook (the optimal size is selected using the MDL principle) extracted from a vector quantizer, can be used to estimate the class-conditional densities needed for the Bayesian methodology. Classification based on color histograms, color coherence vectors, edge direction histograms, and edge-direction coherence vectors as features shows promising results. On a database of 2,716 city and landscape images, our system achieved an accuracy of 95.3 percent for city vs. landscape classification. On a subset of 528 landscape images, our system achieves an accuracy of 94.9 percent for sunset vs. forest and mountain classification, and 93.6 percent for forest vs. mountain classification. Our final goal is to combine multiple 2- class classifiers into a single hierarchical classifier."
            },
            "slug": "Bayesian-framework-for-semantic-classification-of-Vailaya-Figueiredo",
            "title": {
                "fragments": [],
                "text": "Bayesian framework for semantic classification of outdoor vacation images"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper casts the image classification problem in a Bayesian framework, and demonstrates how high-level concepts can be understood from specific low-level image features, under the constraint that the test images do belong to one of the delineated classes."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277853"
                        ],
                        "name": "A. Vailaya",
                        "slug": "A.-Vailaya",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Vailaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vailaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24103951"
                        ],
                        "name": "A. Jain",
                        "slug": "A.-Jain",
                        "structuredName": {
                            "firstName": "Anchit",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46197386"
                        ],
                        "name": "Hong Zhang",
                        "slug": "Hong-Zhang",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "1/T. I. T./1580/95."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "However, its use in content-based retrieval from image databases is just being realized [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122250958,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e901a4e8acddf3514d40c6013514575b64e5f012",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Grouping images into semantically meaningful categories using low-level visual features is a challenging and important problem in content-based image retrieval. Based on these groupings, effective indices can be built for an image database. The authors show how a specific high-level classification problem (city vs. landscape classification) can be solved from relatively simple low-level features suited for the particular classes. They have developed a procedure to qualitatively measure the saliency of a feature for classification problem based on the plot of the intra-class and inter-class distance distributions. They use this approach to determine the discriminative power of the following features: color histogram, color coherence vector DCT coefficient, edge direction histogram, and edge direction coherence vector. They determine that the edge direction-based features have the most discriminative power for the classification problem of interest. A weighted k-NN classifier is used for the classification. The classification system results in an accuracy of 93.9% when evaluated on an image database of 2,716 images using the leave-one-out method."
            },
            "slug": "On-image-classification:-city-vs.-landscape-Vailaya-Jain",
            "title": {
                "fragments": [],
                "text": "On image classification: city vs. landscape"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The authors have developed a procedure to qualitatively measure the saliency of a feature for classification problem based on the plot of the intra-class and inter-class distance distributions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. IEEE Workshop on Content-Based Access of Image and Video Libraries (Cat. No.98EX173)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778989"
                        ],
                        "name": "M. Szummer",
                        "slug": "M.-Szummer",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Szummer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Szummer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14254507,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f45a46dedadf599c12874b22645d596205ed8d5",
            "isKey": false,
            "numCitedBy": 774,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how high-level scene properties can be inferred from classification of low-level image features, specifically for the indoor-outdoor scene retrieval problem. We systematically studied the features of: histograms in the Ohta color space; multiresolution, simultaneous autoregressive model parameters; and coefficients of a shift-invariant DCT. We demonstrate that performance is improved by computing features on subblocks, classifying these subblocks, and then combining these results in a way reminiscent of stacking. State of the art single-feature methods are shown to result in about 75-86% performance, while the new method results in 90.3% correct classification, when evaluated on a diverse database of over 1300 consumer images provided by Kodak."
            },
            "slug": "Indoor-outdoor-image-classification-Szummer-Picard",
            "title": {
                "fragments": [],
                "text": "Indoor-outdoor image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work systematically studied the features of: histograms in the Ohta color space; multiresolution, simultaneous autoregressive model parameters; and coefficients of a shift-invariant DCT to show how high-level scene properties can be inferred from classification of low-level image features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1998 IEEE International Workshop on Content-Based Access of Image and Video Database"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145459057"
                        ],
                        "name": "Y. Rui",
                        "slug": "Y.-Rui",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Rui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401302503"
                        ],
                        "name": "Michael Ortega-Binderberger",
                        "slug": "Michael-Ortega-Binderberger",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ortega-Binderberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Ortega-Binderberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144156242"
                        ],
                        "name": "S. Mehrotra",
                        "slug": "S.-Mehrotra",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Mehrotra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mehrotra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One method to decode human perception is through the use of a relevance feedback mechanism [8], where the user and the computer can interact with each other to improve the retrieval performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3888393,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "460c7b1c0d13a403b3a25a31a86692bb0443002b",
            "isKey": false,
            "numCitedBy": 2027,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "Content-based image retrieval (CBIR) has become one of the most active research areas in the past few years. Many visual feature representations have been explored and many systems built. While these research efforts establish the basis of CBIR, the usefulness of the proposed approaches is limited. Specifically, these efforts have relatively ignored two distinct characteristics of CBIR systems: (1) the gap between high-level concepts and low-level features, and (2) the subjectivity of human perception of visual content. This paper proposes a relevance feedback based interactive retrieval approach, which effectively takes into account the above two characteristics in CBIR. During the retrieval process, the user's high-level query and perception subjectivity are captured by dynamically updated weights based on the user's feedback. The experimental results over more than 70000 images show that the proposed approach greatly reduces the user's effort of composing a query, and captures the user's information need more precisely."
            },
            "slug": "Relevance-feedback:-a-power-tool-for-interactive-Rui-Huang",
            "title": {
                "fragments": [],
                "text": "Relevance feedback: a power tool for interactive content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A relevance feedback based interactive retrieval approach that effectively takes into account the subjectivity of human perception of visual content and the gap between high-level concepts and low-level features in CBIR."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Circuits Syst. Video Technol."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "1/T. I. T./1580/95."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1862649,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "1a972eef0721fd5cc5accdd5656de3c5cb86539d",
            "isKey": false,
            "numCitedBy": 762,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. We present here an implementation of NeTra, a prototype image retrieval system that uses color, texture, shape and spatial location information in segmented image regions to search and retrieve similar regions from the database. A distinguishing aspect of this system is its incorporation of a robust automated image segmentation algorithm that allows object- or region-based search. Image segmentation significantly improves the quality of image retrieval when images contain multiple complex objects. Images are segmented into homogeneous regions at the time of ingest into the database, and image attributes that represent each of these regions are computed. In addition to image segmentation, other important components of the system include an efficient color representation, and indexing of color, texture, and shape features for fast search and retrieval. This representation allows the user to compose interesting queries such as \u201cretrieve all images that contain regions that have the color of object A, texture of object B, shape of object C, and lie in the upper of the image\u201d, where the individual objects could be regions belonging to different images. A Java-based web implementation of NeTra is available at http://vivaldi.ece.ucsb.edu/Netra."
            },
            "slug": "NeTra:-A-toolbox-for-navigating-large-image-Ma-Manjunath",
            "title": {
                "fragments": [],
                "text": "NeTra: A toolbox for navigating large image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "An implementation of NeTra, a prototype image retrieval system that uses color, texture, shape and spatial location information in segmented image regions to search and retrieve similar regions from the database, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Systems"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144973459"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40588714"
                        ],
                        "name": "D. Zhong",
                        "slug": "D.-Zhong",
                        "structuredName": {
                            "firstName": "Di",
                            "lastName": "Zhong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zhong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 24933025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "327cb4556eccf1a293acfe2e2c01165f6cade293",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "As digital images are progressing into the mainstream of information systems, managing and manipulating them as images becomes an important issue to be resolved before we can take full advantage of their information content. To achieve content-based image indexing and retrieval, there are active research efforts in developing techniques to utilize visual features. On the other hand, without an effective indexing scheme, any visual content based image retrieval approach will lose its effectiveness as the number of features increases. This paper presents our initial work in developing an efficient indexing scheme using artificial neural network, which focuses on eliminating unlikely candidates rather than pin-pointing the targets directly. Experiment results in retrieving images using this scheme from a prototype visual database system are given."
            },
            "slug": "Scheme-for-visual-feature-based-image-indexing-Zhang-Zhong",
            "title": {
                "fragments": [],
                "text": "Scheme for visual feature-based image indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper presents the initial work in developing an efficient indexing scheme using artificial neural network, which focuses on eliminating unlikely candidates rather than pin-pointing the targets directly in order to achieve content-based image indexing and retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40588714"
                        ],
                        "name": "D. Zhong",
                        "slug": "D.-Zhong",
                        "structuredName": {
                            "firstName": "Di",
                            "lastName": "Zhong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zhong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144973459"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "1/T. I. T./1580/95."
                    },
                    "intents": []
                }
            ],
            "corpusId": 784372,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f25070619976b2b9c5b9892e8de82339bf26ba91",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The large amount of video data makes it a tedious and hard job to browse and annotate them by just fast forward and rewind. Recent works in video parsing provide a foundation for building interactive and content based video browsing systems. In this paper, a generalized top-down hierarchial clustering process, which adopts partition clustering recursively at each level of the hierarchy, is studied and used to build hierarchical views of video shots. With the clustering processes, when a list of video programs or clips is provided, a browsing system can use either key-frame and/or shot features to cluster shots into classes, each of which consists of shots of similar content. After such clustering, each class of shots can be represented by an icon, which can then be displayed at the high levels of a hierarchical browser. As a result, users can know roughly the content of video shots even without moving down to a lower level of the hierarchy."
            },
            "slug": "Clustering-methods-for-video-browsing-and-Zhong-Zhang",
            "title": {
                "fragments": [],
                "text": "Clustering methods for video browsing and annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A generalized top-down hierarchial clustering process, which adopts partition clustering recursively at each level of the hierarchy, is studied and used to build hierarchical views of video shots."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2621770"
                        ],
                        "name": "K. Wakimoto",
                        "slug": "K.-Wakimoto",
                        "structuredName": {
                            "firstName": "Koji",
                            "lastName": "Wakimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Wakimoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2005019"
                        ],
                        "name": "M. Shima",
                        "slug": "M.-Shima",
                        "structuredName": {
                            "firstName": "Mitsuhide",
                            "lastName": "Shima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111411785"
                        ],
                        "name": "S. Tanaka",
                        "slug": "S.-Tanaka",
                        "structuredName": {
                            "firstName": "Satoshi",
                            "lastName": "Tanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tanaka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061340740"
                        ],
                        "name": "Akira Maeda",
                        "slug": "Akira-Maeda",
                        "structuredName": {
                            "firstName": "Akira",
                            "lastName": "Maeda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akira Maeda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730627"
                        ],
                        "name": "H. Tamura",
                        "slug": "H.-Tamura",
                        "structuredName": {
                            "firstName": "Hideyuki",
                            "lastName": "Tamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Tamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072425643"
                        ],
                        "name": "Shunji Mori",
                        "slug": "Shunji-Mori",
                        "structuredName": {
                            "firstName": "Shunji",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shunji Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143796560"
                        ],
                        "name": "Jun'ichi Shibayama",
                        "slug": "Jun'ichi-Shibayama",
                        "structuredName": {
                            "firstName": "Jun'ichi",
                            "lastName": "Shibayama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun'ichi Shibayama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429796"
                        ],
                        "name": "M. Ireton",
                        "slug": "M.-Ireton",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Ireton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ireton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "1/T. I. T./1580/95."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6009452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a31ac01f61f3957fd195fb1dbab673977da54bed",
            "isKey": false,
            "numCitedBy": 847,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In the QBIC (Query By Image Content) project we are studying methods to query large on-line image databases using the images' content as the basis of the queries. Examples of the content we use include color, texture, and shape of image objects and regions. Potential applications include medical (\\Give me other images that contain a tumor with a texture like this one\"), photo-journalism (\\Give me images that have blue at the top and red at the bottom\"), and many others in art, fashion, cataloging, retailing, and industry. We describe a set of novel features and similarity measures allowing query by color, texture, and shape of image object. We demonstrate the e ectiveness of the QBIC system with normalized precision and recall experiments on test databases containing over 1000 images and 1000 objects populated from commercially available photo clip art images, and of images of airplane silhouettes. We also consider the e cient indexing of these features, speci cally addressing two problems: (a) for our feature vectors, the desired distance function is not Euclidean, and/or (b) the vectors have high dimensionality. We propose novel, general solutions to both problems by allowing some \\false alarms\" (\\false hits\", or \\false positives\") but no false dismissals. For the rst problem, we introduce a new theorem that makes indexing possible by bounding the non-Euclidean, full cross-term quadratic distance expression with a simple Euclidean distance. For the second, we illustrate how orthogonal transforms, such as the Karhunen Loeve transform, can help reduce the dimensionality, without introducing false dismissals. The resulting QBIC system o ers high quality of output, and signi cant speedup over straightforward indexing alternatives. The system is implemented in X/Motif and C running on an RS/6000. On sabbatical from Univ. of Maryland, College Park. His work was partially supported by SRC, by the National Science Foundation under the grant IRI-8958546 (PYI)."
            },
            "slug": "Efficient-and-Effective-Querying-by-Image-Content-Wakimoto-Shima",
            "title": {
                "fragments": [],
                "text": "Efficient and Effective Querying by Image Content"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new theorem is introduced that makes indexing possible by bounding the non-Euclidean, full cross-term quadratic distance expression with a simple Euclidean distance, and it is illustrated how orthogonal transforms, such as the Karhunen Loeve transform, can help reduce the dimensionality, without introducing false dismissals."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699559"
                        ],
                        "name": "N. Vasconcelos",
                        "slug": "N.-Vasconcelos",
                        "structuredName": {
                            "firstName": "Nuno",
                            "lastName": "Vasconcelos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vasconcelos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808594"
                        ],
                        "name": "A. Lippman",
                        "slug": "A.-Lippman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Lippman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lippman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, its use in content-based retrieval from image databases is just being realized [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15068335,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4ad7b6515809b58e678cff7eb993c245ee2f009",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The ubiquity of networking and computational capacity associated with the new communications media unveil a universe of new requirements for image representation. Among such requirements is the ability of the representation used for coding to support higher-level tasks such as content-based retrieval. We explore the relationships between probabilistic modeling and data compression to introduce a representation-library-based coding-which, by enabling retrieval in the compressed domain, satisfies this requirement. Because it contains an embedded probabilistic description of the source, this new representation allows the construction of good inference models without compromise of compression efficiency, leads to very efficient procedures for query and retrieval, and provides a framework for higher level tasks such as the analysis and classification of video shots."
            },
            "slug": "Library-based-coding:-a-representation-for-video-Vasconcelos-Lippman",
            "title": {
                "fragments": [],
                "text": "Library-based coding: a representation for efficient video compression and retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work explores the relationships between probabilistic modeling and data compression to introduce a representation-library-based coding-which, by enabling retrieval in the compressed domain, satisfies this requirement for image representation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings DCC '97. Data Compression Conference"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118965263"
                        ],
                        "name": "John R. Smith",
                        "slug": "John-R.-Smith",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17464838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa8af1c28f8ab2011339627bf8e13e267c57abdb",
            "isKey": false,
            "numCitedBy": 2203,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a highly functional prototype system for searching by visual features in an image database. The VisualSEEk system is novel in that the user forms the queries by diagramming spatial arrangements of color regions. The system nds the images that contain the most similar arrangements of similar regions. Prior to the queries, the system automatically extracts and indexes salient color regions from the images. By utilizing e cient indexing techniques for color information, region sizes and absolute and relative spatial locations, a wide variety of complex joint color/spatial queries may be computed."
            },
            "slug": "VisualSEEk:-a-fully-automated-content-based-image-Smith-Chang",
            "title": {
                "fragments": [],
                "text": "VisualSEEk: a fully automated content-based image query system"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The VisualSEEk system is novel in that the user forms the queries by diagramming spatial arrangements of color regions by utilizing color information, region sizes and absolute and relative spatial locations."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '96"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2838104"
                        ],
                        "name": "T. Papathomas",
                        "slug": "T.-Papathomas",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Papathomas",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Papathomas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1927222"
                        ],
                        "name": "Tiffany E. Conway",
                        "slug": "Tiffany-E.-Conway",
                        "structuredName": {
                            "firstName": "Tiffany",
                            "lastName": "Conway",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tiffany E. Conway"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716933"
                        ],
                        "name": "I. Cox",
                        "slug": "I.-Cox",
                        "structuredName": {
                            "firstName": "Ingemar",
                            "lastName": "Cox",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864754"
                        ],
                        "name": "J. Ghosn",
                        "slug": "J.-Ghosn",
                        "structuredName": {
                            "firstName": "Joumana",
                            "lastName": "Ghosn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ghosn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692121"
                        ],
                        "name": "Matthew L. Miller",
                        "slug": "Matthew-L.-Miller",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Miller",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew L. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3203897"
                        ],
                        "name": "P. Yianilos",
                        "slug": "P.-Yianilos",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Yianilos",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Yianilos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17393414,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "4ba1a102ff84385c8e3ed02cfdc4aea041131a22",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe psychophysical experiments conducted to study PicHunter, a content-based image retrieval (CBIR) system. Experiment 1 studies the importance of using (a) semantic information, (2) memory of earlier input and (3) relative, rather than absolute, judgements of image similarity. The target testing paradigm is used in which a user must search for an image identical to a target. We find that the best performance comes from a version of PicHunter that uses only semantic cues, with memory and relative similarity judgements. Second best is use of both pictorial and semantic cues, with memory and relative similarity judgements. Most reports of CBIR systems provide only qualitative measures of performance based on how similar retrieved images are to a target. Experiment 2 puts PicHunter into this context with a more rigorous test. We first establish a baseline for our database by measuring the time required to find an image that is similar to a target when the images are presented in random order. Although PicHunter's performance is measurably better than this, the test is weak because even random presentation of images yields reasonably short search times. This casts doubt on the strength of results given in other reports where no baseline is established."
            },
            "slug": "Psychophysical-studies-of-the-performance-of-an-Papathomas-Conway",
            "title": {
                "fragments": [],
                "text": "Psychophysical studies of the performance of an image database retrieval system"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Psychophysical experiments conducted to study PicHunter, a content-based image retrieval (CBIR) system, find that the best performance comes from a version of PicHunter that uses only semantic cues, with memory and relative similarity judgements."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14646846,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dccf7738dcfd578f023f4831fb5eca7e1449c753",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital library access is driven by features but features are often context dependent and noisy and their relevance for a query is not always obvious This paper describes an approach for utilizing many data dependent user dependent and task dependent features in a semi automated tool Instead of requiring universal similarity measures or manual selection of relevant features the approach provides a learning algorithm for selecting and combining groupings of the data where groupings can be induced by highly spe cialized and context dependent features The se lection process is guided by a rich example based interaction with the user The inherent com binatorics of using multiple features is reduced by a multistage grouping generation weighting and collection process The stages closest to the user are trained fastest and slowly propagate their adaptations back to earlier stages The weighting stage adapts the collection stage s search space across uses so that in later interactions good groupings are found given few examples from the user Described is an interactive time imple mentation of this architecture for semi automatic within image segmentation and across image la beling driven by concurrently active color mod els texture models or manually provided group ings Issues for digital libraries Digital libraries of images video and sound are a rich area for pattern recognition research They also introduce a host of new problems and requirements since the range of possible queries is immense and requires the utilization of many spe cialized features Also systems for retrieval browsing and annotation i e classifying regions often must perform with only a small number of examples from a user i e an insuf cient amount of training data by traditional requirements Thus the area is doubly exciting since it presents the eld of pattern recognition with new challenges while beckoning in new applications One important issue for digital libraries is nding good models and similarity measures for comparing database en tries A part of this di culty is that feature extraction and comparison methods are highly data dependent see Figure This work was supported in part by BT PLC Hewlett Packard Labs and NEC for an example with texture Similarity measures are also user and task dependent as demonstrated by Figure Un fortunately these dependencies are not at this point under stood well enough especially by the typical digital library user to permit careful selection of the optimal measure be forehand Note that the multi resolution simultaneous auto regressive MRSAR model of which fares poorly com pared to the shift invariant eigenvector EV model in the above two examples scores clearly above the EV model on the standard Brodatz database On the same test data but for a perceptually motivated similarity criteria based on periodicity directionality and randomness both the EV and MRSAR models are beat by a new Wold based model Attempts to use intuitive texture features like coarseness contrast and directionality are appropri ate in some cases but do not fully determine all the qualities people might use in judging similarity Thus an a priori opti mal context dependent selection among similarity measures either by human or computer seems unlikely Next the scope of queries that databases need to address is immense Current computational solutions attempt to of fer location of perceptual content nd round red objects and objective content nd pictures of people in Boston Desirable queries also extend to subjective content give me a scene of a romantic forest task speci c content I need something with open space to place text collaborative con tent show me pictures children like and more An swering such queries requires a variety of features or meta data to be attached to the data in a digital library some of which may not be computable directly from the data The implication for algorithms is that they cannot rely on one model or one small set of carefully picked features but will have to drink from a veritable feature hydrant from which only a few drops may be relevant for the query Finally there is a signi cant need for semi automated ver sus fully automated tools Human computer synergy can make ill de ned tasks manageable and has the power to over come many of the problems of current pattern recognition tools An important application of semi automated tools is to assist the population of a database viz the creation of metadata A crucial technical issue for such tools is the selec tion and combination of existing features which features are most useful for a given query or annotation how should they be combined and which combinations are useful for the sys tem to remember so that it gets smarter with increased use This last point is important since not only are the queries immensely variable but the amount of training data i e ex amples provided by a user of what they do and don t want available at any instant is usually limited Hence a tool should strive to improve its generalization ability"
            },
            "slug": "Interactive-Learning-Using-a-\"Society-of-Models\"-Minka-Picard",
            "title": {
                "fragments": [],
                "text": "Interactive Learning Using a \"Society of Models\""
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This paper describes an approach for utilizing many data dependent user dependent and task dependent features in a semi automated tool instead of requiring universal similarity measures or manual selection of relevant features the approach provides a learning algorithm for selecting and combining groupings of the data."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 1996"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34679741"
                        ],
                        "name": "S. Li",
                        "slug": "S.-Li",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 857008,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5634533a7daecde097a230484df5f0913dd9410",
            "isKey": false,
            "numCitedBy": 1419,
            "numCiting": 241,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nMarkov random field (MRF) theory provides a basis for modeling contextual constraints in visual processing and interpretation. It enables us to develop optimal vision algorithms systematically when used with optimization principles. This book presents a comprehensive study on the use of MRFs for solving computer vision problems. The book covers the following parts essential to the subject: introduction to fundamental theories, formulations of MRF vision models, MRF parameter estimation, and optimization algorithms. Various vision models are presented in a unified framework, including image restoration and reconstruction, edge and region segmentation, texture, stereo and motion, object matching and recognition, and pose estimation. This book is an excellent reference for researchers working in computer vision, image processing, statistical pattern recognition, and applications of MRFs. It is also suitable as a text for advanced courses in these areas."
            },
            "slug": "Markov-Random-Field-Modeling-in-Computer-Vision-Li",
            "title": {
                "fragments": [],
                "text": "Markov Random Field Modeling in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This book presents a comprehensive study on the use of MRFs for solving computer vision problems, and covers the following parts essential to the subject: introduction to fundamental theories, formulations of MRF vision models, MRF parameter estimation, and optimization algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Computer Science Workbench"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699559"
                        ],
                        "name": "N. Vasconcelos",
                        "slug": "N.-Vasconcelos",
                        "structuredName": {
                            "firstName": "Nuno",
                            "lastName": "Vasconcelos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vasconcelos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808594"
                        ],
                        "name": "A. Lippman",
                        "slug": "A.-Lippman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Lippman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lippman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18936249,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0465f2c1f3b1e5b98984b33c166d042ed1f79c9e",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Current systems for content filtering, browsing, and retrieval rely on low-level image descriptors which are unintuitive for most users. In this paper, we propose an alternative framework that exploits the structured nature of most content sources to achieve semantic content characterization, and lead to much more meaningful user interaction. Computationally, this framework is based on the principles of Bayesian inference and can be implemented efficiently with Bayesian networks. As an illustration of its potential we apply it to the domain of movie databases."
            },
            "slug": "A-Bayesian-framework-for-semantic-content-Vasconcelos-Lippman",
            "title": {
                "fragments": [],
                "text": "A Bayesian framework for semantic content characterization"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes an alternative framework that exploits the structured nature of most content sources to achieve semantic content characterization, and can be implemented efficiently with Bayesian networks."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144156242"
                        ],
                        "name": "S. Mehrotra",
                        "slug": "S.-Mehrotra",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Mehrotra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mehrotra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145459057"
                        ],
                        "name": "Y. Rui",
                        "slug": "Y.-Rui",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Rui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401302503"
                        ],
                        "name": "Michael Ortega-Binderberger",
                        "slug": "Michael-Ortega-Binderberger",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ortega-Binderberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Ortega-Binderberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "1/T. I. T./1580/95."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7099198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e03d064282673120f81c86993466a23af00f037",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "While advances in technology allow us to generate, transmit and store large amounts of digital images, video and audio, research in the indexing and retrieval of multimedia information is still at its infancy. To address the challenges in building an effective multimedia database system, we have built the Multimedia Analysis and Retrieval System (MARS) prototype. This paper summarises the retrieval subsystem of MARS and its support for content-based queries over image features. Content-based retrieval techniques have been extensively studied for textual documents in the area of automatic information retrieval. Our objective in MARS is to exploit these existing techniques for content-based retrieval over images and multimedia databases."
            },
            "slug": "Supporting-content-based-queries-over-images-in-Mehrotra-Rui",
            "title": {
                "fragments": [],
                "text": "Supporting content-based queries over images in MARS"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper summarises the retrieval subsystem of MARS and its support for content-based queries over image features and its objective in MARS is to exploit existing techniques forcontent-based retrieval over images and multimedia databases."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Multimedia Computing and Systems"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378652"
                        ],
                        "name": "R. Olshen",
                        "slug": "R.-Olshen",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Olshen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Olshen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, its use in content-based retrieval from image databases is just being realized [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14716061,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f815573475053a62d78e24dcb42348d6e3a5eca",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "The connection between compression and the estimation of probability distributions has long been known for the case of discrete alphabet sources and lossless coding. A universal lossless code which does a good job of compressing must implicitly also do a good job of modeling. In particular, with a collection of codebooks, one for each possible class or model, if codewords are chosen from among the ensemble of codebooks so as to minimize bit rate, then the codebook selected provides an implicit estimate of the underlying class. Less is known about the corresponding connections between lossy compression and continuous sources. We consider aspects of estimating conditional and unconditional densities in conjunction with Bayes-risk weighted vector quantization for joint compression and classification."
            },
            "slug": "Vector-quantization-and-density-estimation-Gray-Olshen",
            "title": {
                "fragments": [],
                "text": "Vector quantization and density estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work considers aspects of estimating conditional and unconditional densities in conjunction with Bayes-risk weighted vector quantization for joint compression and classification."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. Compression and Complexity of SEQUENCES 1997 (Cat. No.97TB100171)"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34659351"
                        ],
                        "name": "M\u00e1rio A. T. Figueiredo",
                        "slug": "M\u00e1rio-A.-T.-Figueiredo",
                        "structuredName": {
                            "firstName": "M\u00e1rio",
                            "lastName": "Figueiredo",
                            "middleNames": [
                                "A.",
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M\u00e1rio A. T. Figueiredo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2102270"
                        ],
                        "name": "J. Leit\u00e3o",
                        "slug": "J.-Leit\u00e3o",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Leit\u00e3o",
                            "middleNames": [
                                "M.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Leit\u00e3o"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5144649,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b5b349ed4382ca531e678a418f2c14c32ea224e5",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "Discontinuity-preserving Bayesian image restoration typically involves two Markov random fields: one representing the image intensities/gray levels to be recovered and another one signaling discontinuities/edges to be preserved. The usual strategy is to perform joint maximum a posterori (MAP) estimation of the image and its edges, which requires the specification of priors for both fields. Instead of taking an edge prior, we interpret discontinuities (in fact their locations) as deterministic unknown parameters of the compound Gauss-Markov random field (CGMRF), which is assumed to model the intensities. This strategy should allow inferring the discontinuity locations directly from the image with no further assumptions. However, an additional problem emerges: the number of parameters (edges) is unknown. To deal with it, we invoke the minimum description length (MDL) principle; according to MDL, the best edge configuration is the one that allows the shortest description of the image and its edges. Taking the other model parameters (noise and CGMRF variances) also as unknown, we propose a new unsupervised discontinuity-preserving image restoration criterion. Implementation is carried out by a continuation-type iterative algorithm which provides estimates of the number of discontinuities, their locations, the noise variance, the original image variance, and the original image itself (restored image). Experimental results with real and synthetic images are reported."
            },
            "slug": "Unsupervised-image-restoration-and-edge-location-Figueiredo-Leit\u00e3o",
            "title": {
                "fragments": [],
                "text": "Unsupervised image restoration and edge location using compound Gauss-Markov random fields and the MDL principle"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A new unsupervised discontinuity-preserving image restoration criterion is proposed, carried out by a continuation-type iterative algorithm which provides estimates of the number of discontinuities, their locations, the noise variance, the original images variance, and the original image itself (restored image)."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144973459"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784312"
                        ],
                        "name": "C. Low",
                        "slug": "C.-Low",
                        "structuredName": {
                            "firstName": "Chien",
                            "lastName": "Low",
                            "middleNames": [
                                "Yong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Low"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743808"
                        ],
                        "name": "S. Smoliar",
                        "slug": "S.-Smoliar",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Smoliar",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Smoliar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40588714"
                        ],
                        "name": "D. Zhong",
                        "slug": "D.-Zhong",
                        "structuredName": {
                            "firstName": "Di",
                            "lastName": "Zhong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zhong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2469411,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16daa3e4fd7fb7c3b8fa843ca79ef27a34ebce1f",
            "isKey": false,
            "numCitedBy": 393,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an integrated solution for computer assisted video parsing and content-based video retrieval and browsing. The uniqueness and effectiveness of this solution lies in its use of video content information provided by a parsing process driven by visual feature analysis. More specifically, parsing will temporally segment and abstract a video source, based on low-level image analyses; then retrieval and browsing of video will be based on key-frames selected during abstraction and spatial-temporal variations of visual features, as well as some shot-level semantics derived from camera operation and motion analysis. These processes, as well as video retrieval and browsing tools, are presented in detail as functions of an integrated system. Also, experimental results on automatic key-frame detection are given."
            },
            "slug": "Video-parsing,-retrieval-and-browsing:-an-and-Zhang-Low",
            "title": {
                "fragments": [],
                "text": "Video parsing, retrieval and browsing: an integrated and content-based solution"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper presents an integrated solution for computer assisted video parsing and content-based video retrieval and browsing that uses video content information provided by a parsing process driven by visual feature analysis."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763529"
                        ],
                        "name": "P. Cosman",
                        "slug": "P.-Cosman",
                        "structuredName": {
                            "firstName": "Pamela",
                            "lastName": "Cosman",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cosman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830639"
                        ],
                        "name": "K. Oehler",
                        "slug": "K.-Oehler",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Oehler",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Oehler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788775"
                        ],
                        "name": "E. Riskin",
                        "slug": "E.-Riskin",
                        "structuredName": {
                            "firstName": "Eve",
                            "lastName": "Riskin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riskin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17304149,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9fd37391b675db8b7751d00780abfbed7596fedf",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "A review is presented of vector quantization, the mapping of pixel intensity vectors into binary vectors indexing a limited number of possible reproductions, which is a popular image compression algorithm. Compression has traditionally been done with little regard for image processing operations that may precede or follow the compression step. Recent work has used vector quantization both to simplify image processing tasks, such as enhancement classification, halftoning, and edge detection, and to reduce the computational complexity by performing the tasks simultaneously with the compression. The fundamental ideas of vector quantization are explained, and vector quantization algorithms that perform image processing are surveyed. >"
            },
            "slug": "Using-vector-quantization-for-image-processing-Cosman-Oehler",
            "title": {
                "fragments": [],
                "text": "Using vector quantization for image processing"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A review is presented of vector quantization, the mapping of pixel intensity vectors into binary vectors indexing a limited number of possible reproductions, which is a popular image compression algorithm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087848"
                        ],
                        "name": "R. Dubes",
                        "slug": "R.-Dubes",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dubes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dubes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119519976,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c5820002582c302736ff6a370904ff685962e3a",
            "isKey": false,
            "numCitedBy": 525,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Image models are useful in quantitatively specifying natural constraints and general assumptions about the physical world and the imaging process. This review paper explains how Gibbs and Markov random field models provide a unifying theme for many contemporary problems in image analysis. Random field models permit the introduction of spatial context into pixel labeling problems, such as segmentation and restoration. Random field models also describe textured images and lead to algorithms for generating textured images, classifying textures and segmenting textured images. In spite of some impressive model-based image restoration and texture segmentation results reported in the literature, a number of fundamental issues remain unexplored, such as the specification of MRF models, modeling noise processes, performance evaluation, parameter estimation, the phase transition phenomenon and the comparative analysis of alternative procedures. The literature of random field models is filled with great promise, but..."
            },
            "slug": "Random-field-models-in-image-analysis-Dubes-Jain",
            "title": {
                "fragments": [],
                "text": "Random field models in image analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This review paper explains how Gibbs and Markov random field models provide a unifying theme for many contemporary problems in image analysis and allows the introduction of spatial context into pixel labeling problems, such as segmentation and restoration."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "1/T. I. T./1580/95."
                    },
                    "intents": []
                }
            ],
            "corpusId": 62196962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "762353f69c1714fa48ba0f0291514f0518830bc1",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new method for indexing large image databases. The method incorporates neural network learning algorithms and pattern recognition techniques to construct an image pattern dictionary. Image retrieval is then formulated as a process of dictionary search to compute the best matching codeword, which in turn indexes into the database items. Experimental results are presented."
            },
            "slug": "Image-indexing-using-a-texture-dictionary-Ma-Manjunath",
            "title": {
                "fragments": [],
                "text": "Image indexing using a texture dictionary"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The method incorporates neural network learning algorithms and pattern recognition techniques to construct an image pattern dictionary and is formulated as a process of dictionary search to compute the best matching codeword, which in turn indexes into the database items."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690709"
                        ],
                        "name": "A. Hampapur",
                        "slug": "A.-Hampapur",
                        "structuredName": {
                            "firstName": "Arun",
                            "lastName": "Hampapur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hampapur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722619"
                        ],
                        "name": "Amarnath Gupta",
                        "slug": "Amarnath-Gupta",
                        "structuredName": {
                            "firstName": "Amarnath",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amarnath Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144152544"
                        ],
                        "name": "B. Horowitz",
                        "slug": "B.-Horowitz",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Horowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144808138"
                        ],
                        "name": "Chiao-Fe Shu",
                        "slug": "Chiao-Fe-Shu",
                        "structuredName": {
                            "firstName": "Chiao-Fe",
                            "lastName": "Shu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chiao-Fe Shu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052276135"
                        ],
                        "name": "Charles Fuller",
                        "slug": "Charles-Fuller",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Fuller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles Fuller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40434992"
                        ],
                        "name": "J. Bach",
                        "slug": "J.-Bach",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087139"
                        ],
                        "name": "M. Gorkani",
                        "slug": "M.-Gorkani",
                        "structuredName": {
                            "firstName": "Monika",
                            "lastName": "Gorkani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gorkani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938732"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "1/T. I. T./1580/95."
                    },
                    "intents": []
                }
            ],
            "corpusId": 28715235,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93235b2f9500528e47e9756c51b95bcb787e25e7",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The temporal and multi-modal nature of video increases the dimensionality of content based retrieval problem. This places new demands on the indexing and retrieval tools required. The Virage Video Engine (VVE) with the default set of primitives provide the necessary frame work and basic tools for video content based retrieval. The video engine is a flexible platform independent architecture which provides support for processing multiple synchronized data streams like image sequences, audio and closed captions. The architecture allows for multi-modal indexing and retrieval of video through the use of media specific primitives. This paper presents the use of the VVE framework for content based video retrieval."
            },
            "slug": "Virage-video-engine-Hampapur-Gupta",
            "title": {
                "fragments": [],
                "text": "Virage video engine"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents the use of the VVE framework for content based video retrieval, a flexible platform independent architecture which provides support for processing multiple synchronized data streams like image sequences, audio and closed captions."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145800809"
                        ],
                        "name": "J. Kangas",
                        "slug": "J.-Kangas",
                        "structuredName": {
                            "firstName": "Jari",
                            "lastName": "Kangas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kangas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708642"
                        ],
                        "name": "Jorma T. Laaksonen",
                        "slug": "Jorma-T.-Laaksonen",
                        "structuredName": {
                            "firstName": "Jorma",
                            "lastName": "Laaksonen",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorma T. Laaksonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770190"
                        ],
                        "name": "K. Torkkola",
                        "slug": "K.-Torkkola",
                        "structuredName": {
                            "firstName": "Kari",
                            "lastName": "Torkkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Torkkola"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18880284,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c0fa29708b7c34ce13a10aa88817fc823b0482b",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The program package is available at the Internet site \"cochlea.hut.\" and will be updated continuously. The indexing of the latest release will always be of the form \"lvq pak-X.Y\". The instructions below are indexed as in the version lvq pak-1.1, which was released on December 31, 1991. The programs are available in two archive formats, one for the UNIX-environment, the other for MS-DOS, respectively. Both archives contain exactly the same les. These les can be accessed via FTP as follows: 1. Create an FTP connection from wherever you are to machine \"cochlea.hut..\". The Internet address of this machine is 130.233.168.48, for those who need it. 2. Log in as user \"anonymous\" with your own e-mail address as password. 3. Change the remote directory to \"/pub/lvq pak\". 4. At this point the FTP should be able to get a listing of les in this directory with DIR and fetch the ones you want with GET. (The exact FTP commands depend on your local FTP program.) Remember to use the binary transfer mode for compressed les. The LVQ PAK program package includes the following les:-Documentation: README short description of the package and installation instructions document.ps documentation in (c) Postcript format document.ps.Z same as above but compressed document.txt documentation in ASCII format-Source le archives (which contain the documentation, too): lvq p1r1.exe self-extracting MS-DOS archive le lvq pak-1.1.tar UNIX tape archive le lvq pak-1.1.tar.Z same as above but compressed An example of FTP access is given below: unix> ftp cochlea.hut.. Password: <your e-mail address> ftp> cd /pub/lvq pak ftp> binary ftp> get lvq pak-1.1.tar.Z ftp> quit unix> uncompress lvq pak-1.1.tar.Z unix> tar xvfo lvq pak-1.1.tar 3.3 Test data les The package also contains two data sets, ex1.dat and ex2.dat, which can be used to experiment with the programs. An exemplary procedure is given in the documentation of the package. All data les (input vectors and codebooks) are stored in ASCII format for their easy editing and checking. 3.4 Diagnostics With all the programs, it is possible to set the verbose parameter (-v n), where the value of n determines the amount of diagnostic output the program generates. For the visualization of topological relationships of data and codebook vectors, the monitoring program sammon generates a list of coordinates of points that can be displayed two-dimensionally by any standard graphics program. The two-dimensional Sammon mapping approximates to Euclidean distances of the data space, and thus visualizes \u2026"
            },
            "slug": "Appendix-2.4-Stopping-Rule-2.3-Fine-Tuning-Using-or-Kohonen-Kangas",
            "title": {
                "fragments": [],
                "text": "Appendix 2.4 Stopping Rule 2.3 Fine Tuning Using the Basic Lvq1 or Lvq2.1 Lvq Pak: a Program Package for the Correct Application of Learning Vector Quantization Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The LVQ PAK program package includes the following les: 1."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3112585"
                        ],
                        "name": "B. Rogowitz",
                        "slug": "B.-Rogowitz",
                        "structuredName": {
                            "firstName": "Bernice",
                            "lastName": "Rogowitz",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rogowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50485519"
                        ],
                        "name": "T. Frese",
                        "slug": "T.-Frese",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Frese",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Frese"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47088868"
                        ],
                        "name": "Joshua R. Smith",
                        "slug": "Joshua-R.-Smith",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745655"
                        ],
                        "name": "C. Bouman",
                        "slug": "C.-Bouman",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bouman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bouman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3438026"
                        ],
                        "name": "Edward B. Kalin",
                        "slug": "Edward-B.-Kalin",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Kalin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward B. Kalin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9665828,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "712e571497d41c3a569e011649d998ae3fc0d916",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we study how human observers judge image similarity. To do so, we have conducted two psychophysical scaling experiments and have compared the results to two algorithmic image similarity metrics. For these experiments, we selected a set of 97 digitized photographic images which represent a range of semantic categories, viewing distances, and colors. We then used the two perceptual and the two algorithmic methods to measure the similarity of each image to every other image in the data set, producing four similarity matrices. These matrices were analyzed using multidimensional scaling techniques to gain insight into the dimensions human observers use for judging image similarity, and how these dimensions differ from the results of algorithmic methods. This paper also describes and validates a new technique for collecting similarity judgments which can provide meaningful results with a factor of four fewer judgments, as compared with the paired comparisons method."
            },
            "slug": "Perceptual-image-similarity-experiments-Rogowitz-Frese",
            "title": {
                "fragments": [],
                "text": "Perceptual image similarity experiments"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new technique for collecting similarity judgments which can provide meaningful results with a factor of four fewer judgments, as compared with the paired comparisons method is described and validates."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, its use in content-based retrieval from image databases is just being realized [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14754287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "81a5952532cdd48eec5e3dc326907c36a70e0a24",
            "isKey": false,
            "numCitedBy": 2922,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "A vector quantizer is a system for mapping a sequence of continuous or discrete vectors into a digital sequence suitable for communication over or storage in a digital channel. The goal of such a system is data compression: to reduce the bit rate so as to minimize communication channel capacity or digital storage memory requirements while maintaining the necessary fidelity of the data. The mapping for each vector may or may not have memory in the sense of depending on past actions of the coder, just as in well established scalar techniques such as PCM, which has no memory, and predictive quantization, which does. Even though information theory implies that one can always obtain better performance by coding vectors instead of scalars, scalar quantizers have remained by far the most common data compression system because of their simplicity and good performance when the communication rate is sufficiently large. In addition, relatively few design techniques have existed for vector quantizers. During the past few years several design algorithms have been developed for a variety of vector quantizers and the performance of these codes has been studied for speech waveforms, speech linear predictive parameter vectors, images, and several simulated random processes. It is the purpose of this article to survey some of these design techniques and their applications."
            },
            "slug": "Vector-quantization-Gray",
            "title": {
                "fragments": [],
                "text": "Vector quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "During the past few years several design algorithms have been developed for a variety of vector quantizers and the performance of these codes has been studied for speech waveforms, speech linear predictive parameter vectors, images, and several simulated random processes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE ASSP Magazine"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d76ef8e61395a6e9c32627f1f108772d084e2e9",
            "isKey": false,
            "numCitedBy": 4156,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural Network-Based Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145800809"
                        ],
                        "name": "J. Kangas",
                        "slug": "J.-Kangas",
                        "structuredName": {
                            "firstName": "Jari",
                            "lastName": "Kangas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kangas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708642"
                        ],
                        "name": "Jorma T. Laaksonen",
                        "slug": "Jorma-T.-Laaksonen",
                        "structuredName": {
                            "firstName": "Jorma",
                            "lastName": "Laaksonen",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorma T. Laaksonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770190"
                        ],
                        "name": "K. Torkkola",
                        "slug": "K.-Torkkola",
                        "structuredName": {
                            "firstName": "Kari",
                            "lastName": "Torkkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Torkkola"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The LVQ PAK package [2] was used for vector quantization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58710632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d00a87cfb0695388783aa90398e5d138358d24d",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "An overview of the software package LVQPAK, which has been developed for convenient and effective application of learning vector quantization algorithms, is presented. Two new features are included: fast conflict-free initial distribution of codebook vectors into the class zones and the optimized-learning-rate algorithm OLVQ1.<<ETX>>"
            },
            "slug": "LVQPAK:-A-software-package-for-the-correct-of-Kohonen-Kangas",
            "title": {
                "fragments": [],
                "text": "LVQPAK: A software package for the correct application of Learning Vector Quantization algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An overview of the software package LVQPAK, which has been developed for convenient and effective application of learning vector quantization algorithms, is presented and two new features are included: fast conflict-free initial distribution of codebook vectors into the class zones and the optimized-learning-rate algorithm OLVQ1."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings 1992] IJCNN International Joint Conference on Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115282352"
                        ],
                        "name": "Joy A. Thomas",
                        "slug": "Joy-A.-Thomas",
                        "structuredName": {
                            "firstName": "Joy",
                            "lastName": "Thomas",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joy A. Thomas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 190432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dbdb4209626fd92d2436a058663206216036e68",
            "isKey": false,
            "numCitedBy": 42794,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface to the Second Edition. Preface to the First Edition. Acknowledgments for the Second Edition. Acknowledgments for the First Edition. 1. Introduction and Preview. 1.1 Preview of the Book. 2. Entropy, Relative Entropy, and Mutual Information. 2.1 Entropy. 2.2 Joint Entropy and Conditional Entropy. 2.3 Relative Entropy and Mutual Information. 2.4 Relationship Between Entropy and Mutual Information. 2.5 Chain Rules for Entropy, Relative Entropy, and Mutual Information. 2.6 Jensen's Inequality and Its Consequences. 2.7 Log Sum Inequality and Its Applications. 2.8 Data-Processing Inequality. 2.9 Sufficient Statistics. 2.10 Fano's Inequality. Summary. Problems. Historical Notes. 3. Asymptotic Equipartition Property. 3.1 Asymptotic Equipartition Property Theorem. 3.2 Consequences of the AEP: Data Compression. 3.3 High-Probability Sets and the Typical Set. Summary. Problems. Historical Notes. 4. Entropy Rates of a Stochastic Process. 4.1 Markov Chains. 4.2 Entropy Rate. 4.3 Example: Entropy Rate of a Random Walk on a Weighted Graph. 4.4 Second Law of Thermodynamics. 4.5 Functions of Markov Chains. Summary. Problems. Historical Notes. 5. Data Compression. 5.1 Examples of Codes. 5.2 Kraft Inequality. 5.3 Optimal Codes. 5.4 Bounds on the Optimal Code Length. 5.5 Kraft Inequality for Uniquely Decodable Codes. 5.6 Huffman Codes. 5.7 Some Comments on Huffman Codes. 5.8 Optimality of Huffman Codes. 5.9 Shannon-Fano-Elias Coding. 5.10 Competitive Optimality of the Shannon Code. 5.11 Generation of Discrete Distributions from Fair Coins. Summary. Problems. Historical Notes. 6. Gambling and Data Compression. 6.1 The Horse Race. 6.2 Gambling and Side Information. 6.3 Dependent Horse Races and Entropy Rate. 6.4 The Entropy of English. 6.5 Data Compression and Gambling. 6.6 Gambling Estimate of the Entropy of English. Summary. Problems. Historical Notes. 7. Channel Capacity. 7.1 Examples of Channel Capacity. 7.2 Symmetric Channels. 7.3 Properties of Channel Capacity. 7.4 Preview of the Channel Coding Theorem. 7.5 Definitions. 7.6 Jointly Typical Sequences. 7.7 Channel Coding Theorem. 7.8 Zero-Error Codes. 7.9 Fano's Inequality and the Converse to the Coding Theorem. 7.10 Equality in the Converse to the Channel Coding Theorem. 7.11 Hamming Codes. 7.12 Feedback Capacity. 7.13 Source-Channel Separation Theorem. Summary. Problems. Historical Notes. 8. Differential Entropy. 8.1 Definitions. 8.2 AEP for Continuous Random Variables. 8.3 Relation of Differential Entropy to Discrete Entropy. 8.4 Joint and Conditional Differential Entropy. 8.5 Relative Entropy and Mutual Information. 8.6 Properties of Differential Entropy, Relative Entropy, and Mutual Information. Summary. Problems. Historical Notes. 9. Gaussian Channel. 9.1 Gaussian Channel: Definitions. 9.2 Converse to the Coding Theorem for Gaussian Channels. 9.3 Bandlimited Channels. 9.4 Parallel Gaussian Channels. 9.5 Channels with Colored Gaussian Noise. 9.6 Gaussian Channels with Feedback. Summary. Problems. Historical Notes. 10. Rate Distortion Theory. 10.1 Quantization. 10.2 Definitions. 10.3 Calculation of the Rate Distortion Function. 10.4 Converse to the Rate Distortion Theorem. 10.5 Achievability of the Rate Distortion Function. 10.6 Strongly Typical Sequences and Rate Distortion. 10.7 Characterization of the Rate Distortion Function. 10.8 Computation of Channel Capacity and the Rate Distortion Function. Summary. Problems. Historical Notes. 11. Information Theory and Statistics. 11.1 Method of Types. 11.2 Law of Large Numbers. 11.3 Universal Source Coding. 11.4 Large Deviation Theory. 11.5 Examples of Sanov's Theorem. 11.6 Conditional Limit Theorem. 11.7 Hypothesis Testing. 11.8 Chernoff-Stein Lemma. 11.9 Chernoff Information. 11.10 Fisher Information and the Cram-er-Rao Inequality. Summary. Problems. Historical Notes. 12. Maximum Entropy. 12.1 Maximum Entropy Distributions. 12.2 Examples. 12.3 Anomalous Maximum Entropy Problem. 12.4 Spectrum Estimation. 12.5 Entropy Rates of a Gaussian Process. 12.6 Burg's Maximum Entropy Theorem. Summary. Problems. Historical Notes. 13. Universal Source Coding. 13.1 Universal Codes and Channel Capacity. 13.2 Universal Coding for Binary Sequences. 13.3 Arithmetic Coding. 13.4 Lempel-Ziv Coding. 13.5 Optimality of Lempel-Ziv Algorithms. Compression. Summary. Problems. Historical Notes. 14. Kolmogorov Complexity. 14.1 Models of Computation. 14.2 Kolmogorov Complexity: Definitions and Examples. 14.3 Kolmogorov Complexity and Entropy. 14.4 Kolmogorov Complexity of Integers. 14.5 Algorithmically Random and Incompressible Sequences. 14.6 Universal Probability. 14.7 Kolmogorov complexity. 14.9 Universal Gambling. 14.10 Occam's Razor. 14.11 Kolmogorov Complexity and Universal Probability. 14.12 Kolmogorov Sufficient Statistic. 14.13 Minimum Description Length Principle. Summary. Problems. Historical Notes. 15. Network Information Theory. 15.1 Gaussian Multiple-User Channels. 15.2 Jointly Typical Sequences. 15.3 Multiple-Access Channel. 15.4 Encoding of Correlated Sources. 15.5 Duality Between Slepian-Wolf Encoding and Multiple-Access Channels. 15.6 Broadcast Channel. 15.7 Relay Channel. 15.8 Source Coding with Side Information. 15.9 Rate Distortion with Side Information. 15.10 General Multiterminal Networks. Summary. Problems. Historical Notes. 16. Information Theory and Portfolio Theory. 16.1 The Stock Market: Some Definitions. 16.2 Kuhn-Tucker Characterization of the Log-Optimal Portfolio. 16.3 Asymptotic Optimality of the Log-Optimal Portfolio. 16.4 Side Information and the Growth Rate. 16.5 Investment in Stationary Markets. 16.6 Competitive Optimality of the Log-Optimal Portfolio. 16.7 Universal Portfolios. 16.8 Shannon-McMillan-Breiman Theorem (General AEP). Summary. Problems. Historical Notes. 17. Inequalities in Information Theory. 17.1 Basic Inequalities of Information Theory. 17.2 Differential Entropy. 17.3 Bounds on Entropy and Relative Entropy. 17.4 Inequalities for Types. 17.5 Combinatorial Bounds on Entropy. 17.6 Entropy Rates of Subsets. 17.7 Entropy and Fisher Information. 17.8 Entropy Power Inequality and Brunn-Minkowski Inequality. 17.9 Inequalities for Determinants. 17.10 Inequalities for Ratios of Determinants. Summary. Problems. Historical Notes. Bibliography. List of Symbols. Index."
            },
            "slug": "Elements-of-Information-Theory-Cover-Thomas",
            "title": {
                "fragments": [],
                "text": "Elements of Information Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author examines the role of entropy, inequality, and randomness in the design of codes and the construction of codes in the rapidly changing environment."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52549908"
                        ],
                        "name": "Elaine C. Yiu",
                        "slug": "Elaine-C.-Yiu",
                        "structuredName": {
                            "firstName": "Elaine",
                            "lastName": "Yiu",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elaine C. Yiu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 56537438,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e45f91dc8ac9ae7b3293e6adc4804e540f4ead6e",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-classification-using-color-cues-and-texture-Yiu",
            "title": {
                "fragments": [],
                "text": "Image classification using color cues and texture orientation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Recently, there has been an added interest to model human perception of image content [3, 7, 5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41186627,
            "fieldsOfStudy": [],
            "id": "a196394a31f83c515cb8a691e1d6386b628edd43",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Interactive learning with a \"Society of Models\""
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087848"
                        ],
                        "name": "R. Dubes",
                        "slug": "R.-Dubes",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dubes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dubes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29535089,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa4bddbd10eafd8e1b54338517eedfee408f03ae",
            "isKey": false,
            "numCitedBy": 10559,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algorithms-for-Clustering-Data-Jain-Dubes",
            "title": {
                "fragments": [],
                "text": "Algorithms for Clustering Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Handbook of Multimedia Computing: Chapter 13 -Content-Based Image Indexing and Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "The Handbook of Multimedia Computing: Chapter 13 -Content-Based Image Indexing and Retrieval"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, its use in content-based retrieval from image databases is just being realized [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Bayesian framework for classification of vacation images"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. SPIE Conference Electronic Imaging '99"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "1/T. I. T./1580/95."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vision texture for annotation Multimedia Systems: Special Issue on Contentbased Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Vision texture for annotation Multimedia Systems: Special Issue on Contentbased Retrieval"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic Complexity in Stastistical I n q u i ~"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "Specifically, first and second order color moments in the LUV color space were used as color features (it was pointed out in [24] that color moments in the LUV color space yielded better results during image retrieval than color moments in other color spaces)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ed., The Handbook of Multimedia Computing: Chapter - Content-Based Image Indexing and Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic Complexity in Stastistical Inquiry"
            },
            "venue": {
                "fragments": [],
                "text": "Singapore: World Scientific"
            },
            "year": 1989
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 7,
            "methodology": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 37,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Content-based-hierarchical-classification-of-images-Vailaya-Figueiredo/d01805e377a90563292322cdce31828ccde40ba5?sort=total-citations"
}