{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925215"
                        ],
                        "name": "W. Lehnert",
                        "slug": "W.-Lehnert",
                        "structuredName": {
                            "firstName": "Wendy",
                            "lastName": "Lehnert",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lehnert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2648450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dab48886932ffb7a3e2c3f2803005bb34345cdee",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The vast amounts of on-line text now available have led to renewed interest in information extraction (IE) systems that analyze unrestricted text, producing a structured representation of selected information from the text. This paper presents a novel approach that uses machine learning to acquire knowledge for some of the higher level IE processing. Wrap-Up is a trainable IE discourse component that makes intersentential inferences and identifies logical relations among information extracted from the text. Previous corpus-based approaches were limited to lower level processing such as part-of-speech tagging, lexical disambiguation, and dictionary construction. Wrap-Up is fully trainable, and not only automatically decides what classifiers are needed, but even derives the feature set for each classifier automatically. Performance equals that of a partially trainable discourse module requiring manual customization for each domain."
            },
            "slug": "Wrap-Up:-a-Trainable-Discourse-Module-for-Soderland-Lehnert",
            "title": {
                "fragments": [],
                "text": "Wrap-Up: a Trainable Discourse Module for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Wrap-Up is a trainable IE discourse component that makes intersentential inferences and identifies logical relations among information extracted from the text, and automatically decides what classifiers are needed, and derives the feature set for each classifier automatically."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2257053,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdc08721414c972ab451f8ef3ef39d63c741b324",
            "isKey": false,
            "numCitedBy": 556,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Knowledge-based natural language processing systems have achieved good success with certain tasks but they are often criticized because they depend on a domain-specific dictionary that requires a great deal of manual knowledge engineering. This knowledge engineering bottleneck makes knowledge-based NLP systems impractical for real-world applications because they cannot be easily scaled up or ported to new domains. In response to this problem, we developed a system called AutoSlog that automatically builds a domain-specific dictionary of concepts for extracting information from text. Using AutoSlog, we constructed a dictionary for the domain of terrorist event descriptions in only 5 person-hours. We then compared the AutoSlog dictionary with a hand-crafted dictionary that was built by two highly skilled graduate students and required approximately 1500 person-hours of effort. We evaluated the two dictionaries using two blind test sets of 100 texts each. Overall, the AutoSlog dictionary achieved 98% of the performance of the hand-crafted dictionary. On the first test set, the AutoSlog dictionary obtained 96.3% of the performance of the hand-crafted dictionary. On the second test set, the overall scores were virtually indistinguishable with the AutoSlog dictionary achieving 99.7% of the performance of the handcrafted dictionary."
            },
            "slug": "Automatically-Constructing-a-Dictionary-for-Tasks-Riloff",
            "title": {
                "fragments": [],
                "text": "Automatically Constructing a Dictionary for Information Extraction Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Using AutoSlog, a system that automatically builds a domain-specific dictionary of concepts for extracting information from text, a dictionary for the domain of terrorist event descriptions was constructed in only 5 person-hours and the overall scores were virtually indistinguishable."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145262164"
                        ],
                        "name": "David Fisher",
                        "slug": "David-Fisher",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fisher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51080653"
                        ],
                        "name": "J. Aseltine",
                        "slug": "J.-Aseltine",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Aseltine",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aseltine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925215"
                        ],
                        "name": "W. Lehnert",
                        "slug": "W.-Lehnert",
                        "structuredName": {
                            "firstName": "Wendy",
                            "lastName": "Lehnert",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lehnert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9168228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8245f6099f547008522ebbe6fb813d8132085746",
            "isKey": false,
            "numCitedBy": 409,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the central knowledge sources of an information extraction (IE) system IS a dictionary of linguistic patterns that can be used to identify references to relevant information in a text Automatic creation of conceptual dictionaries is important for portability and scalability of an IE system This paper describes CRYSTAL, a system which automatically induces a dictionary of \"concept-node definitions\" sufficient to identify relevant information from a training corpus Each of these concept-node definitions is generalized as far as possible without producing errors, so that a minimum number of dictionary entries cover the positive training instances Because it tests the accuracy of each proposed definition, CRYSTAL can often surpass human intuitions in creating reliable extraction rules."
            },
            "slug": "CRYSTAL:-Inducing-a-Conceptual-Dictionary-Soderland-Fisher",
            "title": {
                "fragments": [],
                "text": "CRYSTAL: Inducing a Conceptual Dictionary"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "CRYSTAL is described, a system which automatically induces a dictionary of \"concept-node definitions\" sufficient to identify relevant information from a training corpus that can often surpass human intuitions in creating reliable extraction rules."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145262164"
                        ],
                        "name": "David Fisher",
                        "slug": "David-Fisher",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fisher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8704658,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1f13fc34ba159810e331f010d167d41f91065ea",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The application of statistical approaches to problems in natural language processing generally requires large (1,000,000\u00f7 words) corpora to produce useful results. In this paper we show that a well-known statistical technique, the t test, can be applied to smaller corpora than was previously thought possible, by relying on semantic features rather than lexical items in a corpus of limited domain. We apply the t test to the problem of resolving relative pronoun antecedents, using collocation frequency data collected from the 500,000 word MUC-4 corpus. We conduct two experiments where t is calculated with lexical items and with semantic feature representations. We show that the test cases that are relevant to the MUC-4 domain produce more significant values of t than the ones that are irrelevant. We also show that the t test correctly resolves the relative pronoun in 91.07% of the relevant test cases where the value of t is significant."
            },
            "slug": "Applying-Statistical-Methods-to-Small-Corpora:-from-Fisher-Riloff",
            "title": {
                "fragments": [],
                "text": "Applying Statistical Methods to Small Corpora: Benefitting from a Limited Domain*"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows that a well-known statistical technique, the t test, can be applied to smaller corpora than was previously thought possible, by relying on semantic features rather than lexical items in a corpus of limited domain."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15894892,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "acec622ca4fb7e01a56116522d35ded149969d0a",
            "isKey": false,
            "numCitedBy": 762,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Many corpus-based natural language processing systems rely on text corpora that have been manually annotated with syntactic or semantic tags. In particular, all previous dictionary construction systems for information extraction have used an annotated training corpus or some form of annotated input. We have developed a system called AutoSlog-TS that creates dictionaries of extraction patterns using only untagged text. AutoSlog-TS is based on the AutoSlog system, which generated extraction patterns using annotated text and a set of heuristic rules. By adapting AutoSlog and combining it with statistical techniques, we eliminated its dependency on tagged text. In experiments with the MUG-4 terrorism domain, AutoSlog-TS created a dictionary of extraction patterns that performed comparably to a dictionary created by AutoSlog, using only preclassified texts as input."
            },
            "slug": "Automatically-Generating-Extraction-Patterns-from-Riloff",
            "title": {
                "fragments": [],
                "text": "Automatically Generating Extraction Patterns from Untagged Text"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work has developed a system called AutoSlog-TS that creates dictionaries of extraction patterns using only untagged text, and in experiments with the MUG-4 terrorism domain, created a dictionary of extraction pattern that performed comparably to a dictionary created by autoSlog, using only preclassified texts as input."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI, Vol. 2"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580777"
                        ],
                        "name": "David M. Magerman",
                        "slug": "David-M.-Magerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Magerman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Magerman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 608,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0a14be7e7f5614b91d0f648ae5f2baafc6d7036",
            "isKey": false,
            "numCitedBy": 717,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Syntactic natural language parsers have shown themselves to be inadequate for processing highly-ambiguous large-vocabulary text, as is evidenced by their poor performance on domains like the Wall Street Journal, and by the movement away from parsing-based approaches to text-processing in general. In this paper, I describe SPATTER, a statistical parser based on decision-tree learning techniques which constructs a complete parse for every sentence and achieves accuracy rates far better than any published result. This work is based on the following premises: (1) grammars are too complex and detailed to develop manually for most interesting domains; (2) parsing models must rely heavily on lexical and contextual information to analyze sentences accurately; and (3) existing n-gram modeling techniques are inadequate for parsing models. In experiments comparing SPATTER with IBM's computer manuals parser, SPATTER significantly outperforms the grammar-based parser. Evaluating SPATTER against the Penn Treebank Wall Street Journal corpus using the PARSEVAL measures, SPATTER achieves 86% precision, 86% recall, and 1.3 crossing brackets per sentence for sentences of 40 words or less, and 91% precision, 90% recall, and 0.5 crossing brackets for sentences between 10 and 20 words in length."
            },
            "slug": "Statistical-Decision-Tree-Models-for-Parsing-Magerman",
            "title": {
                "fragments": [],
                "text": "Statistical Decision-Tree Models for Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "SPATTER is described, a statistical parser based on decision-tree learning techniques which constructs a complete parse for every sentence and achieves accuracy rates far better than any published result."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1693468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d922631a6bf8361d7602e12cafb9e15d421c827",
            "isKey": false,
            "numCitedBy": 836,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a program that disambiguates English word senses in unrestricted text using statistical models of the major Roget's Thesaurus categories. Roget's categories serve as approximations of conceptual classes. The categories listed for a word in Roget's index tend to correspond to sense distinctions; thus selecting the most likely category provides a useful level of sense disambiguation. The selection of categories is accomplished by identifying and weighting words that are indicative of each category when seen in context, using a Bayesian theoretical framework.Other statistical approaches have required special corpora or hand-labeled training examples for much of the lexicon. Our use of class models overcomes this knowledge acquisition bottleneck, enabling training on unrestricted monolingual text without human intervention. Applied to the 10 million word Grolier's Encyclopedia, the system correctly disambiguated 92% of the instances of 12 polysemous words that have been previously studied in the literature."
            },
            "slug": "Word-Sense-Disambiguation-Using-Statistical-Models-Yarowsky",
            "title": {
                "fragments": [],
                "text": "Word-Sense Disambiguation Using Statistical Models of Roget\u2019s Categories Trained on Large Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A program that disambiguates English word senses in unrestricted text using statistical models of the major Roget's Thesaurus categories, enabling training on unrestricted monolingual text without human intervention."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2797754"
                        ],
                        "name": "U. Zernik",
                        "slug": "U.-Zernik",
                        "structuredName": {
                            "firstName": "Uri",
                            "lastName": "Zernik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Zernik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58067384,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "6a7d1669748c30ef108d7874edaf4c8cac73a01c",
            "isKey": false,
            "numCitedBy": 288,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Contents: U. Zernik, Introduction. Part I:Lexical Senses. P. Jacobs, Making Sense of Lexical Acquisition. R. Krovetz, Lexical Acquisition and Information Retrieval. B. Slator, Using Context for Sense Preference. U. Zernik, Tagging Word Sense In Corpus. Part II:Lexical Statistics. K. Church, W. Gale, P. Hanks, D. Hindle, Using Statistics in Lexical Analysis. F. Smadja, Macrocoding the Lexicon with Co-Occurrence Knowledge. N. Calzolari, Lexical Databases and Textual Corpora: Perspectives of Integration for a Lexical Knowledge-Base. Part III:Lexical Representation. R. Beckwith, C. Fellbaum, D. Gross, G. Miller, WordNet: A Lexical Database Organized on Psycholinguistic Principles. B. Atkins, B. Levin, Admitting Impediments. B. Dorr, Conceptual Basis of the Lexicon in Machine Translation. M. Dyer, Lexical Acquisition Through Symbol Recirculation. Part IV:Lexical Semantics. P. Velardi, Acquiring a Semantic Lexicon for Natural Language Processing. L. Braden-Harder, W. Zadrozny, Lexicons for Broad Coverage Semantics. J. Martin, Representing and Acquiring Metaphor-Based Polysemy."
            },
            "slug": "Lexical-Acquisition:-Exploiting-On-Line-Resources-a-Zernik",
            "title": {
                "fragments": [],
                "text": "Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This book discusses Lexical Acquisition Through Symbol Recirculation, Lexical Representation, and Lexicons for Broad Coverage Semantics, which are concerned with the acquisition of semantic meaning in the Lexical Knowledge-Base."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2605572"
                        ],
                        "name": "S. Huffman",
                        "slug": "S.-Huffman",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Huffman",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Huffman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14690792,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8dadbf2dfebe794ad4fc5022f8bb65195c8f0d5a",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A growing population of users want to extract a growing variety of information from on-line texts. Unfortunately, current information extraction systems typically require experts to hand-build dictionaries of extraction patterns for each new type of information to be extracted. This paper presents a system that can learn dictionaries of extraction patterns directly from user-provided examples of texts and events to be extracted from them. The system, called LIEP, learns patterns that recognize relationships between key constituents based on local syntax. Sets of patterns learned by LIEP for a sample extraction task perform nearly at the level of a hand-built dictionary of patterns."
            },
            "slug": "Learning-information-extraction-patterns-from-Huffman",
            "title": {
                "fragments": [],
                "text": "Learning information extraction patterns from examples"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A system that can learn dictionaries of extraction patterns directly from user-provided examples of texts and events to be extracted from them, and learns patterns that recognize relationships between key constituents based on local syntax."
            },
            "venue": {
                "fragments": [],
                "text": "Learning for Natural Language Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66511259"
                        ],
                        "name": "R. Beckwith",
                        "slug": "R.-Beckwith",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Beckwith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Beckwith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145386345"
                        ],
                        "name": "Derek Gross",
                        "slug": "Derek-Gross",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Gross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Gross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113623689"
                        ],
                        "name": "K. Miller",
                        "slug": "K.-Miller",
                        "structuredName": {
                            "firstName": "Katherine",
                            "lastName": "Miller",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2146137,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "4bd970a37c59c97804ff93cbb2c108e081de3a37",
            "isKey": false,
            "numCitedBy": 5335,
            "numCiting": 133,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard alphabetical procedures for organizing lexical information put together words that are spelled alike and scatter words with similar or related meanings haphazardly through the list. Unfortunately, there is no obvious alternative, no other simple way for lexicographers to keep track of what has been done or for readers to find the word they are looking for. But a frequent objection to this solution is that finding things on an alphabetical list can be tedious and time-consuming. Many people who would like to refer to a dictionary decide not to bother with it because finding the information would interrupt their work and break their train of thought."
            },
            "slug": "Introduction-to-WordNet:-An-On-line-Lexical-Miller-Beckwith",
            "title": {
                "fragments": [],
                "text": "Introduction to WordNet: An On-line Lexical Database"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Standard alphabetical procedures for organizing lexical information put together words that are spelled alike and scatter words with similar or related meanings haphazardly through the list."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2359882"
                        ],
                        "name": "George R. Krupka",
                        "slug": "George-R.-Krupka",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Krupka",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George R. Krupka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17492055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6fd398dcb4c0a20de0d10c7a30b36fa8e1b24ead",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "SRA used the combination of two systems for the MUC-6 tasks: NameTag\u2122, a commercial software product that recognizes proper names and other key phrases in text; and HASTEN, an experimental text extraction system that has been under development for only one year. For the Named Entity task, SRA adapted a subset of NameTag's capabilities to the MUC-6 specification. For the Template Element task, SRA fed the full results of NameTag into HASTEN, which performed additional processing to extract and generate the organization and person templates. For the Scenario Template task, SRA fed NameTag's results into HASTEN, which used its full extraction capabilities to extract and generate the management succession templates. Figure 1 illustrates the contribution of each system to the MUC-6 tasks. Due to the relative complexity of the scenario template task, this paper will focus on HASTEN and the experimental results for scenario extraction, and will provide brief descriptions of NameTag and the other tasks."
            },
            "slug": "SRA:-description-of-the-SRA-system-as-used-for-Krupka",
            "title": {
                "fragments": [],
                "text": "SRA: description of the SRA system as used for MUC-6"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Due to the relative complexity of the scenario template task, this paper will focus on HASTEN and the experimental results for scenario extraction, and will provide brief descriptions of NameTag and the other tasks."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117769980,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "107ed240fd5a94aa84d9f6297fd6e43a88008755",
            "isKey": false,
            "numCitedBy": 443,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : A method is presented for learning general descriptions of concepts from a sequence of positive and negative training instances. This method involves examining a predetermined space or language of possible concept descriptions, finding those which are consistent with the observed training instances. Rather than use heuristic search techniques to examine this concept description space, the subspace (version space) of all plausible concept descriptions is represented and updated with each training instance. This version space approach determines all concept descriptions consistent with the training instances, without backtracking to reexamine past training instances or previously rejected concept descriptions. Proofs are given for the correctness of the method for representing version spaces, and of the associated concept learning algorithm, for any countably infinite concept description language. Empirical results obtained from computer implementations in two domains are presented. The version space approach has been implemented as one component of the Meta-DENDRAL program for learning production rules in the domain of chemical spectroscopy. Its implementation in this program is described in detail."
            },
            "slug": "Version-spaces:-an-approach-to-concept-learning.-Mitchell",
            "title": {
                "fragments": [],
                "text": "Version spaces: an approach to concept learning."
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The version space approach has been implemented as one component of the Meta-DENDRAL program for learning production rules in the domain of chemical spectroscopy and proofs are given for the correctness of the method for representing version spaces, and of the associated concept learning algorithm, for any countably infinite concept description language."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32688069"
                        ],
                        "name": "C. A. Will",
                        "slug": "C.-A.-Will",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Will",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. A. Will"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 15
                            }
                        ],
                        "text": "An experiment [Will 1993] was conducted that measured the amount ofinter-coder disagreement between four human analysts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 1
                            }
                        ],
                        "text": "[Will 1993] Will, C. Comparing Human and Machine Performance for Nat-ural Language Information Extraction: Results for English Mi-croelectronics from the MUC-5 Evaluation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 14
                            }
                        ],
                        "text": "An experiment [Will 1993] was conducted that measured the amount of inter-coder disagreement between four human analysts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2180596,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b61c2b67a02c7b4d7d855b1f13db2c75e1dae7a",
            "isKey": true,
            "numCitedBy": 19,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents results from a study comparing human performance on the text of natural language information extraction with that of machine extraction systems that were developed as part of the ARPA Tipster program. Information extraction is shown to be a difficult task for both humans and machines. Evidence for one set of text material, English Microelectronics, indicated that a human analyst produces about half the errors as does machine systems."
            },
            "slug": "Comparing-Human-and-Machine-Performance-for-Natural-Will",
            "title": {
                "fragments": [],
                "text": "Comparing Human and Machine Performance for Natural Language Information Extraction: Results from the Tipster Text Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A study comparing human performance on the text of natural language information extraction with that of machine extraction systems that were developed as part of the ARPA Tipster program shows that a human analyst produces about half the errors as does machine systems."
            },
            "venue": {
                "fragments": [],
                "text": "TIPSTER"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32688069"
                        ],
                        "name": "C. A. Will",
                        "slug": "C.-A.-Will",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Will",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. A. Will"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7364826,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23e139e90a856358957baf994bd02717b6af238c",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In evaluating the state of technology for extracting information from natural language text by machine, it is valuable to compare the performance of machine extraction systems with that achieved by humans performing the same task. The purpose of this paper is to present some results from a comparative study of human and machine performance for one of the information extraction tasks used in the MUC-5/Tipster evaluation that can help assess the maturity and applicability of the technology."
            },
            "slug": "Comparing-human-and-machine-performance-for-natural-Will",
            "title": {
                "fragments": [],
                "text": "Comparing human and machine performance for natural language information extraction: results for English microelectronics from the MUC-5 evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results are presented from a comparative study of human and machine performance for one of the information extraction tasks used in the MUC-5/Tipster evaluation that can help assess the maturity and applicability of the technology."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18791110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "407d55ee40f1bdb10745155fde211d566c2d0c71",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a language model in which the probability of a sentence is the sum of the individual parse probabilities, and these are calculated using a probabilistic context-free grammar (PCFG) plus statistics on individual words and how they fit into parses. We have used the model to improve syntactic disambiguation. After training on Wall Street Journal (WSJ) text we tested on about 200 WSJ sentence restricted to the 5400 most common words from our training. We observed a 41\\ performance of our PCFG without the use of the word statistics."
            },
            "slug": "Parsing-with-Context-Free-Grammars-and-Word-Charniak",
            "title": {
                "fragments": [],
                "text": "Parsing with Context-Free Grammars and Word Statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A language model in which the probability of a sentence is the sum of the individual parse probabilities, and these are calculated using a probabilistic context-free grammar (PCFG) plus statistics on individual words and how they fit into parses is presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3166885,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7e084fe51a40eeaaf79bf0b78e837d5bc4a8e10",
            "isKey": false,
            "numCitedBy": 1058,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A program that tags each word in an input sentence with the most likely part of speech has been written. The program uses a linear-time dynamic programming algorithm to find an assignment of parts of speech to words that optimizes the product of (a) lexical probabilities (probability of observing part of speech i given word i) and (b) contextual probabilities (probability of observing part of speech i given n following parts of speech). Program performance is encouraging; a 400-word sample is presented and is judged to be 99.5% correct.<<ETX>>"
            },
            "slug": "A-Stochastic-Parts-Program-and-Noun-Phrase-Parser-Church",
            "title": {
                "fragments": [],
                "text": "A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A program that tags each word in an input sentence with the most likely part of speech has been written and performance is encouraging; a 400-word sample is presented and is judged to be 99.5% correct."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12309040,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "733234e097dceb9011baa8914930861996eb0b5e",
            "isKey": false,
            "numCitedBy": 624,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Most recent research in trainable part of speech taggers has explored stochastic tagging. While these taggers obtain high accuracy, linguistic information is captured indirectly, typically in tens of thousands of lexical and contextual probabilities. In (Brill 1992), a trainable rule-based tagger was described that obtained performance comparable to that of stochastic taggers, but captured relevant linguistic information in a small number of simple non-stochastic rules. In this paper, we describe a number of extensions to this rule-based tagger. First, we describe a method for expressing lexical relations in tagging that stochastic taggers are currently unable to express. Next, we show a rule-based approach to tagging unknown words. Finally, we show how the tagger-can be extended into a k-best tagger, where multiple tags can be assigned to words in some cases of uncertainty."
            },
            "slug": "Some-Advances-in-Transformation-Based-Part-of-Brill",
            "title": {
                "fragments": [],
                "text": "Some Advances in Transformation-Based Part of Speech Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A method for expressing lexical relations in tagging that stochastic taggers are currently unable to express is described and how the tagger-can be extended into a k-best tagger, where multiple tags can be assigned to words in some cases of uncertainty."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2620384"
                        ],
                        "name": "B. Sundheim",
                        "slug": "B.-Sundheim",
                        "structuredName": {
                            "firstName": "Beth",
                            "lastName": "Sundheim",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sundheim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9946972,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "310d432ce7de84de2a54eedde18ee0423a232253",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The Fourth Message Understanding Conference (MUC-4) is the latest in a series of conferences that concern the evaluation of natural language processing (NLP) systems. These conferences have reported on progress being made both in the development of systems capable of analyzing relatively short English texts and in the definition of a rigorous performance evaluation methodology. MUC-4 was preceded by a period of intensive system development by each of the participating organizations and blind testing using materials prepared by NRaD and SAIC that are described in this paper, other papers in this volume, and the MUC-3 proceedings [1]."
            },
            "slug": "Overview-of-the-fourth-message-understanding-and-Sundheim",
            "title": {
                "fragments": [],
                "text": "Overview of the fourth message understanding evaluation and conference"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "The Fourth Message Understanding Conference (MUC-4) is the latest in a series of conferences that concern the evaluation of natural language processing (NLP) systems and reports on progress made both in the development of systems capable of analyzing relatively short English texts and in the definition of a rigorous performance evaluation methodology."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113911099"
                        ],
                        "name": "R. Rivest",
                        "slug": "R.-Rivest",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rivest",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rivest"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 207
                            }
                        ],
                        "text": "Alln instances must be repeatedly consulted while building a decision tree, whichgives a space requirement of O(an).8.5.2 GREEDY3A variant of decision trees is the decision list, introduced by Ronald Rivest[Rivest 1987]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 188
                            }
                        ],
                        "text": "Unlike Aq and CRYSTAL,which build an unordered set of concept descriptions, CN2 builds a decision4or ancestors of classes found in the instance, according to a semantic hierarchy129\nlist [Rivest 1987] of rules that are applied in order."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 5
                            }
                        ],
                        "text": "list [Rivest 1987] of rules that are applied in order."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 88
                            }
                        ],
                        "text": "2 GREEDY3 A variant of decision trees is the decision list, introduced by Ronald Rivest [Rivest 1987]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 1
                            }
                        ],
                        "text": "[Rivest 1987] Rivest, R. Learning Decision Lists."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2840541,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "2c386026b24f993aca44a7a684152778d46c51b0",
            "isKey": true,
            "numCitedBy": 472,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a new representation for Boolean functions, called decision lists, and shows that they are efficiently learnable from examples. More precisely, this result is established for k-DL the set of decision lists with conjunctive clauses of size k at each decision. Since k-DL properly includes other well-known techniques for representing Boolean functions such as k-CNF (formulae in conjunctive normal form with at most k literals per clause), k-DNF (formulae in disjunctive normal form with at most k literals per term), and decision trees of depth k, our result strictly increases the set of functions that are known to be polynomially learnable, in the sense of Valiant (1984). Our proof is constructive: we present an algorithm that can efficiently construct an element of k-DL consistent with a given set of examples, if one exists."
            },
            "slug": "Learning-decision-lists-Rivest",
            "title": {
                "fragments": [],
                "text": "Learning decision lists"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This paper introduces a new representation for Boolean functions, called decision lists, and shows that they are efficiently learnable from examples, and strictly increases the set of functions known to be polynomially learnable, in the sense of Valiant (1984)."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145262164"
                        ],
                        "name": "David Fisher",
                        "slug": "David-Fisher",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fisher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2709427"
                        ],
                        "name": "F. Feng",
                        "slug": "F.-Feng",
                        "structuredName": {
                            "firstName": "Fangfang",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925215"
                        ],
                        "name": "W. Lehnert",
                        "slug": "W.-Lehnert",
                        "structuredName": {
                            "firstName": "Wendy",
                            "lastName": "Lehnert",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lehnert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14606396,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fbda64fc89aa363ce6d4a184303e007b5251f1e5",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction research at the University of Massachusetts is based on portable, trainable language processing components. Some components are more effective than others, some have been under development longer than others, but in all cases, we are working to eliminate manual knowledge engineering. Although UMass has participated in previous MUC evaluations, all of our information extraction software has been redesigned and rewritten since MUC-5, so we are evaluating a completely new system this year."
            },
            "slug": "Description-of-the-UMass-system-as-used-for-MUC-6-Fisher-Soderland",
            "title": {
                "fragments": [],
                "text": "Description of the UMass system as used for MUC-6"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Although UMass has participated in previous MUC evaluations, all of the information extraction software has been redesigned and rewritten since MUC-5, so the system is evaluating a completely new system this year."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32980796"
                        ],
                        "name": "Sreerama K. Murthy",
                        "slug": "Sreerama-K.-Murthy",
                        "structuredName": {
                            "firstName": "Sreerama",
                            "lastName": "Murthy",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sreerama K. Murthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689332"
                        ],
                        "name": "S. Kasif",
                        "slug": "S.-Kasif",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Kasif",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kasif"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744109"
                        ],
                        "name": "S. Salzberg",
                        "slug": "S.-Salzberg",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Salzberg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Salzberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11407469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9fad1ee8b6ed596f72b81f61f01def620a4ee997",
            "isKey": false,
            "numCitedBy": 923,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes a new system for induction of oblique decision trees. This system, OC1, combines deterministic hill-climbing with two forms of randomization to find a good oblique split (in the form of a hyperplane) at each node of a decision tree. Oblique decision tree methods are tuned especially for domains in which the attributes are numeric, although they can be adapted to symbolic or mixed symbolic/numeric attributes. We present extensive empirical studies, using both real and artificial data, that analyze OC1's ability to construct oblique trees that are smaller and more accurate than their axis-parallel counterparts. We also examine the benefits of randomization for the construction of oblique decision trees."
            },
            "slug": "A-System-for-Induction-of-Oblique-Decision-Trees-Murthy-Kasif",
            "title": {
                "fragments": [],
                "text": "A System for Induction of Oblique Decision Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This system, OC1, combines deterministic hill-climbing with two forms of randomization to find a good oblique split (in the form of a hyperplane) at each node of a decision tree."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071175549"
                        ],
                        "name": "S. Vera",
                        "slug": "S.-Vera",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Vera",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vera"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 31594645,
            "fieldsOfStudy": [
                "Chemistry",
                "Materials Science"
            ],
            "id": "bc0418235ad0f5c5db9944858ce989b9b75c1c52",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "P o s i t i v e and n e g a t i v e i ns tances of a concept are assumed to be desc r i bed by a c o n j u n c t i o n o f l i t e r a l s i n the p r e d i c a t e c a l c u l u s , w i t h terms l i m i t e d t o cons tan ts and u n i v e r s a l l y q u a n t i f i e d v a r i a b l e s . A graph r e p r e s e n t a t i o n of a con junc t i o n o f l i t e r a l s , c a l l e d a \"p roduc t g r a p h \" , i s i n t r o d u c e d . I t i s d e s i r a b l e t o merge p o s i t i v e i ns tances by g e n e r a l i z a t i o n , w h i l e m a i n t a i n i n g d i s c r i m i n a t i o n aga ins t n e g a t i v e i n s t a n c e s . Th i s is accompl ished by an i n d u c t i o n procedure which opera tes on the p roduc t graph form of these posi t i v e and n e g a t i v e i n s t a n c e s . The c o r r e c t n e s s o f the procedure i s p r o v e n , t o g e t h e r w i t h seve ra l r e l a t e d r e s u l t s o f d i r e c t p r a c t i c a l s i g n i f i c a n c e . Th is work i s d i r e c t e d t o the goal o f p r o v i d i n g a fo rma l model f o r the i n d u c t i v e processes which are observed i n a r t i f i c i a l i n t e l l i g e n c e s t u d i e s i n s p e c i a l i z e d a reas . 1 . I n t r o d u c t i o n Lnduct ion may be b r o a d l y d e f i n e d as \" r e a s o n ing f rom a p a r t to a who le , f rom p a r t i c u l a r s to g e n e r a l s , o r f rom the i n d i v i d u a l t o the u n i v e r s a l \" [ 1 0 ] . C o n s i s t e n t w i t h t h i s , w e view \" i n d u c t i o n \" as a compu ta t i ona l process, and a \" g e n e r a l i z a t i o n \" as a s tatement computed by t h a t p rocess . The p resen t work is guided by the b e l i e f t h a t genera l purpose i n d u c t i o n procedures can be f o r mulated which would be independent o f the a r t i f i c i a l i n t e l l i g e n c e prob lem domain. I t i s s p e c i f i c a l l y concerned w i t h the i n d u c t i o n o f concepts from p o s i t i v e and nega t i ve i ns tances desc r i bed in the p r e d i c a t e c a l c u l u s , w i t h terms l i m i t e d t o cons t a n t s and u n i v e r s a l l y q u a n t i f i e d v a r i a b l e s . I n d u c t i v e processes i n a r t i f i c i a l i n t e l l i gence have been s t u d i e d from s e v e r a l aspec t s : v i s u a l ana log ies [ 3 ] , p r o p o s i t i o n a l l o g i c concept l e a r n i n g [ 4 , 9 ] , ana log ies i n p r e d i c a t e c a l c u l u s theorem p r o v i n g [ S ] , IQ t e s t comp le t i on problems [ 1 1 ] , t heo ry f o r m a t i o n f rom a data base [ 2 ] , v i s u a l concept l e a r n i n g f rom examples [ 1 2 ] , and i n d u c t i o n as a dual of deduc t i ve theorem p r o v i n g i n the p r e d i c a t e c a l c u l u s [ 1 , 6 , 8 ] , o r i n a gene r a l i z i t t i o n o f t he p r e d i c a t e c a l c u l u s [ 7 ] . The p resen t work may be regarded as a cont inuance of the concept l e a r n i n g research of Hunt and Tows te r , amongs o t h e r s , t o the p r e d i c a t e c a l c u l u s . I t s v i ewpo in t and many of the concepts are d e r i v e d from P l o t k i n . Throughou t , each p o s i t i v e and nega t i ve i n stance of a concept is assumed to be desc r i bed by a c o n j u n c t i o n o f l i t e r a l s i n the p r e d i c a t e c a l c u lus (no t n e c e s s a r i l y f i r s t o r d e r ) . Sec t i on 2 def i n e s t e r m i n o l o g y to be employed, o f which the most s i g n i f i c a n t i s t h e concept o f a \"max ima l , c o n s i s t e n t , u n i f y i n g g e n e r a l i z a t i o n \" , and con ta i ns some genera l o b s e r v a t i o n s on g e n e r a l i z a t i o n s . With t h i s background, a problem statement is then given in the def ined vocabulary. Section 3 i n t r o duces the \"product graph\", a graph representat ion of a conjunct ion of l i t e r a l s , which serves as a convenient medium fo r the d iscussion of the induct i o n process. This process is accomplished by s t ra igh t fo rward operat ions on these product graphs. Section 4 considers the application of product graphs to the quest ion of the \"cons is tency\" o f a genera l i za t ion in view of negat ive i n stances. Sect ion 5 contains concluding remarks. This work was p a r t i a l l y supported by DHEW Grant No. US-PHS-R01-MB-00114-01."
            },
            "slug": "Induction-of-Concepts-in-the-Predicate-Calculus-Vera",
            "title": {
                "fragments": [],
                "text": "Induction of Concepts in the Predicate Calculus"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The p resen t work is guided by the b e l i e f t h a t genera l purpose i n d u c t i o n procedures can be f o r mulated which would be independent o f the a r t i f i c i a l i n t e l l i g e n c e prob lem domain."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925215"
                        ],
                        "name": "W. Lehnert",
                        "slug": "W.-Lehnert",
                        "structuredName": {
                            "firstName": "Wendy",
                            "lastName": "Lehnert",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lehnert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2806570"
                        ],
                        "name": "M. Dyer",
                        "slug": "M.-Dyer",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Dyer",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Dyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151132692"
                        ],
                        "name": "Peter N. Johnson",
                        "slug": "Peter-N.-Johnson",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Johnson",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter N. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117954705"
                        ],
                        "name": "C. J. Yang",
                        "slug": "C.-J.-Yang",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Yang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053350917"
                        ],
                        "name": "Steve Harley",
                        "slug": "Steve-Harley",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Harley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steve Harley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40547263,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "56328e10f7e880486a809da899223fe915dc5c96",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "BORIS-An-Experiment-in-In-Depth-Understanding-of-Lehnert-Dyer",
            "title": {
                "fragments": [],
                "text": "BORIS - An Experiment in In-Depth Understanding of Narratives"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744109"
                        ],
                        "name": "S. Salzberg",
                        "slug": "S.-Salzberg",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Salzberg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Salzberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800681"
                        ],
                        "name": "Alberto Maria Segre",
                        "slug": "Alberto-Maria-Segre",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Segre",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alberto Maria Segre"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60499165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7feb0fc888cd55360949554db032d7d1cba9e947",
            "isKey": false,
            "numCitedBy": 7028,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms for constructing decision trees are among the most well known and widely used of all machine learning methods. Among decision tree algorithms, J. Ross Quinlan's ID3 and its successor, C4.5, are probably the most popular in the machine learning community. These algorithms and variations on them have been the subject of numerous research papers since Quinlan introduced ID3. Until recently, most researchers looking for an introduction to decision trees turned to Quinlan's seminal 1986 Machine Learning journal article [Quinlan, 1986]. In his new book, C4.5: Programs for Machine Learning, Quinlan has put together a definitive, much needed description of his complete system, including the latest developments. As such, this book will be a welcome addition to the library of many researchers and students."
            },
            "slug": "Programs-for-Machine-Learning-Salzberg-Segre",
            "title": {
                "fragments": [],
                "text": "Programs for Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "In his new book, C4.5: Programs for Machine Learning, Quinlan has put together a definitive, much needed description of his complete system, including the latest developments, which will be a welcome addition to the library of many researchers and students."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17162574,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "0df1aac45ff562089a3bdbcb34e2481a71478651",
            "isKey": false,
            "numCitedBy": 1775,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Generalization-as-Search-Mitchell",
            "title": {
                "fragments": [],
                "text": "Generalization as Search"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2215146"
                        ],
                        "name": "S. Vere",
                        "slug": "S.-Vere",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Vere",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vere"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 21333220,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8e70ff97d0e9f9bd4e2a13254deb79fe801e865",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multilevel-Counterfactuals-for-Generalizations-of-Vere",
            "title": {
                "fragments": [],
                "text": "Multilevel Counterfactuals for Generalizations of Relational Concepts and Productions"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341779"
                        ],
                        "name": "J. R. Quinlan",
                        "slug": "J.-R.-Quinlan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Quinlan",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Quinlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398564680"
                        ],
                        "name": "R. Cameron-Jones",
                        "slug": "R.-Cameron-Jones",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Cameron-Jones",
                            "middleNames": [
                                "Mike"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cameron-Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14126712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94f5ae846d1a83b6e79474cac1263ae0d686f46c",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "When learning classifiers, more extensive search for rules is shown to lead to lower predictive accuracy on many of the leal-world domains investigated. This counter-intuitive re suit is particularly relevant to recent system the search methods that use risk-free pruning to achieve the same outcome as exhaustive search. We propose an iterated search method that commences with greedy search extending its scope at each Iteration until a stopping criterion is satisfied. This layered search is often found to produce theories that are more accurate than those obtained with either greedy search or moderately, extensive beam search."
            },
            "slug": "Oversearching-and-Layered-Search-in-Empirical-Quinlan-Cameron-Jones",
            "title": {
                "fragments": [],
                "text": "Oversearching and Layered Search in Empirical Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes an iterated search method that commences with greedy search extending its scope at each Iteration until a stopping criterion is satisfied, and is often found to produce theories that are more accurate than those obtained with either greedy search or moderately, extensive beam search."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 71
                            }
                        ],
                        "text": "Each instances has 35 features with a total of 106 feature-value pairs [Michalski 1983]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 218
                            }
                        ],
                        "text": "I include Vere's conceptinduction algorithm and Mitchell's candidate elimination algorithm in thissection as well.8.3.1 AqRyszard Michalski and his students have published several versions of theAq covering algorithm [Michalski 1983] and the INDUCE inductive learningprogram."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 65
                            }
                        ],
                        "text": "Where CRYSTAL di ers from other cov-ering algorithms such as Aq [Michalski 1983], CN2 [Clark and Niblett 1989],and the candidate elimination algorithm [Mitchell 1978, Mitchell 1982] is inthe method used to nd generalized concept descriptions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 1
                            }
                        ],
                        "text": "[Michalski 1983] Michalski, R. S. and Chilausky, R. L. Learning by Being Toldand Learning from Examples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 259
                            }
                        ],
                        "text": "This will also be true of other machinelearning algorithms6 that operate bottom up, such as instance based learning6given an appropriate implementation 47\n[Aha et al. 1991, Cost and Salzberg 1993] and some covering algorithms thatstart from \\seed\" instances [Michalski 1983]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 71
                            }
                        ],
                        "text": "Each instances has 35 features with a total of 106 feature-valuepairs [Michalski 1983]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 62
                            }
                        ],
                        "text": "Where CRYSTAL di ers from other covering algorithms such as A [Michalski 1983], CN2 [Clark and Niblett 1989], and the candidate elimination algorithm [Mitchell 1978, Mitchell 1982] is in the method used to nd generalized concept descriptions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 92
                            }
                        ],
                        "text": "1991, Cost and Salzberg 1993] and some covering algorithms that start from \\seed\" instances [Michalski 1983]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 95
                            }
                        ],
                        "text": "Ryszard Michalski and his students have published several versions of the A covering algorithm [Michalski 1983] and the INDUCE inductive learning program."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 1
                            }
                        ],
                        "text": "[Michalski 1983] Michalski, R. S."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61536073,
            "fieldsOfStudy": [],
            "id": "dd1d8628cb1dc1b1938aa12cf32fb2d4a85948df",
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A theory and methodology of inductive learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 36
                            }
                        ],
                        "text": "The second system is PALKA [Kim and Moldovan 1992], developed by theUniversity of Southern California for their MUC-5 system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 9
                            }
                        ],
                        "text": "[Kim and Moldovan 1992] Kim, J. and Moldovan, D. PALKA: A System forLinguistic Knowledge Acquisition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 167
                            }
                        ],
                        "text": "The system presented in the next section uses a covering algorithm ap-proach that resembles CRYSTAL more closely than AutoSlog does.7.2 PALKAThe PALKA system [Kim and Moldovan 1992] was developed by Jun-TaeKim and Dan Moldovan for the University of Southern California MUC-5system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PALKA: A System"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognizing Shapes from Simple Queries about Geometry"
            },
            "venue": {
                "fragments": [],
                "text": "T echnical Report"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Case-Based Approach to Knowledge Acquisition for Domain-Speciic Sentence Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Eleventh National Conference on Artiicial Intelligence"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MUC-5 1993] Proceedings of the Fifth Message Understanding Conference"
            },
            "venue": {
                "fragments": [],
                "text": "MUC-5 1993] Proceedings of the Fifth Message Understanding Conference"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MUC-6 19955 Proceedings of the Sixth Message Understanding Conference"
            },
            "venue": {
                "fragments": [],
                "text": "MUC-6 19955 Proceedings of the Sixth Message Understanding Conference"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MUC-5 19933 Proceedings of the Fifth Message Understanding Conference"
            },
            "venue": {
                "fragments": [],
                "text": "MUC-5 19933 Proceedings of the Fifth Message Understanding Conference"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 1
                            }
                        ],
                        "text": "[Cardie 1993] Cardie, C."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 164
                            }
                        ],
                        "text": "\u2026in applying machine learning to natural language processinghas been primarily at the level of lexical or semantic disambiguation of individ-ual words [Brill 1994, Cardie 1993, Yarowsky 1992, Church 1988] and in learn-ing heuristics to guide probabilistic parsing [Charniak 1995, Magerman 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Case-Based Approach to Knowledge Acquisition for Domain-Speci c Sentence Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the Eleventh National Conference on Arti cial Intelligence,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A was named chairman. 2. (pos) Mr. C will be the new president of XYZ Inc. 3. (neg) The board of ABC Corp"
            },
            "venue": {
                "fragments": [],
                "text": "A was named chairman. 2. (pos) Mr. C will be the new president of XYZ Inc. 3. (neg) The board of ABC Corp"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pos Mr. A was named chairman"
            },
            "venue": {
                "fragments": [],
                "text": "pos Mr. A was named chairman"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MUC-4 19922 Proceedings of the Fourth Message Understanding Conference"
            },
            "venue": {
                "fragments": [],
                "text": "MUC-4 19922 Proceedings of the Fourth Message Understanding Conference"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "C will be the new president of XYZ Inc. 3. neg The board of ABC Corp"
            },
            "venue": {
                "fragments": [],
                "text": "C will be the new president of XYZ Inc. 3. neg The board of ABC Corp"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MUC-3 1991] Proceedings of the Third Message Understanding Conference"
            },
            "venue": {
                "fragments": [],
                "text": "MUC-3 1991] Proceedings of the Third Message Understanding Conference"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inducing a Conceptual Dictionary"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the Fourteenth International Joint Conference on Arti cial Intelligence,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning by Being Told and Learning from Examples"
            },
            "venue": {
                "fragments": [],
                "text": "Policy Analysis and Information Systems,"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classiication and Regression Trees"
            },
            "venue": {
                "fragments": [],
                "text": "Classiication and Regression Trees"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MUC-3 19911 Proceedings of the Third Message Understanding Conference"
            },
            "venue": {
                "fragments": [],
                "text": "MUC-3 19911 Proceedings of the Third Message Understanding Conference"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the Fourth Message Understanding Conference"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth Message Understanding Conference"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An Experiment in In-Depth Understanding of Narratives . Artiicial Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "An Experiment in In-Depth Understanding of Narratives . Artiicial Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "CRYSTAL: Inducing a Conceptual Dictionary. I n Proceedings of the Fourteenth International Joint Conference o n A rtiicial Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "CRYSTAL: Inducing a Conceptual Dictionary. I n Proceedings of the Fourteenth International Joint Conference o n A rtiicial Intelligence"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Case-Based Approach to Knowledge Acquisition for Domain-Speciic Sentence Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Eleventh National Conference o n A rtiicial Intelligence"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning by Being Told and Learning from Examples"
            },
            "venue": {
                "fragments": [],
                "text": "Policy Analysis and Information Systems"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning by Being Told"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PALKA: A System for Linguistic Knowledge Acquisition"
            },
            "venue": {
                "fragments": [],
                "text": "PALKA: A System for Linguistic Knowledge Acquisition"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning by Being Told and Learning from Examples"
            },
            "venue": {
                "fragments": [],
                "text": "Policy Analysis and Information Systems"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PALKA: A System for Linguistic Knowledge Acquisition"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report PKPL 928, USC Department of Electrical Engineering Systems,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MUC-6 1995] Proceedings of the Sixth Message Understanding Conference"
            },
            "venue": {
                "fragments": [],
                "text": "MUC-6 1995] Proceedings of the Sixth Message Understanding Conference"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Uniied Medical Language Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Methods of Information in Medicine"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The CN2 Induction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 4,
            "methodology": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 56,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-text-analysis-rules-for-domain-specific-Soderland/ca198cc81878fd036c7b97ee10441f1d09839f65?sort=total-citations"
}