{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5437238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a54657b8de38a18f30fd154d713f9522f705166c",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis is a study of the computational complexity of machine learning from examples in the distribution-free model introduced by L. G. Valiant (V84). In the distribution-free model, a learning algorithm receives positive and negative examples of an unknown target set (or concept) that is chosen from some known class of sets (or concept class). These examples are generated randomly according to a fixed but unknown probability distribution representing Nature, and the goal of the learning algorithm is to infer an hypothesis concept that closely approximates the target concept with respect to the unknown distribution. This thesis is concerned with proving theorems about learning in this formal mathematical model. \nWe are interested in the phenomenon of efficient learning in the distribution-free model, in the standard polynomial-time sense. Our results include general tools for determining the polynomial-time learnability of a concept class, an extensive study of efficient learning when errors are present in the examples, and lower bounds on the number of examples required for learning in our model. A centerpiece of the thesis is a series of results demonstrating the computational difficulty of learning a number of well-studied concept classes. These results are obtained by reducing some apparently hard number-theoretic problems from cryptography to the learning problems. The hard-to-learn concept classes include the sets represented by Boolean formulae, deterministic finite automata and a simplified form of neural networks. We also give algorithms for learning powerful concept classes under the uniform distribution, and give equivalences between natural models of efficient learnability. \nThis thesis also includes detailed definitions and motivation for the distribution-free model, a chapter discussing past research in this model and related models, and a short list of important open problems."
            },
            "slug": "Computational-complexity-of-machine-learning-Kearns",
            "title": {
                "fragments": [],
                "text": "Computational complexity of machine learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A centerpiece of the thesis is a series of results demonstrating the computational difficulty of learning a number of well-studied concept classes by reducing some apparently hard number-theoretic problems from cryptography to the learning problems."
            },
            "venue": {
                "fragments": [],
                "text": "ACM distinguished dissertations"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722243"
                        ],
                        "name": "N. Linial",
                        "slug": "N.-Linial",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Linial",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Linial"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144830983"
                        ],
                        "name": "Y. Mansour",
                        "slug": "Y.-Mansour",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Mansour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Mansour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113911099"
                        ],
                        "name": "R. Rivest",
                        "slug": "R.-Rivest",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rivest",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rivest"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12405514,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "907f58a77ef4909d0e96c352cd5c7379eb22d5f5",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of learning a concept from examples in a distribution-free model is considered. The notion of dynamic sampling, wherein the number of examples examined can increase with the complexity of the target concept, is introduced. This method is used to establish the learnability of various concept classes with an infinite Vapnik-Chervonenkis (VC) dimension. An important variation on the problem of learning from examples, called approximating from examples, is also discussed. The problem of computing the VC dimension of a finite concept set defined on a finite domain is considered.<<ETX>>"
            },
            "slug": "Results-on-learnability-and-the-Vapnik-Chervonenkis-Linial-Mansour",
            "title": {
                "fragments": [],
                "text": "Results on learnability and the Vapnik-Chervonenkis dimension"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The notion of dynamic sampling, wherein the number of examples examined can increase with the complexity of the target concept, is introduced and is used to establish the learnability of various concept classes with an infinite Vapnik-Chervonenkis (VC) dimension."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings 1988] 29th Annual Symposium on Foundations of Computer Science"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9676287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7fa656920ccefcca717ea222a554dbd3ae37d924",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors consider the problem of predicting (0, 1)-valued functions on R/sup n/ and smaller domains, based on their values on randomly drawn points. Their model is related to L.G. Valiant's learnability model (1984), but does not require the hypotheses used for prediction to be represented in any specified form. The authors first disregard computational complexity and show how to construct prediction strategies that are optimal to within a constant factor for any reasonable class F of target functions. These prediction strategies use the 1-inclusion graph structure from N. Alon et al.'s work on geometric range queries (1987) to minimize the probability of incorrect prediction. They then turn to computationally efficient algorithms. For indicator functions of axis-parallel rectangles and halfspaces in R/sup n/, they demonstrate how their techniques can be applied to construct computational efficient prediction strategies that are optimal to within a constant factor. They compare the general performance of prediction strategies derived by their method to those derived from existing methods in Valiant's learnability theory.<<ETX>>"
            },
            "slug": "Predicting-(0,-1)-functions-on-randomly-drawn-Haussler-Littlestone",
            "title": {
                "fragments": [],
                "text": "Predicting (0, 1)-functions on randomly drawn points"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The authors consider the problem of predicting (0, 1)-valued functions on R/sup n/ and smaller domains, based on their values on randomly drawn points, and construct prediction strategies that are optimal to within a constant factor for any reasonable class F of target functions."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings 1988] 29th Annual Symposium on Foundations of Computer Science"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 5119145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5609ee7a8c7432c0f502b2a6dcfe9c0039206ab",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We consider the problem of predicting {0, 1}-valued functions on Rn and smaller domains, based on their values on randomly drawn points. Our model is related to Valiant\u2032s PAC learning model, but does not require the hypotheses used for prediction to be represented in any specified form. In our main result we show how to construct prediction strategies that are optimal to within a constant factor for any reasonable class F of target functions. This result is based on new combinatorial results about classes of functions of finite VC dimension. We also discuss more computationally efficient algorithms for predicting indicator functions of axis-parallel rectangles, more general intersection closed concept classes, and halfspaces in Rn. These are also optimal to within a constant factor. Finally, we compare the general performance of prediction strategies derived by our method to that of those derived from methods in PAC learning theory."
            },
            "slug": "Predicting-{0,1}-functions-on-randomly-drawn-points-Haussler-Littlestone",
            "title": {
                "fragments": [],
                "text": "Predicting {0,1}-functions on randomly drawn points"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This model is related to Valiant\u2032s PAC learning model, but does not require the hypotheses used for prediction to be represented in any specified form and shows how to construct prediction strategies that are optimal to within a constant factor for any reasonable class F of target functions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150652510"
                        ],
                        "name": "Ming Li",
                        "slug": "Ming-Li",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47494927"
                        ],
                        "name": "L. Pitt",
                        "slug": "L.-Pitt",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Pitt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pitt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1053873,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3948494b79dcda6d53237397123efdbb7a9954b2",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the computational feasibility of learning boolean expressions from examples. Our goals are to prove results and develop general techniques that shed light on the boundary between the classes of expressions that are learnable in polynomial time and those that are apparently not. The elucidation of this boundary, for boolean expressions and possibly other knowledge representations, is an example of the potential contribution of complexity theory to artificial intelligence. We employ the distribution-free model of learning introduced in /lo]. A more complete discussion and justification of this model can be found in [4,10,11,12]. [4] includes some discussion that is relevant more particularly to infinite representations, such as geometric ones, rather than the finite case of boolean functions. For other recent related work see [1,2,7,&g]. The results of this paper fall into three categories: closure properties of learnable classes, negative results, and distribution-specific positive results. The closure properties are of two kinds. In section 3 we discuss closure under boolean operations on the members of the learnable classes. The assumption that the classes are learnable from positive or negative ex-"
            },
            "slug": "On-the-learnability-of-Boolean-formulae-Kearns-Li",
            "title": {
                "fragments": [],
                "text": "On the learnability of Boolean formulae"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The goals are to prove results and develop general techniques that shed light on the boundary between the classes of expressions that are learnable in polynomial time and those that are apparently not, and to employ the distribution-free model of learning."
            },
            "venue": {
                "fragments": [],
                "text": "STOC"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2647026"
                        ],
                        "name": "A. Blumer",
                        "slug": "A.-Blumer",
                        "structuredName": {
                            "firstName": "Anselm",
                            "lastName": "Blumer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blumer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683946"
                        ],
                        "name": "A. Ehrenfeucht",
                        "slug": "A.-Ehrenfeucht",
                        "structuredName": {
                            "firstName": "Andrzej",
                            "lastName": "Ehrenfeucht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ehrenfeucht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5225434,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29b6251c84def0cbd35397c71fada0d22cd9409c",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend Valiant's learnability model to learning classes of concepts defined by regions in Euclidean space E\". Our methods lead to a unified treatment of some of Valiant's results, along with previous results of Pearl and Devroye and Wagner on distribution-free convergence of certain pattern recognition algorithms. We show that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned. Using this parameter, we analyze the complexity and closure properties of learnable classes. Authors A. Blumer and D. Haussler gratefully acknowledge the support of NSF grant IST-8317918, author A. Ehrenfeucht the support of NSF grant MCS-8305245, and author M. Warmuth the support of the Faculty Research Committee of the University of California at Santa Cruz. Part of this work was done while A. Blumer was visiting the University of California at Santa Cruz and M. Warmuth the Univer-"
            },
            "slug": "Classifying-learnable-geometric-concepts-with-the-Blumer-Ehrenfeucht",
            "title": {
                "fragments": [],
                "text": "Classifying learnable geometric concepts with the Vapnik-Chervonenkis dimension"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '86"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2270210"
                        ],
                        "name": "R. S. Wenocur",
                        "slug": "R.-S.-Wenocur",
                        "structuredName": {
                            "firstName": "Roberta",
                            "lastName": "Wenocur",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. S. Wenocur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881615"
                        ],
                        "name": "R. Dudley",
                        "slug": "R.-Dudley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dudley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dudley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 204985985,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5e6dfb46ed298ff037e166291c128a465f90bfc0",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Some-special-vapnik-chervonenkis-classes-Wenocur-Dudley",
            "title": {
                "fragments": [],
                "text": "Some special vapnik-chervonenkis classes"
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Math."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6334230,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1dace286582d91916fe470d08f30381cf453f20",
            "isKey": false,
            "numCitedBy": 1612,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Valiant (1984) and others have studied the problem of learning various classes of Boolean functions from examples. Here we discuss incremental learning of these functions. We consider a setting in which the learner responds to each example according to a current hypothesis. Then the learner updates the hypothesis, if necessary, based on the correct classification of the example. One natural measure of the quality of learning in this setting is the number of mistakes the learner makes. For suitable classes of functions, learning algorithms are available that make a bounded number of mistakes, with the bound independent of the number of examples seen by the learner. We present one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions. The basic method can be expressed as a linear-threshold algorithm. A primary advantage of this algorithm is that the number of mistakes grows only logarithmically with the number of irrelevant attributes in the examples. At the same time, the algorithm is computationally efficient in both time and space."
            },
            "slug": "Learning-Quickly-When-Irrelevant-Attributes-Abound:-Littlestone",
            "title": {
                "fragments": [],
                "text": "Learning Quickly When Irrelevant Attributes Abound: A New Linear-Threshold Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions."
            },
            "venue": {
                "fragments": [],
                "text": "28th Annual Symposium on Foundations of Computer Science (sfcs 1987)"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2403454"
                        ],
                        "name": "E. Baum",
                        "slug": "E.-Baum",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Baum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15659829,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "25406e6733a698bfc4ac836f8e74f458e75dad4f",
            "isKey": false,
            "numCitedBy": 1696,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the question of when a network can be expected to generalize from m random training examples chosen from some arbitrary probability distribution, assuming that future test examples are drawn from the same distribution. Among our results are the following bounds on appropriate sample vs. network size. Assume 0 < \u220a 1/8. We show that if m O(W/\u220a log N/\u220a) random examples can be loaded on a feedforward network of linear threshold functions with N nodes and W weights, so that at least a fraction 1 \u220a/2 of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify a fraction 1 \u220a of future test examples drawn from the same distribution. Conversely, for fully-connected feedforward nets with one hidden layer, any learning algorithm using fewer than (W/\u220a) random training examples will, for some distributions of examples consistent with an appropriate weight choice, fail at least some fixed fraction of the time to find a weight choice that will correctly classify more than a 1 \u220a fraction of the future test examples."
            },
            "slug": "What-Size-Net-Gives-Valid-Generalization-Baum-Haussler",
            "title": {
                "fragments": [],
                "text": "What Size Net Gives Valid Generalization?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that if m O(W/ \u220a log N/\u220a) random examples can be loaded on a feedforward network of linear threshold functions with N nodes and W weights, so that at least a fraction 1 \u220a/2 of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify a fraction 2 \u220a of future test examples drawn from the same distribution."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2647026"
                        ],
                        "name": "A. Blumer",
                        "slug": "A.-Blumer",
                        "structuredName": {
                            "firstName": "Anselm",
                            "lastName": "Blumer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blumer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683946"
                        ],
                        "name": "A. Ehrenfeucht",
                        "slug": "A.-Ehrenfeucht",
                        "structuredName": {
                            "firstName": "Andrzej",
                            "lastName": "Ehrenfeucht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ehrenfeucht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1138467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0b8fa3496283d4d808fba9ff62d5f024bcf23be",
            "isKey": false,
            "numCitedBy": 1909,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Valiant's learnability model is extended to learning classes of concepts defined by regions in Euclidean space En. The methods in this paper lead to a unified treatment of some of Valiant's results, along with previous results on distribution-free convergence of certain pattern recognition algorithms. It is shown that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned. Using this parameter, the complexity and closure properties of learnable classes are analyzed, and the necessary and sufficient conditions are provided for feasible learnability."
            },
            "slug": "Learnability-and-the-Vapnik-Chervonenkis-dimension-Blumer-Ehrenfeucht",
            "title": {
                "fragments": [],
                "text": "Learnability and the Vapnik-Chervonenkis dimension"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725956"
                        ],
                        "name": "J. Vitter",
                        "slug": "J.-Vitter",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Vitter",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vitter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710610"
                        ],
                        "name": "Jyh-Han Lin",
                        "slug": "Jyh-Han-Lin",
                        "structuredName": {
                            "firstName": "Jyh-Han",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jyh-Han Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1912267,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bfb5c94f70187d1a1fd7a28b2c7d3100fbc8170",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-in-parallel-Vitter-Lin",
            "title": {
                "fragments": [],
                "text": "Learning in parallel"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47494927"
                        ],
                        "name": "L. Pitt",
                        "slug": "L.-Pitt",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Pitt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pitt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18940285,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93849122caf1b10c9611eddb707e0720441c73f6",
            "isKey": false,
            "numCitedBy": 541,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The computational complexity of learning Boolean concepts from examples is investigated. It is shown for various classes of concept representations that these cannot be learned feasibly in a distribution-free sense unless R = NP. These classes include (a) disjunctions of two monomials, (b) Boolean threshold functions, and (c) Boolean formulas in which each variable occurs at most once. Relationships between learning of heuristics and finding approximate solutions to NP-hard optimization problems are given."
            },
            "slug": "Computational-limitations-on-learning-from-examples-Pitt-Valiant",
            "title": {
                "fragments": [],
                "text": "Computational limitations on learning from examples"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "It is shown for various classes of concept representations that these cannot be learned feasibly in a distribution-free sense unless R = NP, and relationships between learning of heuristics and finding approximate solutions to NP-hard optimization problems are given."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378746"
                        ],
                        "name": "N. Karmarkar",
                        "slug": "N.-Karmarkar",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Karmarkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Karmarkar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7257867,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "dbf8aa1e547c863f509a5a4c03a39fa9c92c9651",
            "isKey": false,
            "numCitedBy": 4006,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new polynomial-time algorithm for linear programming. In the worst case, the algorithm requiresO(n3.5L) arithmetic operations onO(L) bit numbers, wheren is the number of variables andL is the number of bits in the input. The running-time of this algorithm is better than the ellipsoid algorithm by a factor ofO(n2.5). We prove that given a polytopeP and a strictly interior point a \u03b5P, there is a projective transformation of the space that mapsP, a toP\u2032, a\u2032 having the following property. The ratio of the radius of the smallest sphere with center a\u2032, containingP\u2032 to the radius of the largest sphere with center a\u2032 contained inP\u2032 isO(n). The algorithm consists of repeated application of such projective transformations each followed by optimization over an inscribed sphere to create a sequence of points which converges to the optimal solution in polynomial time."
            },
            "slug": "A-new-polynomial-time-algorithm-for-linear-Karmarkar",
            "title": {
                "fragments": [],
                "text": "A new polynomial-time algorithm for linear programming"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is proved that given a polytopeP and a strictly interior point a \u03b5P, there is a projective transformation of the space that mapsP, a toP\u2032, a\u2032 having the following property: the ratio of the radius of the smallest sphere with center a\u2032, containingP\u2032 to theradius of the largest sphere withCenter a\u2032 contained inP\u2032 isO(n)."
            },
            "venue": {
                "fragments": [],
                "text": "Comb."
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911738"
                        ],
                        "name": "D. Angluin",
                        "slug": "D.-Angluin",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Angluin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Angluin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 1279641,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2bab38d12c4ee82319cc89d16bca21b301a7138",
            "isKey": false,
            "numCitedBy": 666,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The main purpose of this paper is to give techniques for analysing the probabilistic performance of certain kinds of algorithms, and hence to suggest some fast algorithms with provably desirable probabilistic behaviour. The particular problems we consider are: finding Hamiltonian circuits in directed graphs (DHC), finding Hamiltonian circuits in undirected graphs (UHC), and finding perfect matchings in undirected graphs (PM). We show that for each problem there is an algorithm that is extremely fast (0(n(log n)2) for DHC and UHC, and 0(nlog n) for PM), and which with probability tending to one finds a solution in randomly chosen graphs of sufficient density. These results contrast with the known NP-completeness of the first two problems [2,12] and the best worst-case upper bound known of 0(n2.5) for the last [9]."
            },
            "slug": "Fast-probabilistic-algorithms-for-hamiltonian-and-Angluin-Valiant",
            "title": {
                "fragments": [],
                "text": "Fast Probabilistic Algorithms for Hamiltonian Circuits and Matchings"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that for each problem there is an algorithm that is extremely fast, and which with probability tending to one finds a solution in randomly chosen graphs of sufficient density, and the results contrast with the known NP-completeness of the first two problems."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 27204621,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b814ad3055d6bfd7828effdbfbf1372646b7c22",
            "isKey": false,
            "numCitedBy": 551,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Quantifying-Inductive-Bias:-AI-Learning-Algorithms-Haussler",
            "title": {
                "fragments": [],
                "text": "Quantifying Inductive Bias: AI Learning Algorithms and Valiant's Learning Framework"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10ddb646feddc12337b5a755c72e153e37088c02",
            "isKey": false,
            "numCitedBy": 4191,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans appear to be able to learn new concepts without needing to be programmed explicitly in any conventional sense. In this paper we regard learning as the phenomenon of knowledge acquisition in the absence of explicit programming. We give a precise methodology for studying this phenomenon from a computational viewpoint. It consists of choosing an appropriate information gathering mechanism, the learning protocol, and exploring the class of concepts that can be learnt using it in a reasonable (polynomial) number of steps. We find that inherent algorithmic complexity appears to set serious limits to the range of concepts that can be so learnt. The methodology and results suggest concrete principles for designing realistic learning systems."
            },
            "slug": "A-theory-of-the-learnable-Valiant",
            "title": {
                "fragments": [],
                "text": "A theory of the learnable"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper regards learning as the phenomenon of knowledge acquisition in the absence of explicit programming, and gives a precise methodology for studying this phenomenon from a computational viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '84"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150652510"
                        ],
                        "name": "Ming Li",
                        "slug": "Ming-Li",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1507349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25875a29eded2acdad72cf897df11c2df2d92ec1",
            "isKey": false,
            "numCitedBy": 396,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper an extension of the distribution-free model of learning introduced by Valiant [Comm. ACM, 27(1984), pp. 1134\u20131142] that allows the presence of malicious errors in the examples given to a learning algorithm is studied. Such errors are generated by an adversary with unbounded computational power and access to the entire history of the learning algorithm\u2019s computation. Thus, a worst-case model of errors is studied.The results of this research include general methods for bounding the rate of error tolerable by any learning algorithm, efficient algorithms tolerating nontrivial rates of malicious errors, and equivalences between problems of learning with errors and standard combinatorial optimization problems."
            },
            "slug": "Learning-in-the-presence-of-malicious-errors-Kearns-Li",
            "title": {
                "fragments": [],
                "text": "Learning in the presence of malicious errors"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "General methods for bounding the rate of error tolerable by any learning algorithm, efficient algorithms tolerating nontrivial rates of malicious errors, and equivalences between problems of learning with errors and standard combinatorial optimization problems are studied."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39419622"
                        ],
                        "name": "B. Natarajan",
                        "slug": "B.-Natarajan",
                        "structuredName": {
                            "firstName": "Balas",
                            "lastName": "Natarajan",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Natarajan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13998435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cad8e85d332dd635dcdb78e2a1aef9c3c3e58f5",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper deals with the learnability of Boolean functions. An intuitively appealing notion of dimensionality is developed and used to identify the most general class of Boolean function families that are learnable from polynomially many positive examples with one-sided error. It is then argued that although bounded DNF expressions lie outside this class, they must have efficient learning algorithms as they are well suited for expressing many human concepts. A framework that permits efficient learning of bounded DNF functions is identified."
            },
            "slug": "On-learning-Boolean-functions-Natarajan",
            "title": {
                "fragments": [],
                "text": "On learning Boolean functions"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "An intuitively appealing notion of dimensionality is developed and used to identify the most general class of Boolean function families that are learnable from polynomially many positive examples with one-sided error."
            },
            "venue": {
                "fragments": [],
                "text": "STOC"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717081"
                        ],
                        "name": "E. Welzl",
                        "slug": "E.-Welzl",
                        "structuredName": {
                            "firstName": "Emo",
                            "lastName": "Welzl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Welzl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8530681,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f52e66066c129bb87f6a4f12f1c17fd4a2b440b3",
            "isKey": false,
            "numCitedBy": 434,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new technique for half-space and simplex range query using <italic>&Ogr;</italic>(<italic>n</italic>) space and <italic>&Ogr;</italic>(<italic>n</italic><supscrpt><italic>a</italic></supscrpt>) query time, where <italic>a</italic> < <italic>d</italic>(d-1)/<italic>d</italic>(<italic>d</italic>-1) + 1 + \u03b3 for all dimensions <italic>d</italic> \u2265 2 and <italic>\u03b3</italic> > 0. These bounds are better than those previously published for all <italic>d</italic> \u2265 2. The technique uses random sampling to build a partition-tree structure. We introduce the concept of an <italic>\u03b5</italic>-net for an abstract set of ranges to describe the desired result of this random sampling and give necessary and sufficient conditions that a random sample is an <italic>\u03b5</italic>-net with high probability. We illustrate the application of these ideas to other range query problems."
            },
            "slug": "Epsilon-nets-and-simplex-range-queries-Haussler-Welzl",
            "title": {
                "fragments": [],
                "text": "Epsilon-nets and simplex range queries"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A new technique for half-space and simplex range query using random sampling to build a partition-tree structure and introduces the concept of an\u03b5-net for an abstract set of ranges to describe the desired result of this random sampling."
            },
            "venue": {
                "fragments": [],
                "text": "SCG '86"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717081"
                        ],
                        "name": "E. Welzl",
                        "slug": "E.-Welzl",
                        "structuredName": {
                            "firstName": "Emo",
                            "lastName": "Welzl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Welzl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 27638326,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dbdfc10b6af746580bd48f2f3757e9060326e5ab",
            "isKey": false,
            "numCitedBy": 674,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "AbstractWe demonstrate the existence of data structures for half-space and simplex range queries on finite point sets ind-dimensional space,d\u22652, with linear storage andO(n\u03b1) query time,\n% MathType!MTEF!2!1!+-% feaafiart1ev1aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn% hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr% 4rNCHbGeaGqiVC0xe9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Gqpi0x% c9q8qqaqFj0df9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x% fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGcbaGaeqySdeMaey% ypa0ZaaSaaaeaacaWGKbGaaiikaiaadsgacqGHsislcaaIXaGaaiyk% aaqaaiaadsgacaGGOaGaamizaiabgkHiTiaaigdacaGGPaGaey4kaS% IaaGymaaaacqGHRaWkcqaHZoWzieaacaWFGaGaa8hiaiaa-bcacaWF% GaGaa8hiaiaa-bcacaWFGaGaa8Nzaiaa-9gacaWFYbGaa8hiaiaa-f% gacaWFSbGaa8hBaiaa-bcacaWFGaGaa8hiaiabeo7aNjaa-5dacaWF% Waaaaa!574F!\n\n$$\\alpha = \\frac{{d(d - 1)}}{{d(d - 1) + 1}} + \\gamma for all \\gamma > 0$$\n.These bounds are better than those previously published for alld\u22652. Based on ideas due to Vapnik and Chervonenkis, we introduce the concept of an \u025b-net of a set of points for an abstract set of ranges and give sufficient conditions that a random sample is an \u025b-net with any desired probability. Using these results, we demonstrate how random samples can be used to build a partition-tree structure that achieves the above query time."
            },
            "slug": "\u025b-nets-and-simplex-range-queries-Haussler-Welzl",
            "title": {
                "fragments": [],
                "text": "\u025b-nets and simplex range queries"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The concept of an \u025b-net of a set of points for an abstract set of ranges is introduced and sufficient conditions that a random sample is an \u00c3\u201a-net with any desired probability are given."
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Comput. Geom."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8142232,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a36b028d024bf358c4af1a5e1dc3ca0aed23b553",
            "isKey": false,
            "numCitedBy": 3710,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter reproduces the English translation by B. Seckler of the paper by Vapnik and Chervonenkis in which they gave proofs for the innovative results they had obtained in a draft form in July 1966 and announced in 1968 in their note in Soviet Mathematics Doklady. The paper was first published in Russian as \u0412\u0430\u043f\u043d\u0438\u043a \u0412. \u041d. and \u0427\u0435\u0440\u0432\u043e\u043d\u0435\u043d\u043a\u0438\u0441 \u0410. \u042f. \u041e \u0440\u0430\u0432\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0419 \u0441\u0445\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438 \u0447\u0430\u0441\u0442\u043e\u0442 \u043f\u043e\u044f\u0432\u043b\u0435\u043d\u0438\u044f \u0441\u043e\u0431\u044b\u0442\u0438\u0419 \u043a \u0438\u0445 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044f\u043c. \u0422\u0435\u043e\u0440\u0438\u044f \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0435\u0419 \u0438 \u0435\u0435 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u044f 16(2), 264\u2013279 (1971)."
            },
            "slug": "Chervonenkis:-On-the-uniform-convergence-of-of-to-Vapnik",
            "title": {
                "fragments": [],
                "text": "Chervonenkis: On the uniform convergence of relative frequencies of events to their probabilities"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter reproduces the English translation by B. Seckler of the paper by Vapnik and Chervonenkis in which they gave proofs for the innovative results they had obtained in a draft form in July 1966 and announced in 1968 in their note in Soviet Mathematics Doklady."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911738"
                        ],
                        "name": "D. Angluin",
                        "slug": "D.-Angluin",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Angluin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Angluin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 122024170,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "791414dcd59b84ba3fe60db09d80f5cae9059978",
            "isKey": false,
            "numCitedBy": 540,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of using queries to learn an unknown concept. Several types of queries are described and studied: membership, equivalence, subset, superset, disjointness, and exhaustiveness queries. Examples are given of efficient learning methods using various subsets of these queries for formal domains, including the regular languages, restricted classes of context-free languages, the pattern languages, and restricted types of prepositional formulas. Some general lower bound techniques are given. Equivalence queries are compared with Valiant's criterion of probably approximately correct identification under random sampling."
            },
            "slug": "Queries-and-Concept-Learning-Angluin",
            "title": {
                "fragments": [],
                "text": "Queries and Concept Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This work considers the problem of using queries to learn an unknown concept, and several types of queries are described and studied: membership, equivalence, subset, superset, disjointness, and exhaustiveness queries."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2706323"
                        ],
                        "name": "H. Chernoff",
                        "slug": "H.-Chernoff",
                        "structuredName": {
                            "firstName": "Herman",
                            "lastName": "Chernoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Chernoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122118814,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "bc22d1610ce680c91b4323a1899b1f22cfdf533f",
            "isKey": false,
            "numCitedBy": 3429,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Measure-of-Asymptotic-Efficiency-for-Tests-of-a-Chernoff",
            "title": {
                "fragments": [],
                "text": "A Measure of Asymptotic Efficiency for Tests of a Hypothesis Based on the sum of Observations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1952
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103033816"
                        ],
                        "name": "L. G. H. Cijan",
                        "slug": "L.-G.-H.-Cijan",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Cijan",
                            "middleNames": [
                                "G.",
                                "Ha"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. G. H. Cijan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118963004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a997e2e9f8a66b932993ca39d903737fa00393a",
            "isKey": false,
            "numCitedBy": 1449,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-polynomial-algorithm-in-linear-programming-Cijan",
            "title": {
                "fragments": [],
                "text": "A polynomial algorithm in linear programming"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109503620"
                        ],
                        "name": "Temple F. Smith",
                        "slug": "Temple-F.-Smith",
                        "structuredName": {
                            "firstName": "Temple",
                            "lastName": "Smith",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Temple F. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 4276691,
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "id": "0b4d43ef0051a225e07af8194e81007ebba8d787",
            "isKey": false,
            "numCitedBy": 705,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Occam's-razor-Smith",
            "title": {
                "fragments": [],
                "text": "Occam's razor"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720169"
                        ],
                        "name": "H. Schweitzer",
                        "slug": "H.-Schweitzer",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Schweitzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schweitzer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5851069,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "be643b663ddaf9ec5fd494008dc6ae7dc170ed89",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Non-Learnable-Classes-of-Boolean-Formulae-That-Are-Schweitzer",
            "title": {
                "fragments": [],
                "text": "Non-Learnable Classes of Boolean Formulae That Are Closer Under Variable Permutation"
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821511"
                        ],
                        "name": "Gyora M. Benedek",
                        "slug": "Gyora-M.-Benedek",
                        "structuredName": {
                            "firstName": "Gyora",
                            "lastName": "Benedek",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gyora M. Benedek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736744"
                        ],
                        "name": "A. Itai",
                        "slug": "A.-Itai",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Itai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Itai"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5260687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c23ed6b3bf16778c9f2a6a5b6b0b629e9b1b0af1",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learnability-by-fixed-distributions-Benedek-Itai",
            "title": {
                "fragments": [],
                "text": "Learnability by fixed distributions"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113911099"
                        ],
                        "name": "R. Rivest",
                        "slug": "R.-Rivest",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rivest",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rivest"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2840541,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "2c386026b24f993aca44a7a684152778d46c51b0",
            "isKey": false,
            "numCitedBy": 472,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a new representation for Boolean functions, called decision lists, and shows that they are efficiently learnable from examples. More precisely, this result is established for k-DL the set of decision lists with conjunctive clauses of size k at each decision. Since k-DL properly includes other well-known techniques for representing Boolean functions such as k-CNF (formulae in conjunctive normal form with at most k literals per clause), k-DNF (formulae in disjunctive normal form with at most k literals per term), and decision trees of depth k, our result strictly increases the set of functions that are known to be polynomially learnable, in the sense of Valiant (1984). Our proof is constructive: we present an algorithm that can efficiently construct an element of k-DL consistent with a given set of examples, if one exists."
            },
            "slug": "Learning-decision-lists-Rivest",
            "title": {
                "fragments": [],
                "text": "Learning decision lists"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This paper introduces a new representation for Boolean functions, called decision lists, and shows that they are efficiently learnable from examples, and strictly increases the set of functions known to be polynomially learnable, in the sense of Valiant (1984)."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 536357,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "05e0d765b024b743520971c5a25569d92c204ad7",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we consider the problem of learning from examples classes of functions when there are no restrictions on the allowed hypotheses other than that they are polynomial time evaluatable. We prove that for Boolean formulae, finite automata, and constant depth threshold circuits (simplified neural nets), this problem is computationally as difficult as the quadratic residue problem, inverting the RSA function and factoring Blum integers (composite number p q where p and q are both primes congruent to 3 modulo 4). These results are for the distributionfree model of learning [31]. They hold even when the inference task is that of deriving a probabilistic polynomial-time classification algorithm that predicts the correct value of a random input with probability $ + &, where s is the size of the formula, automaton or circuit, and p is any polynomial. (We call this model weak learning). Previously the only nonlearnability results that were similarly independent of hypothesis representation were those implied by the work of Goldreich, Goldwasser and Micali [17], for such classes as unrestricted Boolean circuits [25,31]. In addition to the particular results stated above we can abstract from our method a general technique for proving nonlearnability based on the existence of trapdoor functions in the sense of Yao [34]."
            },
            "slug": "Crytographic-limitations-on-learning-Boolean-and-Kearns-Valiant",
            "title": {
                "fragments": [],
                "text": "Crytographic limitations on learning Boolean formulae and finite automata"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is proved that for Boolean formulae, finite automata, and constant depth threshold circuits (simplified neural nets), this problem is computationally as difficult as the quadratic residue problem, inverting the RSA function and factoring Blum integers."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '89"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Identifying kCNF formulas from noisy examples"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Boolean formulae or nite automata is as hard as factoring"
            },
            "venue": {
                "fragments": [],
                "text": "Learning Boolean formulae or nite automata is as hard as factoring"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learnability b y xed distributions"
            },
            "venue": {
                "fragments": [],
                "text": "First Workshop on Computational Learning Theory, M.I.T"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Furthermore, by the above proof the image decision lists are linearly separable in pn-dimensional space, so VCdimkDL = Opn = On k . Similar transformation techniques can be found in KLPV877 and L888"
            },
            "venue": {
                "fragments": [],
                "text": "Ly"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning disjunctions of conjunctions"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 9th IJCAI"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Quantifying Inductive Bias: AI Learning Algorithms and Valiant's Model"
            },
            "venue": {
                "fragments": [],
                "text": "Artiicial Intelligence"
            },
            "year": 1988
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 35,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/A-general-lower-bound-on-the-number-of-examples-for-Ehrenfeucht-Haussler/b83396caf4762c906530c9219a9e4dd0658232b0?sort=total-citations"
}