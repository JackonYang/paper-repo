{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144987107"
                        ],
                        "name": "Jamie Callan",
                        "slug": "Jamie-Callan",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Callan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jamie Callan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2533154"
                        ],
                        "name": "J. Broglio",
                        "slug": "J.-Broglio",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Broglio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Broglio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 119
                            }
                        ],
                        "text": "Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6573717,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aca07a7288c4eaaf37eb71e9d44e4ac9366ed3a1",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The ARPA TIPSTER project which is the source of the data and funding for TREC, has involved four sites in the area of text retrieval and routing. The TIPSTER project in the information Retrieval of the Computer Science Department, University of Massachussetts, Amherst (which includes MCC as a subcontractor), has focused on the following goals: improving the effectiveness of information retrieval techniques for large, full-text databases; 2: improving the effectiveness of routing techiques appropriate for long-term information needs; 3- Demonstrating the effectiveness of these retrieval and routinq techniques for Japanese full text database. Our general approach to achieve these goals has been to use improved representations of text and information needs in the framework of a new model of retrieval. This model uses Bayesian netwoks to describe how text and queries should be uses to identify relevant document. Retrieval (and routing) is viewed as a probabilistic inference process whic compares text representations based on different forms of linguistic and statistical evidence to representations of information needs. Learnin techniques are uses to modify the initial query both for short-terme and long-term information needs (relevance feedback and routing, respectively)"
            },
            "slug": "TREC-2-Routing-and-Ad-Hoc-Retrieval-Evaluation-the-Croft-Callan",
            "title": {
                "fragments": [],
                "text": "TREC-2 Routing and Ad-Hoc Retrieval Evaluation using the INQUERY System"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The general approach to achieve these goals has been to use improved representations of text and information needs in the framework of a new model of retrieval that uses Bayesian netwoks to describe how text and queries should be uses to identify relevant document."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724728"
                        ],
                        "name": "R. Tong",
                        "slug": "R.-Tong",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Tong",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1812139"
                        ],
                        "name": "L. Appelbaum",
                        "slug": "L.-Appelbaum",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Appelbaum",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Appelbaum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 91
                            }
                        ],
                        "text": "Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 28456675,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d0a7dabadadfeb30e91448cda4743583a9ec9a6",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper contains a description of the experiments performed by Advanced Decision Systems as part of the Second Retrieval Conference (TREC-2). The overall system developed for TREC-2 demonstrates how it can be combined statistically techniques with a commercially available knowledge-based information retrieval system. As in TREC-1, the tool used for the fully automatic construction of routing queries is based on the Classification and Regression Trees (CART) algorithm. However, in, a departure from TREC-1, we have expanded our definition of what constitutes a document featureswithin the CART output can be used as the basis of topic definitions that can be interpreted by the TOPIC retrieval system developed by Veery, Inc"
            },
            "slug": "Machine-Learning-for-Knowledge-Based-Document-(A-on-Tong-Appelbaum",
            "title": {
                "fragments": [],
                "text": "Machine Learning for Knowledge-Based Document Routing (A Report on the TREC-2 Experiment)"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The overall system developed for TREC-2 demonstrates how it can be combined statistically techniques with a commercially available knowledge-based information retrieval system."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35211746"
                        ],
                        "name": "David A. Hull",
                        "slug": "David-A.-Hull",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hull",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. Hull"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "[20] David A. Hull."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "[18] David Hull."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "This approach differs from the one in [19] in that the local region now contains both relevant and non-relevant documents, which was found to be more effective than using only relevant documents [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 66
                            }
                        ],
                        "text": "Rather, they are used as input parameters to a learning algorithm [19, 34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "LDA has already been applied to the routing problem by Hull [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 288
                            }
                        ],
                        "text": "Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "LDA has already been applied to the routing problem \nby Hull [19]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "Previous work has shown that LSI is more successfulwhen applied to a local region on a query specific basis [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "We compute a separate representation of terms and documents for each query, focusing on the documents which are most likely to be relevant [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "[19] David Hull."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13177734,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e3729dcdf9230f695cac56d5f291391762a1262",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Latent Semantic Indexing (LSI) is a novel approach to information retrieval that attempts to model the underlying structure of term associations by transforming the traditional representation of documents as vectors of weighted term frequencies to a new coordinate space where both documents and terms are represented as linear combinations of underlying semantic factors. In previous research, LSI has produced a small improvement in retrieval performance. In this paper, we apply LSI to the routing task, which operates under the assumption that a sample of relevant and non-relevant documents is available to use in constructing the query. Once again, LSI slightly improves performance. However, when LSI is used is conjuction with statistical classification, there is a dramatic improvement in performance."
            },
            "slug": "Improving-text-retrieval-for-the-routing-problem-Hull",
            "title": {
                "fragments": [],
                "text": "Improving text retrieval for the routing problem using latent semantic indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper applies LSI to the routing task, which operates under the assumption that a sample of relevant and non-relevant documents is available to use in constructing the query, and finds that when LSI is used is conjuction with statistical classification, there is a dramatic improvement in performance."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 204
                            }
                        ],
                        "text": "Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16041292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc8e59e4c7c2cbb6695ee5488aa569780449b212",
            "isKey": false,
            "numCitedBy": 485,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Expert Network (ExpNet) is our new approach to automatic categorization and retrieval of natural language texts. We use a training set of texts with expert-assigned categories to construct a network which approximately reflects the conditional probabilities of categories given a text. The input nodes of the network are words in the training texts, the nodes on the intermediate level are the training texts, and the output nodes are categories. The links between nodes are computed based on statistics of the word distribution and the category distribution over the training set. ExpNet is used for relevance ranking of candidate categories of an arbitrary text in the case of text categorization, and for relevance ranking of documents via categories in the case of text retrieval. We have evaluated ExpNet in categorization and retrieval on a document collection of the MEDLINE database, and observed a performance in recall and precision comparable to the Linear Least Squares Fit (LLSF) mapping method, and significantly better than other methods tested. Computationally, ExpNet has an O(N 1og N) time complexity which is much more efficient than the cubic complexity of the LLSF method. The simplicity of the model, the high recall-precision rates, and the efficient computation together make ExpNet preferable as a practical solution for real-world applications."
            },
            "slug": "Expert-network:-effective-and-efficient-learning-in-Yang",
            "title": {
                "fragments": [],
                "text": "Expert network: effective and efficient learning from human decisions in text categorization and retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The simplicity of the model, the high recall-precision rates, and the efficient computation together make ExpNet preferable as a practical solution for real-world applications."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144430625"
                        ],
                        "name": "S. Robertson",
                        "slug": "S.-Robertson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Robertson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Robertson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48872185"
                        ],
                        "name": "S. Walker",
                        "slug": "S.-Walker",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Walker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398053996"
                        ],
                        "name": "M. Hancock-Beaulieu",
                        "slug": "M.-Hancock-Beaulieu",
                        "structuredName": {
                            "firstName": "Micheline",
                            "lastName": "Hancock-Beaulieu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hancock-Beaulieu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402011177"
                        ],
                        "name": "Aarron Gull",
                        "slug": "Aarron-Gull",
                        "structuredName": {
                            "firstName": "Aarron",
                            "lastName": "Gull",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aarron Gull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406277707"
                        ],
                        "name": "Marianna Lau",
                        "slug": "Marianna-Lau",
                        "structuredName": {
                            "firstName": "Marianna",
                            "lastName": "Lau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marianna Lau"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41563977,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa8ffa9f8d8367b987845ae88f2adcac2689f110",
            "isKey": false,
            "numCitedBy": 2125,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "City submitted two runs each for the automatic ad hoc, very large collection track, automatic routing and Chinese track; and took part in the interactive and filtering tracks. The method used was : expansion using terms from the top documents retrieved by a pilot search on topic terms. Additional runs seem to show that we would have done better without expansion. Twor runs using the method of city96al were also submitted for the Very Large Collection track. The training database and its relevant documents were partitioned into three parts. Working on a pool of terms extracted from the relevant documents for one partition, an iterative procedure added or removed terms and/or varied their weights. After each change in query content or term weights a score was calculated by using the current query to search a second protion of the training database and evaluating the results against the corresponding set of relevant documents. Methods were compared by evaluating queries predictively against the third training partition. Queries from different methods were then merged and the results evaluated in the same way. Two runs were submitted, one based on character searching and the other on words or phrases. Much of the work involved investigating plausible methods of applying Okapi-style weighting to phrases"
            },
            "slug": "Okapi-at-TREC-Robertson-Walker",
            "title": {
                "fragments": [],
                "text": "Okapi at TREC"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Much of the work involved investigating plausible methods of applying Okapi-style weighting to phrases, and expansion using terms from the top documents retrieved by a pilot search on topic terms was used."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889602"
                        ],
                        "name": "Erik D. Wiener",
                        "slug": "Erik-D.-Wiener",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Wiener",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erik D. Wiener"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2024710"
                        ],
                        "name": "A. Weigend",
                        "slug": "A.-Weigend",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Weigend",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Weigend"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17503448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abbe40b7503f51971c92f9f9b20ebea6c0b36d77",
            "isKey": false,
            "numCitedBy": 459,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an application of nonlinear neural networks to topic spotting. Neural networks allow us to model higher-order interaction between document terms and to simultaneously predict multiple topics using shared hidden features. In the context of this model, we compare two approaches to dimensionality reduction in representation: one based on term selection and another based on Latent Semantic Indexing (LSI). Two diierent methods are proposed for improving LSI representations for the topic spotting task. We nd that term selection and our modiied LSI representations lead to similar topic spotting performance, and that this performance is equal to or better than other published results on the same corpus."
            },
            "slug": "A-neural-network-approach-to-topic-spotting-Wiener-Pedersen",
            "title": {
                "fragments": [],
                "text": "A neural network approach to topic spotting"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is shown that term selection and the modiied LSI representations lead to similar topic spotting performance, and that this performance is equal to or better than other published results on the same corpus."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 145
                            }
                        ],
                        "text": "Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16644750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07f0f4553cfb42c0ed2bd6b07c9b22777b313d8",
            "isKey": false,
            "numCitedBy": 694,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Syntactic phrase indexing and term clustering have been widely explored as text representation techniques for text retrieval. In this paper we study the properties of phrasal and clustered indexing languages on a text categorization task, enabling us to study their properties in isolation from query interpretation issues. We show that optimal effectiveness occurs when using only a small proportion of the indexing terms available, and that effectiveness peaks at a higher feature set size and lower effectiveness level for a syntactic phrase indexing than for word-based indexing. We also present results suggesting that traditional term clustering method are unlikely to provide significantly improved text representations. An improved probabilistic text categorization method is also presented."
            },
            "slug": "An-evaluation-of-phrasal-and-clustered-on-a-text-Lewis",
            "title": {
                "fragments": [],
                "text": "An evaluation of phrasal and clustered representations on a text categorization task"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that optimal effectiveness occurs when using only a small proportion of the indexing terms available, and that effectiveness peaks at a higher feature set size and lower effectiveness level for a syntactic phrase indexing than for word-based indexing."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16266966,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5dc31d2fa745ef07541666bdee815b38d6be1ea9",
            "isKey": false,
            "numCitedBy": 272,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Latent Semantic Indexing (LSI) is an extension of the vector retrieval method (e.g., Salton & McGill, 1983) in which the dependencies between terms are explicitly taken into account in the representation and exploited in retrieval. This is done by simultaneously modeling all the interrelationships among terms and documents. We assume that there is some underlying or \"latent\" structure in the pattern of word usage across documents, and use statistical techniques to estimate this latent structure. A description of terms, documents and user queries based on the underlying, \"latent semantic\", structure (rather than surface level word choice) is used for representing and retrieving information. One advantage of the LSI representation is that a query can be very similar to a document even when they share no words."
            },
            "slug": "Latent-Semantic-Indexing-(LSI)-and-TREC-2-Dumais",
            "title": {
                "fragments": [],
                "text": "Latent Semantic Indexing (LSI) and TREC-2"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "LSI is an extension of the vector retrieval method in which the dependencies between terms are explicitly taken into account in the representation and exploited in retrieval by simultaneously modeling all the interrelationships among terms and documents."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145219946"
                        ],
                        "name": "K. Kwok",
                        "slug": "K.-Kwok",
                        "structuredName": {
                            "firstName": "Kui-Lam",
                            "lastName": "Kwok",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kwok"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Kwok\u2019s work in [21] bears most similarity with our approach."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 15464590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72484a136db9a20d42c658296f69ad47c22488fb",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "A component theory of information retrieval using single content terms as component for queries and documents was reviewed and experimented with. The theory has the advantages of being able to (1) bootstrap itself, that is, define initial term weights naturally based on the fact that items are self relevent; (2) make use of within-item term frequencies; (3) account for query-focused and document-focused indexing and retrieval strategies cooperatively; and (4) allow for component-specific feedback if such information is available. Retrieval results with four collections support the effectiveness of all the first three aspects, except for predictive retrieval. At the initial indexing stage, the retrieval theory performed much more consistantly across collections than croft's model and provided results comparable to Salton's tf*idf approach. An inverse collection term frequency (ICTF) formula was also tested that performed much better than the inverse document frequency (IDF). With full feedback retrospective retrieval, the component theory performed substantially better than Croft's, because of the highly specific nature of document-focused feedback. Repetitive retireval results with partial relevance feedback mirrored those for the retrospective. However, for the important case of predictive retrieval using residual ranking, results were not unequivocal."
            },
            "slug": "Experiments-with-a-component-theory-of-information-Kwok",
            "title": {
                "fragments": [],
                "text": "Experiments with a component theory of probabilistic information retrieval based on single terms as document components"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A component theory of information retrieval using single content terms as component for queries and documents was reviewed and experimented with and performed substantially better than Croft's model because of the highly specific nature of document-focused feedback."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2697855"
                        ],
                        "name": "M. Ringuette",
                        "slug": "M.-Ringuette",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Ringuette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ringuette"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 91
                            }
                        ],
                        "text": "Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16894634,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9fd1a7ae0322d417ab2d32017e373dd50efc063",
            "isKey": false,
            "numCitedBy": 745,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper examines the use of inductive learning to categorize natural language documents into predeened content categories. Categorization of text is of increasing importance in information retrieval and natural language processing systems. Previous research on automated text categorization has mixed machine learning and knowledge engineering methods, making it diicult to draw conclusions about the performance of particular methods. In this paper we present empirical results on the performance of a Bayesian classiier and a decision tree learning algorithm on two text categorization data sets. We nd that both algorithms achieve reasonable performance and allow controlled tradeoos between false positives and false negatives. The stepwise feature selection in the decision tree algorithm is particularly eeective in dealing with the large feature sets common in text categorization. However, even this algorithm is aided by an initial preeltering of features, connrming the results found by Almuallim and Dietterich on artiicial data sets. We also demonstrate the impact of the time-varying nature of category deenitions."
            },
            "slug": "A-comparison-of-two-learning-algorithms-for-text-Lewis-Ringuette",
            "title": {
                "fragments": [],
                "text": "A comparison of two learning algorithms for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that both algorithms achieve reasonable performance and allow controlled tradeoos between false positives and false negatives, and the stepwise feature selection in the decision tree algorithm is particularly eeective in dealing with the large feature sets common in text categorization."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2126632"
                        ],
                        "name": "W. S. Cooper",
                        "slug": "W.-S.-Cooper",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cooper",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. S. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2346862"
                        ],
                        "name": "Aitao Chen",
                        "slug": "Aitao-Chen",
                        "structuredName": {
                            "firstName": "Aitao",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aitao Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772996"
                        ],
                        "name": "F. Gey",
                        "slug": "F.-Gey",
                        "structuredName": {
                            "firstName": "Fredric",
                            "lastName": "Gey",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Gey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 77
                            }
                        ],
                        "text": "Logistic regression has been used for text retrieval in previous experiments [5, 12, 32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 234
                            }
                        ],
                        "text": "Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35107004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d3811f2b64008910980c9732ec611c19a532737d",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The experiments described here ara part of research program whose objective is to develop a full text retrieval methodology that is statistically sound and powerful, yet reasonably simple. The methodology is based on the use of a probabilistic model whose parameters ara fitted empirically to a learning set of relevance judgements by logistic regression. The method was applied to the TIPSTER data with optimally relativized frequencies of occurence of match stems as the regression variables. In a routing retrieval experiment, these were supplemented by other variables coresponding to sums of logodds associated with particular match stems"
            },
            "slug": "Full-Text-Retrieval-based-on-Probalistic-Equations-Cooper-Chen",
            "title": {
                "fragments": [],
                "text": "Full Text Retrieval based on Probalistic Equations with Coefficients fitted by Logistic Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The experiments described here are part of research program whose objective is to develop a full text retrieval methodology that is statistically sound and powerful, yet reasonably simple."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682655"
                        ],
                        "name": "R. Belew",
                        "slug": "R.-Belew",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Belew",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Belew"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 127
                            }
                        ],
                        "text": "In contrast, other work on neural networks in IR has been closely related to the vector space model [35] or relevance feedback [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13130282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e51772a52d8defcee1a3b26b12648523ec3f0119",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "AIR represents a connectionist approach to the task of information retrieval. The system uses relevance feedback from its users to change its representation of authors, index terms and documents so that, over time, AIR improves at its task. The result is a representation of the consensual meaning of keywords and documents shared by some group of users. The central focus goal of this paper is to use our experience with AIR to highlight those characteristics of connectionist representations that make them particularly appropriate for IR applications. We argue that this associative representation is a natural generalization of traditional IR techniques, and that connectionist learning techniques are effective in this setting."
            },
            "slug": "Adaptive-information-retrieval:-using-a-to-retrieve-Belew",
            "title": {
                "fragments": [],
                "text": "Adaptive information retrieval: using a connectionist representation to retrieve and learn about documents"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is argued that this associative representation of authors, index terms and documents in AIR is a natural generalization of traditional IR techniques, and that connectionist learning techniques are effective in this setting."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '89"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35211746"
                        ],
                        "name": "David A. Hull",
                        "slug": "David-A.-Hull",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hull",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. Hull"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 60
                            }
                        ],
                        "text": "These experimental results are \nanalyzed using ANOVA and the Friedman Test [18] to measure their statistical significance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 108
                            }
                        ],
                        "text": "For LSI features, logistic regression is less effective than the other learning algo\u00adrithms according \nto the Friedman Test, although the magnitude of the difference is small."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "These experimental results are analyzed using ANOVA and the Friedman Test [18] to measure their statistical significance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7149948,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6525eded7f93c6890563ea7bf870b513a67e18c",
            "isKey": false,
            "numCitedBy": 569,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The standard strategies for evaluation based on precision and recall are examined and their relative advantages and disadvantages are discussed. In particular, it is suggested that relevance feedback be evaluated from the perspective of the user. A number of different statistical tests are described for determining if differences in performance between retrieval methods are significant. These tests have often been ignored in the past because most are based on an assumption of normality which is not strictly valid for the standard performance measures. However, one can test this assumption using simple diagnostic plots, and if it is a poor approximation, there are a number of non-parametric alternatives."
            },
            "slug": "Using-statistical-testing-in-the-evaluation-of-Hull",
            "title": {
                "fragments": [],
                "text": "Using statistical testing in the evaluation of retrieval experiments"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is suggested that relevance feedback be evaluated from the perspective of the user and a number of different statistical tests are described for determining if differences in performance between retrieval methods are significant."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2092997919"
                        ],
                        "name": "Ulrich Pfeifer",
                        "slug": "Ulrich-Pfeifer",
                        "structuredName": {
                            "firstName": "Ulrich",
                            "lastName": "Pfeifer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ulrich Pfeifer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 77
                            }
                        ],
                        "text": "Logistic regression has been used for text retrieval in previous experiments [5, 12, 32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14888569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff1ba0b9e5d77d0845a3c9ce85795fc9405daff2",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that former approaches in probabilistic information retrieval are based on one or two of the three concepts abstraction, inductive learning, and probabilistic assumptions, and we propose a new approach which combines all three concepts. This approach is illustrated for the case of indexing with a controlled vocabulary. For this purpose, we describe a new probabilistic model first, which is then combined with logistic regression, thus yielding a generalization of the original model. Experimental results for the pure theoretical model as well as for heuristic variants are given. Furthermore, linear and logistic regression are compared."
            },
            "slug": "Probabilistic-information-retrieval-as-a-of-and-Fuhr-Pfeifer",
            "title": {
                "fragments": [],
                "text": "Probabilistic information retrieval as a combination of abstraction, inductive learning, and probabilistic assumptions"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new probabilistic model is described first, which is then combined with logistic regression, thus yielding a generalization of the original model, and this approach is illustrated for the case of indexing with a controlled vocabulary."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127759"
                        ],
                        "name": "B. Masand",
                        "slug": "B.-Masand",
                        "structuredName": {
                            "firstName": "Brij",
                            "lastName": "Masand",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Masand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2132345"
                        ],
                        "name": "G. Linoff",
                        "slug": "G.-Linoff",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Linoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Linoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788375"
                        ],
                        "name": "D. Waltz",
                        "slug": "D.-Waltz",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Waltz",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Waltz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[25] Brij Masand, Gordon Linoff, and David Waltz."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 204
                            }
                        ],
                        "text": "Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7048166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1240054ed60e8e42de9683947d21bd76582a281d",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for classifying news stories using Memory Based Reasoning (MBR) a k-nearest neighbor method), that does not require manual topic definitions. Using an already coded training database of about 50,000 stories from the Dow Jones Press Release News Wire, and SEEKER [Stanfill] (a text retrieval system that supports relevance feedback) as the underlying match engine, codes are assigned to new, unseen stories with a recall of about 80% and precision of about 70%. There are about 350 different codes to be assigned. Using a massively parallel supercomputer, we leverage the information already contained in the thousands of coded stories and are able to code a story in about 2 seconds. Given SEEKER, the text retrieval system, we achieved these results in about two person-months. We believe this approach is effective in reducing the development time to implement classification systems involving large number of topics for the purpose of classification, message routing etc."
            },
            "slug": "Classifying-news-stories-using-memory-based-Masand-Linoff",
            "title": {
                "fragments": [],
                "text": "Classifying news stories using memory based reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A method for classifying news stories using Memory Based Reasoning (MBR) a k-nearest neighbor method, that does not require manual topic definitions, that is effective in reducing the development time to implement classification systems involving large number of topics for the purpose of classification, message routing etc."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144430625"
                        ],
                        "name": "S. Robertson",
                        "slug": "S.-Robertson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Robertson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Robertson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48872185"
                        ],
                        "name": "S. Walker",
                        "slug": "S.-Walker",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Walker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48795085"
                        ],
                        "name": "Susan Jones",
                        "slug": "Susan-Jones",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Susan Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398053996"
                        ],
                        "name": "M. Hancock-Beaulieu",
                        "slug": "M.-Hancock-Beaulieu",
                        "structuredName": {
                            "firstName": "Micheline",
                            "lastName": "Hancock-Beaulieu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hancock-Beaulieu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2328476"
                        ],
                        "name": "Mike Gatford",
                        "slug": "Mike-Gatford",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Gatford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mike Gatford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 159
                            }
                        ],
                        "text": "To the best of our knowl\u00adedge, the results given here for LDA and neural networks are \nat least as good as the best routing results published for TREC-2 [4] and TREC-3 [27]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 122
                            }
                        ],
                        "text": "We demonstrate that the classifiers perform 10\u00ad15% better than relevance feedback via \nRocchio expansion for the TREC-2 and TREC-3 routing tasks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 76
                            }
                        ],
                        "text": "[16] Doma Harman, editor, Proceedings \nof the 3rd Text Retrieval Conference (TREC-3), 1995. to appear."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 166
                            }
                        ],
                        "text": "To the best of our knowledge, the results given here for LDA and neural networks are at least as good as the best routing results published for TREC-2 [4] and TREC-3 [27]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 49
                            }
                        ],
                        "text": "We use the Tipster collection and the TREC-2 and TREC-3 routing tasks to test classifiers and \nrepresentations [15, 16]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3946054,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2071c1e4a6030dc0005dbfeefdd196a8b293e84",
            "isKey": true,
            "numCitedBy": 1810,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "During the course of TREC{1 the low-level search functions were split o into a separate Basic Search System (BSS) [2], but retrieval and ranking of documents was still done using the \\classical\" probabilistic model of Robertson and Sparck Jones[7] with no account taken of document length or term frequency within document or query. Four runs were submitted to NIST for evaluation: automatic ad hoc, automatic routing, manual ad hoc and manual ad hoc with feedback. The results were undistinguished, although not among the worst. Of the ad hoc runs, the manual was better than the automatic (in which only the CONCEPTS elds of the topics were used), and feedback appeared bene cial."
            },
            "slug": "Okapi-at-TREC-3-Robertson-Walker",
            "title": {
                "fragments": [],
                "text": "Okapi at TREC-3"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "During the course of TREC{1 the low-level search functions were split o into a separate Basic Search System (BSS), but retrieval and ranking of documents was still done using the \\classical\" probabilistic model of Robertson and Sparck Jones with no account taken of document length or term frequency within document or query."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 260
                            }
                        ],
                        "text": "Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16632383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "733952333854f1662c6038573aca67e575757932",
            "isKey": false,
            "numCitedBy": 147,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that any approach to developing optimum retrieval functions is based on two kinds of assumptions: first, a certain form of representation for documents and requests, and second, additional simplifying assumptions that predefine the type of the retrieval function. Then we describe an approach for the development of optimum polynomial retrieval functions: request-document pairs (<italic>f<subscrpt>l</subscrpt></italic>, <italic>d<subscrpt>m</subscrpt></italic>) are mapped onto description vectors <italic>x</italic>(<italic>f<subscrpt>l</subscrpt></italic>, <italic>d<subscrpt>m</subscrpt></italic>), and a polynomial function <italic>e</italic>(<italic>x</italic>) is developed such that it yields estimates of the probability of relevance P(<italic>R</italic> | x (<italic>f<subscrpt>l</subscrpt></italic>, <italic>d<subscrpt>m</subscrpt></italic>) with minimum square errors. We give experimental results for the application of this approach to documents with weighted indexing as well as to documents with complex representations. In contrast to other probabilistic models, our approach yields estimates of the actual probabilities, it can handle very complex representations of documents and requests, and it can be easily applied to multivalued relevance scales. On the other hand, this approach is not suited to log-linear probabilistic models and it needs large samples of relevance feedback data for its application."
            },
            "slug": "Optimum-polynomial-retrieval-functions-based-on-the-Fuhr",
            "title": {
                "fragments": [],
                "text": "Optimum polynomial retrieval functions based on the probability ranking principle"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This approach is not suited to log-linear probabilistic models and it needs large samples of relevance feedback data for its application, but it can handle very complex representations of documents and requests and it can be easily applied to multivalued relevance scales."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "The traditional approach to relevance feedback [30] defines \"!$#&% , where # , the feedback query, is a weighted combination of the original query vector and the vectors of the relevant (and perhaps non-relevant) documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7725217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e50a316f97c9a405aa000d883a633bd5707f1a34",
            "isKey": false,
            "numCitedBy": 9463,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Term-Weighting-Approaches-in-Automatic-Text-Salton-Buckley",
            "title": {
                "fragments": [],
                "text": "Term-Weighting Approaches in Automatic Text Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145272844"
                        ],
                        "name": "C. Apt\u00e9",
                        "slug": "C.-Apt\u00e9",
                        "structuredName": {
                            "firstName": "Chidanand",
                            "lastName": "Apt\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Apt\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "68982679"
                        ],
                        "name": "Fred J. Damerau",
                        "slug": "Fred-J.-Damerau",
                        "structuredName": {
                            "firstName": "Fred",
                            "lastName": "Damerau",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fred J. Damerau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145700185"
                        ],
                        "name": "S. Weiss",
                        "slug": "S.-Weiss",
                        "structuredName": {
                            "firstName": "Sholom",
                            "lastName": "Weiss",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 171
                            }
                        ],
                        "text": "Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 775418,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "248380e4b3cc91a87bfb11d29fb95125496dd2c9",
            "isKey": false,
            "numCitedBy": 205,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the results of extensive machine learning experiments on large collections of Reuters\u2019 English and German newswires. The goal of these experiments was to automatically discover classification patterns that can be used for assignment of topics to the individual newswires. Our results with the English newswire collection show a very large gain in performance as compared to published benchmarks, while our initial results with the German newswires appear very promising. We present our methodology, which seems to be insensitive to the language of the document collections, and discuss issues related to the differences in results that we have obtained for the two collections."
            },
            "slug": "Towards-language-independent-automated-learning-of-Apt\u00e9-Damerau",
            "title": {
                "fragments": [],
                "text": "Towards language independent automated learning of text categorization models"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The results of extensive machine learning experiments on large collections of Reuters\u2019 English and German newswires are described, and the methodology, which seems to be insensitive to the language of the document collections, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144890574"
                        ],
                        "name": "James Allan",
                        "slug": "James-Allan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Allan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Allan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 144
                            }
                        ],
                        "text": "To the best of our knowl\u00adedge, the results given here for LDA and neural networks are \nat least as good as the best routing results published for TREC-2 [4] and TREC-3 [27]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 39
                            }
                        ],
                        "text": "In The Second Text REtneval Confewtce (TREC-2), \npages 105\u00ad115, 1993."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "plain why our performance is not as good as the one in [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 182
                            }
                        ],
                        "text": "We define the local region for a query as the 2000 nearest documents, where similarity is measured using the inner product score to the Rocchio-expansion of the initial query vector [4], corresponding to our baseline feedback algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 111
                            }
                        ],
                        "text": "We demonstrate that the classifiers perform 10\u00ad15% better than relevance feedback via \nRocchio expansion for the TREC-2 and TREC-3 routing tasks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 50
                            }
                        ],
                        "text": "Proceedings of the 2nd Text Retrieval Conference (TREC-2), 1994."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 151
                            }
                        ],
                        "text": "To the best of our knowledge, the results given here for LDA and neural networks are at least as good as the best routing results published for TREC-2 [4] and TREC-3 [27]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[4] Chris Buckley, Gerard Salton, and James Allan."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 38
                            }
                        ],
                        "text": "We use the Tipster collection and the TREC-2 and TREC-3 routing tasks to test classifiers and \nrepresentations [15, 16]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "Buckley\u2019s recent experiments that show better performance with increasing number of terms [4])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17522959,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "c972982771aeaaafdbdfbbcc7fe205bdecb3cf24",
            "isKey": true,
            "numCitedBy": 372,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The effects of adding information from relevant documents are examined in the TREC routing environment. A modified Rocchio relevance feedback approach is used, with a varying number of relevant documents retrieved by an initial SMART search, and a varying number of terms from those relevant documents used to expand the initial query. Recall-precision evaluation reveals that as the amount of expansion of the query due to adding terms from relevant documents increases, so does the effectiveness. There appears to be a linear relationship between the log of the number of terms added and the recall-precision effectiveness. There also appears to be a linear relationship between the log of the number of known relevant documents and the recall-precision effectiveness."
            },
            "slug": "The-effect-of-adding-relevance-information-in-a-Buckley-Salton",
            "title": {
                "fragments": [],
                "text": "The effect of adding relevance information in a relevance feedback environment"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Recall-precision evaluation reveals that as the amount of expansion of the query due to adding terms from relevant documents increases, so does the effectiveness, and there appears to be a linear relationship between the log of the number of terms added and the recall- Precision effectiveness."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144169170"
                        ],
                        "name": "D. Harman",
                        "slug": "D.-Harman",
                        "structuredName": {
                            "firstName": "Donna",
                            "lastName": "Harman",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "3 gigabytes of text in over one million documents from several different sources: newswire, patents, scientific abstracts, and the Federal Register [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 148
                            }
                        ],
                        "text": "It consists of 3.3 gigabytes of text in over one million documents \nfrom several dif\u00adferent sources: newswire, patents, scientific abstracts, and the Fed\u00aderal Register [14]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12675599,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "727c7527c3981db176d3357344bd00419309c633",
            "isKey": true,
            "numCitedBy": 201,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The first Text REtrieval Conference (TREC-1) was held in early November 1992 and was attended by about 100 people working in the 25 participating groups. The goal of the conference was to bring research groups together to discuss their work on a new large test collection. There was a large variety of retrieval techniques reported on, including methods using automatic thesaurii, sophisticated term weighting, natural language techniques, relevance feedback, and advanced pattern matching. As results had been run through a common evaluation package, groups were able to compare the effectiveness of different techniques, and discuss how differences among the sytems affected performance."
            },
            "slug": "Overview-of-the-first-TREC-conference-Harman",
            "title": {
                "fragments": [],
                "text": "Overview of the first TREC conference"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "There was a large variety of retrieval techniques reported on, including methods using automatic thesaurii, sophisticated term weighting, natural language techniques, relevance feedback, and advanced pattern matching."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144169170"
                        ],
                        "name": "D. Harman",
                        "slug": "D.-Harman",
                        "structuredName": {
                            "firstName": "Donna",
                            "lastName": "Harman",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2143884,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1168df8436f10b279594a440cbde69f4bef0583",
            "isKey": false,
            "numCitedBy": 362,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Overview-of-the-Second-Text-REtrieval-Conference-Harman",
            "title": {
                "fragments": [],
                "text": "Overview of the Second Text REtrieval Conference (TREC-2)"
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187514"
                        ],
                        "name": "R. Durbin",
                        "slug": "R.-Durbin",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Durbin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Durbin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2181418"
                        ],
                        "name": "R. Golden",
                        "slug": "R.-Golden",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Golden",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Golden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2952703"
                        ],
                        "name": "Y. Chauvin",
                        "slug": "Y.-Chauvin",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Chauvin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chauvin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "as the activation function for the units of the network, It can be shown [29] that in this case backpropagation minimizes the same error as the logistic regression, the cross-entropy error:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60753175,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00f9e28afef06df4c8bc9553cbd46227cdcaf5c9",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Since the publication of the PDP volumes in 1986, learning by backpropagation has become the most popular method of training neural networks. The reason for the popularity is the underlying simplicity and relative power of the algorithm. Its power derives from the fact that, unlike its precursors, the perceptron learning rule and the Widrow-Hoff learning rule, it can be employed for training nonlinear networks of arbitrary connectivity. Since such networks are often required for real-world applications, such a learning procedure is critical. Nearly as important as its power in explaining its popularity is its simplicity. The basic idea is old and simple; namely define an error function and use hill climbing (or gradient descent if you prefer going downhill) to find a set of weights which optimize performance on a particular task. The algorithm is so simple that it can be implemented in a few lines of code, and there have been no doubt many thousands of implementations of the algorithm by now. The name back propagation actually comes from the term employed by Rosenblatt (1962) for his attempt to generalize the perceptron learning algorithm to the multilayer case. There were many attempts to generalize the perceptron learning procedure to multiple layers during the 1960s and 1970s, but none of them were especially successful. There appear to have been at least three independent inventions of the modern version of the back-propagation algorithm: Paul Werbos developed the basic idea in 1974 in a Ph.D. dissertation entitled"
            },
            "slug": "Backpropagation:-the-basic-theory-Rumelhart-Durbin",
            "title": {
                "fragments": [],
                "text": "Backpropagation: the basic theory"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "Since the publication of the PDP volumes in 1986, learning by backpropagation has become the most popular method of training neural networks because of the underlying simplicity and relative power of the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3133664"
                        ],
                        "name": "D. Cutting",
                        "slug": "D.-Cutting",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Cutting",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cutting"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066217332"
                        ],
                        "name": "Per Christian Halvorsen",
                        "slug": "Per-Christian-Halvorsen",
                        "structuredName": {
                            "firstName": "Per",
                            "lastName": "Halvorsen",
                            "middleNames": [
                                "Christian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Per Christian Halvorsen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0558d4b776eedb9956b0ec5c14b23f4f81870533",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "For almost all aspects of information access systems it is still the case that their optimal composition and functionality is hotly debated. Moreover, diierent application scenarios put diierent demands on individual components. It is therefore of the essence to be able to quickly build systems that permit exploration of diierent designs and implementation strategies. This paper presents a software implementation architecture for text retrieval systems that facilitates (a) functional modularization (b) mix-and-match combination of module implementations and (c) deenition of inter-module protocols. We show how an object-oriented approach easily accommodates this type of architecture. The design principles are exempliied by code examples in Common Lisp. Taken together these code examples constitute an operational retrieval system. The design principles and protocols implemented have also been instantiated in a large scale retrieval prototype in our research laboratory."
            },
            "slug": "An-object-oriented-architecture-for-text-retrieval-Cutting-Pedersen",
            "title": {
                "fragments": [],
                "text": "An object-oriented architecture for text retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A software implementation architecture for text retrieval systems that facilitates functional modularization, a mix-and-match combination of module implementations and a deenition of inter-module protocols is presented."
            },
            "venue": {
                "fragments": [],
                "text": "RIAO"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2198160,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e23c634a7beb02a127ecb11551fd0333491c602",
            "isKey": false,
            "numCitedBy": 2302,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Linear and quadratic discriminant analysis are considered in the small-sample, high-dimensional setting. Alternatives to the usual maximum likelihood (plug-in) estimates for the covariance matrices are proposed. These alternatives are characterized by two parameters, the values of which are customized to individual situations by jointly minimizing a sample-based estimate of future misclassification risk. Computationally fast implementations are presented, and the efficacy of the approach is examined through simulation studies and application to data. These studies indicate that in many circumstances dramatic gains in classification accuracy can be achieved."
            },
            "slug": "Regularized-Discriminant-Analysis-Friedman",
            "title": {
                "fragments": [],
                "text": "Regularized Discriminant Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Alternatives to the usual maximum likelihood estimates for the covariance matrices are proposed, characterized by two parameters, the values of which are customized to individual situations by jointly minimizing a sample-based estimate of future misclassification risk."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144509232"
                        ],
                        "name": "R. Wilkinson",
                        "slug": "R.-Wilkinson",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Wilkinson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Wilkinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747011"
                        ],
                        "name": "P. Hingston",
                        "slug": "P.-Hingston",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Hingston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hingston"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "In contrast, other work on neural networks in IR has been closely related to the vector space model [35] or relevance feedback [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[35] Ross Wilkinson and Philip Hingston."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16593675,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "3d71d53eb9adfe5744fad9cd6bf53a21f33882f0",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "An air separation process using pressure swing adsorption techniques, for providing high purity oxygen. Two sections are employed one comprising beds of molecular sieve carbon and the other comprising beds of zeolite molecular sieve. Air is fed to a first of the sections which provides an oxygen-rich gas stream as feedstock for the next section where further enrichment takes place. The zeolite sieve section serves to effect a separation as between oxygen and nitrogen while the carbon sieve section serves to effect a separation as between oxygen and argon and the processes performed at each section are integrated in such a manner as to minimize power consumption and make use of gas recycled from the second section to the first in addition to the flow of gas from the first section to the second."
            },
            "slug": "Using-the-cosine-measure-in-a-neural-network-for-Wilkinson-Hingston",
            "title": {
                "fragments": [],
                "text": "Using the cosine measure in a neural network for document retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An air separation process using pressure swing adsorption techniques, for providing high purity oxygen using beds of molecular sieve carbon and zeolite molecular sieves, is employed."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '91"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716902"
                        ],
                        "name": "Marti A. Hearst",
                        "slug": "Marti-A.-Hearst",
                        "structuredName": {
                            "firstName": "Marti",
                            "lastName": "Hearst",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marti A. Hearst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18638525,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9eae218d86d7bb8735b6f549906f7452c0824ff",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Cet article presente deux techniques de traitement de l'information lors d'une recherche d'information en texte integral, l'une pour les travaux ad hoc et l'autre pour les travaux de routine, chacune explorant les combinaisons de predicteurs exactes et flous. Les experiences de travail de routine puis les experiences ad hoc sont donc presentees, et enfin, les resultats de ces experiences sont discutees ainsi que les experiences possibles pour l'avenir"
            },
            "slug": "Xerox-TREC-3-Report:-Combining-Exact-and-Fuzzy-Sch\u00fctze-Pedersen",
            "title": {
                "fragments": [],
                "text": "Xerox TREC-3 Report: Combining Exact and Fuzzy Predictors"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "Deux techniques de traitement de l'information lors d'une recherche d'information en texte integral are presented, l'une pour les travaux ad hoc et l'autre pour les Travaux de routine, chacune explorant les combinaisons de predicteurs exactes et flous."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "The run \u201cexpansion\u201d was tf-idf weighted [31], and terms in the baseline runs were idf-weighted."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17637032,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2ebb3dd597bbd7028d8c68bcf509e5bb09ea1e78",
            "isKey": false,
            "numCitedBy": 1442,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Relevance feedback is an automatic process, introduced over 20 years ago, designed to produce query formulations following an initial retrieval operation. The principal relevance feedback methods described over the years are examined briefly, and evaluation data are included to demonstrate the effectiveness of the various methods. Prescriptions are given for conducting text retrieval operations iteratively using relevance feedback."
            },
            "slug": "Improving-retrieval-performance-by-relevance-Salton-Buckley",
            "title": {
                "fragments": [],
                "text": "Improving retrieval performance by relevance feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Prescriptions are given for conducting text retrieval operations iteratively using relevance feedback, and evaluation data are included to demonstrate the effectiveness of the various methods."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2271549"
                        ],
                        "name": "M. Berry",
                        "slug": "M.-Berry",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Berry",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Berry"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119721307,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4eebdd4761f5db209944a933d1124812c998039b",
            "isKey": false,
            "numCitedBy": 406,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We present four numerical methods for computing the singular value decomposition (SVD) of large sparse matrices on a multiprocessor architecture. We emphasize Lanczos and subspace iteration-based methods for determining several of the largest singular triplets (singular values and corresponding left- and right-singular vectors) for sparse matrices arising from two practical applications: information retrieval and seismic reflection tomography. The target architectures for our implementations are the CRAY-2S/4\u2013128 and Alliant FX/80. The sparse SVD problem is well motivated by recent information-retrieval techniques in which dominant singular values and their corresponding singular vectors of large sparse term-document matrices are desired, and by nonlinear inverse problems from seismic tomography applications which require approximate pseudo-inverses of large sparse Jacobian matrices. This research may help advance the development of future out-of-core sparse SVD methods, which can be used, for example, to handle extremely large sparse matrices 0 \u00d7 (106) rows or columns associated with extremely large databases in query-based information-retrieval applications."
            },
            "slug": "Large-Scale-Sparse-Singular-Value-Computations-Berry",
            "title": {
                "fragments": [],
                "text": "Large-Scale Sparse Singular Value Computations"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Four numerical methods for computing the singular value decomposition (SVD) of large sparse matrices on a multiprocessor architecture are presented and may help advance the development of future out-of-core sparse SVD methods, which can be used to handle extremely large sparsematrices associated with extremely large databases in query-based information-retrieval applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716902"
                        ],
                        "name": "Marti A. Hearst",
                        "slug": "Marti-A.-Hearst",
                        "structuredName": {
                            "firstName": "Marti",
                            "lastName": "Hearst",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marti A. Hearst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 796701,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c92968494a79135c7e8cfb48414312722f14d8a3",
            "isKey": false,
            "numCitedBy": 682,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes TextTiling, an algorithm for partitioning expository texts into coherent multi-paragraph discourse units which reflect the subtopic structure of the texts. The algorithm uses domain-independent lexical frequency and distribution information to recognize the interactions of multiple simultaneous themes. Two fully-implemented versions of the algorithm are described and shown to produce segmentation that corresponds well to human judgments of the major subtopic boundaries of thirteen lengthy texts."
            },
            "slug": "Multi-Paragraph-Segmentation-of-Expository-Text-Hearst",
            "title": {
                "fragments": [],
                "text": "Multi-Paragraph Segmentation of Expository Text"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "TextTiling, an algorithm for partitioning expository texts into coherent multi-paragraph discourse units which reflect the subtopic structure of the texts, is described and shown to produce segmentation that corresponds well to human judgments of the major subtopic boundaries of thirteen lengthy texts."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 227
                            }
                        ],
                        "text": "Neural networks are trained by backpropagation: the activation of each input pattern is propagated forward through the network, and the error produced is then backpropagated and the parameters changed so as to reduce the error [28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 275
                            }
                        ],
                        "text": "Relevance for a document is computed by setting the activations of the input units to the document\u2019s representation and propagating the activation through the network to the output unit, then propagating the error back through the network, using a gradient descent algorithm [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19356,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47433002"
                        ],
                        "name": "D. A. Hull",
                        "slug": "D.-A.-Hull",
                        "structuredName": {
                            "firstName": "D",
                            "lastName": "Hull",
                            "middleNames": [
                                "A"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. A. Hull"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "However, previous experiments have not found much benefit to applying RDA to the routing problem [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Previous work [20] suggests that RDA does not improve performance when applied to the LSI representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 195
                            }
                        ],
                        "text": "This approach differs from the one in [19] in that the local region now contains both relevant and non-relevant documents, which was found to be more effective than using only relevant documents [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8623858,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df09c9d0be69a798dea606330f511f9600a02812",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "A miniature rose plant having sweet fragrance; light pink buds, opening to creamy-white flowers borne singly and in clusters of three to five; upright, vigorous habit; and easy propagation from softwood cuttings."
            },
            "slug": "Information-retrieval-using-statistical-Hull",
            "title": {
                "fragments": [],
                "text": "Information retrieval using statistical classification"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A miniature rose plant having sweet fragrance; light pink buds, opening to creamy-white flowers borne singly and in clusters of three to five; upright, vigorous habit; and easy propagation from softwood cuttings."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "In analogy to the way \nthat non\u00ad linear RDA generalizes linear LDA, linear neural networks have a simple non-linear extension: \nneural networks with hidden units, corresponding to feature detectors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "Pre\u00advious work [20] suggests that RDA does not improve performance when applied to the LSI \nrepresentation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "We also provide evidence that non-linear extensions of \nthe classi\u00adfiers (RDA and non-linem neural networks) do not improve perfor\u00admance, probably because there \nis not enough information in the Tip\u00adster data collection to accurately learn complex models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "RDA uses a pair of shrink\u00adage parameters to create \na very general family of estimators for the group covariance matrices."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 70
                            }
                        ],
                        "text": "However, previous experiments have not found much benefit to applying RDA to the routing problem \n[20]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "RDA \nselects the optimal val\u00adues for the shrinkage parameters based on cross-validation over the training \nset."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "One might be able to improve performance for wordbased features by applying regularized discriminant analysis [10], which uses cross-validation to adjust for this problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 327,
                                "start": 324
                            }
                        ],
                        "text": "However, QDA is only effective when the number of elements in each \ngroup is significant] y larger than the number of feature variables, which is almost never the case for \nthe routing problem because relevant documents are rel\u00adatively rare, There is a more well-behaved alternative \nknown as Regularized Discriminant Analysis (RDA) [10]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "There is a more well-behaved alternative known as Regularized Discriminant Analysis (RDA) [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Regularizeddiscriminant analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the American Statistical Association,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 126123958,
            "fieldsOfStudy": [],
            "id": "358fe49d4eab63e89ce9ca21de4f35ea27d078e4",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalized Linear Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[ 26 ] and the Newton-Raphson method of numerical optimization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117796698,
            "fieldsOfStudy": [],
            "id": "ea54f0c0568cab38619ee51e6ac021e76d6a6559",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalized Linear Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the 3rd Text Retrieval Conference (TREC-3)"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 3rd Text Retrieval Conference (TREC-3)"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "Previous approaches to routing and text categorization [24] have used classification trees [33, 22], Bayesian networks [6], Bayesian classifiers [22, 23], rules induction [1], nearest-neighbor techniques [25, 36], logistic regression [5], least-square methods [11], discriminant analysis [19], and neural networks [32, 34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Special issue on text categorization. guest editorial"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Transactions on Information Systems,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ", Richard Durbin , Richard Golden , and Yves Chauvin . Backpropagation : The basic theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Overview of the first tree conference"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of SIGIR '93"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Conference Proceedings of RIAO '91, Intelligent Text and Image Handling"
            },
            "venue": {
                "fragments": [],
                "text": "Conference Proceedings of RIAO '91, Intelligent Text and Image Handling"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ","
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Yves Chauvin . Backpropagation : The basic theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Okapi at tree-3"
            },
            "venue": {
                "fragments": [],
                "text": "Text Retrieval Conference 3 (preproceedings)"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Friedman . Regularizeddiscriminant analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Jour - nal of the American Statistical Association"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "The optimal value of 5 is derived using maximum likelihood [26] and the Newton-Raphson method of numerical optimization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalized Linear Models, chapter 4, pages 101\u2013123"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hearst . Multiparagraph segmentation of expository discourse"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 32 nd Meeting of the Association for Computational Linguistics , June"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gnanadesikam Methods for Statistical Data Analysis of A4ultivariate Observations"
            },
            "venue": {
                "fragments": [],
                "text": "Gnanadesikam Methods for Statistical Data Analysis of A4ultivariate Observations"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Friedman . Regularized discriminant analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Jour - nal of the American Statistical Association"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the 2nd Text Retrieval Conference (TREC-2)"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2nd Text Retrieval Conference (TREC-2)"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hearst . Multi - paragraph segmentation of expository discourse"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 3 rd Text Retrieval Conference ( TREC - 3 )"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hull . Information Retrieval using Statistical Classification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "We also break up documents into chunks of about 250 terms, called text-tiles [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multi-paragraph segmentation of expository discourse"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the 32nd Meeting of the Association for Computational Linguistics,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Retrieval using Statistical Classification Experiment with a component theory of probabilistic information retrieval based on single terms as document components"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Transactions on Information Systems"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tree - 2 routing and ad - hoc retrieval evahtation using the INQUERY system . 1994"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 19,
            "result": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 54,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/A-comparison-of-classifiers-and-document-for-the-Sch\u00fctze-Hull/92062ccb796efbf56fe1ae2dcc8b3a943a2c989b?sort=total-citations"
}