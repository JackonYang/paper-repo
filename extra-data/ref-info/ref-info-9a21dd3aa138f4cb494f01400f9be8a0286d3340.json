{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6141636,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b1a8b66a5ea2c3431911e220499c6481bb4231c3",
            "isKey": false,
            "numCitedBy": 567,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper develops a new approach for extremely fast detection in domains where the distribution of positive and negative examples is highly skewed (e.g. face detection or database retrieval). In such domains a cascade of simple classifiers each trained to achieve high detection rates and modest false positive rates can yield a final detector with many desirable features: including high detection rates, very low false positive rates, and fast performance. Achieving extremely high detection rates, rather than low error, is not a task typically addressed by machine learning algorithms. We propose a new variant of AdaBoost as a mechanism for training the simple classifiers used in the cascade. Experimental results in the domain of face detection show the training algorithm yields significant improvements in performance over conventional AdaBoost. The final face detection system can process 15 frames per second, achieves over 90% detection, and a false positive rate of 1 in a 1,000,000."
            },
            "slug": "Fast-and-Robust-Classification-using-Asymmetric-and-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Fast and Robust Classification using Asymmetric AdaBoost and a Detector Cascade"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A new variant of AdaBoost is proposed as a mechanism for training the simple classifiers used in the cascade in domains where the distribution of positive and negative examples is highly skewed (e.g. face detection or database retrieval)."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145736680"
                        ],
                        "name": "S. Brubaker",
                        "slug": "S.-Brubaker",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Brubaker",
                            "middleNames": [
                                "Charles"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Brubaker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31562428"
                        ],
                        "name": "M. D. Mullin",
                        "slug": "M.-D.-Mullin",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Mullin",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. D. Mullin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 130
                            }
                        ],
                        "text": "The conceptual and computational complexity of the training process has led to many papers proposing improvements and refinements [1, 2, 4, 5, 9, 14, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15772099,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "723f12c9eebea3e7ccb51ff06856780c74850626",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Cascades of boosted ensembles have become popular in the object detection community following their highly successful introduction in the face detector of Viola and Jones [1]. In this paper, we explore several aspects of this architecture that have not yet received adequate attention: decision points of cascade stages, faster ensemble learning, and stronger weak hypotheses. We present a novel strategy to determine the appropriate balance between false positive and detection rates in the individual stages of the cascade based on a probablistic model of the overall cascade's performance. To improve the training time of individual stages, we explore the use of feature filtering before the application of Adaboost. Finally, we show that the use of stronger weak hypotheses based on CART can significantly improve upon the standard face detection results on the CMU-MIT data set."
            },
            "slug": "Towards-Optimal-Training-of-Cascaded-Detectors-Brubaker-Mullin",
            "title": {
                "fragments": [],
                "text": "Towards Optimal Training of Cascaded Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel strategy to determine the appropriate balance between false positive and detection rates in the individual stages of the cascade based on a probablistic model of the overall cascade's performance is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808816"
                        ],
                        "name": "Jianxin Wu",
                        "slug": "Jianxin-Wu",
                        "structuredName": {
                            "firstName": "Jianxin",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianxin Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31562428"
                        ],
                        "name": "M. D. Mullin",
                        "slug": "M.-D.-Mullin",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Mullin",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. D. Mullin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 412675,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a55afef9df6e1315230726b216fa245b6c9d160",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The detection of faces in images is fundamentally a rare event detection problem. Cascade classifiers provide an efficient computational solution, by leveraging the asymmetry in the distribution of faces vs. non-faces. Training a cascade classifier in turn requires a solution for the following subproblems: Design a classifier for each node in the cascade with very high detection rate but only moderate false positive rate. While there are a few strategies in the literature for indirectly addressing this asymmetric node learning goal, none of them are based on a satisfactory theoretical framework. We present a mathematical characterization of the node-learning problem and describe an effective closed form approximation to the optimal solution, which we call the Linear Asymmetric Classifier (LAC). We first use AdaBoost or AsymBoost to select features, and use LAC to learn a linear discriminant function to achieve the node learning goal. Experimental results on face detection show that LAC can improve the detection performance in comparison to standard methods. We also show that Fisher Discriminant Analysis on the features selected by AdaBoost yields better performance than AdaBoost itself."
            },
            "slug": "Linear-Asymmetric-Classifier-for-cascade-detectors-Wu-Mullin",
            "title": {
                "fragments": [],
                "text": "Linear Asymmetric Classifier for cascade detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experimental results on face detection show that LAC can improve the detection performance in comparison to standard methods, and it is shown that Fisher Discriminant Analysis on the features selected by AdaBoost yields better performance than AdaBoost itself."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144739319"
                        ],
                        "name": "R. Lienhart",
                        "slug": "R.-Lienhart",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Lienhart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lienhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144789920"
                        ],
                        "name": "A. Kuranov",
                        "slug": "A.-Kuranov",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Kuranov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kuranov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3066817"
                        ],
                        "name": "V. Pisarevsky",
                        "slug": "V.-Pisarevsky",
                        "structuredName": {
                            "firstName": "Vadim",
                            "lastName": "Pisarevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Pisarevsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8862236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67c63f6b3eeb0b619d6306fcf1c4b144710f79b0",
            "isKey": false,
            "numCitedBy": 937,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently Viola et al. have introduced a rapid object detection scheme based on a boosted cascade of simple feature classifiers. In this paper we introduce and empirically analysis two extensions to their approach: Firstly, a novel set of rotated haar-like features is introduced. These novel features significantly enrich the simple features of [6] and can also be calculated efficiently. With these new rotated features our sample face detector shows off on average a 10% lower false alarm rate at a given hit rate. Secondly, we present a through analysis of different boosting algorithms (namely Discrete, Real and Gentle Adaboost) and weak classifiers on the detection performance and computational complexity. We will see that Gentle Adaboost with small CART trees as base classifiers outperform Discrete Adaboost and stumps. The complete object detection training and detection system as well as a trained face detector are available in the Open Computer Vision Library at sourceforge.net [8]."
            },
            "slug": "Empirical-Analysis-of-Detection-Cascades-of-Boosted-Lienhart-Kuranov",
            "title": {
                "fragments": [],
                "text": "Empirical Analysis of Detection Cascades of Boosted Classifiers for Rapid Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel set of rotated haar-like features is introduced that significantly enrich the simple features of [6] and can also be calculated efficiently and present a through analysis of different boosting algorithms and weak classifiers on the detection performance and computational complexity."
            },
            "venue": {
                "fragments": [],
                "text": "DAGM-Symposium"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109292017"
                        ],
                        "name": "Cha Zhang",
                        "slug": "Cha-Zhang",
                        "structuredName": {
                            "firstName": "Cha",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cha Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 105
                            }
                        ],
                        "text": "Note the soft cascade\nis similar to, but simpler than both the boosting chain approach of Xiao, Zhu, and Zhang and the WaldBoost approach of Sochman and Matas."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 67
                            }
                        ],
                        "text": "Among them, three are closely related to this paper: Xiao, Zhu and Zhang[15], Sochman and Matas[9], and Bourdev and Brandt[1]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "Two papers which have fundamentally integrated this observation into the training process are Nowlan and Platt [6] and more recently by Viola, Platt, and Zhang [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7564408,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "521768f7772163bc7c57ae2c9855889abb747fbb",
            "isKey": false,
            "numCitedBy": 772,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A good image object detection algorithm is accurate, fast, and does not require exact locations of objects in a training set. We can create such an object detector by taking the architecture of the Viola-Jones detector cascade and training it with a new variant of boosting that we call MIL-Boost. MILBoost uses cost functions from the Multiple Instance Learning literature combined with the AnyBoost framework. We adapt the feature selection criterion of MILBoost to optimize the performance of the Viola-Jones cascade. Experiments show that the detection rate is up to 1.6 times better using MILBoost. This increased detection rate shows the advantage of simultaneously learning the locations and scales of the objects in the training set along with the parameters of the classifier."
            },
            "slug": "Multiple-Instance-Boosting-for-Object-Detection-Viola-Platt",
            "title": {
                "fragments": [],
                "text": "Multiple Instance Boosting for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "MILBoost adapts the feature selection criterion of MILBoost to optimize the performance of the Viola-Jones cascade to show the advantage of simultaneously learning the locations and scales of the objects in the training set along with the parameters of the classifier."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "It takes less than 2 days to train a classifier with 700 weak classifiers based on the Haar features [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "One very successful approach was initiated by Viola and Jones [11]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 24
                            }
                        ],
                        "text": "Like the original Viola-Jones proposal, the soft-cascade gradually gives up on a number of positive examples in an effort to aggressively reduce the number of negatives passing through the cascade."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 6
                            }
                        ],
                        "text": "Viola-Jones attempted to reject zero positive examples until this become impossible and then reluctantly gave up on one positive example at a time."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 24
                            }
                        ],
                        "text": "Detectors such as Viola-Jones, boosting chain, FloatBoost, and Wu et al. all requires manual tuning."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 16
                            }
                        ],
                        "text": "Since the Viola-Jones training process requires CPU days to train and evaluate, it is difficult, if not impossible, to pick these parameters optimally."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2715202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63",
            "isKey": false,
            "numCitedBy": 17887,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection."
            },
            "slug": "Rapid-object-detection-using-a-boosted-cascade-of-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Rapid object detection using a boosted cascade of simple features"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates and the introduction of a new image representation called the \"integral image\" which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808816"
                        ],
                        "name": "Jianxin Wu",
                        "slug": "Jianxin-Wu",
                        "structuredName": {
                            "firstName": "Jianxin",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianxin Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31562428"
                        ],
                        "name": "M. D. Mullin",
                        "slug": "M.-D.-Mullin",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Mullin",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. D. Mullin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 130
                            }
                        ],
                        "text": "The conceptual and computational complexity of the training process has led to many papers proposing improvements and refinements [1, 2, 4, 5, 9, 14, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1886465,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "349ed21e62643371342a050a9f25d23d0991ca0b",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Face detection is a canonical example of a rare event detection problem, in which target patterns occur with much lower frequency than non-targets. Out of millions of face-sized windows in an input image, for example, only a few will typically contain a face. Viola and Jones recently proposed a cascade architecture for face detection which successfully addresses the rare event nature of the task. A central part of their method is a feature selection algorithm based on AdaBoost. We present a novel cascade learning algorithm based on forward feature selection which is two orders of magnitude faster than the Viola-Jones approach and yields classifiers of equivalent quality. This faster method could be used for more demanding classification tasks, such as on-line learning."
            },
            "slug": "Learning-a-Rare-Event-Detection-Cascade-by-Direct-Wu-Rehg",
            "title": {
                "fragments": [],
                "text": "Learning a Rare Event Detection Cascade by Direct Feature Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel cascade learning algorithm based on forward feature selection which is two orders of magnitude faster than the Viola-Jones approach and yields classifiers of equivalent quality could be used for more demanding classification tasks, such as on-line learning."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34679741"
                        ],
                        "name": "S. Li",
                        "slug": "S.-Li",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144850567"
                        ],
                        "name": "Long Zhu",
                        "slug": "Long-Zhu",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2651359"
                        ],
                        "name": "ZhenQiu Zhang",
                        "slug": "ZhenQiu-Zhang",
                        "structuredName": {
                            "firstName": "ZhenQiu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "ZhenQiu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154486"
                        ],
                        "name": "H. Shum",
                        "slug": "H.-Shum",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Shum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 130
                            }
                        ],
                        "text": "The conceptual and computational complexity of the training process has led to many papers proposing improvements and refinements [1, 2, 4, 5, 9, 14, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32107239,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c4fdffc12589f9f312a44802b8e2fe8311aa13e",
            "isKey": false,
            "numCitedBy": 462,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A new boosting algorithm, called FloatBoost, is proposed to overcome the monotonicity problem of the sequential AdaBoost learning. AdaBoost [1, 2] is a sequential forward search procedure using the greedy selection strategy. The premise oyered by the sequential procedure can be broken-down when the monotonicity assumption, i.e. that when adding a new feature to the current set, the value of the performance criterion does not decrease, is violated. FloatBoost incorporates the idea of Floating Search [3] into AdaBoost to solve the non-monotonicity problem encountered in the sequential search of AdaBoost.We then present a system which learns to detect multi-view faces using FloatBoost. The system uses a coarse-to-fine, simple-to-complex architecture called detector-pyramid. FloatBoost learns the component detectors in the pyramid and yields similar or higher classification accuracy than AdaBoost with a smaller number of weak classifiers. This work leads to the first real-time multi-view face detection system in the world. It runs at 200 ms per image of size 320x240 pixels on a Pentium-III CPU of 700 MHz. A live demo will be shown at the conference."
            },
            "slug": "Statistical-Learning-of-Multi-view-Face-Detection-Li-Zhu",
            "title": {
                "fragments": [],
                "text": "Statistical Learning of Multi-view Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "FloatBoost incorporates the idea of Floating Search into AdaBoost to solve the non-monotonicity problem encountered in the sequential search of AdaBoost and leads to the first real-time multi-view face detection system in the world."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1883588"
                        ],
                        "name": "Jun-Su Jang",
                        "slug": "Jun-Su-Jang",
                        "structuredName": {
                            "firstName": "Jun-Su",
                            "lastName": "Jang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun-Su Jang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699362"
                        ],
                        "name": "Jong-Hwan Kim",
                        "slug": "Jong-Hwan-Kim",
                        "structuredName": {
                            "firstName": "Jong-Hwan",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jong-Hwan Kim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10433390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8107aeb507ae6cb4a6d481ac128fb8d7f3b6838c",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Face detection task can be considered as a classifier training problem. It is a process to find the parameters of the classifier model by using the training data. To solve such a complex problem, evolutionary algorithm is employed in cascade structure of classifiers. In this paper, evolutionary pruning is proposed to reduce the number of weak classifiers in AdaBoost-based cascade detector while maintaining the detection accuracy. The computation time is proportional to the number of weak classifiers and therefore the reduction causes fast detection speed. The proposed cascade structure experimentally proves its efficient computation time. It is also compared with the state-of-the-art face detectors in terms of the detection accuracy, and the results show that the proposed method outperforms the previous studies."
            },
            "slug": "Evolutionary-Pruning-for-Fast-and-Robust-Face-Jang-Kim",
            "title": {
                "fragments": [],
                "text": "Evolutionary Pruning for Fast and Robust Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Empirical pruning is proposed to reduce the number of weak classifiers in AdaBoost-based cascade detector while maintaining the detection accuracy, and the results show that the proposed method outperforms the previous studies."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE International Conference on Evolutionary Computation"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2833915"
                        ],
                        "name": "J. Sochman",
                        "slug": "J.-Sochman",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Sochman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sochman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 7
                            }
                        ],
                        "text": "SochmanMatas used a ratio test to determine the rejection thresholds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 153
                            }
                        ],
                        "text": "Note the soft cascade\nis similar to, but simpler than both the boosting chain approach of Xiao, Zhu, and Zhang and the WaldBoost approach of Sochman and Matas."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 130
                            }
                        ],
                        "text": "The conceptual and computational complexity of the training process has led to many papers proposing improvements and refinements [1, 2, 4, 5, 9, 14, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "Among them, three are closely related to this paper: Xiao, Zhu and Zhang[15], Sochman and Matas[9], and Bourdev and Brandt[1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2576620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ed6fe696a3afc0154c45fecbef4c14e13b01a8a",
            "isKey": true,
            "numCitedBy": 272,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In many computer vision classification problems, both the error and time characterizes the quality of a decision. We show that such problems can be formalized in the framework of sequential decision-making. If the false positive and false negative error rates are given, the optimal strategy in terms of the shortest average time to decision (number of measurements used) is the Wald's sequential probability ratio test (SPRT). We built on the optimal SPRT test and enlarge its capabilities to problems with dependent measurements. We show how to overcome the requirements of SPRT - (i) a priori ordered measurements and (ii) known joint probability density functions. We propose an algorithm with near optimal time and error rate trade-off, called WaldBoost, which integrates the AdaBoost algorithm for measurement selection and ordering and the joint probability density estimation with the optimal SPRT decision strategy. The WaldBoost algorithm is tested on the face detection problem. The results are superior to the state-of-the-art methods in the average evaluation time and comparable in detection rates."
            },
            "slug": "WaldBoost-learning-for-time-constrained-sequential-Sochman-Matas",
            "title": {
                "fragments": [],
                "text": "WaldBoost - learning for time constrained sequential detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An algorithm with near optimal time and error rate trade-off is proposed, called WaldBoost, which integrates the AdaBoost algorithm for measurement selection and ordering and the joint probability density estimation with the optimal SPRT decision strategy."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2796017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b09ec0b350f8352bce46a2f5bf7ae97c83a7b9ca",
            "isKey": false,
            "numCitedBy": 11229,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second."
            },
            "slug": "Robust-Real-Time-Face-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-Time Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new image representation called the \u201cIntegral Image\u201d is introduced which allows the features used by the detector to be computed very quickly and a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769383"
                        ],
                        "name": "Lubomir D. Bourdev",
                        "slug": "Lubomir-D.-Bourdev",
                        "structuredName": {
                            "firstName": "Lubomir",
                            "lastName": "Bourdev",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lubomir D. Bourdev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145561604"
                        ],
                        "name": "Jonathan Brandt",
                        "slug": "Jonathan-Brandt",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Brandt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Brandt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "We use the same exponential function family as [1] for B-B, and adjust the control parameter \u03b1 in the range between \u221216 and 4."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 58
                            }
                        ],
                        "text": "The direct performance comparison between MIP and Bourdev-Brandt (B-B) was performed using the same soft-cascade and the same data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 100
                            }
                        ],
                        "text": "The proposed MIP-based detector yields a much lower false positive rate than the 25-feature Bourdev-Brandt soft cascade and nearly 35% improvement on detection speed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Bourdev and Brandt proposed a method for setting rejection thresholds based on an ad hoc detection rate target called a \u201crejection distribution vector\u201d, which is a parameterized exponential curve."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 111
                            }
                        ],
                        "text": "This is certainly true in our experiments, but it is also true in past papers (e.g., the two curves of Bourdev-Brandt soft cascade in Figure 3(a))."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 95
                            }
                        ],
                        "text": "In contrast, although the detection rate on the training set can also be guaranteed in Bourdev-Brandt\u2019s algorithm, there is no guarantee that false positive rate will not increase."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 115
                            }
                        ],
                        "text": "While with our detector the performance of B-B is acceptable even when \u03b1 = \u221216, the performance of the detector in [1] drops significantly from 37 features to 25 features, as shown in Fig."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Bourdev and Brandt coined the term, \u201csoft-cascade\u201d, where the entire detector is trained as a single strong classifier without stages (with 100\u2019s or 1000\u2019s of weak classifiers sometimes called \u201cfeatures\u201d)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 8
                            }
                        ],
                        "text": "Bourdev-Brandt propose reordering the weak classifiers based on the separation between the mean score of the positive examples and the mean score of the negative examples."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 130
                            }
                        ],
                        "text": "The conceptual and computational complexity of the training process has led to many papers proposing improvements and refinements [1, 2, 4, 5, 9, 14, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 93
                            }
                        ],
                        "text": "Figure 5: The detector performance comparison after applying MIP and Bourdev-Brandt\u2019s method [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 122
                            }
                        ],
                        "text": "Among them, three are closely related to this paper: Xiao, Zhu and Zhang[15], Sochman and Matas[9], and Bourdev and Brandt[1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 192358,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "9a0024fbad7fcda8af1d241064f0948a8365b969",
            "isKey": true,
            "numCitedBy": 379,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for training object detectors using a generalization of the cascade architecture, which results in a detection rate and speed comparable to that of the best published detectors while allowing for easier training and a detector with fewer features. In addition, the method allows for quickly calibrating the detector for a target detection rate, false positive rate or speed. One important advantage of our method is that it enables systematic exploration of the ROC surface, which characterizes the trade-off between accuracy and speed for a given classifier."
            },
            "slug": "Robust-object-detection-via-soft-cascade-Bourdev-Brandt",
            "title": {
                "fragments": [],
                "text": "Robust object detection via soft cascade"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A method for training object detectors using a generalization of the cascade architecture is described, which results in a detection rate and speed comparable to that of the best published detectors while allowing for easier training and a detector with fewer features."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069928477"
                        ],
                        "name": "Rong Xiao",
                        "slug": "Rong-Xiao",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Xiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144850567"
                        ],
                        "name": "Long Zhu",
                        "slug": "Long-Zhu",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 105
                            }
                        ],
                        "text": "Note the soft cascade\nis similar to, but simpler than both the boosting chain approach of Xiao, Zhu, and Zhang and the WaldBoost approach of Sochman and Matas."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 130
                            }
                        ],
                        "text": "The conceptual and computational complexity of the training process has led to many papers proposing improvements and refinements [1, 2, 4, 5, 9, 14, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "Among them, three are closely related to this paper: Xiao, Zhu and Zhang[15], Sochman and Matas[9], and Bourdev and Brandt[1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 154
                            }
                        ],
                        "text": "Two papers which have fundamentally integrated this observation into the training process are Nowlan and Platt [6] and more recently by Viola, Platt, and Zhang [12]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5093465,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76b9c2e83cd61029e36f1397286ac687d26957a6",
            "isKey": true,
            "numCitedBy": 188,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A general classification framework, called boosting chain, is proposed for learning boosting cascade. In this framework, a \"chain\" structure is introduced to integrate historical knowledge into successive boosting learning. Moreover, a linear optimization scheme is proposed to address the problems of redundancy in boosting learning and threshold adjusting in cascade coupling. By this means, the resulting classifier consists of fewer weak classifiers yet achieves lower error rates than boosting cascade in both training and test. Experimental comparisons of boosting chain and boosting cascade are provided through a face detection problem. The promising results clearly demonstrate the effectiveness made by boosting chain."
            },
            "slug": "Boosting-chain-learning-for-object-detection-Xiao-Zhu",
            "title": {
                "fragments": [],
                "text": "Boosting chain learning for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A linear optimization scheme is proposed to address the problems of redundancy in boosting learning and threshold adjusting in cascade coupling, and the resulting classifier consists of fewer weak classifiers yet achieves lower error rates than boosting cascade in both training and test."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8540654,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e56ae29377bff8e04336c778cac011f2bcf2b88",
            "isKey": false,
            "numCitedBy": 488,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a new learning framework - probabilistic boosting-tree (PBT), is proposed for learning two-class and multi-class discriminative models. In the learning stage, the probabilistic boosting-tree automatically constructs a tree in which each node combines a number of weak classifiers (evidence, knowledge,) into a strong classifier (a conditional posterior probability). It approaches the target posterior distribution by data augmentation (tree expansion) through a divide-and-conquer strategy. In the testing stage, the conditional probability is computed at each tree node based on the learned classifier, which guides the probability propagation in its sub-trees. The top node of the tree therefore outputs the overall posterior probability by integrating the probabilities gathered from its sub-trees. Also, clustering is naturally embedded in the learning phase and each sub-tree represents a cluster of certain level. The proposed framework is very general and it has interesting connections to a number of existing methods such as the A* algorithm, decision tree algorithms, generative models, and cascade approaches. In this paper, we show the applications of PBT for classification, detection, and object recognition. We have also applied the framework in segmentation"
            },
            "slug": "Probabilistic-boosting-tree:-learning-models-for-Tu",
            "title": {
                "fragments": [],
                "text": "Probabilistic boosting-tree: learning discriminative models for classification, recognition, and clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The applications of PBT for classification, detection, and object recognition are shown and the framework has interesting connections to a number of existing methods such as the A* algorithm, decision tree algorithms, generative models, and cascade approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39628912"
                        ],
                        "name": "H. Luo",
                        "slug": "H.-Luo",
                        "structuredName": {
                            "firstName": "Huitao",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Luo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 130
                            }
                        ],
                        "text": "The conceptual and computational complexity of the training process has led to many papers proposing improvements and refinements [1, 2, 4, 5, 9, 14, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5251450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12231d92eea4b89d4f3476d0f900b244d8e4e26b",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present two optimization algorithms for the design of a cascade of classifiers, which is becoming a popular choice for many classification problems. Both algorithms represent each node classifier of a cascade using a high-level abstraction model and attempt to jointly optimize the setting of the thresholding parameters of all the node classifiers within the cascade. We applied both algorithms to optimize the famous Viola and Jones face detector and one of them in particular greatly improved the performance. We believe both algorithms can serve as a useful post-processing process for general cascaded classifier design."
            },
            "slug": "Optimization-design-of-cascaded-classifiers-Luo",
            "title": {
                "fragments": [],
                "text": "Optimization design of cascaded classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "Two optimization algorithms for the design of a cascade of classifiers are presented, which is becoming a popular choice for many classification problems, and can serve as a useful post-processing process for general cascaded classifier design."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143774737"
                        ],
                        "name": "J. Shotton",
                        "slug": "J.-Shotton",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Shotton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shotton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716777"
                        ],
                        "name": "A. Criminisi",
                        "slug": "A.-Criminisi",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Criminisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Criminisi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6075144,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb444dc25bab36a8e273ed654d49e3841905e5af",
            "isKey": false,
            "numCitedBy": 1349,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new approach to learning a discriminative model of object classes, incorporating appearance, shape and context information efficiently. The learned model is used for automatic visual recognition and semantic segmentation of photographs. Our discriminative model exploits novel features, based on textons, which jointly model shape and texture. Unary classification and feature selection is achieved using shared boosting to give an efficient classifier which can be applied to a large number of classes. Accurate image segmentation is achieved by incorporating these classifiers in a conditional random field. Efficient training of the model on very large datasets is achieved by exploiting both random feature selection and piecewise training methods. \n \nHigh classification and segmentation accuracy are demonstrated on three different databases: i) our own 21-object class database of photographs of real objects viewed under general lighting conditions, poses and viewpoints, ii) the 7-class Corel subset and iii) the 7-class Sowerby database used in [1]. The proposed algorithm gives competitive results both for highly textured (e.g. grass, trees), highly structured (e.g. cars, faces, bikes, aeroplanes) and articulated objects (e.g. body, cow)."
            },
            "slug": "TextonBoost:-Joint-Appearance,-Shape-and-Context-Shotton-Winn",
            "title": {
                "fragments": [],
                "text": "TextonBoost: Joint Appearance, Shape and Context Modeling for Multi-class Object Recognition and Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A new approach to learning a discriminative model of object classes, incorporating appearance, shape and context information efficiently, is proposed, which is used for automatic visual recognition and semantic segmentation of photographs."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115595183"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679380"
                        ],
                        "name": "H. Ai",
                        "slug": "H.-Ai",
                        "structuredName": {
                            "firstName": "Haizhou",
                            "lastName": "Ai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144528373"
                        ],
                        "name": "Chang Huang",
                        "slug": "Chang-Huang",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710195"
                        ],
                        "name": "S. Lao",
                        "slug": "S.-Lao",
                        "structuredName": {
                            "firstName": "Shihong",
                            "lastName": "Lao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1436853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73d8fbafae3b09568ec63e8683b563d395f48308",
            "isKey": false,
            "numCitedBy": 396,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a rotation invariant multi-view face detection method based on Real Adaboost algorithm. Human faces are divided into several categories according to the variant appearance from different viewpoints. For each view category, weak classifiers are configured as confidence-rated look-up-table (LUT) of Haar feature. Real Adaboost algorithm is used to boost these weak classifiers and construct a nesting-structured face detector. To make it rotation invariant, we divide the whole 360-degree range into 12 sub-ranges and construct their corresponding view based detectors separately. To improve performance, a pose estimation method is introduced and results in a processing speed of four frames per second on 320/spl times/240 sized image. Experiments on faces with 360-degree in-plane rotation and /spl mnplus/90-degree out-of-plane rotation are reported, of which the frontal face detector subsystem retrieves 94.5% of the faces with 57 false alarms on the CMU+MlT frontal face test set and the multi-view face detector subsystem retrieves 89.8% of the faces with 221 false alarms on the CMU profile face test set."
            },
            "slug": "Fast-rotation-invariant-multi-view-face-detection-Wu-Ai",
            "title": {
                "fragments": [],
                "text": "Fast rotation invariant multi-view face detection based on real Adaboost"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A rotation invariant multi-view face detection method based on Real Adaboost algorithm is proposed and a pose estimation method is introduced and results in a processing speed of four frames per second on 320/spl times/240 sized image."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth IEEE International Conference on Automatic Face and Gesture Recognition, 2004. Proceedings."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108960018"
                        ],
                        "name": "Xiaoming Liu",
                        "slug": "Xiaoming-Liu",
                        "structuredName": {
                            "firstName": "Xiaoming",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoming Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1560575,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df412c52c929d6761ad4899b15f73478a9c96645",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a discriminative framework for efficiently aligning images. Although conventional active appearance models (AAM)-based approaches have achieved some success, they suffer from the generalization problem, i.e., how to align any image with a generic model. We treat the iterative image alignment problem as a process of maximizing the score of a trained two-class classifier that is able to distinguish correct alignment (positive class) from incorrect alignment (negative class). During the modeling stage, given a set of images with ground truth landmarks, we train a conventional point distribution model (PDM) and a boosting-based classifier, which we call boosted appearance model (BAM). When tested on an image with the initial landmark locations, the proposed algorithm iteratively updates the shape parameters of the PDM via the gradient ascent method such that the classification score of the warped image is maximized. The proposed framework is applied to the face alignment problem. Using extensive experimentation, we show that, compared to the AAM-based approach, this framework greatly improves the robustness, accuracy and efficiency of face alignment by a large margin, especially for unseen data."
            },
            "slug": "Generic-Face-Alignment-using-Boosted-Appearance-Liu",
            "title": {
                "fragments": [],
                "text": "Generic Face Alignment using Boosted Appearance Model"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A discriminative framework for efficiently aligning images that greatly improves the robustness, accuracy and efficiency of face alignment by a large margin, especially for unseen data."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 62
                            }
                        ],
                        "text": "The testing set is the standard MIT+CMU frontal face database [10, 7], which consists of 125 grayscale images containing 483 labeled frontal faces."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d76ef8e61395a6e9c32627f1f108772d084e2e9",
            "isKey": false,
            "numCitedBy": 4156,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural Network-Based Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071710863"
                        ],
                        "name": "S. Thompson",
                        "slug": "S.-Thompson",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Thompson",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thompson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34196528,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee18404c8a1a693f815fcfb1230468b78dba052a",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pruning-boosted-classifiers-with-a-real-valued-Thompson",
            "title": {
                "fragments": [],
                "text": "Pruning boosted classifiers with a real valued genetic algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Knowl. Based Syst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784682"
                        ],
                        "name": "T. Hastie",
                        "slug": "T.-Hastie",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Hastie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hastie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761784"
                        ],
                        "name": "R. Tibshirani",
                        "slug": "R.-Tibshirani",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tibshirani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tibshirani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "Weight trimming was proposed by Friedman, Hastie and Tibshirani [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "\u2022 Perform weight trimming [3] to trim 10% of the negative weights."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2354909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "277c2139eb4e11455a0b16759b7249c3b95b479e",
            "isKey": false,
            "numCitedBy": 1349,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The main and important contribution of this paper is in establishing a connection between boosting, a newcomer to the statistics scene, and additive models. One of the main properties of boosting that has made it interesting to statisticians and others is its relative (but not complete) immunity to overrtting. As pointed out by the authors, the current paper does not address this issue. Leo Breiman 1] tried to explain this behaviour in terms of bias and variance. In our paper with Bartlett and Lee 4], we gave an explanation in terms of the \\margins\" of the training examples and the VC-dimension of the base class. Breiman, as well as the current paper, point out that our bounds are very rough and yield bounds that are not useful in practice. While this is clearly true at this time, it is also true that the analysis given by Breiman and by this paper yield no provable bounds whatsoever. It is completely unclear whether this analysis can be used to predict the performance of classiication rules outside of the training sample. At the root of this argument about boosting is a much more fundamental argument about the type of prior assumptions that one should make when embarking on the task of inducing a classiication rule from data. The assumption that seems to underlie the use of maximum likelihood in the 1"
            },
            "slug": "Discussion-of-the-Paper-\\additive-Logistic-a-View-Friedman-Hastie",
            "title": {
                "fragments": [],
                "text": "Discussion of the Paper \\additive Logistic Regression: a Statistical View of Boosting\" By"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This paper establishes a connection between boosting, a newcomer to the statistics scene, and additive models and investigates the assumption that seems to underlie the use of maximum likelihood in the additive models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3302531"
                        ],
                        "name": "David Kauchak",
                        "slug": "David-Kauchak",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kauchak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Kauchak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1855302"
                        ],
                        "name": "Joseph Smarr",
                        "slug": "Joseph-Smarr",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Smarr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph Smarr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722831"
                        ],
                        "name": "C. Elkan",
                        "slug": "C.-Elkan",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Elkan",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Elkan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10817004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f9f027cd0f176c355ad6d605045b98243c912c4",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we examine an important recent rule-based information extraction (IE) technique named Boosted Wrapper Induction (BWI) by conducting experiments on a wider variety of tasks than previously studied, including tasks using several collections of natural text documents. We investigate systematically how each algorithmic component of BWI, in particular boosting, contributes to its success. We show that the benefit of boosting arises from the ability to reweight examples to learn specific rules (resulting in high precision) combined with the ability to continue learning rules after all positive examples have been covered (resulting in high recall). As a quantitative indicator of the regularity of an extraction task, we propose a new measure that we call the SWI ratio. We show that this measure is a good predictor of IE success and a useful tool for analyzing IE tasks. Based on these results, we analyze the strengths and limitations of BWI. Specifically, we explain limitations in the information made available, and in the representations used. We also investigate the consequences of the fact that confidence values returned during extraction are not true probabilities. Next, we investigate the benefits of including grammatical and semantic information for natural text documents, as well as parse tree and attribute-value information for XML and HTML documents. We show experimentally that incorporating even limited grammatical information can increase the regularity of natural text extraction tasks, resulting in improved performance. We conclude with proposals for enriching the representational power of BWI and other IE methods to exploit these and other types of regularities."
            },
            "slug": "Sources-of-Success-for-Boosted-Wrapper-Induction-Kauchak-Smarr",
            "title": {
                "fragments": [],
                "text": "Sources of Success for Boosted Wrapper Induction"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown experimentally that incorporating even limited grammatical information can increase the regularity of natural text extraction tasks, resulting in improved performance, and proposals for enriching the representational power of BWI and other IE methods to exploit these and other types of regularities."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The testing set is the standard MIT+CMU frontal face database [ 10 , 7], which consists of 125 grayscale images containing 483 labeled frontal faces."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7164794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088eb2d102c6bb486f5270d0b2adff76961994cf",
            "isKey": false,
            "numCitedBy": 2061,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system."
            },
            "slug": "Example-Based-Learning-for-View-Based-Human-Face-Sung-Poggio",
            "title": {
                "fragments": [],
                "text": "Example-Based Learning for View-Based Human Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An example-based learning approach for locating vertical frontal views of human faces in complex scenes and shows empirically that the distance metric adopted for computing difference feature vectors, and the \"nonface\" clusters included in the distribution-based model, are both critical for the success of the system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143634393"
                        ],
                        "name": "Rong Yan",
                        "slug": "Rong-Yan",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7661726"
                        ],
                        "name": "Alexander Hauptmann",
                        "slug": "Alexander-Hauptmann",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Hauptmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Hauptmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1666704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74d6986ebf77c73d61339d1345802bd58b295242",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Video retrieval compares multimedia queries to a video collection in multiple dimensions and combines all the retrieval scores into a final ranking. Although text are the most reliable feature for video retrieval, features from other modalities can provide complementary information. This paper presents a reranking framework for video retrieval to augment retrieval based on text features with other evidence. We also propose a boosted reranking algorithm called Co-Retrieval, which combines a boosting type algorithm and a noisy label prediction scheme to automatically select the most useful weak hypotheses for different queries. The proposed approach is evaluated with queries and video from the 65-hour test collection of the 2003 NIST TRECVID evaluation."
            },
            "slug": "Co-retrieval:-A-Boosted-Reranking-Approach-for-Yan-Hauptmann",
            "title": {
                "fragments": [],
                "text": "Co-retrieval: A Boosted Reranking Approach for Video Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A reranking framework for video retrieval to augment retrieval based on text features with other evidence is presented and a boosted reranking algorithm called Co-Retrieval is proposed, which combines a boosting type algorithm and a noisy label prediction scheme to automatically select the most useful weak hypotheses for different queries."
            },
            "venue": {
                "fragments": [],
                "text": "CIVR"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109292017"
                        ],
                        "name": "Cha Zhang",
                        "slug": "Cha-Zhang",
                        "structuredName": {
                            "firstName": "Cha",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cha Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183557"
                        ],
                        "name": "Pei Yin",
                        "slug": "Pei-Yin",
                        "structuredName": {
                            "firstName": "Pei",
                            "lastName": "Yin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pei Yin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145459057"
                        ],
                        "name": "Y. Rui",
                        "slug": "Y.-Rui",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Rui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145952419"
                        ],
                        "name": "Ross Cutler",
                        "slug": "Ross-Cutler",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Cutler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross Cutler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9733446,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d7ddd2bb128cf9110d2701f4c511ef7d53f97e1",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Speaker detection is a very important task in distributed meeting applications. This paper discusses a number of challenges we met while designing a speaker detector for the Microsoft RoundTable distributed meeting device, and proposes a boosting-based multimodal speaker detection (BMSD) algorithm. Instead of performing sound source localization (SSL) and multi-person detection (MPD) separately and subsequently fusing their individual results, the proposed algorithm uses boosting to select features from a combined pool of both audio and visual features simultaneously. The result is a very accurate speaker detector with extremely high efficiency. The algorithm reduces the error rate of SSL-only approach by 47%, and the SSL and MPD fusion approach by 27%"
            },
            "slug": "Boosting-Based-Multimodal-Speaker-Detection-for-Zhang-Yin",
            "title": {
                "fragments": [],
                "text": "Boosting-Based Multimodal Speaker Detection for Distributed Meetings"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A boosting-based multimodal speaker detection (BMSD) algorithm that uses boosting to select features from a combined pool of both audio and visual features simultaneously, resulting in a very accurate speaker detector with extremely high efficiency."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Workshop on Multimedia Signal Processing"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802785"
                        ],
                        "name": "S. Nowlan",
                        "slug": "S.-Nowlan",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Nowlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nowlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 111
                            }
                        ],
                        "text": "Two papers which have fundamentally integrated this observation into the training process are Nowlan and Platt [6] and more recently by Viola, Platt, and Zhang [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9066905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b234385356cb10d448908cef49584bece15d94b",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a system that can track a hand in a sequence of video frames and recognize hand gestures in a user-independent manner. The system locates the hand in each video frame and determines if the hand is open or closed. The tracking system is able to track the hand to within \u00b110 pixels of its correct location in 99.7% of the frames from a test set containing video sequences from 18 different individuals captured in 18 different room environments. The gesture recognition network correctly determines if the hand being tracked is open or closed in 99.1% of the frames in this test set. The system has been designed to operate in real time with existing hardware."
            },
            "slug": "A-Convolutional-Neural-Network-Hand-Tracker-Nowlan-Platt",
            "title": {
                "fragments": [],
                "text": "A Convolutional Neural Network Hand Tracker"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A system that can track a hand in a sequence of video frames and recognize hand gestures in a user-independent manner and is designed to operate in real time with existing hardware is described."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152836534"
                        ],
                        "name": "Li Zhang",
                        "slug": "Li-Zhang",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679380"
                        ],
                        "name": "H. Ai",
                        "slug": "H.-Ai",
                        "structuredName": {
                            "firstName": "Haizhou",
                            "lastName": "Ai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2412964"
                        ],
                        "name": "Shengjun Xin",
                        "slug": "Shengjun-Xin",
                        "structuredName": {
                            "firstName": "Shengjun",
                            "lastName": "Xin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shengjun Xin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144528373"
                        ],
                        "name": "Chang Huang",
                        "slug": "Chang-Huang",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144168"
                        ],
                        "name": "Shuichiro Tsukiji",
                        "slug": "Shuichiro-Tsukiji",
                        "structuredName": {
                            "firstName": "Shuichiro",
                            "lastName": "Tsukiji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuichiro Tsukiji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710195"
                        ],
                        "name": "S. Lao",
                        "slug": "S.-Lao",
                        "structuredName": {
                            "firstName": "Shihong",
                            "lastName": "Lao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52862068,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "acaefc4c312b31660d874893f794ed7189c2a4dc",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a robust face alignment algorithm with a novel discriminative local texture model. Different from the conventional descriptive PCA local texture model in ASM, classifiers using LUT-type Haar-like features are trained from a large data set as local texture model. The strong discriminative power of the classifier greatly improves the accuracy and robustness of local searching on faces with expression variation and ambiguous contours. A Bayesian framework is configured for shape parameter optimization and the algorithm is implemented in a hierarchical structure for efficiency. Extensive experiments are reported to show its accuracy and robustness."
            },
            "slug": "Robust-face-alignment-based-on-local-texture-Zhang-Ai",
            "title": {
                "fragments": [],
                "text": "Robust face alignment based on local texture classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A robust face alignment algorithm with a novel discriminative local texture model based on LUT-type Haar-like features that greatly improves the accuracy and robustness of local searching on faces with expression variation and ambiguous contours."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Image Processing 2005"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 94
                            }
                        ],
                        "text": "For each rectangle filter in the pool, construct a weak classifier that minimizes the Z score [8] under the current set of weights \u03c9t,i, i \u2208 Q."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12646365,
            "fieldsOfStudy": [],
            "id": "14e53403a0055dbe5faaf9f1f3be96ca0e692a4d",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improved Boosting Algorithms using Confidence-Rated Predictions"
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 62
                            }
                        ],
                        "text": "The testing set is the standard MIT+CMU frontal face database [10, 7], which consists of 125 grayscale images containing 483 labeled frontal faces."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Example-based learning for view-based face detection"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. on PAMI,"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 29,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Multiple-Instance-Pruning-For-Learning-Efficient-Zhang-Viola/9a21dd3aa138f4cb494f01400f9be8a0286d3340?sort=total-citations"
}