{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47749181"
                        ],
                        "name": "M. Franzini",
                        "slug": "M.-Franzini",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Franzini",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Franzini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2819135"
                        ],
                        "name": "M. Witbrock",
                        "slug": "M.-Witbrock",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Witbrock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Witbrock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429215"
                        ],
                        "name": "Kai-Fu Lee",
                        "slug": "Kai-Fu-Lee",
                        "structuredName": {
                            "firstName": "Kai-Fu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Fu Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61288855,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1307b3953cc9d272411e57011a40e4fe74e5f0b0",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors have applied connectionist learning procedures to speaker-independent continuous recognition, creating a system which has achieved 97% word accuracy and 91% sentence accuracy in preliminary tests on the TI/NBS connected-digits database. The system uses a four-layer back-propagation network with recurrent connections to generate and refine hypotheses about the identity of an utterance over successive intervals. The hypotheses generated by the network are used as input to a Markov-chain-based Viterbi recognizer which produces a final identification of the entire utterance.<<ETX>>"
            },
            "slug": "A-connectionist-approach-to-continuous-speech-Franzini-Witbrock",
            "title": {
                "fragments": [],
                "text": "A connectionist approach to continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors have applied connectionist learning procedures to speaker-independent continuous recognition, creating a system which has achieved 97% word accuracy and 91% sentence accuracy in preliminary tests on the TI/NBS connected-digits database."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40396597"
                        ],
                        "name": "Toshiyuki Hanazawa",
                        "slug": "Toshiyuki-Hanazawa",
                        "structuredName": {
                            "firstName": "Toshiyuki",
                            "lastName": "Hanazawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshiyuki Hanazawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9243990"
                        ],
                        "name": "K. Shikano",
                        "slug": "K.-Shikano",
                        "structuredName": {
                            "firstName": "Kiyohiro",
                            "lastName": "Shikano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shikano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49464494"
                        ],
                        "name": "Kevin J. Lang",
                        "slug": "Kevin-J.-Lang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Lang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12251177,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "834b3738673dacc767563c2714239852a8a6d4b4",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error.<<ETX>>"
            },
            "slug": "Phoneme-recognition:-neural-networks-vs.-hidden-vs.-Waibel-Hanazawa",
            "title": {
                "fragments": [],
                "text": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A time-delay neural network for phoneme recognition that was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation and does not rely on precise alignment or segmentation of the input."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862682"
                        ],
                        "name": "G. Doddington",
                        "slug": "G.-Doddington",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Doddington",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Doddington"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60507740,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "e2656c7c34cd19d131710aad96ea7d1b96440985",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A phonetically sensitive transformation of speech features has yielded significant improvement in speech-recognition performance. This (linear) transformation of the speech feature vector is designed to discriminate against out-of-class confusion data and is a function of phonetic state. Evaluation of the technique on the TI/NBS connected digit database demonstrates word (sentence) error rates of 0.5% (1.5%) for unknown-length strings and 0.2% (0.6%) for known-length strings. These error rates are two to three times lower than the best previously reported results and suggest that significant improvements in speech-recognition system performance can be achieved by better acoustic-phonetic modeling.<<ETX>>"
            },
            "slug": "Phonetically-sensitive-discriminants-for-improved-Doddington",
            "title": {
                "fragments": [],
                "text": "Phonetically sensitive discriminants for improved speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A phonetically sensitive transformation of speech features has yielded significant improvement in speech-recognition performance and is designed to discriminate against out-of-class confusion data and is a function of phonetic state."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2154317"
                        ],
                        "name": "J. Wilpon",
                        "slug": "J.-Wilpon",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Wilpon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wilpon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71520871"
                        ],
                        "name": "B.-H. Juang",
                        "slug": "B.-H.-Juang",
                        "structuredName": {
                            "firstName": "B.-H.",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B.-H. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37344085,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff07698f776f27878fa904f7f51220e1cdf0b744",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms for recognizing strings of connected words from whole-word patterns have become highly efficient and accurate, although computation rates remain high. Even the most ambitious connected-word recognition task is practical with today's integrated circuit technology, but extracting reliable, robust whole-word reference patterns still is difficult. In the past, connected-word recognizers relied on isolated-word reference patterns or patterns derived from a limited context (e.g., the middle digit from strings of three digits). These whole-word patterns were adequate for slow rates of articulated speech, but not for strings of words spoken at high rates (e.g., about 200 to 300 words per minute). To alleviate this difficulty, a segmental k-means training procedure was used to extract whole-word patterns from naturally spoken word strings. The segmented words are then used to create a set of word reference patterns for recognition. Recognition string accuracies were 98 to 99 percent for digits in variable length strings and 90 to 98 percent for sentences from an airline reservation task. These performance scores represent significant improvements over previous connected-word recognizers."
            },
            "slug": "A-segmental-k-means-training-procedure-for-word-Rabiner-Wilpon",
            "title": {
                "fragments": [],
                "text": "A segmental k-means training procedure for connected word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A segmental k-means training procedure was used to extract whole-word patterns from naturally spoken word strings to create a set of word reference patterns for recognition, and recognition string accuracies were significant improvements over previous connected-word recognizers."
            },
            "venue": {
                "fragments": [],
                "text": "AT&T Technical Journal"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112105858"
                        ],
                        "name": "William Y. Huang",
                        "slug": "William-Y.-Huang",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Huang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Y. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144990248"
                        ],
                        "name": "R. Lippmann",
                        "slug": "R.-Lippmann",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lippmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lippmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42048702,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7be696497de01c57b300e19feeb51a43934985a4",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Two approaches were explored which integrate neural net classifiers with Hidden Markov Model (HMM) speech recognizers. Both attempt to improve speech pattern discrimination while retaining the temporal processing advantages of HMMs. One approach used neural nets to provide second-stage discrimination following an HMM recognizer. On a small vocabulary task, Radial Basis Function (RBF) and back-propagation neural nets reduced the error rate substantially (from 7.9% to 4.2% for the RBF classifier). In a larger vocabulary task, neural net classifiers did not reduce the error rate. They, however, outperformed Gaussian, Gaussian mixture, and k-nearest neighbor (KNN) classifiers. In another approach, neural nets functioned as low-level acoustic-phonetic feature extractors. When classifying phonemes based on single 10 msec. frames, discriminant RBF neural net classifiers outperformed Gaussian mixture classifiers. Performance, however, differed little when classifying phones by accumulating scores across all frames in phonetic segments using a single node HMM recognizer."
            },
            "slug": "HMM-Speech-Recognition-with-Neural-Net-Huang-Lippmann",
            "title": {
                "fragments": [],
                "text": "HMM Speech Recognition with Neural Net Discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "Two approaches were explored which integrate neural net classifiers with Hidden Markov Model (HMM) speech recognizers to improve speech pattern discrimination while retaining the temporal processing advantages of HMMs."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60769407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1aa31d5deb45f477a6de45b3b75b62c7f4a213e7",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : This thesis examines the acoustic-modeling problem in automatic speech recognition from an information-theoretic point of view. This problem is to design a speech-recognition system which can extract from the speech waveform as much information as possible about the corresponding word sequence. The information extraction process is broken down into two steps: a signal processing step which converts a speech waveform into a sequence of information bearing acoustic feature vectors, and a step which models such a sequence. This thesis is primarily concerned with the use of hidden Markov models to model sequences of feature vectors which lie in a continuous space such as R sub N. It explores the trade-off between packing a lot of information into such sequences and being able to model them accurately. The difficulty of developing accurate models of continuous parameter sequences is addressed by investigating a method of parameter estimation which is specifically designed to cope with inaccurate modeling assumptions."
            },
            "slug": "The-acoustic-modeling-problem-in-automatic-speech-Brown",
            "title": {
                "fragments": [],
                "text": "The acoustic-modeling problem in automatic speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This thesis is primarily concerned with the use of hidden Markov models to model sequences of feature vectors which lie in a continuous space such as R sub N and explores the trade-off between packing a lot of information into such sequences and being able to model them accurately."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744408"
                        ],
                        "name": "J. Picone",
                        "slug": "J.-Picone",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Picone",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Picone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62059793,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "60902cbdc9ee53de02c6327ba0f73fca43337d7e",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A clustering algorithm is introduced that allows clustering of HMM (hidden Markov models) models directly. This clustering algorithm determines the appropriate duration profile for a recognition unit. High-performance speaker-independent digit recognition on a studio-quality connected-digit database is demonstrated using this algorithm.<<ETX>>"
            },
            "slug": "On-modeling-duration-in-context-in-speech-Picone",
            "title": {
                "fragments": [],
                "text": "On modeling duration in context in speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A clustering algorithm is introduced that allows clustering of HMM (hidden Markov models) models directly and high-performance speaker-independent digit recognition on a studio-quality connected-digit database is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054828791"
                        ],
                        "name": "R. G. Leonard",
                        "slug": "R.-G.-Leonard",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Leonard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. G. Leonard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42906443,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a33cb603f95ac7c65a445c9022d1d60f7821a5a1",
            "isKey": false,
            "numCitedBy": 645,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A large speech database has been collected for use in designing and evaluating algorithms for speaker independent recognition of connected digit sequences. This dialect balanced database consists of more than 25 thousand digit sequences spoken by over 300 men, women, and children. The data were collected in a quiet environment and digitized at 20 KHz. Formal human listening tests on this database provided certification of the labelling of the digit sequences, and also provided information about human recognition performance and the inherent recognizability of the data."
            },
            "slug": "A-database-for-speaker-independent-digit-Leonard",
            "title": {
                "fragments": [],
                "text": "A database for speaker-independent digit recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A large speech database has been collected for use in designing and evaluating algorithms for speaker independent recognition of connected digit sequences and formal human listening tests on this database provided certification of the labelling of the digit sequences."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2546518"
                        ],
                        "name": "D. Plaut",
                        "slug": "D.-Plaut",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Plaut",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Plaut"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802785"
                        ],
                        "name": "S. Nowlan",
                        "slug": "S.-Nowlan",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Nowlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nowlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15150815,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a42b2104ca8ff891ae77c40a915d4c94c8f8428",
            "isKey": false,
            "numCitedBy": 390,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Rumelhart, Hinton and Williams (Rumelhart 86) describe a learning procedure for layered networks of deterministic, neuron-like units. This paper describes further research on the learning procedure. We start by describing the units, the way they are connected, the learning procedure, and the extension to iterative nets. We then give an example in which a network learns a set of filters that enable it to discriminate formant-like patterns in the presence of noise. The speed of learning is strongly dependent on the shape of the surface formed by the error measure in weight space . We give examples of the shape of the error surface for a typical task and illustrate how an acceleration method speeds up descent in weight space. The main drawback of the learning procedure is the way it scales as the size of the task and the network increases. We give some preliminary results on scaling and show how the magnitude of the optimal weight changes depends on the fan-in of the units. Additional results illustrate the effects on learning speed of the amount of interaction between the weights. A variation of the learning procedure that back-propagates desired state information rather than error gradients is developed and compared with the standard procedure. Finally, we discuss the relationship between our iterative networks and the analog networks described by Hopefield and Tank (Hopfield 85). The learning procedure can discover appropriate weights in their kind of network, as well as determine an optimal schedule for varying the nonlinearity of the units during a search."
            },
            "slug": "Experiments-on-Learning-by-Back-Propagation.-Plaut-Nowlan",
            "title": {
                "fragments": [],
                "text": "Experiments on Learning by Back Propagation."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The learning procedure can discover appropriate weights in their kind of network, as well as determine an optimal schedule for varying the nonlinearity of the units during a search."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2763403,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "668087f0ae7ce1de6e0bd0965dbb480c08103260",
            "isKey": false,
            "numCitedBy": 9860,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands; indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction."
            },
            "slug": "Finding-Structure-in-Time-Elman",
            "title": {
                "fragments": [],
                "text": "Finding Structure in Time"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory and suggests a method for representing lexical categories and the type/token distinction is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19356,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145502114"
                        ],
                        "name": "R. Reddy",
                        "slug": "R.-Reddy",
                        "structuredName": {
                            "firstName": "Raj",
                            "lastName": "Reddy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Reddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429215"
                        ],
                        "name": "Kai-Fu Lee",
                        "slug": "Kai-Fu-Lee",
                        "structuredName": {
                            "firstName": "Kai-Fu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Fu Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 54110621,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0afb2945389d55df4dc09d03c2a70e752458d1e",
            "isKey": false,
            "numCitedBy": 346,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Large-vocabulary-speaker-independent-continuous-the-Reddy-Lee",
            "title": {
                "fragments": [],
                "text": "Large-vocabulary speaker-independent continuous speech recognition: the sphinx system"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lorge-Vocabulary Speaker-Independent Continuous Speech Recognition: The SPHINX Sys(em"
            },
            "venue": {
                "fragments": [],
                "text": "Lorge-Vocabulary Speaker-Independent Continuous Speech Recognition: The SPHINX Sys(em"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speech Recognition with Back Prop agation"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Ninth Conf. of the IEEE Engineering in Medicine and Biology Society"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "nectionist Approach to Continuous Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Finding Structure in Time, Tech. report, Center for Researcb in Language"
            },
            "venue": {
                "fragments": [],
                "text": "Finding Structure in Time, Tech. report, Center for Researcb in Language"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Merging Multilayer Perceptrons and Hidden Markov Models: Some Experiments in Continuous Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Merging Multilayer Perceptrons and Hidden Markov Models: Some Experiments in Continuous Speech Recognition"
            },
            "year": 1989
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 17,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Connectionist-Viterbi-training:-a-new-hybrid-method-Franzini-Lee/f866ac085771f5676800db2d9b102975b2a1b2d7?sort=total-citations"
}