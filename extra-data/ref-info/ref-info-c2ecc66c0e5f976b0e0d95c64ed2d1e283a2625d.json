{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 449252,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74fe7ec751cd50295b15cfd46389a8fefb37c414",
            "isKey": false,
            "numCitedBy": 874,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of mapping natural language sentences to lambda\u2013calculus encodings of their meaning. We describe a learning algorithm that takes as input a training set of sentences labeled with expressions in the lambda calculus. The algorithm induces a grammar for the problem, along with a log-linear model that represents a distribution over syntactic and semantic analyses conditioned on the input sentence. We apply the method to the task of learning natural language interfaces to databases and show that the learned parsers outperform previous methods in two benchmark database domains."
            },
            "slug": "Learning-to-Map-Sentences-to-Logical-Form:-with-Zettlemoyer-Collins",
            "title": {
                "fragments": [],
                "text": "Learning to Map Sentences to Logical Form: Structured Classification with Probabilistic Categorial Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A learning algorithm is described that takes as input a training set of sentences labeled with expressions in the lambda calculus and induces a grammar for the problem, along with a log-linear model that represents a distribution over syntactic and semantic analyses conditioned on the input sentence."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8075439"
                        ],
                        "name": "Y. W. Wong",
                        "slug": "Y.-W.-Wong",
                        "structuredName": {
                            "firstName": "Yuk",
                            "lastName": "Wong",
                            "middleNames": [
                                "Wah"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. W. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 87
                            }
                        ],
                        "text": "While WASP works well for target MRLs that are free of logical variables such as CLANG (Wong and Mooney, 2006), it cannot easily handle various kinds of logical forms used in computational semantics, such as predicate logic."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 21
                            }
                        ],
                        "text": "In our previous work (Wong and Mooney, 2006), semantic parsing is cast as a machine translation task, where an SCFG is used to model the translation of an NL into a formal meaning-representation language (MRL)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 91
                            }
                        ],
                        "text": "The larger GEOQUERY corpus consists of 880 English questions gathered from various sources (Wong and Mooney, 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 57
                            }
                        ],
                        "text": "Our work is based on the WASP semantic parsing algorithm (Wong and Mooney, 2006), which translates NL sentences into MRs using an SCFG."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7785983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "687dce9ac01f5996601655035c34b449c27c3b6a",
            "isKey": false,
            "numCitedBy": 293,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel statistical approach to semantic parsing, WASP, for constructing a complete, formal meaning representation of a sentence. A semantic parser is learned given a set of sentences annotated with their correct meaning representations. The main innovation of WASP is its use of state-of-the-art statistical machine translation techniques. A word alignment model is used for lexical acquisition, and the parsing model itself can be seen as a syntax-based translation model. We show that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision, and shows better robustness to variations in task complexity and word order."
            },
            "slug": "Learning-for-Semantic-Parsing-with-Statistical-Wong-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning for Semantic Parsing with Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision, and shows better robustness to variations in task complexity and word order."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760616"
                        ],
                        "name": "F. J. Pelletier",
                        "slug": "F.-J.-Pelletier",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Pelletier",
                            "middleNames": [
                                "Jeffry"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. J. Pelletier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 150
                            }
                        ],
                        "text": "This is unfortunate because most existing work on computational semantics is based on predicate logic, where logical variables play an important role (Blackburn and Bos, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58761668,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "975b9c246611a35a41474ddf7403828b437551e8",
            "isKey": false,
            "numCitedBy": 297,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This book introduces fundamental techniques for computing semantic representations for fragments of natural language and performing inference with the result. The prinary tools used are first-order logic and lambda calculus. All the techniques introduced are implemented in Prolog. The book also shown how to use theorem provers and model builders in parallel to deal with natrual language inference."
            },
            "slug": "Representation-and-Inference-for-Natural-Language:-Pelletier",
            "title": {
                "fragments": [],
                "text": "Representation and Inference for Natural Language: A First Course in Computational Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This book introduces fundamental techniques for computing semantic representations for fragments of natural language and performing inference with the result by using first-order logic and lambda calculus."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787006"
                        ],
                        "name": "Ruifang Ge",
                        "slug": "Ruifang-Ge",
                        "structuredName": {
                            "firstName": "Ruifang",
                            "lastName": "Ge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruifang Ge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 155
                            }
                        ],
                        "text": "Figure 8 shows the learning curves for the \u03bb-\nWASP algorithm compared to: (1) the original WASP algorithm which uses a functional query language (FunQL); (2) SCISSOR (Ge and Mooney, 2005), a fully-supervised, combined syntacticsemantic parsing algorithm which also uses FunQL; and (3) Zettlemoyer and Collins (2005) (Z&C), a CCG-based algorithm which uses Prolog logical forms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 120
                            }
                        ],
                        "text": "WASP algorithm compared to: (1) the original WASP algorithm which uses a functional query language (FunQL); (2) SCISSOR (Ge and Mooney, 2005), a fully-supervised, combined syntacticsemantic parsing algorithm which also uses FunQL; and (3) Zettlemoyer and Collins (2005) (Z&C), a CCG-based algorithm which uses Prolog logical forms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 32
                            }
                        ],
                        "text": "A major advantage of \u03bb-WASP over SCISSOR and Z&C is that it does not require any prior knowledge of the NL syntax."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 107
                            }
                        ],
                        "text": "Table 1 summarizes the results at the end of the learning curves (792 training examples for \u03bbWASP, WASP and SCISSOR, 600 for Z&C)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 13
                            }
                        ],
                        "text": "In contrast, SCISSOR cannot be used directly on the nonEnglish data, because syntactic annotations are only available in English."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2046600,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ae207cfaf01dc2b6799da67f454190b34994870",
            "isKey": false,
            "numCitedBy": 201,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a learning semantic parser, Scissor, that maps natural-language sentences to a detailed, formal, meaning-representation language. It first uses an integrated statistical parser to produce a semantically augmented parse tree, in which each non-terminal node has both a syntactic and a semantic label. A compositional-semantics procedure is then used to map the augmented parse tree into a final meaning representation. We evaluate the system in two domains, a natural-language database interface and an interpreter for coaching instructions in robotic soccer. We present experimental results demonstrating that Scissor produces more accurate semantic representations than several previous approaches."
            },
            "slug": "A-Statistical-Semantic-Parser-that-Integrates-and-Ge-Mooney",
            "title": {
                "fragments": [],
                "text": "A Statistical Semantic Parser that Integrates Syntax and Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A learning semantic parser that maps natural-language sentences to a detailed, formal, meaning-representation language and presents experimental results demonstrating that Scissor produces more accurate semantic representations than several previous approaches."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710450"
                        ],
                        "name": "J. Zelle",
                        "slug": "J.-Zelle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Zelle",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 263135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7c0e47f8b768258b7d536c21b218e6c46ab8791",
            "isKey": false,
            "numCitedBy": 642,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural-language interface for database queries. CHILL treats parser acquisition as the learning of search-control rules within a logic program representing a shift-reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge. Starting with a general framework for constructing a suitable logical form, CHILL is able to train on a corpus comprising sentences paired with database queries and induce parsers that map subsequent sentences directly into executable queries. Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart. These results demonstrate the ability of a corpus-based system to produce more than purely syntactic representations. They also provide direct evidence of the utility of an empirical approach at the level of a complete natural language application."
            },
            "slug": "Learning-to-Parse-Database-Queries-Using-Inductive-Zelle-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning to Parse Database Queries Using Inductive Logic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart, and provide direct evidence of the utility of an empirical approach at the level of a complete natural language application."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI, Vol. 2"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747648"
                        ],
                        "name": "William Schuler",
                        "slug": "William-Schuler",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Schuler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Schuler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6991244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d6105382ce0a1ddddeb401cea70aaf26e3c3493",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an extension of the semantic grammars used in conventional statistical spoken language interfaces to allow the probabilities of derived analyses to be conditioned on the meanings or denotations of input utterances in the context of an interface's underlying application environment or world model. Since these denotations will be used to guide disambiguation in interactive applications, they must be efficiently shared among the many possible analyses that may be assigned to an input utterance. This paper therefore presents a formal restriction on the scope of variables in a semantic grammar which guarantees that the denotations of all possible analyses of an input utterance can be calculated in polynomial time, without undue constraints on the expressivity of the derived semantics. Empirical tests show that this model-theoretic interpretation yields a statistically significant improvement on standard measures of parsing accuracy over a baseline grammar not conditioned on denotations."
            },
            "slug": "Using-Model-Theoretic-Semantic-Interpretation-to-in-Schuler",
            "title": {
                "fragments": [],
                "text": "Using Model-Theoretic Semantic Interpretation to Guide Statistical Parsing and Word Recognition in a Spoken Language Interface"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A formal restriction on the scope of variables in a semantic grammar is presented which guarantees that the denotations of all possible analyses of an input utterance can be calculated in polynomial time, without undue constraints on the expressivity of the derived semantics."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8075439"
                        ],
                        "name": "Y. W. Wong",
                        "slug": "Y.-W.-Wong",
                        "structuredName": {
                            "firstName": "Yuk",
                            "lastName": "Wong",
                            "middleNames": [
                                "Wah"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. W. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 154
                            }
                        ],
                        "text": "More recently, we show that our SCFG-based parser can be inverted to produce a state-of-the-art NL generator, where a formal MRL is translated into an NL (Wong and Mooney, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 799077,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85fd72fe9a4fd351c6f9663fb0d808ebc9f6264e",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of statistical machine translation (SMT) methods for tactical natural language generation. We present results on using phrase-based SMT for learning to map meaning representations to natural language. Improved results are obtained by inverting a semantic parser that uses SMT methods to map sentences into meaning representations. Finally, we show that hybridizing these two approaches results in still more accurate generation systems. Automatic and human evaluation of generated sentences are presented across two domains and four languages."
            },
            "slug": "Generation-by-Inverting-a-Semantic-Parser-that-Uses-Wong-Mooney",
            "title": {
                "fragments": [],
                "text": "Generation by Inverting a Semantic Parser that Uses Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Improved results are obtained by inverting a semantic parser that uses SMT methods to map sentences into meaning representations to natural language, and it is shown that hybridizing these two approaches results in still more accurate generation systems."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109821889"
                        ],
                        "name": "Kenji Yamada",
                        "slug": "Kenji-Yamada",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenji Yamada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 179
                            }
                        ],
                        "text": "Among the grammar formalisms successfully put into use in syntaxbased SMT are synchronous context-free grammars (SCFG) (Wu, 1997) and synchronous treesubstitution grammars (STSG) (Yamada and Knight, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 455928,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11cd7fbc0ea8605ea498ecfc82b3ff6a44c027e9",
            "isKey": false,
            "numCitedBy": 846,
            "numCiting": 163,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a syntax-based statistical translation model. Our model transforms a source-language parse tree into a target-language string by applying stochastic operations at each node. These operations capture linguistic differences such as word order and case marking. Model parameters are estimated in polynomial time using an EM algorithm. The model produces word alignments that are better than those produced by IBM Model 5."
            },
            "slug": "A-Syntax-based-Statistical-Translation-Model-Yamada-Knight",
            "title": {
                "fragments": [],
                "text": "A Syntax-based Statistical Translation Model"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This model transforms a source-language parse tree into a target-language string by applying stochastic operations at each node, and produces word alignments that are better than those produced by IBM Model 5."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2390150"
                        ],
                        "name": "Dekai Wu",
                        "slug": "Dekai-Wu",
                        "structuredName": {
                            "firstName": "Dekai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekai Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 119
                            }
                        ],
                        "text": "Among the grammar formalisms successfully put into use in syntaxbased SMT are synchronous context-free grammars (SCFG) (Wu, 1997) and synchronous treesubstitution grammars (STSG) (Yamada and Knight, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 912349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13b6eeb28328252a35cdcbe3ab8d09d2a9caf99d",
            "isKey": false,
            "numCitedBy": 1000,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce (1) a novel stochastic inversion transduction grammar formalism for bilingual language modeling of sentence-pairs, and (2) the concept of bilingual parsing with a variety of parallel corpus analysis applications. Aside from the bilingual orientation, three major features distinguish the formalism from the finite-state transducers more traditionally found in computational linguistics: it skips directly to a context-free rather than finite-state base, it permits a minimal extra degree of ordering flexibility, and its probabilistic formulation admits an efficient maximum-likelihood bilingual parsing algorithm. A convenient normal form is shown to exist. Analysis of the formalism's expressiveness suggests that it is particularly well suited to modeling ordering shifts between languages, balancing needed flexibility against complexity constraints. We discuss a number of examples of how stochastic inversion transduction grammars bring bilingual constraints to bear upon problematic corpus analysis tasks such as segmentation, bracketing, phrasal alignment, and parsing."
            },
            "slug": "Stochastic-Inversion-Transduction-Grammars-and-of-Wu",
            "title": {
                "fragments": [],
                "text": "Stochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A novel stochastic inversion transduction grammar formalism for bilingual language modeling of sentence-pairs, and the concept of bilingual parsing with a variety of parallel corpus analysis applications are introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145287425"
                        ],
                        "name": "David Chiang",
                        "slug": "David-Chiang",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Chiang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 44
                            }
                        ],
                        "text": "Like most existing work on syntax-based SMT (Chiang, 2005; Galley et al., 2006), we construct G using rules extracted from word alignments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "This work shows that it is possible to use standard SMT methods in tasks where logical forms are involved."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 110
                            }
                        ],
                        "text": "A semantic parser is learned given a set of training sentences and their correct logical forms using standard SMT techniques."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 78
                            }
                        ],
                        "text": "Both formalisms have led to SMT systems whose performance is state-of-the-art (Chiang, 2005; Galley et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "In this work, we show that methods developed for SMT can be brought to bear on tasks where logical forms are involved, such as semantic parsing."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "Our algorithm, WASP, uses statistical models developed for syntax-based SMT for lexical learning and parse disambiguation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "A semantic parser is learned given a set of sentences and their correct logical forms using SMT methods."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 70
                            }
                        ],
                        "text": "Among the grammar formalisms successfully put into use in syntaxbased SMT are synchronous context-free grammars (SCFG) (Wu, 1997) and synchronous treesubstitution grammars (STSG) (Yamada and Knight, 2001)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 192
                            }
                        ],
                        "text": "Originally developed as a theory of compiling programming languages (Aho and Ullman, 1972), synchronous grammars have seen a surge of interest recently in the statistical machine translation (SMT) community as a way of formalizing syntax-based translation models between natural languages (NL)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 384994,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad3d2f463916784d0c14a19936c1544309a0a440",
            "isKey": true,
            "numCitedBy": 1298,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a statistical phrase-based translation model that uses hierarchical phrases---phrases that contain subphrases. The model is formally a synchronous context-free grammar but is learned from a bitext without any syntactic information. Thus it can be seen as a shift to the formal machinery of syntax-based translation systems without any linguistic commitment. In our experiments using BLEU as a metric, the hierarchical phrase-based model achieves a relative improvement of 7.5% over Pharaoh, a state-of-the-art phrase-based system."
            },
            "slug": "A-Hierarchical-Phrase-Based-Model-for-Statistical-Chiang",
            "title": {
                "fragments": [],
                "text": "A Hierarchical Phrase-Based Model for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The model is formally a synchronous context-free grammar but is learned from a bitext without any syntactic information, which can be seen as a shift to the formal machinery of syntax-based translation systems without any linguistic commitment."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1947267"
                        ],
                        "name": "Michel Galley",
                        "slug": "Michel-Galley",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Galley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michel Galley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3223661"
                        ],
                        "name": "Jonathan Graehl",
                        "slug": "Jonathan-Graehl",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Graehl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Graehl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2553663"
                        ],
                        "name": "Steve DeNeefe",
                        "slug": "Steve-DeNeefe",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "DeNeefe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steve DeNeefe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49337181"
                        ],
                        "name": "Wei Wang",
                        "slug": "Wei-Wang",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2805094"
                        ],
                        "name": "I. Thayer",
                        "slug": "I.-Thayer",
                        "structuredName": {
                            "firstName": "Ignacio",
                            "lastName": "Thayer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Thayer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 59
                            }
                        ],
                        "text": "Like most existing work on syntax-based SMT (Chiang, 2005; Galley et al., 2006), we construct G using rules extracted from word alignments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "This work shows that it is possible to use standard SMT methods in tasks where logical forms are involved."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 110
                            }
                        ],
                        "text": "A semantic parser is learned given a set of training sentences and their correct logical forms using standard SMT techniques."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 93
                            }
                        ],
                        "text": "Both formalisms have led to SMT systems whose performance is state-of-the-art (Chiang, 2005; Galley et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "In this work, we show that methods developed for SMT can be brought to bear on tasks where logical forms are involved, such as semantic parsing."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "Our algorithm, WASP, uses statistical models developed for syntax-based SMT for lexical learning and parse disambiguation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "A semantic parser is learned given a set of sentences and their correct logical forms using SMT methods."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 70
                            }
                        ],
                        "text": "Among the grammar formalisms successfully put into use in syntaxbased SMT are synchronous context-free grammars (SCFG) (Wu, 1997) and synchronous treesubstitution grammars (STSG) (Yamada and Knight, 2001)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 192
                            }
                        ],
                        "text": "Originally developed as a theory of compiling programming languages (Aho and Ullman, 1972), synchronous grammars have seen a surge of interest recently in the statistical machine translation (SMT) community as a way of formalizing syntax-based translation models between natural languages (NL)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 765547,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d01737b617acc555153f4660417908bf3971b1a5",
            "isKey": true,
            "numCitedBy": 483,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical MT has made great progress in the last few years, but current translation models are weak on re-ordering and target language fluency. Syntactic approaches seek to remedy these problems. In this paper, we take the framework for acquiring multi-level syntactic translation rules of (Galley et al., 2004) from aligned tree-string pairs, and present two main extensions of their approach: first, instead of merely computing a single derivation that minimally explains a sentence pair, we construct a large number of derivations that include contextually richer rules, and account for multiple interpretations of unaligned words. Second, we propose probability estimates and a training procedure for weighting these rules. We contrast different approaches on real examples, show that our estimates based on multiple derivations favor phrasal re-orderings that are linguistically better motivated, and establish that our larger rules provide a 3.63 BLEU point increase over minimal rules."
            },
            "slug": "Scalable-Inference-and-Training-of-Context-Rich-Galley-Graehl",
            "title": {
                "fragments": [],
                "text": "Scalable Inference and Training of Context-Rich Syntactic Translation Models"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper takes the framework for acquiring multi-level syntactic translation rules of (Galley et al., 2004) from aligned tree-string pairs, and presents two main extensions of their approach: instead of merely computing a single derivation that minimally explains a sentence pair, a large number of derivations that include contextually richer rules, and account for multiple interpretations of unaligned words."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060101052"
                        ],
                        "name": "Terry Koo",
                        "slug": "Terry-Koo",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Koo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Terry Koo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 405878,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "844db702be4bc149b06b822b47247e15f5894cc3",
            "isKey": false,
            "numCitedBy": 776,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "This article considers approaches which rerank the output of an existing probabilistic parser. The base parser produces a set of candidate parses for each input sentence, with associated probabilities that define an initial ranking of these parses. A second model then attempts to improve upon this initial ranking, using additional features of the tree as evidence. The strength of our approach is that it allows a tree to be represented as an arbitrary set of features, without concerns about how these features interact or overlap and without the need to define a derivation or a generative model which takes these features into account. We introduce a new method for the reranking task, based on the boosting approach to ranking problems described in Freund et al. (1998). We apply the boosting method to parsing the Wall Street Journal treebank. The method combined the log-likelihood under a baseline model (that of Collins [1999]) with evidence from an additional 500,000 features over parse trees that were not included in the original model. The new model achieved 89.75 F-measure, a 13 relative decrease in F-measure error over the baseline model's score of 88.2. The article also introduces a new algorithm for the boosting approach which takes advantage of the sparsity of the feature space in the parsing data. Experiments show significant efficiency gains for the new algorithm over the obvious implementation of the boosting approach. We argue that the method is an appealing alternative-in terms of both simplicity and efficiency-to work on feature selection methods within log-linear (maximum-entropy) models. Although the experiments in this article are on natural language parsing (NLP), the approach should be applicable to many other NLP problems which are naturally framed as ranking tasks, for example, speech recognition, machine translation, or natural language generation."
            },
            "slug": "Discriminative-Reranking-for-Natural-Language-Collins-Koo",
            "title": {
                "fragments": [],
                "text": "Discriminative Reranking for Natural Language Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The boosting approach to ranking problems described in Freund et al. (1998) is applied to parsing the Wall Street Journal treebank, and it is argued that the method is an appealing alternative-in terms of both simplicity and efficiency-to work on feature selection methods within log-linear (maximum-entropy) models."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714374"
                        ],
                        "name": "A. Joshi",
                        "slug": "A.-Joshi",
                        "structuredName": {
                            "firstName": "Aravind",
                            "lastName": "Joshi",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Joshi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400820110"
                        ],
                        "name": "K. Vijay-Shanker",
                        "slug": "K.-Vijay-Shanker",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Vijay-Shanker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Vijay-Shanker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 169
                            }
                        ],
                        "text": "On the other hand, most existing methods for mapping NL sentences to logical forms involve substantial hand-written components that are difficult to maintain (Joshi and Vijay-Shanker, 2001; Bayer et al., 2004; Bos, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 116030453,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "48e8ed40e24253d52b8b5798a43f59087df01cb2",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Let us consider a possible implication of the lexicalization of grammatical structures and the localization of dependencies (especially the predicate- argument relationships) that are central features of LTAG. Consider the elementary trees in the LTAG in Figure 1.. The tree corresponding to John likes peanuts passionately is derived by starting with the elementary tree for likes and then substituting the trees for John and peanuts at the respective nodes of the tree \u03b11 and adjoining the tree for passionately at the VP node of the tree \u03b11. The derivation tree in Figure 1. shows this derivation. If both substitution and adjoining are described as attachment of one tree to another tree, then the entire derivation consists of a set of attachments."
            },
            "slug": "Compositional-Semantics-With-Lexicalized-Grammar-is-Joshi-Vijay-Shanker",
            "title": {
                "fragments": [],
                "text": "Compositional Semantics With Lexicalized Tree-Adjoining Grammar (LTAG): How Much Underspecification is Necessary?"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A possible implication of the lexicalization of grammatical structures and the localization of dependencies (especially the predicate- argument relationships) that are central features of LTAG is considered."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715952"
                        ],
                        "name": "A. Aho",
                        "slug": "A.-Aho",
                        "structuredName": {
                            "firstName": "Alfred",
                            "lastName": "Aho",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742391"
                        ],
                        "name": "J. Ullman",
                        "slug": "J.-Ullman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Ullman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ullman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 68
                            }
                        ],
                        "text": "Originally developed as a theory of compiling programming languages (Aho and Ullman, 1972), synchronous grammars have seen a surge of interest recently in the statistical machine translation (SMT) community as a way of formalizing syntax-based translation models between natural languages (NL)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60775129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40dbb25a15b63af3faccb81c8e64a3f5d659e07e",
            "isKey": false,
            "numCitedBy": 1856,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From volume 1 Preface (See Front Matter for full Preface) \n \nThis book is intended for a one or two semester course in compiling theory at the senior or graduate level. It is a theoretically oriented treatment of a practical subject. Our motivation for making it so is threefold. \n \n(1) In an area as rapidly changing as Computer Science, sound pedagogy demands that courses emphasize ideas, rather than implementation details. It is our hope that the algorithms and concepts presented in this book will survive the next generation of computers and programming languages, and that at least some of them will be applicable to fields other than compiler writing. \n \n(2) Compiler writing has progressed to the point where many portions of a compiler can be isolated and subjected to design optimization. It is important that appropriate mathematical tools be available to the person attempting this optimization. \n \n(3) Some of the most useful and most efficient compiler algorithms, e.g. LR(k) parsing, require a good deal of mathematical background for full understanding. We expect, therefore, that a good theoretical background will become essential for the compiler designer. \n \nWhile we have not omitted difficult theorems that are relevant to compiling, we have tried to make the book as readable as possible. Numerous examples are given, each based on a small grammar, rather than on the large grammars encountered in practice. It is hoped that these examples are sufficient to illustrate the basic ideas, even in cases where the theoretical developments are difficult to follow in isolation. \n \nFrom volume 2 Preface (See Front Matter for full Preface) \n \nCompiler design is one of the first major areas of systems programming for which a strong theoretical foundation is becoming available. Volume I of The Theory of Parsing, Translation, and Compiling developed the relevant parts of mathematics and language theory for this foundation and developed the principal methods of fast syntactic analysis. Volume II is a continuation of Volume I, but except for Chapters 7 and 8 it is oriented towards the nonsyntactic aspects of compiler design. \n \nThe treatment of the material in Volume II is much the same as in Volume I, although proofs have become a little more sketchy. We have tried to make the discussion as readable as possible by providing numerous examples, each illustrating one or two concepts. \n \nSince the text emphasizes concepts rather than language or machine details, a programming laboratory should accompany a course based on this book, so that a student can develop some facility in applying the concepts discussed to practical problems. The programming exercises appearing at the ends of sections can be used as recommended projects in such a laboratory. Part of the laboratory course should discuss the code to be generated for such programming language constructs as recursion, parameter passing, subroutine linkages, array references, loops, and so forth."
            },
            "slug": "The-Theory-of-Parsing,-Translation,-and-Compiling-Aho-Ullman",
            "title": {
                "fragments": [],
                "text": "The Theory of Parsing, Translation, and Compiling"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is the hope that the algorithms and concepts presented in this book will survive the next generation of computers and programming languages, and that at least some of them will be applicable to fields other than compiler writing."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3461596"
                        ],
                        "name": "Johan Bos",
                        "slug": "Johan-Bos",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Bos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johan Bos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 158
                            }
                        ],
                        "text": "On the other hand, most existing methods for mapping NL sentences to logical forms involve substantial hand-written components that are difficult to maintain (Joshi and Vijay-Shanker, 2001; Bayer et al., 2004; Bos, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18586841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "913c0fe31e99379dcc3e9e8c584c596bf6113941",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Wide-coverage and robust NLP techniques always seemed to go hand in hand with shallow analyses. This was certainly true a couple of years ago, but the state-of-the-art in stochastic approaches has advanced considerably and nowadays there are sophisticated parsers available achieving high coverage and producing accurate syntactic analyses. It seems we have finally reached a stage in NLP where we can apply well known techniques of formal and computational semantics to a larger scale, and get a detailed semantic analysis from a wide-coverage parser. A proof of concept of this idea was demonstrated in [BCS04], with a coverage of over 95% on newspaper texts. In this paper we discuss the further developments in this work, generating semantic representations for sentences or small texts, showing how we can calculate background knowledge required for reasoning, and performing inferences using state-of-the-art theorem provers and model builders. The semantic representation language that we will use is a first-order language, arguing that given the current state of automated deduction, any language with more expressive power (such as second or higher-order logic) cannot be used efficiently to perform inference tasks. There are however highly sophisticated inference tools for first-order logic available which we will use in our work. Despite the tradition in formal semantics to use higher-order logics, firstorder logic is able to cover a (perhaps surprisingly) large variety of interesting natural language phenomena. The language we are going to adopt is developed in Discourse Representation Theory (DRT), closed under a translation to first-order logic, and is described in Section 2. The choice for DRT is motivated by its impressive theoretical coverage of linguistic phenomena [KR93, VdS92]. Next, of course, we need a grammar formalism suitable for computational semantics (i.e. one that is able to produce fine-grained syntactic analyses)."
            },
            "slug": "Towards-Wide-Coverage-Semantic-Interpretation-Bos",
            "title": {
                "fragments": [],
                "text": "Towards Wide-Coverage Semantic Interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Further developments in this work are discussed, generating semantic representations for sentences or small texts, showing how to calculate background knowledge required for reasoning, and performing inferences using state-of-the-art theorem provers and model builders."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144169446"
                        ],
                        "name": "S. Bayer",
                        "slug": "S.-Bayer",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Bayer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bayer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5416402"
                        ],
                        "name": "J. Burger",
                        "slug": "J.-Burger",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Burger",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2009955"
                        ],
                        "name": "W. Greiff",
                        "slug": "W.-Greiff",
                        "structuredName": {
                            "firstName": "Warren",
                            "lastName": "Greiff",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Greiff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107124"
                        ],
                        "name": "Ben Wellner",
                        "slug": "Ben-Wellner",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Wellner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ben Wellner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 190
                            }
                        ],
                        "text": "On the other hand, most existing methods for mapping NL sentences to logical forms involve substantial hand-written components that are difficult to maintain (Joshi and Vijay-Shanker, 2001; Bayer et al., 2004; Bos, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18016748,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c08a0c1e5babc97449706d4ab9254a501d5359aa",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe MITRE\u2019s contribution to the logical form generation track of Senseval-3. We begin with a description of the context of MITRE\u2019s work, followed by a description of the MITRE system and its results. We conclude with a commentary on the form and structure of this evaluation track."
            },
            "slug": "The-MITRE-logical-form-generation-system-Bayer-Burger",
            "title": {
                "fragments": [],
                "text": "The MITRE logical form generation system"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The context of MITRE\u2019s work is described, followed by a description of the context of the MITRE system and its results, and a commentary on the form and structure of this evaluation track."
            },
            "venue": {
                "fragments": [],
                "text": "SENSEVAL@ACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 84
                            }
                        ],
                        "text": "We use the K = 5 most probable word alignments for the training set given by GIZA++ (Och and Ney, 2003), with variable names ignored to reduce sparsity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5219389,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de2df29b0a0312de7270c3f5a0af6af5645cf91a",
            "isKey": false,
            "numCitedBy": 4471,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We present and compare various methods for computing word alignments using statistical or heuristic models. We consider the five alignment models presented in Brown, Della Pietra, Della Pietra, and Mercer (1993), the hidden Markov alignment model, smoothing techniques, and refinements. These statistical models are compared with two heuristic models based on the Dice coefficient. We present different methods for combining word alignments to perform a symmetrization of directed statistical alignment models. As evaluation criterion, we use the quality of the resulting Viterbi alignment compared to a manually produced reference alignment. We evaluate the models on the German-English Verbmobil task and the French-English Hansards task. We perform a detailed analysis of various design decisions of our statistical alignment system and evaluate these on training corpora of various sizes. An important result is that refined alignment models with a first-order dependence and a fertility model yield significantly better results than simple heuristic models. In the Appendix, we present an efficient training algorithm for the alignment models presented."
            },
            "slug": "A-Systematic-Comparison-of-Various-Statistical-Och-Ney",
            "title": {
                "fragments": [],
                "text": "A Systematic Comparison of Various Statistical Alignment Models"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An important result is that refined alignment models with a first-order dependence and a fertility model yield significantly better results than simple heuristic models."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48221821"
                        ],
                        "name": "Siobhan Chapman",
                        "slug": "Siobhan-Chapman",
                        "structuredName": {
                            "firstName": "Siobhan",
                            "lastName": "Chapman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Siobhan Chapman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 123
                            }
                        ],
                        "text": "The use of type checking is to exploit the fact that people tend not to ask questions that obviously have no valid answers (Grice, 1975)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 148132585,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "b25e5bca74d74abb1687315fa3c637bb9911554d",
            "isKey": false,
            "numCitedBy": 8419,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "As Grice\u2019s enthusiasm for ordinary language philosophy became increasingly qualified during the 1950s, his interest was growing in the rather different styles of philosophy of language then current in America. Recent improvements in communications had made possible an exchange of ideas across the Atlantic that would have been unthinkable before the war. W. V. O. Quine had made a considerable impression at Oxford during his time as Eastman Professor. Grice was interested in Quine\u2019s logical approach to language, although he differed from him over certain specific questions, such as the viability of the distinction between analytic and synthetic statements. Quine, who was visiting England for a whole year, and who brought with him clothes, books and even provisions in the knowledge that rationing was still in force, travelled by ship.1 However, during the same decade the rapid proliferation of passenger air travel enabled movement of academics between Britain and America for even short stays and lecture tours. Grice himself made a number of such visits, and was impressed by the formal and theory-driven philosophy he encountered. Most of all he was impressed by the work of Noam Chomsky."
            },
            "slug": "Logic-and-Conversation-Chapman",
            "title": {
                "fragments": [],
                "text": "Logic and Conversation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14956436"
                        ],
                        "name": "L. Dezs\u00f6",
                        "slug": "L.-Dezs\u00f6",
                        "structuredName": {
                            "firstName": "L\u00e1szl\u00f3",
                            "lastName": "Dezs\u00f6",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Dezs\u00f6"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 75
                            }
                        ],
                        "text": "The resulting synchronous grammar generates logical forms using \u03bb-calculus (Montague, 1970)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 201904046,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "e69e5953905b9b9ded4c07f0505ed401ec39babf",
            "isKey": false,
            "numCitedBy": 704,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Universal-Grammar-Dezs\u00f6",
            "title": {
                "fragments": [],
                "text": "Universal Grammar"
            },
            "venue": {
                "fragments": [],
                "text": "Certainty in Action"
            },
            "year": 2021
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3323275"
                        ],
                        "name": "Kishore Papineni",
                        "slug": "Kishore-Papineni",
                        "structuredName": {
                            "firstName": "Kishore",
                            "lastName": "Papineni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kishore Papineni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144582029"
                        ],
                        "name": "T. Ward",
                        "slug": "T.-Ward",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Ward",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ward"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 156
                            }
                        ],
                        "text": "We only consider features that are based on the MR translations, and therefore, these features can be seen as an implicit language model of the target MRL (Papineni et al., 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46353430,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23645d7e433009061d8dd6c81f8556166f97acdd",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Feature-based-language-understanding-Papineni-Roukos",
            "title": {
                "fragments": [],
                "text": "Feature-based language understanding"
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 20,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-Synchronous-Grammars-for-Semantic-Parsing-Wong-Mooney/c2ecc66c0e5f976b0e0d95c64ed2d1e283a2625d?sort=total-citations"
}