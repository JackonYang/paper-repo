{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40316280"
                        ],
                        "name": "Dennis Tell",
                        "slug": "Dennis-Tell",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Tell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dennis Tell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153120475"
                        ],
                        "name": "S. Carlsson",
                        "slug": "S.-Carlsson",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Carlsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carlsson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38014951,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a6ea7bd5be7631f671ea0069bc296cc51654895",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of establishing correspondences between images taken from different viewpoints is fundamental in computer vision. We propose an algorithm which is capable of handling larger changes in viewpoint than classical correlation based techniques. Optimal performance for the algorithm is achieved for textured objects which are locally planar in at least one direction. The algorithm works by computing affinely invariant fourier features from intensity profiles in each image. The intensity profiles are extracted from the image data between randomly selected pairs of image interest points. Using a voting scheme, pairs of interest points are matched across images by comparing vectors of fourier features. Outliers among the matches are rejected in two stages, a fast stage using novel view consistency constraints, and a second, slower stage using RANSAC and fundamental matrix computation. In order to demonstrate the quality of the results, the algorithm is tested on several different image pairs."
            },
            "slug": "Wide-Baseline-Point-Matching-Using-Affine-Computed-Tell-Carlsson",
            "title": {
                "fragments": [],
                "text": "Wide Baseline Point Matching Using Affine Invariants Computed from Intensity Profiles"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An algorithm which is capable of handling larger changes in viewpoint than classical correlation based techniques is proposed, which works by computing affinely invariant fourier features from intensity profiles in each image."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40316280"
                        ],
                        "name": "Dennis Tell",
                        "slug": "Dennis-Tell",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Tell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dennis Tell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18551343,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3ee13c8dee2c82c1559c8f42be53210f1436997",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 141,
            "paperAbstract": {
                "fragments": [],
                "text": "Matching is a fundamental problem in computer vision. In one formulation of the matching problem, the task is to determine what point in one image that corresponds to a given point in another image of the same scene. If sufficiently many correspondences between the images are known, the 3D structure of the scene may be recovered. A system capable of performing this task would have applications in robotics, computer vision for the entertainment industry and media, and 3D modeling from multiple views. Stereo matching is a restricted version of the image matching problem, in which the viewpoints of the different images are required to have a very small separation. In such cases, corresponding points will have almost the same position in both images, and the complexity of the matching problem is reduced. Furthermore, a potential correspondence between two images may be verified by requiring that the image neighbourhoods of the points are similar to one and another. As the viewpoint difference between the images is assumed to be small, this verification can be made using cross-correlation of image data. Many impressive results on stereo matching have been demonstrated in the computer vision community. However, another form of the problem \u2014 wide baseline matching \u2014 has not yet seen this success. In the wide baseline formulation, the images are allowed to be taken from widely separated viewpoints, so that a point in one image may have moved anywhere in the other image. This creates a much more difficult matching problem. Not only are larger search areas needed, there is no longer an easy way of verifying potential matches. The image data in the neighbourhood of a point may be severely distorted by the change of viewpoint, and cross-correlation techniques will fail. New techniques for matching in such conditions are thus required. To this end, several wide baseline matching algorithms have been developed during the last few years. In this thesis, we will introduce new contributions to this class of algorithms. We propose novel methods for matching using line segments as well as using points. The algorithms can in theory handle large changes of viewpoint. The viewpoint invariance properties of the line matching algorithm are data dependent, but for many realistic situations, they are more than adequate. Concerning the point matching algorithm, it is invariant to affine transformations. However, it is shown that it can also successfully match image pairs where projective distortions are present. The matching algorithms are both demonstrated in a visual servoing application. Finally, an extension to the robust estimation method RANSAC is introduced. The extension enables the algorithm to handle ambiguous correspondences in a principled manner. Experiments show that the performance is better than RANSAC, at the price of a higher computational complexity."
            },
            "slug": "Wide-baseline-matching-with-applications-to-visual-Tell",
            "title": {
                "fragments": [],
                "text": "Wide baseline matching with applications to visual servoing"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "New contributions to wide baseline matching algorithms are introduced, including novel methods for matching using line segments as well as using points, and an extension to the robust estimation method RANSAC that enables the algorithm to handle ambiguous correspondences in a principled manner."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2679389"
                        ],
                        "name": "A. Baumberg",
                        "slug": "A.-Baumberg",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Baumberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Baumberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15626261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67f693427d956c0dbc822e7f3452aee8ca36204b",
            "isKey": false,
            "numCitedBy": 767,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints. Unlike conventional stereo matching approaches we assume no prior knowledge about the relative camera positions and orientations. In fact in our application this is the information we wish to determine from the image feature matches. Features are detected in two or more images and characterised using affine texture invariants. The problem of window effects is explicitly addressed by our method-our feature characterisation is invariant to linear transformations of the image data including rotation, stretch and skew. The feature matching process is optimised for a structure-from-motion application where we wish to ignore unreliable matches at the expense of reducing the number of feature matches."
            },
            "slug": "Reliable-feature-matching-across-widely-separated-Baumberg",
            "title": {
                "fragments": [],
                "text": "Reliable feature matching across widely separated views"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints that is optimised for a structure-from-motion application where it wishes to ignore unreliable matches at the expense of reducing the number of feature matches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51064498"
                        ],
                        "name": "Zhengyou Zhang",
                        "slug": "Zhengyou-Zhang",
                        "structuredName": {
                            "firstName": "Zhengyou",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengyou Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702017"
                        ],
                        "name": "R. Deriche",
                        "slug": "R.-Deriche",
                        "structuredName": {
                            "firstName": "Rachid",
                            "lastName": "Deriche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Deriche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624076"
                        ],
                        "name": "Q. Luong",
                        "slug": "Q.-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5858737,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3ec4ceea040b7b4129ee5d71b4f95539bf876b7",
            "isKey": false,
            "numCitedBy": 1625,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Robust-Technique-for-Matching-two-Uncalibrated-of-Zhang-Deriche",
            "title": {
                "fragments": [],
                "text": "A Robust Technique for Matching two Uncalibrated Images Through the Recovery of the Unknown Epipolar Geometry"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8446909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "500db68171e4a961d7fa87b8020b3a3e62133caf",
            "isKey": false,
            "numCitedBy": 324,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by (1) solving for correspondences between points on the two shapes, (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. Dis-similarity between two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework. Results are presented for silhouettes, trademarks, handwritten digits and the COIL dataset."
            },
            "slug": "Matching-shapes-Belongie-Malik",
            "title": {
                "fragments": [],
                "text": "Matching shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A novel approach to measuring similarity between shapes and exploiting it for object recognition in a nearest-neighbor classification framework that applies regularized thin-plate splines to the transformation maps for this purpose."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398773259"
                        ],
                        "name": "L. D'haene",
                        "slug": "L.-D'haene",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "D'haene",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D'haene"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144839904"
                        ],
                        "name": "R. Koch",
                        "slug": "R.-Koch",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Koch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206541238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12c794d7a7315ab87e5477b2abdaf84a06c86adb",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper develops new image matching techniques for visual servoing based on affine invariants which allow one to deal with large viewpoint changes and that do not rely on specific markers. The only assumption is that there are some locally planar and unoccluded scene regions that have enough structure to be detected in the image. Those regions are classified by a set of illumination and viewpoint invariant features. The features represent the image in a very compact way and allow fast comparison and feature matching between quite different viewpoints. The matching procedure is embedded in a visual servoing system for a mobile robot. Experiments show its potential for navigation with large camera rotations and view point changes in a cluttered environment without the need for artificial landmarks."
            },
            "slug": "Matching-of-affinely-invariant-regions-for-visual-Tuytelaars-Gool",
            "title": {
                "fragments": [],
                "text": "Matching of affinely invariant regions for visual servoing"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "New image matching techniques for visual servoing based on affine invariants which allow one to deal with large viewpoint changes and that do not rely on specific markers are developed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No.99CH36288C)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144677513"
                        ],
                        "name": "David G. Jones",
                        "slug": "David-G.-Jones",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jones",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David G. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 359416,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ff22944d8a76831867d902570ed85a7e0e3cac6",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a computational framework for stereopsis based on the outputs of linear spatial filters tuned to a range of orientations and scales. This approach goes beyond edge-based and area-based approaches by using a richer image description and incorporating several stereo cues that previously have been neglected in the computer vision literature. A technique based on using the pseudo-inverse is presented for characterizing the information present in a vector of filter responses. We show how in our framework viewing geometry can be recovered to determine the locations of epipolar lines. An assumption that visible surfaces in the scene are piecewise smooth leads to differential treatment of image regions corresponding to binocularly visible surfaces, surface boundaries, and occluded regions that are only monocularly visible. The constraints imposed by viewing geometry and piecewise smoothness are incorporated into an iterative algorithm that gives good results on random-dot stereograms, artificially generated scenes, and natural grey-level images."
            },
            "slug": "A-Computational-Framework-for-Determining-Stereo-a-Jones-Malik",
            "title": {
                "fragments": [],
                "text": "A Computational Framework for Determining Stereo Correspondence from a Set of Linear Spatial Filters"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A computational framework for stereopsis based on the outputs of linear spatial filters tuned to a range of orientations and scales is presented and a technique based on using the pseudo-inverse is presented for characterizing the information present in a vector of filter responses."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143921197"
                        ],
                        "name": "P. Montesinos",
                        "slug": "P.-Montesinos",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Montesinos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Montesinos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398826846"
                        ],
                        "name": "V. Gouet-Brunet",
                        "slug": "V.-Gouet-Brunet",
                        "structuredName": {
                            "firstName": "Val\u00e9rie",
                            "lastName": "Gouet-Brunet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Gouet-Brunet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702017"
                        ],
                        "name": "R. Deriche",
                        "slug": "R.-Deriche",
                        "structuredName": {
                            "firstName": "Rachid",
                            "lastName": "Deriche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Deriche"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5753786,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b35483eedfca4258f0ec33076707055cbfab203e",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for matching points in stereoscopic, uncalibrated color images. Our approach consists of characterizing points of interest using differential invariants. We define additional invariants of first order, exploiting color information. We show that this contribution makes the characterization sufficient for first order. In addition, we make our description robust to usual transformations of image. We present a robust generalization of a gray level corner detector to the case of color images. We also propose a simple and efficient scheme for matching these points, using our characterization. Finally, we present matching results and the epipolar geometry obtained on complex scenes, which clearly show the pertinence of our approach. We are able to match points robustly and rapidly, using only first order derivatives."
            },
            "slug": "Differential-invariants-for-color-images-Montesinos-Gouet-Brunet",
            "title": {
                "fragments": [],
                "text": "Differential invariants for color images"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A new method for matching points in stereoscopic, uncalibrated color images by characterizing points of interest using differential invariants and defining additional invariants of first order, exploiting color information is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48121727"
                        ],
                        "name": "D. W. Murray",
                        "slug": "D.-W.-Murray",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Murray",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. W. Murray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12031059,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c72ce4ef9f433db764b1c52f03412e4d0400dca",
            "isKey": false,
            "numCitedBy": 740,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper has two goals. The first is to develop a variety of robust methods for the computation of the Fundamental Matrix, the calibration-free representation of camera motion. The methods are drawn from the principal categories of robust estimators, viz. case deletion diagnostics, M-estimators and random sampling, and the paper develops the theory required to apply them to non-linear orthogonal regression problems. Although a considerable amount of interest has focussed on the application of robust estimation in computer vision, the relative merits of the many individual methods are unknown, leaving the potential practitioner to guess at their value. The second goal is therefore to compare and judge the methods.Comparative tests are carried out using correspondences generated both synthetically in a statistically controlled fashion and from feature matching in real imagery. In contrast with previously reported methods the goodness of fit to the synthetic observations is judged not in terms of the fit to the observations per se but in terms of fit to the ground truth. A variety of error measures are examined. The experiments allow a statistically satisfying and quasi-optimal method to be synthesized, which is shown to be stable with up to 50 percent outlier contamination, and may still be used if there are more than 50 percent outliers. Performance bounds are established for the method, and a variety of robust methods to estimate the standard deviation of the error and covariance matrix of the parameters are examined.The results of the comparison have broad applicability to vision algorithms where the input data are corrupted not only by noise but also by gross outliers."
            },
            "slug": "The-Development-and-Comparison-of-Robust-Methods-Torr-Murray",
            "title": {
                "fragments": [],
                "text": "The Development and Comparison of Robust Methods for Estimating the Fundamental Matrix"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A variety of robust methods for the computation of the Fundamental Matrix, the calibration-free representation of camera motion, are developed from the principal categories of robust estimators, viz. case deletion diagnostics, M-estimators and random sampling, and the theory required to apply them to non-linear orthogonal regression problems is developed."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3083483"
                        ],
                        "name": "D. Nist\u00e9r",
                        "slug": "D.-Nist\u00e9r",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Nist\u00e9r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nist\u00e9r"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62222198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7fa589eec4658cf7f5beecb4b34273ad41c46f1",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis describes a system that completely automaticallybuilds a three-dimensional model of a scene given a sequence ofimages of the scene. The system also estimates the internalparameters of the camera and the poses from where the originalimages were taken. Results that have been produced from realworld sequences acquired with a handheld video camera arepresented.The main contribution of the thesis is in building acomplete system and applying it to full-scale real worldproblems, thereby facing the practical difficulties of far fromideal imagery. Contributions are also made to several systemcomponents, most notably in dealing with variable amounts ofmotion between frames, auto-calibration and densereconstruction from a large number of images. Thesecontributions are presented as appended papers to enable theexperienced reader to easily study the novelty of the thesis.The main text gives a detailed coherent account of thetheoretical foundation for the system and its components.There are several motivations for constructing systems ofthe proposed type. One motivation is to make it possible forany amateur photographer to produce graphical models of theworld with the use of a computer. The viewer of the materialcan then navigate through the model and view it from any point.Another application is the insertion of synthetic objects intoan existing video sequence. This task is frequently carried outin movie making but is then performed with a great deal ofexpensive manual work. A quite futuristic but highlyinteresting application is augmented reality where theuser\u0092s view of the world is augmented by the insertion ofsynthetic objects."
            },
            "slug": "Automatic-Dense-Reconstruction-from-Uncalibrated-Nist\u00e9r",
            "title": {
                "fragments": [],
                "text": "Automatic Dense Reconstruction from Uncalibrated Video Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This thesis describes a system that completely automatically builds a three-dimensional model of a scene given a sequence of images of the scene, and estimates the internalparameters of the camera and the poses from where the original images were taken."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069304183"
                        ],
                        "name": "Colin Davidson",
                        "slug": "Colin-Davidson",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Davidson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Colin Davidson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11564224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9ecef69e75400eebe14c718d02b63fe9fefd10c",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new method for recovery of epipolar geometry and feature correspondence between images which have undergone a significant deformation, either due to large rotation or wide baseline of the cameras. The method also encodes the uncertainty by providing an arbitrarily close approximation to the posterior distribution of the two view relation. The method operates on a pyramid from coarse to fine resolution, thus raising the problem of how to propagate information from one level to another in a statistically consistent way. The distribution of the parameters at each resolution is encoded nonparametrically as a set of particles. At the coarsest level, a random sample consensus Monte Carlo Markov chain (RANSAC-MCMC) estimator is used to initialize this set of particles, the posterior can then be approximated as a mixture of Gaussians fitted to these particles. The distribution at a coarser level influences the distribution at a finer level using the technique of sampling-importance-resampling (SIR) and MCMC, which allows for asymptotically correct approximations of the posterior distribution. The estimate of the posterior distribution at the level above is being used as the importance sampling function to generate a new set of particles, which can be further improved by MCMC. It is shown that the method is superior to previous single resolution RANSAC-style feature matchers."
            },
            "slug": "IMPSAC:-Synthesis-of-Importance-Sampling-and-Random-Torr-Davidson",
            "title": {
                "fragments": [],
                "text": "IMPSAC: Synthesis of Importance Sampling and Random Sample Consensus"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The method is shown that the method is superior to previous single resolution RANSAC-style feature matchers, and encodes the uncertainty by providing an arbitrarily close approximation to the posterior distribution of the two view relation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 325871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fcd806450d947e56c82ef2b438ad9c484069dc",
            "isKey": false,
            "numCitedBy": 1792,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations."
            },
            "slug": "Local-Grayvalue-Invariants-for-Image-Retrieval-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Local Grayvalue Invariants for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of retrieving images from large image databases with a method based on local grayvalue invariants which are computed at automatically detected interest points and allows for efficient retrieval from a database of more than 1,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144677513"
                        ],
                        "name": "David G. Jones",
                        "slug": "David-G.-Jones",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jones",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David G. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 13573519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef4da68443bd6fa826b05196f4fccdb62588a426",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computational-framework-for-determining-stereo-from-Jones-Malik",
            "title": {
                "fragments": [],
                "text": "Computational framework for determining stereo correspondence from a set of linear spatial filters"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808406"
                        ],
                        "name": "G. M. Landau",
                        "slug": "G.-M.-Landau",
                        "structuredName": {
                            "firstName": "Gad",
                            "lastName": "Landau",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. M. Landau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145910"
                        ],
                        "name": "E. Myers",
                        "slug": "E.-Myers",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Myers",
                            "middleNames": [
                                "Wimberly"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Myers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149399683"
                        ],
                        "name": "Jeanette P. Schmidt",
                        "slug": "Jeanette-P.-Schmidt",
                        "structuredName": {
                            "firstName": "Jeanette",
                            "lastName": "Schmidt",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeanette P. Schmidt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10405891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3025ac00c409a170c4765972756278c666fd97d",
            "isKey": false,
            "numCitedBy": 169,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of comparing two sequences A and B to determine their longest common subsequence (LCS) or the edit distance between them has been much studied. In this paper we consider the following incremental version of these problems: given an appropriate encoding of a comparison between A and B, can one incrementally compute the answer for A and bB, and the answer for A and Bb with equal efficiency, where b is an additional symbol? Our main result is a theorem exposing a surprising relationship between the dynamic programming solutions for two such \"adjacent\" problems. Given a threshold k on the number of differences to be permitted in an alignment, the theorem leads directly to an O(k) algorithm for incrementally computing a new solution from an old one, as contrasts the O(k2) time required to compute a solution from scratch. We further show, with a series of applications, that this algorithm is indeed more powerful than its nonincremental counterpart. We show this by solving the applications with greater asymptotic efficiency than heretofore possible. For example, we obtain O(nk) algorithms for the longest prefix approximate match problem, the approximate overlap problem, and cyclic string comparison."
            },
            "slug": "Incremental-String-Comparison-Landau-Myers",
            "title": {
                "fragments": [],
                "text": "Incremental String Comparison"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This paper considers the following incremental version of comparing two sequences A and B to determine their longest common subsequence (LCS) or the edit distance between them, and obtains O(nk) algorithms for the longest prefix approximate match problem, the approximate overlap problem, and cyclic string comparison."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Comput."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692283"
                        ],
                        "name": "C. Bauckhage",
                        "slug": "C.-Bauckhage",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Bauckhage",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bauckhage"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14571093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2713e7a59105a832e20c01c3c202b9dcd2b5f889",
            "isKey": false,
            "numCitedBy": 1730,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Many different low-level feature detectors exist and it is widely agreed that the evaluation of detectors is important. In this paper we introduce two evaluation criteria for interest points' repeatability rate and information content. Repeatability rate evaluates the geometric stability under different transformations. Information content measures the distinctiveness of features. Different interest point detectors are compared using these two criteria. We determine which detector gives the best results and show that it satisfies the criteria well."
            },
            "slug": "Evaluation-of-Interest-Point-Detectors-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Evaluation of Interest Point Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two evaluation criteria for interest points' repeatability rate and information content are introduced and different interest point detectors are compared using these two criteria."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725180"
                        ],
                        "name": "T. Cormen",
                        "slug": "T.-Cormen",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cormen",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cormen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145372049"
                        ],
                        "name": "C. Leiserson",
                        "slug": "C.-Leiserson",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Leiserson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leiserson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113911099"
                        ],
                        "name": "R. Rivest",
                        "slug": "R.-Rivest",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rivest",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rivest"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 222237163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f01c4e51cb33f4bed8d37832dc1325ec5dedf49d",
            "isKey": false,
            "numCitedBy": 12424,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThe updated new edition of the classic Introduction to Algorithms is intended primarily for use in undergraduate or graduate courses in algorithms or data structures. Like the first edition,this text can also be used for self-study by technical professionals since it discusses engineering issues in algorithm design as well as the mathematical aspects. \nIn its new edition,Introduction to Algorithms continues to provide a comprehensive introduction to the modern study of algorithms. The revision has been updated to reflect changes in the years since the book's original publication. New chapters on the role of algorithms in computing and on probabilistic analysis and randomized algorithms have been included. Sections throughout the book have been rewritten for increased clarity,and material has been added wherever a fuller explanation has seemed useful or new information warrants expanded coverage. \nAs in the classic first edition,this new edition of Introduction to Algorithms presents a rich variety of algorithms and covers them in considerable depth while making their design and analysis accessible to all levels of readers. Further,the algorithms are presented in pseudocode to make the book easily accessible to students from all programming language backgrounds. \nEach chapter presents an algorithm,a design technique,an application area,or a related topic. The chapters are not dependent on one another,so the instructor can organize his or her use of the book in the way that best suits the course's needs. Additionally,the new edition offers a 25% increase over the first edition in the number of problems,giving the book 155 problems and over 900 exercises thatreinforcethe concepts the students are learning."
            },
            "slug": "Introduction-to-Algorithms-Cormen-Leiserson",
            "title": {
                "fragments": [],
                "text": "Introduction to Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The updated new edition of the classic Introduction to Algorithms is intended primarily for use in undergraduate or graduate courses in algorithms or data structures and presents a rich variety of algorithms and covers them in considerable depth while making their design and analysis accessible to all levels of readers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47139824"
                        ],
                        "name": "A. Fitzgibbon",
                        "slug": "A.-Fitzgibbon",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Fitzgibbon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fitzgibbon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19144160,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "8ceca527eb7df6c08112ba09c9f3c16cf0cf6ea1",
            "isKey": false,
            "numCitedBy": 500,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe progress in completely automatically recovering 3D scene structure together with 3D camera positions from a sequence of images acquired by an unknown camera undergoing unknown movement."
            },
            "slug": "Automatic-Camera-Recovery-for-Closed-or-Open-Image-Fitzgibbon-Zisserman",
            "title": {
                "fragments": [],
                "text": "Automatic Camera Recovery for Closed or Open Image Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "Progress in completely automatically recovering 3D scene structure together with 3D camera positions from a sequence of images acquired by an unknown camera undergoing unknown movement is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145770978"
                        ],
                        "name": "J. Gregor",
                        "slug": "J.-Gregor",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Gregor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gregor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700257"
                        ],
                        "name": "M. Thomason",
                        "slug": "M.-Thomason",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Thomason",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Thomason"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6684070,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cad73e2c8f46c06947025a926175b09441b1e8fc",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "String alignment by dynamic programming is generalized to include cyclic shift and corresponding optimal alignment cost for strings representing cyclic patterns. A guided search algorithm uses bounds on alignment costs to find all optimal cyclic shifts. The bounds are derived from submatrices of an initial dynamic programming matrix. Algorithmic complexity is analyzed for major stages in the search. The applicability of the method is illustrated with satellite DNA sequences and circularly permuted protein sequences. >"
            },
            "slug": "Dynamic-Programming-Alignment-of-Sequences-Cyclic-Gregor-Thomason",
            "title": {
                "fragments": [],
                "text": "Dynamic Programming Alignment of Sequences Representing Cyclic Patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A guided search algorithm uses bounds on alignment costs to find all optimal cyclic shifts and corresponding optimal alignment cost for strings representing cyclic patterns."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 18,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Combining-Appearance-and-Topology-for-Wide-Baseline-Tell-Carlsson/835ddd57d615cc7e93a2b7589bbcbe49992ad14d?sort=total-citations"
}