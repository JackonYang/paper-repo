{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724065"
                        ],
                        "name": "D. M. Chickering",
                        "slug": "D.-M.-Chickering",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chickering",
                            "middleNames": [
                                "Maxwell"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Chickering"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50004012"
                        ],
                        "name": "Christopher Meek",
                        "slug": "Christopher-Meek",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Meek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Meek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 206
                            }
                        ],
                        "text": "To learn the decision-tree structure, we use a simple hill-climbingapproach in conjunction with a Bayesian score (posterior probability of model structure)as described by Friedman and Goldszmdit (1996) and Chickering, Heckerman, and Meek(1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1621481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f7e689a465ac321ce607427d86dd17163c12bc4",
            "isKey": false,
            "numCitedBy": 386,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently several researchers have investigated techniques for using data to learn Bayesian networks containing compact representations for the conditional probability distributions (CPDs) stored at each node. The majority of this work has concentrated on using decision-tree representations for the CPDs. In addition, researchers typically apply non-Bayesian (or asymptotically Bayesian) scoring functions such as MDL to evaluate the goodness-of-fit of networks to the data. \n \nIn this paper we investigate a Bayesian approach to learning Bayesian networks that contain the more general decision-graph representations of the CPDs. First, we describe how to evaluate the posterior probability-- that is, the Bayesian score--of such a network, given a database of observed cases. Second, we describe various search spaces that can be used, in conjunction with a scoring function and a search procedure, to identify one or more high-scoring networks. Finally, we present an experimentd evaluation of the search spaces, using a greedy algorithm and a Bayesian scoring function."
            },
            "slug": "A-Bayesian-Approach-to-Learning-Bayesian-Networks-Chickering-Heckerman",
            "title": {
                "fragments": [],
                "text": "A Bayesian Approach to Learning Bayesian Networks with Local Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A Bayesian approach to learning Bayesian networks that contain the more general decision-graph representations of the CPDs is investigated, and how to evaluate the posterior probability-- that is, the Bayesian score--of such a network, given a database of observed cases is described."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778725"
                        ],
                        "name": "J. Breese",
                        "slug": "J.-Breese",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Breese",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Breese"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772349"
                        ],
                        "name": "C. Kadie",
                        "slug": "C.-Kadie",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Kadie",
                            "middleNames": [
                                "Myers"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kadie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 11
                            }
                        ],
                        "text": "As done in Breese, Heckerman, and Kadie (1998), let us concentrate on the applicationof collaborative ltering|that is, preference prediction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 16
                            }
                        ],
                        "text": "In their paper, Breese et al. (1998) describe several CF scenarios, including binary versus non-binary preferences and implicit versus explicit voting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 942,
                                "start": 45
                            }
                        ],
                        "text": "A simple approach to this task, described in Breese et al. (1998), is as follows. For each item (e.g., product), de ne a variable with two states corresponding to whether or not that item was preferred (e.g., purchased). We shall use \\0\" and \\1\" to denote not preferred and preferred, respectively. Next, use the dataset of ratings to learn a Bayesian network for the joint distribution of these variables X = (X1; : : : ; Xn). The preferences of each user constitutes a case in the learning procedure. Once the Bayesian network is constructed, make predictions as follows. Given a new user's preferences x, use the Bayesian network to determine p(Xi = 1jx n Xi = 0) for each product Xi not purchased. That is, infer the probability that the user would have purchased the item had we not known he did not. Then, return a list of recommended products|among those that the user did not purchase|ranked by this probability. Breese et al. (1998) show that this approach outperforms memory-based and clusterbased methods on several implicit rating datasets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Breese et al. (1998) show that this approach outperforms memory-based and cluster-based methods on several implicit rating datasets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 45
                            }
                        ],
                        "text": "A simple approach to this task, described in Breese et al. (1998), is as follows."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 16
                            }
                        ],
                        "text": "In their paper, Breese et al. (1998)describe several CF scenarios, including binary versus non-binary preferences and implicitversus explicit voting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2885948,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36b4a92c8eca6fd6d1b8588fc1fd0e3f89a16623",
            "isKey": false,
            "numCitedBy": 5604,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Collaborative filtering or recommender systems use a database about user preferences to predict additional topics or products a new user might like. In this paper we describe several algorithms designed for this task, including techniques based on correlation coefficients, vector-based similarity calculations, and statistical Bayesian methods. We compare the predictive accuracy of the various methods in a set of representative problem domains. We use two basic classes of evaluation metrics. The first characterizes accuracy over a set of individual predictions in terms of average absolute deviation. The second estimates the utility of a ranked list of suggested items. This metric uses an estimate of the probability that a user will see a recommendation in an ordered list. \n \nExperiments were run for datasets associated with 3 application areas, 4 experimental protocols, and the 2 evaluation metr rics for the various algorithms. Results indicate that for a wide range of conditions, Bayesian networks with decision trees at each node and correlation methods outperform Bayesian-clustering and vector-similarity methods. Between correlation and Bayesian networks, the preferred method depends on the nature of the dataset, nature of the application (ranked versus one-by-one presentation), and the availability of votes with which to make predictions. Other considerations include the size of database, speed of predictions, and learning time."
            },
            "slug": "Empirical-Analysis-of-Predictive-Algorithms-for-Breese-Heckerman",
            "title": {
                "fragments": [],
                "text": "Empirical Analysis of Predictive Algorithms for Collaborative Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "Several algorithms designed for collaborative filtering or recommender systems are described, including techniques based on correlation coefficients, vector-based similarity calculations, and statistical Bayesian methods, to compare the predictive accuracy of the various methods in a set of representative problem domains."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31579914"
                        ],
                        "name": "R. Hofmann",
                        "slug": "R.-Hofmann",
                        "structuredName": {
                            "firstName": "Reimar",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hofmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700754"
                        ],
                        "name": "Volker Tresp",
                        "slug": "Volker-Tresp",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Tresp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volker Tresp"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 0
                            }
                        ],
                        "text": "Tresp and Hofmann (1998) describe (general) dependency networks, calling themMarkov blanket networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6338543,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8b6999fa84023803f9666faf0940ffd0219d4ce",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of learning structure in nonlinear Markov networks with continuous variables. This can be viewed as non-Gaussian multidimensional density estimation exploiting certain conditional independencies in the variables. Markov networks are a graphical way of describing conditional independencies well suited to model relationships which do not exhibit a natural causal ordering. We use neural network structures to model the quantitative relationships between variables. The main focus in this paper will be on learning the structure for the purpose of gaining insight into the underlying process. Using two data sets we show that interesting structures can be found using our approach. Inference will be briefly addressed."
            },
            "slug": "Nonlinear-Markov-Networks-for-Continuous-Variables-Hofmann-Tresp",
            "title": {
                "fragments": [],
                "text": "Nonlinear Markov Networks for Continuous Variables"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The main focus in this paper will be on learning the structure for the purpose of gaining insight into the underlying process using neural network structures to model the quantitative relationships between variables."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50785579"
                        ],
                        "name": "N. Friedman",
                        "slug": "N.-Friedman",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Friedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770007"
                        ],
                        "name": "M. Goldszmidt",
                        "slug": "M.-Goldszmidt",
                        "structuredName": {
                            "firstName": "Mois\u00e9s",
                            "lastName": "Goldszmidt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Goldszmidt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15634497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c9e02656982419870ccc0b60d4c8b1a6e4b449d",
            "isKey": false,
            "numCitedBy": 584,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we examine a novel addition to the known methods for learning Bayesian networks from data that improves the quality of the learned networks. Our approach explicitly represents and learns the local structure in the conditional probability tables (CPTs), that quantify these networks. This increases the space of possible models, enabling the representation of CPTs with a variable number of parameters that depends on the learned local structures. The resulting learning procedure is capable of inducing models that better emulate the real complexity of the interactions present in the data. We describe the theoretical foundations and practical aspects of learning local structures, as well as an empirical evaluation of the proposed method. This evaluation indicates that learning curves characterizing the procedure that exploits the local structure converge faster than these of the standard procedure. Our results also show that networks learned with local structure tend to be more complex (in terms of arcs), yet require less parameters."
            },
            "slug": "Learning-Bayesian-Networks-with-Local-Structure-Friedman-Goldszmidt",
            "title": {
                "fragments": [],
                "text": "Learning Bayesian Networks with Local Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A novel addition to the known methods for learning Bayesian networks from data that improves the quality of the learned networks and indicates that learning curves characterizing the procedure that exploits the local structure converge faster than these of the standard procedure."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6286159,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e16a25faf7428e1fc5ed0a10b8196c0499c7fd0d",
            "isKey": false,
            "numCitedBy": 3412,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical applications in fields such as bioinformatics, information retrieval, speech processing, image processing and communications often involve large-scale models in which thousands or millions of random variables are linked in complex ways. Graphical models provide a general methodology for approaching these problems, and indeed many of the models developed by researchers in these applied fields are instances of the general graphical model formalism. We review some of the basic ideas underlying graphical models, including the algorithmic ideas that allow graphical models to be deployed in large-scale data analysis problems. We also present examples of graphical models in bioinformatics, error-control coding and language processing."
            },
            "slug": "Graphical-Models-Jordan",
            "title": {
                "fragments": [],
                "text": "Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Some of the basic ideas underlying graphical models are reviewed, including the algorithmic ideas that allow graphical models to be deployed in large-scale data analysis problems and examples of graphical models in bioinformatics, error-control coding and language processing are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739329"
                        ],
                        "name": "Silvia Acid",
                        "slug": "Silvia-Acid",
                        "structuredName": {
                            "firstName": "Silvia",
                            "lastName": "Acid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Silvia Acid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728509"
                        ],
                        "name": "L. M. D. Campos",
                        "slug": "L.-M.-D.-Campos",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Campos",
                            "middleNames": [
                                "M.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. M. D. Campos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144359099"
                        ],
                        "name": "Antonio Gonz\u00e1lez",
                        "slug": "Antonio-Gonz\u00e1lez",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Gonz\u00e1lez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antonio Gonz\u00e1lez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143719659"
                        ],
                        "name": "R. Molina",
                        "slug": "R.-Molina",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Molina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Molina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6703190"
                        ],
                        "name": "N. P. D. L. Blanca",
                        "slug": "N.-P.-D.-L.-Blanca",
                        "structuredName": {
                            "firstName": "Nicol\u00e1s",
                            "lastName": "Blanca",
                            "middleNames": [
                                "P\u00e9rez",
                                "de",
                                "la"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. P. D. L. Blanca"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 206
                            }
                        ],
                        "text": "To learn the decision-tree structure, we use a simple hill-climbingapproach in conjunction with a Bayesian score (posterior probability of model structure)as described by Friedman and Goldszmdit (1996) and Chickering, Heckerman, and Meek(1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 63886303,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c452d66a2a44f5b01bb7178ee50ca0b5edd1c71",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The aim of this work is to introduce CASTLE (Causal Structures from Inductive Learning), a tool based on the bayesian approach to learning. CASTLE can be used so far to learn causal structures from raw data, propagate knowledge throughout polytrees, simulate and also edit polytree dependent distributions. CASTLE ([1] and [2]), is currently being developed by the authors in the DECSAI at the University of Granada. Basically, CASTLE estimates, from a file of examples, the (in)dependencies among the variables involved in the examples in order to build a polytree displaying such (in)dependencies. The steps to construct such polytree are: setting constrains among the variables, selecting a criterion to calculate the skeleton of the polytree and, finally, selecting the criterion to direct the obtained skeleton. Once the polytree is built, CASTLE allows the user to propagate knowledge throughout the obtained singly-connected graph using what has been called the bayesian approach to the knowledge propagation task. CASTLE can be also used as a platform where to test learning methods since it allows the users to create polytrees and simulate data from them and use the generated sample as learning samples."
            },
            "slug": "On-the-Bayesian-Approach-to-Learning-Acid-Campos",
            "title": {
                "fragments": [],
                "text": "On the Bayesian Approach to Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The aim of this work is to introduce CASTLE (Causal Structures from Inductive Learning), a tool based on the bayesian approach to learning that can be used so far to learn causal structures from raw data, propagate knowledge throughout polytrees, simulate and also edit polytree dependent distributions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70219052"
                        ],
                        "name": "Wray L. Buntine",
                        "slug": "Wray-L.-Buntine",
                        "structuredName": {
                            "firstName": "Wray",
                            "lastName": "Buntine",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wray L. Buntine"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 65
                            }
                        ],
                        "text": "We have used methods based onprobabilistic decision trees (e.g., Buntine, 1991) and probabilistic support vector machines57\n(e.g., Platt, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 149
                            }
                        ],
                        "text": "\u2026cation techniques (or regression techniques, if we were to consider continuousvariables) such as methods using a probabilistic decision tree (e.g., Buntine, 1991), a gen-eralized linear model (e.g., McCullagh and Nelder, 1989), a neural network (e.g., Bishop,1995), a probabilistic support-vector\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2124212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "011fc271a69a3aa4cf2683099a5abcdc03317e26",
            "isKey": false,
            "numCitedBy": 756,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Theory-Refinement-on-Bayesian-Networks-Buntine",
            "title": {
                "fragments": [],
                "text": "Theory Refinement on Bayesian Networks"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50004012"
                        ],
                        "name": "Christopher Meek",
                        "slug": "Christopher-Meek",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Meek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Meek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 410,
                                "start": 384
                            }
                        ],
                        "text": "If we assume that each local distribution has a parametric model p(xijpai; i), and ignore the dependencies among the parameter sets 1; : : : ; n, then we can learn each local distribution independently using any regression/classi cation technique for models such as a generalized linear model, a neural network, a support-vector machine, or an embedded regression/classi cation model (Heckerman and Meek, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 270
                            }
                        ],
                        "text": "\u2026using a probabilistic decision tree (e.g., Buntine, 1991), a gen-eralized linear model (e.g., McCullagh and Nelder, 1989), a neural network (e.g., Bishop,1995), a probabilistic support-vector machine (e.g., Platt, 1999), or an embedded regres-sion/classi cation model (Heckerman and Meek, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 792,
                                "start": 385
                            }
                        ],
                        "text": "If we assume that each local distribution has a parametric model p(xijpai; i), and ignore the dependencies among the parameter sets 1; : : : ; n, then we can learn each local distribution independently using any regression/classi cation technique for models such as a generalized linear model, a neural network, a support-vector machine, or an embedded regression/classi cation model (Heckerman and Meek, 1997). From this perspective, the dependency network can be thought of as a mechanism for combining regression/classi cation models via Gibbs sampling to determine a joint distribution. In the work described in this paper, we use decision trees for the local distributions. A good discussion of methods for learning decision trees is given in Breiman, Friedman, Olshen, and Stone (1984). We learn a decision tree using a simple hill-climbing approach in conjunction with a Bayesian score as described in Friedman and Goldszmdit (1996) and Chickering, Heckerman, and Meek (1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 983,
                                "start": 385
                            }
                        ],
                        "text": "If we assume that each local distribution has a parametric model p(xijpai; i), and ignore the dependencies among the parameter sets 1; : : : ; n, then we can learn each local distribution independently using any regression/classi cation technique for models such as a generalized linear model, a neural network, a support-vector machine, or an embedded regression/classi cation model (Heckerman and Meek, 1997). From this perspective, the dependency network can be thought of as a mechanism for combining regression/classi cation models via Gibbs sampling to determine a joint distribution. In the work described in this paper, we use decision trees for the local distributions. A good discussion of methods for learning decision trees is given in Breiman, Friedman, Olshen, and Stone (1984). We learn a decision tree using a simple hill-climbing approach in conjunction with a Bayesian score as described in Friedman and Goldszmdit (1996) and Chickering, Heckerman, and Meek (1997). To learn a decision tree for Xi, we initialize the search algorithm with a singleton root node having no children."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5080990,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab57b6241c6f3d472fe804bb2cfda5dded0c4c67",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "When performing regression or classification, we are interested in the conditional probability distribution for an outcome or class variable Y given a set of explanatory or input variables X. We consider Bayesian models for this task. In particular, we examine a special class of models, which we call Bayesian regression/classification (BRC) models, that can be factored into independent conditional (y[x) and input (x) models. These models are convenient, because the conditional model (the portion of the full model that we care about) can be analyzed by itself. We examine the practice of transforming arbitrary Bayesian models to BRC models, and argue that this practice is often inappropriate because it ignores prior knowledge that may be important for learning. In addition, we examine Bayesian methods for learning models from data. We discuss two criteria for Bayesian model selection that are appropriate for repression/classification: one described by Spiegelhalter etah (1993), and other by Buntine (1993). We contrast these two criteria using the prequentia] framework of Dawid (1984), and give sufficient conditions under which the criteria agree."
            },
            "slug": "Models-and-Selection-Criteria-for-Regression-and-Heckerman-Meek",
            "title": {
                "fragments": [],
                "text": "Models and Selection Criteria for Regression and Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A special class of models that can be factored into independent conditional (y[x) and input (x) models, that are convenient for regression or classification and are appropriate for repression/classification are examined."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3072213"
                        ],
                        "name": "J. Besag",
                        "slug": "J.-Besag",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Besag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Besag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145392702"
                        ],
                        "name": "P. Green",
                        "slug": "P.-Green",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Green",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Green"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145880785"
                        ],
                        "name": "D. Higdon",
                        "slug": "D.-Higdon",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Higdon",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Higdon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3069617"
                        ],
                        "name": "K. Mengersen",
                        "slug": "K.-Mengersen",
                        "structuredName": {
                            "firstName": "Kerrie",
                            "lastName": "Mengersen",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mengersen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 120361769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41fb79ea7f0fcde0f2f55a2979446a28a733b6b9",
            "isKey": false,
            "numCitedBy": 1055,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "Markov chain Monte Carlo (MCMC) methods have been used extensively in statistical physics over the last 40 years, in spatial statistics for the past 20 and in Bayesian image analysis over the last decade. In the last five years, MCMC has been introduced into significance testing, general Bayesian inference and maximum likelihood estimation. This paper presents basic methodology of MCMC, emphasizing the Bayesian paradigm, conditional probability and the intimate relationship with Markov random fields in spatial statistics. Hastings algorithms are discussed, including Gibbs, Metropolis and some other variations. Pairwise difference priors are described and are used subsequently in three Bayesian applications, in each of which there is a pronounced spatial or temporal aspect to the modeling. The examples involve logistic regression in the presence of unobserved covariates and ordinal factors; the analysis of agricultural field experiments, with adjustment for fertility gradients; and processing of low-resolution medical images obtained by a gamma camera. Additional methodological issues arise in each of these applications and in the Appendices. The paper lays particular emphasis on the calculation of posterior probabilities and concurs with others in its view that MCMC facilitates a fundamental breakthrough in applied Bayesian modeling."
            },
            "slug": "Bayesian-Computation-and-Stochastic-Systems-Besag-Green",
            "title": {
                "fragments": [],
                "text": "Bayesian Computation and Stochastic Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Basic methodology of MCMC is presented, emphasizing the Bayesian paradigm, conditional probability and the intimate relationship with Markov random fields in spatial statistics, and particular emphasis on the calculation of posterior probabilities."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 37
                            }
                        ],
                        "text": "Proof: We use the graphoid axioms of Pearl (1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 37
                            }
                        ],
                        "text": "Proof: We use the graphoid axioms of Pearl (1988). Suppose the theorem is false."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 32583695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70ef29e6f0ce082bb8a47fd85b9bfb7cc0f20c93",
            "isKey": false,
            "numCitedBy": 18219,
            "numCiting": 230,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nProbabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty\u0097and offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognition\u0097in short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. \nProbabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability."
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-of-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems - networks of plausible inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic."
            },
            "venue": {
                "fragments": [],
                "text": "Morgan Kaufmann series in representation and reasoning"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144238498"
                        ],
                        "name": "B. N. Larsen",
                        "slug": "B.-N.-Larsen",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Larsen",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. N. Larsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "74208271"
                        ],
                        "name": "H.-G. Leimer",
                        "slug": "H.-G.-Leimer",
                        "structuredName": {
                            "firstName": "H.-G.",
                            "lastName": "Leimer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H.-G. Leimer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 404,
                                "start": 36
                            }
                        ],
                        "text": "The type of algorithm introduced by Resnik et al. (1994), sometimes called amemorybased algorithm, does something similar. Given a user's preferences on a series of items, the algorithm nds similar users in a database of stored preferences. It then returns some weighted average of preferences among these users on items not yet rated by the original user. As done in Breese, Heckerman, and Kadie (1998), let us concentrate on the application of collaborative ltering|that is, preference prediction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 36
                            }
                        ],
                        "text": "The type of algorithm introduced by Resnik et al. (1994), sometimes called amemorybased algorithm, does something similar."
                    },
                    "intents": []
                }
            ],
            "corpusId": 20450895,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f78884604e3fb89b1fb24d2a9403191dc9e63bd3",
            "isKey": false,
            "numCitedBy": 572,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate directed Markov fields over finite graphs without positivity assumptions on the densities involved. A criterion for conditional independence of two groups of variables given a third is given and named as the directed, global Markov property. We give a simple proof of the fact that the directed, local Markov property and directed, global Markov property are equivalent and \u2013 in the case of absolute continuity w. r. t. a product measure \u2013 equivalent to the recursive factorization of densities. It is argued that our criterion is easy to use, it is sharper than that given by Kiiveri, Speed, and Carlin and equivalent to that of Pearl. It follows that our criterion cannot be sharpened."
            },
            "slug": "Independence-properties-of-directed-markov-fields-Lauritzen-Dawid",
            "title": {
                "fragments": [],
                "text": "Independence properties of directed markov fields"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A criterion for conditional independence of two groups of variables given a third is given and named as the directed, global Markov property and it is argued that this criterion is easy to use, it is sharper than that given by Kiiveri, Speed, and Carlin and equivalent to that of Pearl."
            },
            "venue": {
                "fragments": [],
                "text": "Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3072213"
                        ],
                        "name": "J. Besag",
                        "slug": "J.-Besag",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Besag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Besag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Besag (1975) also described an approach called pseudo-likelihood estimation,in which the conditionals are learned directly|as in our approach|without respecting theconsistency constraints."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 116757950,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1406b6d771c270aff4dcb1c96e4f5c62c02c00a5",
            "isKey": false,
            "numCitedBy": 1657,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In rather formal terms, the situation with which this paper is concerned may be described as follows. We are given a fixed system of n sites, labelled by the first n positive integers, and an associated vector x of observations, Xi, . . ., Xn, which, in turn, is presumed to be a realization of a vector X of (dependent) random variables, Xi, . . ., X.. In practice, the sites may represent points or regions in space and the random variables may be either continuous or discrete. The main statistical objectives are the following: firstly, to provide a means of using the available concomitant information, particularly the configuration of the sites, to attach a plausible probability distribution to the random vector X; secondly, to estimate any unknown parameters in the distribution from the realization x; thirdly, where possible, to quantify the extent of disagreement between hypothesis and observation."
            },
            "slug": "Statistical-Analysis-of-Non-Lattice-Data-Besag",
            "title": {
                "fragments": [],
                "text": "Statistical Analysis of Non-Lattice Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52089885"
                        ],
                        "name": "Wray L. BuntineRIACS",
                        "slug": "Wray-L.-BuntineRIACS",
                        "structuredName": {
                            "firstName": "Wray",
                            "lastName": "BuntineRIACS",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wray L. BuntineRIACS"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 65
                            }
                        ],
                        "text": "We have used methods based onprobabilistic decision trees (e.g., Buntine, 1991) and probabilistic support vector machines57\n(e.g., Platt, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 149
                            }
                        ],
                        "text": "\u2026cation techniques (or regression techniques, if we were to consider continuousvariables) such as methods using a probabilistic decision tree (e.g., Buntine, 1991), a gen-eralized linear model (e.g., McCullagh and Nelder, 1989), a neural network (e.g., Bishop,1995), a probabilistic support-vector\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13593309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9bdb1db3a2ba290cd69c665674c1d205ecd8523a",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Theory reenement is the task of updating a domain theory in the light of new cases, to be done automatically or with some expert assistance. The problem of theory reenement under uncertainty is reviewed here in the context of Bayesian statistics, a theory of belief revision. The problem is reduced to an incre-mental learning task as follows: the learning system is initially primed with a partial theory supplied by a domain expert, and thereafter maintains its own internal representation of alternative theories which is able to be interrogated by the domain expert and able to be incrementally reened from data. Algorithms for reenement of Bayesian networks are presented to illustrate what is meant by \\partial theory\", \\alternative theory repre-sentation\", etc. The algorithms are an incre-mental variant of batch learning algorithms from the literature so can work well in batch and incremental mode."
            },
            "slug": "Theory-Reenement-on-Bayesian-Networks-BuntineRIACS",
            "title": {
                "fragments": [],
                "text": "Theory Reenement on Bayesian Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Algorithms for reenement of Bayesian networks are presented to illustrate what is meant by partial theory, and are an incre-mental variant of batch learning algorithms from the literature so can work well in batch and incremental mode."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69410608"
                        ],
                        "name": "E. Fowlkes",
                        "slug": "E.-Fowlkes",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69060716"
                        ],
                        "name": "A. Freeny",
                        "slug": "A.-Freeny",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Freeny",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Freeny"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2720076"
                        ],
                        "name": "J. Landwehr",
                        "slug": "J.-Landwehr",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Landwehr",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Landwehr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 148
                            }
                        ],
                        "text": "\u2026regarding thecollege plans of high-school seniors, (2) Women and Mathematics (WAM), data regardingwomen's preferences for a career in Mathematics (Fowlkes, Freeny, and Landwehr, 1988),(3) Digits, images of handwritten digits made available by the US Postal Service O ce forAdvanced Technology\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 137
                            }
                        ],
                        "text": "We use four datasets: (1) Sewall/Shah, data from Sewall and Shah (1968) regarding thecollege plans of high-school seniors, (2) Women and Mathematics (WAM), data regardingwomen's preferences for a career in Mathematics (Fowlkes, Freeny, and Landwehr, 1988),(3) Digits, images of handwritten digits made available by the US Postal Service O ce forAdvanced Technology (Frey, Hinton, and Dayan, 1995), and (4)Nielsen, data about whetheror not users watched ve or more minutes of network TV shows aired during a two-weekperiod in 1995 (made available by Nielsen Media Research)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 123671120,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "fa573502785e42a521f9c58b324d2c220c815001",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract This article discusses through three examples several new methods to aid in the analysis of large contingency tables. The general goal is to give better understanding of specific contingency tables, both by comparing how various log-linear/logistic models fit and through clearer interpretations of the resulting fits. For model selection, we show how to focus on a subset of simple, good-fitting models, beginning with a plot of a goodness-of-fit statistic versus residual degrees of freedom for all of the fitted models. To assess whether a particular model is adequate, we demonstrate that certain plots of residuals can reveal interesting effects that are often otherwise hidden. For model summarization and interpretation, we plot odds-ratio factors with confidence intervals to show the effects of explanatory variables in a concise and appealing way. The first example involves the relationship of job satisfaction to demographic variables for craft employees of a large corporation. The data presented c..."
            },
            "slug": "Evaluating-Logistic-Models-for-Large-Contingency-Fowlkes-Freeny",
            "title": {
                "fragments": [],
                "text": "Evaluating Logistic Models for Large Contingency Tables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145833095"
                        ],
                        "name": "S. Kothari",
                        "slug": "S.-Kothari",
                        "structuredName": {
                            "firstName": "Suresh",
                            "lastName": "Kothari",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kothari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681982"
                        ],
                        "name": "H. Oh",
                        "slug": "H.-Oh",
                        "structuredName": {
                            "firstName": "Heekuck",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Oh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 148
                            }
                        ],
                        "text": "\u2026using a probabilistic decision tree (e.g., Buntine, 1991), a gen-eralized linear model (e.g., McCullagh and Nelder, 1989), a neural network (e.g., Bishop,1995), a probabilistic support-vector machine (e.g., Platt, 1999), or an embedded regres-sion/classi cation model (Heckerman and Meek, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 177751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbc0a468ab103ae29717703d4aa9f682f6a2b664",
            "isKey": false,
            "numCitedBy": 15339,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-Networks-for-Pattern-Recognition-Kothari-Oh",
            "title": {
                "fragments": [],
                "text": "Neural Networks for Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Comput."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Jensen, F., Lauritzen, S., & Olesen, K. (1990)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 347,
                                "start": 340
                            }
                        ],
                        "text": "Given a consistent dependency network for X, we can perform probabilistic inferenceby converting it to a Markov network, triangulating that network (forming a decompos-able graphical model), and then applying one of the standard algorithms for probabilisticinference in the latter representation|for example, the junction tree algorithm of Jensen,Lauritzen, and Olesen (1990)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 378,
                                "start": 349
                            }
                        ],
                        "text": "Given a consistent dependency network for X, we can perform probabilistic inference by converting it to a Markov network, triangulating that network (forming a decomposable graphical model), and then applying one of the standard algorithms for probabilistic inference in the latter representation|for example, the junction tree algorithm of Jensen, Lauritzen, and Olesen (1990). Alternatively, we can use Gibbs sampling (e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": false,
            "numCitedBy": 18711,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144741762"
                        ],
                        "name": "P. Resnick",
                        "slug": "P.-Resnick",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Resnick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32895600"
                        ],
                        "name": "N. Iacovou",
                        "slug": "N.-Iacovou",
                        "structuredName": {
                            "firstName": "Neophytos",
                            "lastName": "Iacovou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Iacovou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48185525"
                        ],
                        "name": "M. Suchak",
                        "slug": "M.-Suchak",
                        "structuredName": {
                            "firstName": "Mitesh",
                            "lastName": "Suchak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Suchak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073783270"
                        ],
                        "name": "P. Bergstrom",
                        "slug": "P.-Bergstrom",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bergstrom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bergstrom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2579342"
                        ],
                        "name": "J. Riedl",
                        "slug": "J.-Riedl",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Riedl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Riedl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 36
                            }
                        ],
                        "text": "The type of algorithm introduced by Resnik et al. (1994), sometimes called amemory-based algorithm, does something similar."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2616594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64a717dc148b76070bbb6a3190a7e05bb9734400",
            "isKey": false,
            "numCitedBy": 5750,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Collaborative filters help people make choices based on the opinions of other people. GroupLens is a system for collaborative filtering of netnews, to help people find articles they will like in the huge stream of available articles. News reader clients display predicted scores and make it easy for users to rate articles after they read them. Rating servers, called Better Bit Bureaus, gather and disseminate the ratings. The rating servers predict scores based on the heuristic that people who agreed in the past will probably agree again. Users can protect their privacy by entering ratings under pseudonyms, without reducing the effectiveness of the score prediction. The entire architecture is open: alternative software for news clients and Better Bit Bureaus can be developed independently and can interoperate with the components we have developed."
            },
            "slug": "GroupLens:-an-open-architecture-for-collaborative-Resnick-Iacovou",
            "title": {
                "fragments": [],
                "text": "GroupLens: an open architecture for collaborative filtering of netnews"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "GroupLens is a system for collaborative filtering of netnews, to help people find articles they will like in the huge stream of available articles, and protect their privacy by entering ratings under pseudonyms, without reducing the effectiveness of the score prediction."
            },
            "venue": {
                "fragments": [],
                "text": "CSCW '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72184075"
                        ],
                        "name": "F. William",
                        "slug": "F.-William",
                        "structuredName": {
                            "firstName": "Feller",
                            "lastName": "William",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. William"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 65112646,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "65ba8fd8ef9c2a70cee99d2e5cab9302d0307a1e",
            "isKey": false,
            "numCitedBy": 12393,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Office hours: MWF, immediately after class or early afternoon (time TBA). We will cover the mathematical foundations of probability theory. The basic terminology and concepts of probability theory include: random experiments, sample or outcome spaces (discrete and continuous case), events and their algebra, probability measures, conditional probability A First Course in Probability (8th ed.) by S. Ross. This is a lively text that covers the basic ideas of probability theory including those needed in statistics. Theoretical concepts are introduced via interesting concrete examples. In 394 I will begin my lectures with the basics of probability theory in Chapter 2. However, your first assignment is to review Chapter 1, which treats elementary counting methods. They are used in applications in Chapter 2. I expect to cover Chapters 2-5 plus portions of 6 and 7. You are encouraged to read ahead. In lectures I will not be able to cover every topic and example in Ross, and conversely, I may cover some topics/examples in lectures that are not treated in Ross. You will be responsible for all material in my lectures, assigned reading, and homework, including supplementary handouts if any."
            },
            "slug": "An-Introduction-To-Probability-Theory-And-Its-William",
            "title": {
                "fragments": [],
                "text": "An Introduction To Probability Theory And Its Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A First Course in Probability (8th ed.) by S. Ross is a lively text that covers the basic ideas of probability theory including those needed in statistics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1950
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 404,
                                "start": 36
                            }
                        ],
                        "text": "The type of algorithm introduced by Resnik et al. (1994), sometimes called amemorybased algorithm, does something similar. Given a user's preferences on a series of items, the algorithm nds similar users in a database of stored preferences. It then returns some weighted average of preferences among these users on items not yet rated by the original user. As done in Breese, Heckerman, and Kadie (1998), let us concentrate on the application of collaborative ltering|that is, preference prediction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 131
                            }
                        ],
                        "text": "We have used methods based onprobabilistic decision trees (e.g., Buntine, 1991) and probabilistic support vector machines57\n(e.g., Platt, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 208
                            }
                        ],
                        "text": "\u2026using a probabilistic decision tree (e.g., Buntine, 1991), a gen-eralized linear model (e.g., McCullagh and Nelder, 1989), a neural network (e.g., Bishop,1995), a probabilistic support-vector machine (e.g., Platt, 1999), or an embedded regres-sion/classi cation model (Heckerman and Meek, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 36
                            }
                        ],
                        "text": "The type of algorithm introduced by Resnik et al. (1994), sometimes called amemorybased algorithm, does something similar."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1099857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4de39c94e340a108fff01a90a67b0c17c86fb981",
            "isKey": true,
            "numCitedBy": 5910,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter describes a new algorithm for training Support Vector Machines: Sequential Minimal Optimization, or SMO. Training a Support Vector Machine (SVM) requires the solution of a very large quadratic programming (QP) optimization problem. SMO breaks this large QP problem into a series of smallest possible QP problems. These small QP problems are solved analytically, which avoids using a time-consuming numerical QP optimization as an inner loop. The amount of memory required for SMO is linear in the training set size, which allows SMO to handle very large training sets. Because large matrix computation is avoided, SMO scales somewhere between linear and quadratic in the training set size for various test problems, while a standard projected conjugate gradient (PCG) chunking algorithm scales somewhere between linear and cubic in the training set size. SMO's computation time is dominated by SVM evaluation, hence SMO is fastest for linear SVMs and sparse data sets. For the MNIST database, SMO is as fast as PCG chunking; while for the UCI Adult database and linear SVMs, SMO can be more than 1000 times faster than the PCG chunking algorithm."
            },
            "slug": "Fast-training-of-support-vector-machines-using-in-Platt",
            "title": {
                "fragments": [],
                "text": "Fast training of support vector machines using sequential minimal optimization, advances in kernel methods"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "SMO breaks this large quadratic programming problem into a series of smallest possible QP problems, which avoids using a time-consuming numerical QP optimization as an inner loop and hence SMO is fastest for linear SVMs and sparse data sets."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2527241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbb0362cbfef094dbed0907329e6057dc5d09714",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The wake-sleep algorithm (Hinton, Dayan, Frey and Neal 1995) is a relatively efficient method of fitting a multilayer stochastic generative model to high-dimensional data. In addition to the top-down connections in the generative model, it makes use of bottom-up connections for approximating the probability distribution over the hidden units given the data, and it trains these bottom-up connections using a simple delta rule. We use a variety of synthetic and real data sets to compare the performance of the wake-sleep algorithm with Monte Carlo and mean field methods for fitting the same generative model and also compare it with other models that are less powerful but easier to fit."
            },
            "slug": "Does-the-Wake-sleep-Algorithm-Produce-Good-Density-Frey-Hinton",
            "title": {
                "fragments": [],
                "text": "Does the Wake-sleep Algorithm Produce Good Density Estimators?"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work uses a variety of synthetic and real data sets to compare the performance of the wake-sleep algorithm with Monte Carlo and mean field methods for fitting the same generative model and also compares it with other models that are less powerful but easier to fit."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1999,
                                "start": 36
                            }
                        ],
                        "text": "The type of algorithm introduced by Resnik et al. (1994), sometimes called amemorybased algorithm, does something similar. Given a user's preferences on a series of items, the algorithm nds similar users in a database of stored preferences. It then returns some weighted average of preferences among these users on items not yet rated by the original user. As done in Breese, Heckerman, and Kadie (1998), let us concentrate on the application of collaborative ltering|that is, preference prediction. In their paper, Breese et al. (1998) describe several CF scenarios, including binary versus non-binary preferences and implicit versus explicit voting. An example of explicit voting would be movie ratings provided by a user. An example of implicit voting would be knowing only whether a person has or has not purchased a product. Here, we concentrate on one scenario important for e-commerce: implicit voting with binary preferences|for example, the task of predicting what products a person will buy, knowing only what other products they have purchased. A simple approach to this task, described in Breese et al. (1998), is as follows. For each item (e.g., product), de ne a variable with two states corresponding to whether or not that item was preferred (e.g., purchased). We shall use \\0\" and \\1\" to denote not preferred and preferred, respectively. Next, use the dataset of ratings to learn a Bayesian network for the joint distribution of these variables X = (X1; : : : ; Xn). The preferences of each user constitutes a case in the learning procedure. Once the Bayesian network is constructed, make predictions as follows. Given a new user's preferences x, use the Bayesian network to estimate p(xi = 1jx n xi = 0) for each product Xi not purchased. That is, estimate the probability that the user would have purchased the item had we not known he did not. Then, return a list of recommended products|among those that the user did not purchase|ranked by these estimates. Breese et al. (1998) show that this approach outperforms memory-based and clusterbased methods on several implicit rating datasets."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 36
                            }
                        ],
                        "text": "The type of algorithm introduced by Resnik et al. (1994), sometimes called amemorybased algorithm, does something similar."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 404,
                                "start": 36
                            }
                        ],
                        "text": "The type of algorithm introduced by Resnik et al. (1994), sometimes called amemorybased algorithm, does something similar. Given a user's preferences on a series of items, the algorithm nds similar users in a database of stored preferences. It then returns some weighted average of preferences among these users on items not yet rated by the original user. As done in Breese, Heckerman, and Kadie (1998), let us concentrate on the application of collaborative ltering|that is, preference prediction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 36
                            }
                        ],
                        "text": "The type of algorithm introduced by Resnik et al. (1994), sometimes called amemory-based algorithm, does something similar."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 537,
                                "start": 36
                            }
                        ],
                        "text": "The type of algorithm introduced by Resnik et al. (1994), sometimes called amemorybased algorithm, does something similar. Given a user's preferences on a series of items, the algorithm nds similar users in a database of stored preferences. It then returns some weighted average of preferences among these users on items not yet rated by the original user. As done in Breese, Heckerman, and Kadie (1998), let us concentrate on the application of collaborative ltering|that is, preference prediction. In their paper, Breese et al. (1998) describe several CF scenarios, including binary versus non-binary preferences and implicit versus explicit voting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1122,
                                "start": 36
                            }
                        ],
                        "text": "The type of algorithm introduced by Resnik et al. (1994), sometimes called amemorybased algorithm, does something similar. Given a user's preferences on a series of items, the algorithm nds similar users in a database of stored preferences. It then returns some weighted average of preferences among these users on items not yet rated by the original user. As done in Breese, Heckerman, and Kadie (1998), let us concentrate on the application of collaborative ltering|that is, preference prediction. In their paper, Breese et al. (1998) describe several CF scenarios, including binary versus non-binary preferences and implicit versus explicit voting. An example of explicit voting would be movie ratings provided by a user. An example of implicit voting would be knowing only whether a person has or has not purchased a product. Here, we concentrate on one scenario important for e-commerce: implicit voting with binary preferences|for example, the task of predicting what products a person will buy, knowing only what other products they have purchased. A simple approach to this task, described in Breese et al. (1998), is as follows."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60502900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c4da62e9e89e65ac78ee271e424e8b498053e8c",
            "isKey": true,
            "numCitedBy": 5544,
            "numCiting": 260,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction to support vector learning roadmap. Part 1 Theory: three remarks on the support vector method of function estimation, Vladimir Vapnik generalization performance of support vector machines and other pattern classifiers, Peter Bartlett and John Shawe-Taylor Bayesian voting schemes and large margin classifiers, Nello Cristianini and John Shawe-Taylor support vector machines, reproducing kernel Hilbert spaces, and randomized GACV, Grace Wahba geometry and invariance in kernel based methods, Christopher J.C. Burges on the annealed VC entropy for margin classifiers - a statistical mechanics study, Manfred Opper entropy numbers, operators and support vector kernels, Robert C. Williamson et al. Part 2 Implementations: solving the quadratic programming problem arising in support vector classification, Linda Kaufman making large-scale support vector machine learning practical, Thorsten Joachims fast training of support vector machines using sequential minimal optimization, John C. Platt. Part 3 Applications: support vector machines for dynamic reconstruction of a chaotic system, Davide Mattera and Simon Haykin using support vector machines for time series prediction, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel. Part 4 Extensions of the algorithm: reducing the run-time complexity in support vector machines, Edgar E. Osuna and Federico Girosi support vector regression with ANOVA decomposition kernels, Mark O. Stitson et al support vector density estimation, Jason Weston et al combining support vector and mathematical programming methods for classification, Bernhard Scholkopf et al."
            },
            "slug": "Advances-in-kernel-methods:-support-vector-learning-Sch\u00f6lkopf-Burges",
            "title": {
                "fragments": [],
                "text": "Advances in kernel methods: support vector learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Support vector machines for dynamic reconstruction of a chaotic system, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39988880"
                        ],
                        "name": "D. Brook",
                        "slug": "D.-Brook",
                        "structuredName": {
                            "firstName": "D",
                            "lastName": "Brook",
                            "middleNames": [
                                "F"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Brook"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 92
                            }
                        ],
                        "text": "In particular, several researchers including L evy(1948), Bartlett (1955, Section 2.2), and Brook (1964) considered lattice systems where eachvariable Xi depended only on its nearest neighbors Pai, and quanti ed the dependencieswithin these systems using the conditional probability distributions\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122229925,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "802aea06a5a751558e45e7df622717e399e2e3f4",
            "isKey": true,
            "numCitedBy": 211,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-distinction-between-the-conditional-and-the-Brook",
            "title": {
                "fragments": [],
                "text": "On the distinction between the conditional probability and the joint probability approaches in the specification of nearest-neighbour systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117335982"
                        ],
                        "name": "W. H. Sewell",
                        "slug": "W.-H.-Sewell",
                        "structuredName": {
                            "firstName": "W",
                            "lastName": "Sewell",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. H. Sewell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66854271"
                        ],
                        "name": "V. Shah",
                        "slug": "V.-Shah",
                        "structuredName": {
                            "firstName": "Vimal",
                            "lastName": "Shah",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Shah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20441078,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "49e96ad389dfd274460be994cb53e078d1217316",
            "isKey": false,
            "numCitedBy": 484,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "In this study of a randomly selected cohort of 10,318 Wisconsin high school seniors, correlational, path, and cross-tabular analyses show that socioeconomic status, intelligence, and parental encouragement all have substantial independent relationships to college plans of males as well as of females and that neither intelligence nor parental encouragement-individually or jointly-can completely account for social class differences in college plans. It substantiates, however, the claim made by other investigators using less rigorous methods and less representative samples that parental encouragement is a powerful intervening variable between socioeconomic class background and intelligence of the child and his educational aspirations. Parental encouragement appears to have its strongest effect on the college plans of males and females who score relatively high on intelligence and come from families occupying relatively high socioeconomic position. Also, ability continues to accentuate the social class differences in aspirations of both males and females regardless of parental encouragement."
            },
            "slug": "Social-Class,-Parental-Encouragement,-and-Sewell-Shah",
            "title": {
                "fragments": [],
                "text": "Social Class, Parental Encouragement, and Educational Aspirations"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This study substantiates the claim made by other investigators using less rigorous methods and less representative samples that parental encouragement is a powerful intervening variable between socioeconomic class background and intelligence of the child and his educational aspirations."
            },
            "venue": {
                "fragments": [],
                "text": "American Journal of Sociology"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227161"
                        ],
                        "name": "J. Kiefer",
                        "slug": "J.-Kiefer",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Kiefer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kiefer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36234815"
                        ],
                        "name": "M. Bartlett",
                        "slug": "M.-Bartlett",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bartlett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124557023,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "84b21963d39bf7ee45a8e4436f2ad2b0a7df9aa3",
            "isKey": false,
            "numCitedBy": 664,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "M. S. Bartlett: An Introduction to Stochastic Processes. Cambridge University Press, 1955. Pp. xiv + 312. 35s."
            },
            "slug": "An-Introduction-to-Stochastic-Processes.-Kiefer-Bartlett",
            "title": {
                "fragments": [],
                "text": "An Introduction to Stochastic Processes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1956
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3072213"
                        ],
                        "name": "J. Besag",
                        "slug": "J.-Besag",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Besag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Besag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2155,
                                "start": 100
                            }
                        ],
                        "text": "For an excellent discussion of this development as well as original contributions in this area, see Besag (1974). Besag (1975) also described an approach called pseudo-likelihood estimation, in which the conditionals are learned directly|as in our approach|without respecting the consistency constraints. We use the name pseudo-Gibbs sampling to make a connection to his work. Tresp and Hofmann (1998) describe (general) dependency networks, calling them Markov blanket networks. They stated and proved Theorem 3, and evaluated the predictive accuracy of the representation on several data sets using local distributions consisting of conditional Parzen windows. 4. Collaborative Filtering We now turn our attention to collaborative ltering (CF), the task of predicting preferences. Examples of this task include predicting what movies a person will like based on his or her ratings of movies seen, predicting what news stories a person is interested in based on other stories he or she has read, and predicting what web pages a person will go to next based on his or her history on the site. Another important application in the burgeoning area of e-commerce is predicting what products a person will buy based on products he or she has already purchased and/or dropped into his or her shopping basket. Collaborative ltering was introduced by Resnick, Iacovou, Suchak, Bergstrom, and Riedl (1994) as both the task of predicting preferences and a class of algorithms for this task. The class of algorithms they described was based on the informal mechanisms people use to understand their own preferences. For example, when we want to nd a good movie, we talk to other people that have similar tastes and ask them what they like that we haven't seen. The type of algorithm introduced by Resnik et al. (1994), sometimes called amemorybased algorithm, does something similar. Given a user's preferences on a series of items, the algorithm nds similar users in a database of stored preferences. It then returns some weighted average of preferences among these users on items not yet rated by the original user. As done in Breese, Heckerman, and Kadie (1998), let us concentrate on the application of collaborative ltering|that is, preference prediction."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 124
                            }
                        ],
                        "text": "The proof of Theorem 1 appears in the Appendix, but it is essentially a restatement of theHammersley-Cli ord theorem (e.g., Besag, 1974)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2288,
                                "start": 100
                            }
                        ],
                        "text": "For an excellent discussion of this development as well as original contributions in this area, see Besag (1974). Besag (1975) also described an approach called pseudo-likelihood estimation, in which the conditionals are learned directly|as in our approach|without respecting the consistency constraints. We use the name pseudo-Gibbs sampling to make a connection to his work. Tresp and Hofmann (1998) describe (general) dependency networks, calling them Markov blanket networks. They stated and proved Theorem 3, and evaluated the predictive accuracy of the representation on several data sets using local distributions consisting of conditional Parzen windows. 4. Collaborative Filtering We now turn our attention to collaborative ltering (CF), the task of predicting preferences. Examples of this task include predicting what movies a person will like based on his or her ratings of movies seen, predicting what news stories a person is interested in based on other stories he or she has read, and predicting what web pages a person will go to next based on his or her history on the site. Another important application in the burgeoning area of e-commerce is predicting what products a person will buy based on products he or she has already purchased and/or dropped into his or her shopping basket. Collaborative ltering was introduced by Resnick, Iacovou, Suchak, Bergstrom, and Riedl (1994) as both the task of predicting preferences and a class of algorithms for this task. The class of algorithms they described was based on the informal mechanisms people use to understand their own preferences. For example, when we want to nd a good movie, we talk to other people that have similar tastes and ask them what they like that we haven't seen. The type of algorithm introduced by Resnik et al. (1994), sometimes called amemorybased algorithm, does something similar. Given a user's preferences on a series of items, the algorithm nds similar users in a database of stored preferences. It then returns some weighted average of preferences among these users on items not yet rated by the original user. As done in Breese, Heckerman, and Kadie (1998), let us concentrate on the application of collaborative ltering|that is, preference prediction. In their paper, Breese et al. (1998) describe several CF scenarios, including binary versus non-binary preferences and implicit versus explicit voting."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 185
                            }
                        ],
                        "text": "\u2026i = 1; : : : ; n. Becausep is positive and these independencies comprise the global Markov property of a Markovnetwork with Ai = Pai, i = 1; : : : ; n, the Hammersley{Cli ord theorem (Besag, 1974;72\nLauritzen, Dawid, Larsen, and Leimer, 1990) implies that p can be represented by thisMarkov network."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 100
                            }
                        ],
                        "text": "For an excellent discussion of this development as well as original contributions in this area, see Besag (1974). Besag (1975) also described an approach called pseudo-likelihood estimation, in which the conditionals are learned directly|as in our approach|without respecting the consistency constraints."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1398,
                                "start": 100
                            }
                        ],
                        "text": "For an excellent discussion of this development as well as original contributions in this area, see Besag (1974). Besag (1975) also described an approach called pseudo-likelihood estimation, in which the conditionals are learned directly|as in our approach|without respecting the consistency constraints. We use the name pseudo-Gibbs sampling to make a connection to his work. Tresp and Hofmann (1998) describe (general) dependency networks, calling them Markov blanket networks. They stated and proved Theorem 3, and evaluated the predictive accuracy of the representation on several data sets using local distributions consisting of conditional Parzen windows. 4. Collaborative Filtering We now turn our attention to collaborative ltering (CF), the task of predicting preferences. Examples of this task include predicting what movies a person will like based on his or her ratings of movies seen, predicting what news stories a person is interested in based on other stories he or she has read, and predicting what web pages a person will go to next based on his or her history on the site. Another important application in the burgeoning area of e-commerce is predicting what products a person will buy based on products he or she has already purchased and/or dropped into his or her shopping basket. Collaborative ltering was introduced by Resnick, Iacovou, Suchak, Bergstrom, and Riedl (1994) as both the task of predicting preferences and a class of algorithms for this task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 19
                            }
                        ],
                        "text": "As is discussed in Besag (1974), several researchers who developed the Markov-networkrepresentation did so by initially investigating a graphical representation that ts our de -nition of consistent dependency network."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 60
                            }
                        ],
                        "text": "Hammersley and Cli ord,in a never published manuscript, and Besag (1974) considered the more general case whereeach variable could have an arbitrary set of parents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1808,
                                "start": 100
                            }
                        ],
                        "text": "For an excellent discussion of this development as well as original contributions in this area, see Besag (1974). Besag (1975) also described an approach called pseudo-likelihood estimation, in which the conditionals are learned directly|as in our approach|without respecting the consistency constraints. We use the name pseudo-Gibbs sampling to make a connection to his work. Tresp and Hofmann (1998) describe (general) dependency networks, calling them Markov blanket networks. They stated and proved Theorem 3, and evaluated the predictive accuracy of the representation on several data sets using local distributions consisting of conditional Parzen windows. 4. Collaborative Filtering We now turn our attention to collaborative ltering (CF), the task of predicting preferences. Examples of this task include predicting what movies a person will like based on his or her ratings of movies seen, predicting what news stories a person is interested in based on other stories he or she has read, and predicting what web pages a person will go to next based on his or her history on the site. Another important application in the burgeoning area of e-commerce is predicting what products a person will buy based on products he or she has already purchased and/or dropped into his or her shopping basket. Collaborative ltering was introduced by Resnick, Iacovou, Suchak, Bergstrom, and Riedl (1994) as both the task of predicting preferences and a class of algorithms for this task. The class of algorithms they described was based on the informal mechanisms people use to understand their own preferences. For example, when we want to nd a good movie, we talk to other people that have similar tastes and ask them what they like that we haven't seen. The type of algorithm introduced by Resnik et al. (1994), sometimes called amemorybased algorithm, does something similar."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 402,
                                "start": 100
                            }
                        ],
                        "text": "For an excellent discussion of this development as well as original contributions in this area, see Besag (1974). Besag (1975) also described an approach called pseudo-likelihood estimation, in which the conditionals are learned directly|as in our approach|without respecting the consistency constraints. We use the name pseudo-Gibbs sampling to make a connection to his work. Tresp and Hofmann (1998) describe (general) dependency networks, calling them Markov blanket networks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2873,
                                "start": 100
                            }
                        ],
                        "text": "For an excellent discussion of this development as well as original contributions in this area, see Besag (1974). Besag (1975) also described an approach called pseudo-likelihood estimation, in which the conditionals are learned directly|as in our approach|without respecting the consistency constraints. We use the name pseudo-Gibbs sampling to make a connection to his work. Tresp and Hofmann (1998) describe (general) dependency networks, calling them Markov blanket networks. They stated and proved Theorem 3, and evaluated the predictive accuracy of the representation on several data sets using local distributions consisting of conditional Parzen windows. 4. Collaborative Filtering We now turn our attention to collaborative ltering (CF), the task of predicting preferences. Examples of this task include predicting what movies a person will like based on his or her ratings of movies seen, predicting what news stories a person is interested in based on other stories he or she has read, and predicting what web pages a person will go to next based on his or her history on the site. Another important application in the burgeoning area of e-commerce is predicting what products a person will buy based on products he or she has already purchased and/or dropped into his or her shopping basket. Collaborative ltering was introduced by Resnick, Iacovou, Suchak, Bergstrom, and Riedl (1994) as both the task of predicting preferences and a class of algorithms for this task. The class of algorithms they described was based on the informal mechanisms people use to understand their own preferences. For example, when we want to nd a good movie, we talk to other people that have similar tastes and ask them what they like that we haven't seen. The type of algorithm introduced by Resnik et al. (1994), sometimes called amemorybased algorithm, does something similar. Given a user's preferences on a series of items, the algorithm nds similar users in a database of stored preferences. It then returns some weighted average of preferences among these users on items not yet rated by the original user. As done in Breese, Heckerman, and Kadie (1998), let us concentrate on the application of collaborative ltering|that is, preference prediction. In their paper, Breese et al. (1998) describe several CF scenarios, including binary versus non-binary preferences and implicit versus explicit voting. An example of explicit voting would be movie ratings provided by a user. An example of implicit voting would be knowing only whether a person has or has not purchased a product. Here, we concentrate on one scenario important for e-commerce: implicit voting with binary preferences|for example, the task of predicting what products a person will buy, knowing only what other products they have purchased. A simple approach to this task, described in Breese et al. (1998), is as follows."
                    },
                    "intents": []
                }
            ],
            "corpusId": 42087677,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8bf730243ed967afd5349bef053641a6043517a0",
            "isKey": true,
            "numCitedBy": 6166,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Spatial-Interaction-and-the-Statistical-Analysis-of-Besag",
            "title": {
                "fragments": [],
                "text": "Spatial Interaction and the Statistical Analysis of Lattice Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 77
                            }
                        ],
                        "text": "When it is not, however, there are no existing guarantees such as the one in Hofmann (2000) for the unmodi ed ordered Gibbs sampler."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 50
                            }
                        ],
                        "text": "The representation was conceived independently by Hofmann and Tresp (1997), who used it for density estimation; and Hofmann (2000) investigated several of its theoretical properties."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 450,
                                "start": 77
                            }
                        ],
                        "text": "When it is not, however, there are no existing guarantees such as the one in Hofmann (2000) for the unmodi ed ordered Gibbs sampler. In the remainder of this section, we evaluate this algorithm on inconsistent dependency networks learned from a real datasets as a rst step towards an empirical justi cation of the algorithm. To evaluate our algorithm, we perform density estimation on four datasets: (1) Sewall/Shah, data from Sewall and Shah (1968) regarding the college plans of high-school"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 218
                            }
                        ],
                        "text": ", generalized linear models, neural networks, support-vector machines, or embedded regression/classi cation models) for a dependency network's local distributions? Another example of particular theoretical interest is Hofmann's (2000) result that small L2-norm perturbations in the local distributions lead to small L2-norm perturbations in the joint distributions de ned by the dependency network."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 240
                            }
                        ],
                        "text": "If we start with learned local distributions that are only slight perturbations (in some sense) of the true local distributions, will Gibbs sampling produce a joint distribution that is a slight perturbation of the true joint distribution? Hofmann (2000) argues that, for discrete dependency networks with positive local distributions, the answer to this question is yes when perturbations are measured with an L2 norm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inference in Markov blanket networks"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report FKI-235-00, Technical University of Munich."
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 62
                            }
                        ],
                        "text": "Here, wecite a potentially useful bound of this form given by Cho and Meyer (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 63
                            }
                        ],
                        "text": "Here, we cite a potentially useful bound of this form given by Cho and Meyer (1999). These authors provide references to many other bounds as well."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 9
                            }
                        ],
                        "text": "Theorem (Cho and Meyer, 1999): Let P and ~P = P + E be transition matrices fortwo homogenous, irreducible k-state Markov chains with respective stationary distributions and ~ ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 8
                            }
                        ],
                        "text": "Theorem (Cho and Meyer, 1999): Let P and ~ P = P + E be transition matrices for two homogenous, irreducible k-state Markov chains with respective stationary distributions and ~ ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Markov chain sensitivity by mean rst passage"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 629,
                                "start": 2
                            }
                        ],
                        "text": ", Buntine, 1991) and probabilistic support vector machines (e.g., Platt, 1999). For simplicity, we limit our discussion in this paper to the use of probabilistic decision trees. In this approach, for each variable Xi in X, we learn a probabilistic decision tree where Xi is the target variable and X n Xi are the input variables. Each leaf is modeled as a multinomial distribution. To learn the decision-tree structure, we use a simple hill-climbing approach in conjunction with a Bayesian score (posterior probability of model structure) as described by Friedman and Goldszmdit (1996) and Chickering, Heckerman, and Meek (1997). To learn a decision-tree structure for Xi, we initialize the search algorithm with a singleton root node having no children."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 65
                            }
                        ],
                        "text": "We have used methods based onprobabilistic decision trees (e.g., Buntine, 1991) and probabilistic support vector machines57\n(e.g., Platt, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 149
                            }
                        ],
                        "text": "\u2026cation techniques (or regression techniques, if we were to consider continuousvariables) such as methods using a probabilistic decision tree (e.g., Buntine, 1991), a gen-eralized linear model (e.g., McCullagh and Nelder, 1989), a neural network (e.g., Bishop,1995), a probabilistic support-vector\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 586,
                                "start": 2
                            }
                        ],
                        "text": ", Buntine, 1991) and probabilistic support vector machines (e.g., Platt, 1999). For simplicity, we limit our discussion in this paper to the use of probabilistic decision trees. In this approach, for each variable Xi in X, we learn a probabilistic decision tree where Xi is the target variable and X n Xi are the input variables. Each leaf is modeled as a multinomial distribution. To learn the decision-tree structure, we use a simple hill-climbing approach in conjunction with a Bayesian score (posterior probability of model structure) as described by Friedman and Goldszmdit (1996) and Chickering, Heckerman, and Meek (1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theory re nement on Bayesian networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Seventh"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 47
                            }
                        ],
                        "text": "In particular, several researchers including L evy(1948), Bartlett (1955, Section 2.2), and Brook (1964) considered lattice systems where eachvariable Xi depended only on its nearest neighbors Pai, and quanti ed the dependencieswithin these systems using the conditional probability distributions\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chaines doubles de Markoo et fonctions aleatories de deux variables"
            },
            "venue": {
                "fragments": [],
                "text": "Academcy of Science"
            },
            "year": 1948
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 47
                            }
                        ],
                        "text": "In particular, several researchers including L evy(1948), Bartlett (1955, Section 2.2), and Brook (1964) considered lattice systems where eachvariable Xi depended only on its nearest neighbors Pai, and quanti ed the dependencieswithin these systems using the conditional probability distributions\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chaines doubles de Marko et fonctions aleatories de deux variables"
            },
            "venue": {
                "fragments": [],
                "text": "Academcy of Science, Paris, 226, 53{55."
            },
            "year": 1948
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 11
                            }
                        ],
                        "text": "As done in Breese, Heckerman, and Kadie (1998), let us concentrate on the applicationof collaborative ltering|that is, preference prediction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Breese et al. (1998) show that this approach outperforms memory-based and cluster-based methods on several implicit rating datasets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Breese et al. (1998) show that this approach outperforms memory-based and clusterbased methods on several implicit rating datasets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 45
                            }
                        ],
                        "text": "A simple approach to this task, described in Breese et al. (1998), is as follows."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 16
                            }
                        ],
                        "text": "In their paper, Breese et al. (1998)describe several CF scenarios, including binary versus non-binary preferences and implicitversus explicit voting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Empirical analysis of predictive algorithms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683101"
                        ],
                        "name": "H. Kyburg",
                        "slug": "H.-Kyburg",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Kyburg",
                            "middleNames": [
                                "E."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kyburg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 37
                            }
                        ],
                        "text": "Proof: We use the graphoid axioms of Pearl (1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 151318556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be955ed381c2c03ec4dee5a005b8a1a37fca15c0",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-Reasoning-in-Intelligent-Systems:-of-Kyburg",
            "title": {
                "fragments": [],
                "text": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference by Judea Pearl"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145392702"
                        ],
                        "name": "P. Green",
                        "slug": "P.-Green",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Green",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Green"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125093681,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3f1bb45d5d20c107daa9dbc489019cf22a3a6e6b",
            "isKey": false,
            "numCitedBy": 4620,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Markov-chain-Monte-Carlo-in-Practice-Green",
            "title": {
                "fragments": [],
                "text": "Markov chain Monte Carlo in Practice"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Independence properties ofdirected Markov elds"
            },
            "venue": {
                "fragments": [],
                "text": "Networks"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 65
                            }
                        ],
                        "text": "We have used methods based onprobabilistic decision trees (e.g., Buntine, 1991) and probabilistic support vector machines57\n(e.g., Platt, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 149
                            }
                        ],
                        "text": "\u2026cation techniques (or regression techniques, if we were to consider continuousvariables) such as methods using a probabilistic decision tree (e.g., Buntine, 1991), a gen-eralized linear model (e.g., McCullagh and Nelder, 1989), a neural network (e.g., Bishop,1995), a probabilistic support-vector\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theory reenement o n B a yesian networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Seventh Conference on Uncertainty in Artiicial Intelligence"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Besag (1975) also described an approach called pseudo-likelihood estimation,in which the conditionals are learned directly|as in our approach|without respecting theconsistency constraints."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical analysis of nonlattice data"
            },
            "venue": {
                "fragments": [],
                "text": "The Statistician"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Jensen, F., Lauritzen, S., & Olesen, K. (1990)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 347,
                                "start": 340
                            }
                        ],
                        "text": "Given a consistent dependency network for X, we can perform probabilistic inferenceby converting it to a Markov network, triangulating that network (forming a decompos-able graphical model), and then applying one of the standard algorithms for probabilisticinference in the latter representation|for example, the junction tree algorithm of Jensen,Lauritzen, and Olesen (1990)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 378,
                                "start": 349
                            }
                        ],
                        "text": "Given a consistent dependency network for X, we can perform probabilistic inference by converting it to a Markov network, triangulating that network (forming a decomposable graphical model), and then applying one of the standard algorithms for probabilistic inference in the latter representation|for example, the junction tree algorithm of Jensen, Lauritzen, and Olesen (1990). Alternatively, we can use Gibbs sampling (e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian updating in recursive graphical models by local computations"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Statisticals Quarterly,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chaines doubles de Marko et fonctions aleatories de deux variables"
            },
            "venue": {
                "fragments": [],
                "text": "Academcy of Science , Paris"
            },
            "year": 1948
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 149
                            }
                        ],
                        "text": "\u2026were to consider continuousvariables) such as methods using a probabilistic decision tree (e.g., Buntine, 1991), a gen-eralized linear model (e.g., McCullagh and Nelder, 1989), a neural network (e.g., Bishop,1995), a probabilistic support-vector machine (e.g., Platt, 1999), or an embedded\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalized Linear Models, Second Edition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 148
                            }
                        ],
                        "text": "\u2026regarding thecollege plans of high-school seniors, (2) Women and Mathematics (WAM), data regardingwomen's preferences for a career in Mathematics (Fowlkes, Freeny, and Landwehr, 1988),(3) Digits, images of handwritten digits made available by the US Postal Service O ce forAdvanced Technology\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 137
                            }
                        ],
                        "text": "We use four datasets: (1) Sewall/Shah, data from Sewall and Shah (1968) regarding thecollege plans of high-school seniors, (2) Women and Mathematics (WAM), data regardingwomen's preferences for a career in Mathematics (Fowlkes, Freeny, and Landwehr, 1988),(3) Digits, images of handwritten digits made available by the US Postal Service O ce forAdvanced Technology (Frey, Hinton, and Dayan, 1995), and (4)Nielsen, data about whetheror not users watched ve or more minutes of network TV shows aired during a two-weekperiod in 1995 (made available by Nielsen Media Research)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluating logistic models for large"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 70
                            }
                        ],
                        "text": "Here, wecite a potentially useful bound of this form given by Cho and Meyer (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 17
                            }
                        ],
                        "text": "Theorem (Cho and Meyer, 1999): Let P and ~P = P + E be transition matrices fortwo homogenous, irreducible k-state Markov chains with respective stationary distributions and ~ ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Markov chain sensitivity by mean rst passage times"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian updating in recursive graphical"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Markov chain sensitivity by mean rst passage times"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 62
                            }
                        ],
                        "text": "Here, wecite a potentially useful bound of this form given by Cho and Meyer (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 9
                            }
                        ],
                        "text": "Theorem (Cho and Meyer, 1999): Let P and ~P = P + E be transition matrices fortwo homogenous, irreducible k-state Markov chains with respective stationary distributions and ~ ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Markov chain sensitivity by mean rst passage times"
            },
            "venue": {
                "fragments": [],
                "text": "Markov chain sensitivity by mean rst passage times"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 62
                            }
                        ],
                        "text": "Here, wecite a potentially useful bound of this form given by Cho and Meyer (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 9
                            }
                        ],
                        "text": "Theorem (Cho and Meyer, 1999): Let P and ~P = P + E be transition matrices fortwo homogenous, irreducible k-state Markov chains with respective stationary distributions and ~ ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Markov c hain sensitivity b y mean rst passage times"
            },
            "venue": {
                "fragments": [],
                "text": "Markov c hain sensitivity b y mean rst passage times"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nonlinear Markov n e t works for continuous variables"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems 10"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian updating in recursive graphicalmodels by local computations"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Statisticals Quarterly"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian computation andstochastic systems"
            },
            "venue": {
                "fragments": [],
                "text": "Statistical Science"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Independence properties of directed Markov elds. Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Independence properties of directed Markov elds. Networks"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 36
                            }
                        ],
                        "text": "The type of algorithm introduced by Resnik et al. (1994), sometimes called amemory-based algorithm, does something similar."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Grouplens: An open"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Grouplens : An openarchitecture for collaborative ltering of netnews"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the ACM 1994 Conference on Computer Supported Cooperative Work"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Does the wakesleep algorithm produce gooddensity estimators ?"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 17,
            "methodology": 20
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 52,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Dependency-Networks-for-Inference,-Collaborative-Heckerman-Chickering/30afca3a4056bc54deadc1c5794048436d1c9eb4?sort=total-citations"
}