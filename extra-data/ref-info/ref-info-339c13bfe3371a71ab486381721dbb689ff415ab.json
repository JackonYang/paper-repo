{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12172268,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "f546e10689e4f4557b12ae34a777bab50f78b0cb",
            "isKey": false,
            "numCitedBy": 221,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an algorithm that robustly locates salient convex collections of line segments in an image. The algorithm is guaranteed to find all convex sets of line segments in which the length of the gaps between segments is smaller than some fixed proportion of the total length of the lines. This enables the algorithm to find convex groups whose contours are partially occluded or missing due to noise. We give an expected case analysis of the algorithm performance. This demonstrates that salient convexity is unlikely to occur at random, and hence is a strong clue that grouped line segments reflect underlying structure in the scene. We also show that our algorithm run time is O(n/sup 2/log(n)+nm), when we wish to find the m most salient groups in an image with n line segments. We support this analysis with experiments on real data, and demonstrate the grouping system as part of a complete recognition system."
            },
            "slug": "Robust-and-Efficient-Detection-of-Salient-Convex-Jacobs",
            "title": {
                "fragments": [],
                "text": "Robust and Efficient Detection of Salient Convex Groups"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "An algorithm that robustly locates salient convex collections of line segments in an image that is guaranteed to find all convex sets ofline segments in which the length of the gaps between segments is smaller than some fixed proportion of the totallength of the lines."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32235446,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "af7b47f8fd7a97a39df2442f45dd4b2a36b9c1d1",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm is presented that finds all convex sets of line segments in an image, such that the length of the line segments account for at least some fixed proportion of the length of the convex hull. This enables the algorithm to find convex groups whose contours are partially occluded or missing due to noise. An expected time analysis of the algorithm's performance is performed, together with experiments on real images that show that the algorithm is efficient and that tell when the groups found are unlikely to occur at random, and are likely to capture the underlying structure of a scene.<<ETX>>"
            },
            "slug": "Robust-and-efficient-detection-of-convex-groups-Jacobs",
            "title": {
                "fragments": [],
                "text": "Robust and efficient detection of convex groups"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An algorithm is presented that finds all convex sets of line segments in an image, such that the length of the line segments account for at least some fixed proportion of thelength of the convex hull, which enables the algorithm to find convex groups whose contours are partially occluded or missing due to noise."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144891282"
                        ],
                        "name": "David R. Martin",
                        "slug": "David-R.-Martin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Martin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8165754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33a7a59f785ef46091c30c4c85ef88c6bdabab51",
            "isKey": false,
            "numCitedBy": 2381,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this work is to accurately detect and localize boundaries in natural scenes using local image measurements. We formulate features that respond to characteristic changes in brightness, color, and texture associated with natural boundaries. In order to combine the information from these features in an optimal way, we train a classifier using human labeled images as ground truth. The output of this classifier provides the posterior probability of a boundary at each image location and orientation. We present precision-recall curves showing that the resulting detector significantly outperforms existing approaches. Our two main results are 1) that cue combination can be performed adequately with a simple linear model and 2) that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "slug": "Learning-to-detect-natural-image-boundaries-using-Martin-Fowlkes",
            "title": {
                "fragments": [],
                "text": "Learning to detect natural image boundaries using local brightness, color, and texture cues"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The two main results are that cue combination can be performed adequately with a simple linear model and that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738591"
                        ],
                        "name": "T. Binford",
                        "slug": "T.-Binford",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Binford",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Binford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8394861,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8336e347624d32b8d3762dc7a4640dfcb96dbe06",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Evidence is presented showing that bottom-up grouping of image features is usually prerequisite to the recognition and interpretation of images. We describe three functions of these groupings: 1) segmentation, 2) three-dimensional interpretation, and 3) stable descriptions for accessing object models. Several principles are hypothesized for determining which image relations should he formed: relations are significant to the extent that they are unlikely to have arisen by accident from the surrounding distribution of features, relations can only be formed where there are few alternatives within the same proximity, and relations must be based on properties which are invariant over a range of imaging conditions. Using these principles we develop an algorithm for curve segmentation which detects significant structure at multiple resolutions, including the linking of segments on the basis of curvilinearity. The algorithm is able to detect structures which no single-resolution algorithm could detect. Its performance is demonstrated on synthetic and natural image data."
            },
            "slug": "Perceptual-Organization-as-a-Basis-for-Visual-Lowe-Binford",
            "title": {
                "fragments": [],
                "text": "Perceptual Organization as a Basis for Visual Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm for curve segmentation is developed which detects significant structure at multiple resolutions, including the linking of segments on the basis of curvilinearity, able to detect structures which no single-resolution algorithm could detect."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31614700"
                        ],
                        "name": "R. Nelson",
                        "slug": "R.-Nelson",
                        "structuredName": {
                            "firstName": "Randal",
                            "lastName": "Nelson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7785990"
                        ],
                        "name": "A. Salgian",
                        "slug": "A.-Salgian",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Salgian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Salgian"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6517661,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4717123c61bd51dcf27c250e96113742d0d3bd33",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an appearance-based object recognition system using a keyed, multi-level contest representation reminiscent of certain aspects of cubist art. Specifically, we utilize distinctive intermediate-level features in this case automatically extracted 2-D boundary fragments, as keys, which are then verified within a local contest, and assembled within a loose global contest to evoke an overall percept. This system demonstrates good recognition of a variety of 3-D shapes, ranging from sports cars and fighter planes to snakes and lizards with full orthographic invariance. We report the results of large-scale tests, involving over 2000 separate test images, that evaluate performance with increasing number of items in the database, in the presence of clutter, background change, and occlusion, and also the results of some generic classification experiments where the system is tested on objects never previously seen or modeled. To our knowledge, the results we report are the best in the literature for full-sphere tests of general shapes with occlusion and clutter resistance."
            },
            "slug": "A-cubist-approach-to-object-recognition-Nelson-Salgian",
            "title": {
                "fragments": [],
                "text": "A cubist approach to object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An appearance-based object recognition system using a keyed, multi-level contest representation reminiscent of certain aspects of cubist art, demonstrates good recognition of a variety of 3-D shapes, ranging from sports cars and fighter planes to snakes and lizards with full orthographic invariance."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32250556"
                        ],
                        "name": "D. H. Cooper",
                        "slug": "D.-H.-Cooper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cooper",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. H. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47581828"
                        ],
                        "name": "J. Graham",
                        "slug": "J.-Graham",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Graham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Graham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15242659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f731b6745d829241941307c3ebf163e90e200318",
            "isKey": false,
            "numCitedBy": 7909,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "!, Model-based vision is firmly established as a robust approach to recognizing and locating known rigid objects in the presence of noise, clutter, and occlusion. It is more problematic to apply modelbased methods to images of objects whose appearance can vary, though a number of approaches based on the use of flexible templates have been proposed. The problem with existing methods is that they sacrifice model specificity in order to accommodate variability, thereby compromising robustness during image interpretation. We argue that a model should only be able to deform in ways characteristic of the class of objects it represents. We describe a method for building models by learning patterns of variability from a training set of correctly annotated images. These models can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes). The key difference is that our Active Shape Models can only deform to fit the data in ways consistent with the training set. We show several practical examples where we have built such models and used them to locate partially occluded objects in noisy, cluttered images. Q 199s A&& prrss, IN."
            },
            "slug": "Active-Shape-Models-Their-Training-and-Application-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Active Shape Models-Their Training and Application"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work describes a method for building models by learning patterns of variability from a training set of correctly annotated images that can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes)."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083209039"
                        ],
                        "name": "Edgar Seemann",
                        "slug": "Edgar-Seemann",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Seemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edgar Seemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14395688,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1854005a7178b2df6afaacdcf91bc35d90616075",
            "isKey": false,
            "numCitedBy": 932,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the problem of detecting pedestrians in crowded real-world scenes with severe overlaps. Our basic premise is that this problem is too difficult for any type of model or feature alone. Instead, we present an algorithm that integrates evidence in multiple iterations and from different sources. The core part of our method is the combination of local and global cues via probabilistic top-down segmentation. Altogether, this approach allows examining and comparing object hypotheses with high precision down to the pixel level. Qualitative and quantitative results on a large data set confirm that our method is able to reliably detect pedestrians in crowded scenes, even when they overlap and partially occlude each other. In addition, the flexible nature of our approach allows it to operate on very small training sets."
            },
            "slug": "Pedestrian-detection-in-crowded-scenes-Leibe-Seemann",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection in crowded scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Qualitative and quantitative results on a large data set confirm that the core part of the method is the combination of local and global cues via probabilistic top-down segmentation that allows examining and comparing object hypotheses with high precision down to the pixel level."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762260"
                        ],
                        "name": "V. Philomin",
                        "slug": "V.-Philomin",
                        "structuredName": {
                            "firstName": "Vasanth",
                            "lastName": "Philomin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Philomin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 766556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb490d879512b3d43b267e3ac8931c099a5a2fd3",
            "isKey": false,
            "numCitedBy": 760,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an efficient shape-based object detection method based on Distance Transforms and describes its use for real-time vision on-board vehicles. The method uses a template hierarchy to capture the variety of object shapes; efficient hierarchies can be generated offline for given shape distributions using stochastic optimization techniques (i.e. simulated annealing). Online, matching involves a simultaneous coarse-to-fine approach over the shape hierarchy and over the transformation parameters. Very large speed-up factors are typically obtained when comparing this approach with the equivalent brute-force formulation; we have measured gains of several orders of magnitudes. We present experimental results on the real-time detection of traffic signs and pedestrians from a moving vehicle. Because of the highly time sensitive nature of these vision tasks, we also discuss some hardware-specific implementations of the proposed method as far as SIMD parallelism is concerned."
            },
            "slug": "Real-time-object-detection-for-\"smart\"-vehicles-Gavrila-Philomin",
            "title": {
                "fragments": [],
                "text": "Real-time object detection for \"smart\" vehicles"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "An efficient shape-based object detection method based on Distance Transforms is presented and its use for real-time vision on-board vehicles and some hardware-specific implementations of the proposed method as far as SIMD parallelism is concerned are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1835501,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9c7565f52470b9f81f7e1911734c9a8699b664e",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe some techniques that can be used to represent and detect deformable shapes in images. The main difficulty with deformable template models is the very large or infinite number of possible nonrigid transformations of the templates. This makes the problem of finding an optimal match of a deformable template to an image incredibly hard. Using a new representation for deformable shapes, we show how to efficiently find a global optimal solution to the nonrigid matching problem. The representation is based on the description of objects using triangulated polygons. Our matching algorithm can minimize a large class of energy functions, making it applicable to a wide range of problems. We present experimental results of detecting shapes in medical images and images of natural scenes. We also consider the problem of learning a nonrigid shape model for a class of objects from examples. We show how to learn good models while constraining them to be in the form required by the matching algorithm."
            },
            "slug": "Representation-and-detection-of-deformable-shapes-Felzenszwalb",
            "title": {
                "fragments": [],
                "text": "Representation and detection of deformable shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new representation for deformable shapes is used and it is shown how to efficiently find a global optimal solution to the nonrigid matching problem, based on the description of objects using triangulated polygons."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707867"
                        ],
                        "name": "A. Thayananthan",
                        "slug": "A.-Thayananthan",
                        "structuredName": {
                            "firstName": "Arasanathan",
                            "lastName": "Thayananthan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Thayananthan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746940"
                        ],
                        "name": "B. Stenger",
                        "slug": "B.-Stenger",
                        "structuredName": {
                            "firstName": "Bj\u00f6rn",
                            "lastName": "Stenger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Stenger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12758052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77db36ebf6b6a48a7ffa881cbb7aa79d2988de0c",
            "isKey": false,
            "numCitedBy": 368,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper compares two methods for object localization from contours: shape context and chamfer matching of templates. In the light of our experiments, we suggest improvements to the shape context: shape contexts are used to find corresponding features between model and image. In real images it is shown that the shape context is highly influenced by clutters; furthermore, even when the object is correctly localized, the feature correspondence may be poor. We show that the robustness of shape matching can be increased by including a figural continuity constraint. The combined shape and continuity cost is minimized using the Viterbi algorithm on features, resulting in improved localization and correspondence. Our algorithm can be generally applied to any feature based shape matching method. Chamfer matching correlates model templates with the distance transform of the edge image. This can be done efficiently using a coarse-to-fine search over the transformation parameters. The method is robust in clutter, however, multiple templates are needed to handle scale, rotation and shape variation. We compare both methods for locating hand shapes in cluttered images, and applied to word recognition in EZ-Gimpy images."
            },
            "slug": "Shape-context-and-chamfer-matching-in-cluttered-Thayananthan-Stenger",
            "title": {
                "fragments": [],
                "text": "Shape context and chamfer matching in cluttered scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that the robustness of shape matching can be increased by including a figural continuity constraint, and the combined shape and continuity cost is minimized using the Viterbi algorithm on features, resulting in improved localization and correspondence."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18146552,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0171d901a544924b70cd2013371d7459ad082a73",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach for tracking locally planar regions in an image sequence and their grouping into larger planar surfaces. The tracker recovers the affine transformation of the region and therefore yields reliable point correspondences between frames. Both edges and texture information are exploited in an integrated way, while not requiring the complete region's contour. The tracker withstands zoom, out-of-plane rotations, discontinuous motion and changes in illumination conditions while achieving real-time performance for a region. Multiple tracked regions are grouped into disjoint coplanarity classes. We first define a coplanarity score between each pair of regions, based on motion and texture cues. The scores are then analyzed by a clique-partitioning algorithm yielding the coplanarity classes that best fit the data. The method works in the presence of perspective distortions, discontinuous planar surfaces and considerable amounts of measurement noise."
            },
            "slug": "Real-time-affine-region-tracking-and-coplanar-Ferrari-Tuytelaars",
            "title": {
                "fragments": [],
                "text": "Real-time affine region tracking and coplanar grouping"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A novel approach for tracking locally planar regions in an image sequence and their grouping into larger planar surfaces that recovers the affine transformation of the region and therefore yields reliable point correspondences between frames."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38899341"
                        ],
                        "name": "C. Schnorr",
                        "slug": "C.-Schnorr",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Schnorr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schnorr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7789445"
                        ],
                        "name": "J. Weickert",
                        "slug": "J.-Weickert",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Weickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weickert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14929019,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d1577f1b8ee6cac39f682808f3a62c633b5024c7",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a modification of the Mumford-Shah functional and its cartoon limit which allows the incorporation of statistical shape knowledge in a single energy functional. We show segmentation results on artificial and real-world images with and without prior shape information. In the case of occlusion and strongly cluttered background the shape prior significantly improves segmentation. Finally we compare our results to those obtained by a level-set implementation of geodesic active contours."
            },
            "slug": "Diffusion-snakes:-combining-statistical-shape-and-a-Cremers-Schnorr",
            "title": {
                "fragments": [],
                "text": "Diffusion-snakes: combining statistical shape knowledge and image information in a variational framework"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Workshop on Variational and Level Set Methods in Computer Vision"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767957"
                        ],
                        "name": "P. Pala",
                        "slug": "P.-Pala",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Pala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pala"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1608216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6182e4e462fd25ac6e1744415b481d422c861b2",
            "isKey": false,
            "numCitedBy": 474,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Effective image retrieval by content from database requires that visual image properties are used instead of textual labels to properly index and recover pictorial data. Retrieval by shape similarity, given a user-sketched template is particularly challenging, owing to the difficulty to derive a similarity measure that closely conforms to the common perception of similarity by humans. In this paper, we present a technique which is based on elastic matching of sketched templates over the shapes in the images to evaluate similarity ranks. The degree of matching achieved and the elastic deformation energy spent by the sketch to achieve such a match are used to derive a measure of similarity between the sketch and the images in the database and to rank images to be displayed. The elastic matching is integrated with arrangements to provide scale invariance and take into account spatial relationships between objects in multi-object queries. Examples from a prototype system are expounded with considerations about the effectiveness of the approach and comparative performance analysis."
            },
            "slug": "Visual-Image-Retrieval-by-Elastic-Matching-of-User-Bimbo-Pala",
            "title": {
                "fragments": [],
                "text": "Visual Image Retrieval by Elastic Matching of User Sketches"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A technique which is based on elastic matching of sketched templates over the shapes in the images to evaluate similarity ranks and is integrated with arrangements to provide scale invariance and take into account spatial relationships between objects in multi-object queries."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685538"
                        ],
                        "name": "Tamara L. Berg",
                        "slug": "Tamara-L.-Berg",
                        "structuredName": {
                            "firstName": "Tamara",
                            "lastName": "Berg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamara L. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6055435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12c7fc38debaf3589e712973642246bd54fe63b3",
            "isKey": false,
            "numCitedBy": 956,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We approach recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points. This algorithm sets up correspondence as an integer quadratic programming problem, where the cost function has terms based on similarity of corresponding geometric blur point descriptors as well as the geometric distortion between pairs of corresponding feature points. The algorithm handles outliers, and thus enables matching of exemplars to query images in the presence of occlusion and clutter. Given the correspondences, we estimate an aligning transform, typically a regularized thin plate spline, resulting in a dense correspondence between the two shapes. Object recognition is then handled in a nearest neighbor framework where the distance between exemplar and query is the matching cost between corresponding points. We show results on two datasets. One is the Caltech 101 dataset (Fei-Fei, Fergus and Perona), an extremely challenging dataset with large intraclass variation. Our approach yields a 48% correct classification rate, compared to Fei-Fei et al 's 16%. We also show results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "slug": "Shape-matching-and-object-recognition-using-low-Berg-Berg",
            "title": {
                "fragments": [],
                "text": "Shape matching and object recognition using low distortion correspondences"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work approaches recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points, and shows results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143905691"
                        ],
                        "name": "J. Beveridge",
                        "slug": "J.-Beveridge",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Beveridge",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beveridge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31338632"
                        ],
                        "name": "E. Riseman",
                        "slug": "E.-Riseman",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Riseman",
                            "middleNames": [
                                "M."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riseman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 194507,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "829179096059559603b204575991358382a2ad55",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 101,
            "paperAbstract": {
                "fragments": [],
                "text": "Local search is a well established and highly effective method for solving complex combinatorial optimization problems. Here, local search is adapted to solve difficult geometric matching problems. Matching is posed as the problem of finding the optimal many-to-many correspondence mapping between a line segment model and image line segments. Image data is assumed to be fragmented, noisy, and cluttered. The algorithms presented have been used for robot navigation, photo interpretation, and scene understanding. This paper explores how local search performs as model complexity increases, image clutter increases, and additional model instances are added to the image data. Expected run-times to find optimal matches with 95 percent confidence are determined for 48 distinct problems involving six models. Nonlinear regression is used to estimate run-time growth as a function of problem size. Both polynomial and exponential growth models are fit to the run-time data. For problems with random clutter, the polynomial model fits better and growth is comparable to that for tree search. For problems involving symmetric models and multiple model instances, where tree search is exponential, the polynomial growth model is superior to the exponential growth model for one search algorithm and comparable for another."
            },
            "slug": "How-Easy-is-Matching-2D-Line-Models-Using-Local-Beveridge-Riseman",
            "title": {
                "fragments": [],
                "text": "How Easy is Matching 2D Line Models Using Local Search?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper explores how local search performs as model complexity increases, image clutter increases, and additional model instances are added to the image data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153159931"
                        ],
                        "name": "Luiz A. Costa",
                        "slug": "Luiz-A.-Costa",
                        "structuredName": {
                            "firstName": "Luiz",
                            "lastName": "Costa",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luiz A. Costa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14489533"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16105092,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "723696d3b45dedcc7db4e609dfce04e53202f363",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 110,
            "paperAbstract": {
                "fragments": [],
                "text": "Determining the similarity of two shapes is a significant task in both machine and human vision systems that must recognize or classify objects. The exact properties of human shape similarity judgements are not well understood yet, and this task is particularly difficult in domains where the shapes are not related by rigid transformation. In this paper we identify a number of possibly desirable properties of a shape similarity method, and determine the extent to which these properties can be captured by approaches that compare local properties of the contours of the shapes, through elastic matching. Special attention is devoted to objects that possess articulations, i.e. articulated parts. Elastic matching evaluates the similarity of two shapes as the sum of local deformations needed to change one shape into another. We show that similarities of part structure can be captured by such an approach, without the explicit computation of part structure. This may be of importance, since although parts appear to play a significant role in visual recognition, it is difficult to stably determine part structure. We also show novel results about how one can evaluate smooth and polyhedral shapes with the same method. Finally, we describe shape similarity effects that cannot be handled by current approaches."
            },
            "slug": "Determining-the-similarity-of-deformable-shapes-Basri-Costa",
            "title": {
                "fragments": [],
                "text": "Determining the similarity of deformable shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper identifies a number of possibly desirable properties of a shape similarity method, and determines the extent to which these properties can be captured by approaches that compare local properties of the contours of the shapes, through elastic matching."
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8152491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc1d7345c22c17735222762ba8bac4ffa348b85d",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We address comparing related, but not identical shapes in images following a deformable template strategy. At the heart of this is the notion of an alignment between the shapes to be matched. The transformation necessary for alignment and the remaining differences after alignment are then used to make a comparison. \nA model determines what kind of deformations or alignments are acceptable, and what variation in appearance should remain after alignment. This ties strongly with the idea that the difference in shape is the residual difference, after some family of transformations has been applied for alignment. \nFinding an alignment of a model to a novel object involves search through the space of possible alignments. In many settings this search is quite difficult. This work shows that the search can be approximated by an easier discrete matching problem between key points on a model and a novel object. This is a departure from traditional approaches to deformable template matching that concentrate on analyzing differential models. This thesis presents theories and experiments on searching for, identifying, and using alignments found via discrete matchings. \nIn particular we present a mathematical and ecological motivation for a medium scale descriptor of shape, geometric blur. Geometric blur is an average over transformations of a sparse signal or feature channel, and can be computed using a spatially varying convolution. The resulting shape descriptors are useful for evaluating local shape similarity. Experiments demonstrate their efficacy for image classification and shape correspondence. \nFinding alignments between shapes is formulated as an optimization problem over discrete matchings between feature points in images. Similarity between putative correspondences is measured using geometric blur, and the deformation in the configuration of points is measured by summing over deformations in pairwise relationships. The snatching problem is formulated as an integer quadratic programming problem and approximated with a simple technique. Experimental results indicate that this generic model of local shape and deformation is applicable across a wide variety of object categories, providing good (currently the best known) performance for object recognition and localization on a difficult object recognition benchmark. \nFurthermore this generic object alignment strategy can be used to model variation in images of an object category, identifying the repeated object structures and providing automatic localization of the objects."
            },
            "slug": "Shape-Matching-and-Object-Recognition-Berg-Malik",
            "title": {
                "fragments": [],
                "text": "Shape Matching and Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results indicate that this generic model of local shape and deformation is applicable across a wide variety of object categories, providing good performance for object recognition and localization on a difficult object recognition benchmark."
            },
            "venue": {
                "fragments": [],
                "text": "Toward Category-Level Object Recognition"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388700951"
                        ],
                        "name": "Tomas Lozano-Perez",
                        "slug": "Tomas-Lozano-Perez",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Lozano-Perez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Lozano-Perez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14484943,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1230072567fed362e7a39bb8bc83c867c0c1a9f5",
            "isKey": false,
            "numCitedBy": 550,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses how local measurements of positions and surface normals may be used to identify and locate overlapping objects. The objects are modeled as polyhedra (or polygons) having up to six degrees of positional freedom relative to the sensors. The approach operates by examining all hypotheses about pairings between sensed data and object surfaces and efficiently discarding inconsistent ones by using local constraints on: distances between faces, angles between face normals, and angles (relative to the surface normals) of vectors between sensed points. The method described here is an extension of a method for recognition and localization of nonoverlapping parts previously described in [18] and [15]."
            },
            "slug": "Localizing-Overlapping-Parts-by-Searching-the-Tree-Grimson-Lozano-Perez",
            "title": {
                "fragments": [],
                "text": "Localizing Overlapping Parts by Searching the Interpretation Tree"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The approach operates by examining all hypotheses about pairings between sensed data and object surfaces and efficiently discarding inconsistent ones by using local constraints on distances between faces, angles between face normals, and angles of vectors between sensed points."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 18,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Object-Detection-by-Contour-Segment-Networks-Ferrari-Tuytelaars/339c13bfe3371a71ab486381721dbb689ff415ab?sort=total-citations"
}