{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32521935"
                        ],
                        "name": "R. Alter",
                        "slug": "R.-Alter",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Alter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Alter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58660562,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "0db0b414aa464e6d1bf52672d7450d4ab2bd13b9",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of contextual constraints in speech recognition has been contemplated by many authors. This paper describes a system under development which will perform correction of errors made in a phonemic recognizer by comparison of the received phoneme sequence with the syntax and dictionary of \"the language being spoken. The language syntax is stored in a relatively efficient manner, being essentially in Backus-Naur Form. The error correction procedure can best be described as a sequential decoding on the tree of syntax generated by the tables, as traversed by a syntactical parser. The system is currently being implemented in a form such that it will recognize a \"spoken FORTRAN\" language. Some initial results of its application to certain error-containing inputs are described."
            },
            "slug": "Utilization-of-contextual-constraints-in-automatic-Alter",
            "title": {
                "fragments": [],
                "text": "Utilization of contextual constraints in automatic speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A system under development which will perform correction of errors made in a phonemic recognizer by comparison of the received phoneme sequence with the syntax and dictionary of \"the language being spoken\" is described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729905"
                        ],
                        "name": "C. Tappert",
                        "slug": "C.-Tappert",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Tappert",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tappert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36134716"
                        ],
                        "name": "N. Dixon",
                        "slug": "N.-Dixon",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Dixon",
                            "middleNames": [
                                "Rex"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dixon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144771314"
                        ],
                        "name": "A. Rabinowitz",
                        "slug": "A.-Rabinowitz",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Rabinowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rabinowitz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61368524,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff69f1f419b4c14d6f8a09b47b63b98ea95d2d8f",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Following segmentation and phonetic classification in automatic recognition of continuous speech (ARCS), it is necessary to provide methods for linguistic decoding, In this work a graph search procedure, based on the Fano algorithm, is used to convert machine-contaminated phonetic descriptions of speaker performance into standard orthography. The information utilized by the decoder consists of a syntax, a lexicon containing transcription variation for each word, and performance-based statistics from acoustic analysis. The latter contain information related to automatic segmentation and classification accuracy and certainty (anchor-point) data. A distinction is made between speaker- and machine-dependent corruption of phonetic input strings. Preliminary results are presented and discussed, together with some considerations for evaluation."
            },
            "slug": "Application-of-sequential-decoding-for-converting-Tappert-Dixon",
            "title": {
                "fragments": [],
                "text": "Application of sequential decoding for converting phonetic to graphic representation in automatic recognition of continuous speech(ARCS)"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A graph search procedure, based on the Fano algorithm, is used to convert machine-contaminated phonetic descriptions of speaker performance into standard orthography and preliminary results are presented and discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38697325,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "22b6737a38179c01444d69443e327850c9956c15",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Most current attempts at automatic speech recognition are formulated in an artificial intelligence framework. In this paper we approach the problem from an information-theoretic point of view. We describe the overall structure of a linguistic statistical decoder (LSD) for the recognition of continuous speech. The input to the decoder is a string of phonetic symbols estimated by an acoustic processor (AP). For each phonetic string, the decoder finds the most likely input sentence. The decoder consists of four major subparts: 1) a statistical model of the language being recognized; 2) a phonemic dictionary and statistical phonological rules characterizing the speaker; 3) a phonetic matching algorithm that computes the similarity between phonetic strings, using the performance characteristics of the AP; 4) a word level search control. The details of each of the subparts and their interaction during the decoding process are discussed."
            },
            "slug": "Design-of-a-linguistic-statistical-decoder-for-the-Jelinek-Bahl",
            "title": {
                "fragments": [],
                "text": "Design of a linguistic statistical decoder for the recognition of continuous speech"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper describes the overall structure of a linguistic statistical decoder (LSD) for the recognition of continuous speech and describes a phonetic matching algorithm that computes the similarity between phonetic strings, using the performance characteristics of the AP."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62562997,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae9443b39a5abfbf3cc9776173c1ae4f94732408",
            "isKey": false,
            "numCitedBy": 593,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a new sequential decoding algorithm is introduced that uses stack storage at the receiver. It is much simpler to describe and analyze than the Fano algorithm, and is about six times faster than the latter at transmission rates equal to Rcomp the rate below which the average number of decoding steps is bounded by a constant. Practical problems connected with implementing the stack algorithm are discussed and a scheme is described that facilitates satisfactory performance even with limited stack storage capacity. Preliminary simulation results estimating the decoding effort and the needed stack siazree presented."
            },
            "slug": "Fast-sequential-decoding-algorithm-using-a-stack-Jelinek",
            "title": {
                "fragments": [],
                "text": "Fast sequential decoding algorithm using a stack"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new sequential decoding algorithm is introduced that uses stack storage at the receiver that is much simpler to describe and analyze than the Fano algorithm, and is about six times faster than the latter at transmission rates equal to Rcomp."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500689"
                        ],
                        "name": "A. Viterbi",
                        "slug": "A.-Viterbi",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Viterbi",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Viterbi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15843983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "145c0b53514b02bdc3dadfb2e1cea124f2abd99b",
            "isKey": false,
            "numCitedBy": 5209,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The probability of error in decoding an optimal convolutional code transmitted over a memoryless channel is bounded from above and below as a function of the constraint length of the code. For all but pathological channels the bounds are asymptotically (exponentially) tight for rates above R_{0} , the computational cutoff rate of sequential decoding. As a function of constraint length the performance of optimal convolutional codes is shown to be superior to that of block codes of the same length, the relative improvement increasing with rate. The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "slug": "Error-bounds-for-convolutional-codes-and-an-optimum-Viterbi",
            "title": {
                "fragments": [],
                "text": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1967
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 5,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Decoding-for-channels-with-insertions,-deletions,-Bahl-Jelinek/2543dea11cbfce22c38fc2f57bd1dc3c502794b1?sort=total-citations"
}