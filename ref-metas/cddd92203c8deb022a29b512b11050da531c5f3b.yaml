authors:
- Ashutosh Saxena
- Sung H. Chung
- A. Ng
badges:
- id: OPEN_ACCESS
corpusId: 10748875
fieldsOfStudy:
- Computer Science
numCitedBy: 981
numCiting: 16
paperAbstract: We consider the task of depth estimation from a single monocular image.
  We take a supervised learning approach to this problem, in which we begin by collecting
  a training set of monocular images (of unstructured outdoor environments which include
  forests, trees, buildings, etc.) and their corresponding ground-truth depthmaps.
  Then, we apply supervised learning to predict the depthmap as a function of the
  image. Depth estimation is a challenging problem, since local features alone are
  insufficient to estimate depth at a point, and one needs to consider the global
  context of the image. Our model uses a discriminatively-trained Markov Random Field
  (MRF) that incorporates multiscale local- and global-image features, and models
  both depths at individual points as well as the relation between depths at different
  points. We show that, even on unstructured scenes, our algorithm is frequently able
  to recover fairly accurate depthmaps.
ref_count: 17
references:
- pid: 015293bf7c4cf7ce50a01ce1ceb11f584d123d25
  title: Discriminative Fields for Modeling Spatial Dependencies in Natural Images
- pid: 6a4300efb6895695205dfc1b74e124f9fea6aff2
  title: 'Using the Forest to See the Trees: A Graphical Model Relating Features,
    Objects, and Scenes'
- pid: 363b56f85e12389017ba8894056a1b309e46a5f7
  title: Multiscale conditional random fields for image labeling
- pid: d2f78c2b2b325d72f359d4c797c9aab6a8e60942
  title: A taxonomy and evaluation of dense two-frame stereo correspondence algorithms
- pid: 787827850b614135f6b432603afc90b58a8cc665
  title: 'Computer Vision: A Modern Approach'
slug: Learning-Depth-from-Single-Monocular-Images-Saxena-Chung
title: Learning Depth from Single Monocular Images
url: https://www.semanticscholar.org/paper/Learning-Depth-from-Single-Monocular-Images-Saxena-Chung/cddd92203c8deb022a29b512b11050da531c5f3b?sort=total-citations
venue: NIPS
year: 2005
