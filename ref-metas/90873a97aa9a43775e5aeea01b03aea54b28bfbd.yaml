authors:
- Aishwarya Agrawal
- Dhruv Batra
- Devi Parikh
- Aniruddha Kembhavi
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 19298149
fieldsOfStudy:
- Computer Science
meta_key: don-t-just-assume-look-and-answer-overcoming-priors-for-visual-question-answering
numCitedBy: 335
numCiting: 45
paperAbstract: A number of studies have found that today's Visual Question Answering
  (VQA) models are heavily driven by superficial correlations in the training data
  and lack sufficient image grounding. To encourage development of models geared towards
  the latter, we propose a new setting for VQA where for every question type, train
  and test sets have different prior distributions of answers. Specifically, we present
  new splits of the VQA v1 and VQA v2 datasets, which we call Visual Question Answering
  under Changing Priors (VQA-CP v1 and VQA-CP v2 respectively). First, we evaluate
  several existing VQA models under this new setting and show that their performance
  degrades significantly compared to the original VQA setting. Second, we propose
  a novel Grounded Visual Question Answering model (GVQA) that contains inductive
  biases and restrictions in the architecture specifically designed to prevent the
  model from 'cheating' by primarily relying on priors in the training data. Specifically,
  GVQA explicitly disentangles the recognition of visual concepts present in the image
  from the identification of plausible answer space for a given question, enabling
  the model to more robustly generalize across different distributions of answers.
  GVQA is built off an existing VQA model - Stacked Attention Networks (SAN). Our
  experiments demonstrate that GVQA significantly outperforms SAN on both VQA-CP v1
  and VQA-CP v2 datasets. Interestingly, it also outperforms more powerful VQA models
  such as Multimodal Compact Bilinear Pooling (MCB) in several cases. GVQA offers
  strengths complementary to SAN when trained and evaluated on the original VQA v1
  and VQA v2 datasets. Finally, GVQA is more transparent and interpretable than existing
  VQA models.
ref_count: 45
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: c-vqa-a-compositional-split-of-the-visual-question-answering-vqa-v1-0-dataset
  numCitedBy: 59
  pid: a3d071d2a5c11329aa324b2cae6b7b6ca7800213
  show_ref_link: false
  title: C-VQA - A Compositional Split of the Visual Question Answering (VQA) v1.0
    Dataset
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: making-the-v-in-vqa-matter-elevating-the-role-of-image-understanding-in-visual-question-answering
  numCitedBy: 1162
  pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  show_ref_link: true
  title: Making the V in VQA Matter - Elevating the Role of Image Understanding in
    Visual Question Answering
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: zero-shot-visual-question-answering
  numCitedBy: 51
  pid: 8a8224266b8ab1483f6548307ab96227147f34da
  show_ref_link: false
  title: Zero-Shot Visual Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: being-negative-but-constructively-lessons-learnt-from-creating-better-visual-question-answering-datasets
  numCitedBy: 29
  pid: 3374dfe0419cf452d2a60cdd750bdeb6e7433e59
  show_ref_link: false
  title: Being Negative but Constructively - Lessons Learnt from Creating Better Visual
    Question Answering Datasets
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: an-analysis-of-visual-question-answering-algorithms
  numCitedBy: 150
  pid: 915b5b12f9bdebc321e970ecd713458c3479d70e
  show_ref_link: true
  title: An Analysis of Visual Question Answering Algorithms
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: analyzing-the-behavior-of-visual-question-answering-models
  numCitedBy: 222
  pid: 8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5
  show_ref_link: true
  title: Analyzing the Behavior of Visual Question Answering Models
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: an-empirical-evaluation-of-visual-question-answering-for-novel-objects
  numCitedBy: 23
  pid: 6e77e651f44a11c7c3a459c7dfcdfabba0fb6891
  show_ref_link: false
  title: An Empirical Evaluation of Visual Question Answering for Novel Objects
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: cross-dataset-adaptation-for-visual-question-answering
  numCitedBy: 25
  pid: 1bfc74bad04b407d1792a70d73a3f5dc0be0506d
  show_ref_link: false
  title: Cross-Dataset Adaptation for Visual Question Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: visual7w-grounded-question-answering-in-images
  numCitedBy: 591
  pid: def584565d05d6a8ba94de6621adab9e301d375d
  show_ref_link: true
  title: Visual7W - Grounded Question Answering in Images
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: answer-type-prediction-for-visual-question-answering
  numCitedBy: 89
  pid: ebe5081b8a24b4740db929b6eae75f28f8edbc58
  show_ref_link: false
  title: Answer-Type Prediction for Visual Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: vqa-visual-question-answering
  numCitedBy: 2887
  pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  show_ref_link: true
  title: VQA - Visual Question Answering
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: yin-and-yang-balancing-and-answering-binary-visual-questions
  numCitedBy: 243
  pid: 5fa973b8d284145bf0ced9acf2913a74674260f6
  show_ref_link: true
  title: Yin and Yang - Balancing and Answering Binary Visual Questions
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: ask-me-anything-free-form-visual-question-answering-based-on-knowledge-from-external-sources
  numCitedBy: 304
  pid: 20dbdf02497aa84510970d0f5e8b599073bca1bc
  show_ref_link: true
  title: Ask Me Anything - Free-Form Visual Question Answering Based on Knowledge
    from External Sources
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: compositional-memory-for-visual-question-answering
  numCitedBy: 33
  pid: 3d1382fa43c31e594ed2d84dda9984b1db047b0e
  show_ref_link: false
  title: Compositional Memory for Visual Question Answering
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: a-focused-dynamic-attention-model-for-visual-question-answering
  numCitedBy: 105
  pid: 7214daf035ab005b3d1e739750dd597b4f4513fa
  show_ref_link: true
  title: A Focused Dynamic Attention Model for Visual Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: ask-attend-and-answer-exploring-question-guided-spatial-attention-for-visual-question-answering
  numCitedBy: 652
  pid: 1cf6bc0866226c1f8e282463adc8b75d92fba9bb
  show_ref_link: true
  title: Ask, Attend and Answer - Exploring Question-Guided Spatial Attention for
    Visual Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: multimodal-compact-bilinear-pooling-for-visual-question-answering-and-visual-grounding
  numCitedBy: 1086
  pid: fddc15480d086629b960be5bff96232f967f2252
  show_ref_link: true
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: hierarchical-question-image-co-attention-for-visual-question-answering
  numCitedBy: 1121
  pid: fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b
  show_ref_link: true
  title: Hierarchical Question-Image Co-Attention for Visual Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: are-you-talking-to-a-machine-dataset-and-methods-for-multilingual-image-question
  numCitedBy: 408
  pid: 2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1
  show_ref_link: false
  title: Are You Talking to a Machine? Dataset and Methods for Multilingual Image
    Question
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: where-to-look-focus-regions-for-visual-question-answering
  numCitedBy: 360
  pid: 175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22
  show_ref_link: true
  title: Where to Look - Focus Regions for Visual Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: exploring-models-and-data-for-image-question-answering
  numCitedBy: 530
  pid: 62a956d7600b10ca455076cd56e604dfd106072a
  show_ref_link: false
  title: Exploring Models and Data for Image Question Answering
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: abc-cnn-an-attention-based-convolutional-neural-network-for-visual-question-answering
  numCitedBy: 216
  pid: b196bc11ad516c8e6ff96f83acfc443fd7161730
  show_ref_link: false
  title: ABC-CNN - An Attention Based Convolutional Neural Network for Visual Question
    Answering
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-compositional-question-answering-with-neural-module-networks
  numCitedBy: 149
  pid: 0ac8f1a3c679b90d22c1f840cdc8d61ffef750ac
  show_ref_link: false
  title: Deep Compositional Question Answering with Neural Module Networks
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: dualnet-domain-invariant-network-for-visual-question-answering
  numCitedBy: 46
  pid: 121a9a160f1f2819a01edbe522024b58dbfee798
  show_ref_link: false
  title: DualNet - Domain-invariant network for visual question answering
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: stacked-attention-networks-for-image-question-answering
  numCitedBy: 1474
  pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  show_ref_link: true
  title: Stacked Attention Networks for Image Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: training-recurrent-answering-units-with-joint-loss-minimization-for-vqa
  numCitedBy: 66
  pid: b58e08741fb9803fa2a870eee139137d3bade332
  show_ref_link: false
  title: Training Recurrent Answering Units with Joint Loss Minimization for VQA
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: dynamic-memory-networks-for-visual-and-textual-question-answering
  numCitedBy: 659
  pid: f96898d15a1bf1fa8925b1280d0e07a7a8e72194
  show_ref_link: true
  title: Dynamic Memory Networks for Visual and Textual Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: explicit-knowledge-based-reasoning-for-visual-question-answering
  numCitedBy: 143
  pid: 0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a
  show_ref_link: true
  title: Explicit Knowledge-based Reasoning for Visual Question Answering
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations
  numCitedBy: 2772
  pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  show_ref_link: true
  title: Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-to-compose-neural-networks-for-question-answering
  numCitedBy: 476
  pid: 75ddc7ee15be14013a3462c01b38b0548486fbcb
  show_ref_link: true
  title: Learning to Compose Neural Networks for Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: a-multi-world-approach-to-question-answering-about-real-world-scenes-based-on-uncertain-input
  numCitedBy: 550
  pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  show_ref_link: false
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: clevr-a-diagnostic-dataset-for-compositional-language-and-elementary-visual-reasoning
  numCitedBy: 1223
  pid: 03eb382e04cca8cca743f7799070869954f1402a
  show_ref_link: true
  title: CLEVR - A Diagnostic Dataset for Compositional Language and Elementary Visual
    Reasoning
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: visual-turing-test-for-computer-vision-systems
  numCitedBy: 244
  pid: 050da5d159fb0dd96143948e1cffeb3dec814673
  show_ref_link: false
  title: Visual Turing test for computer vision systems
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: multimodal-residual-learning-for-visual-qa
  numCitedBy: 223
  pid: 1afb710a5b35a2352a6495e4bf6eef66808daf1b
  show_ref_link: true
  title: Multimodal Residual Learning for Visual QA
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-to-generalize-to-new-compositions-in-image-understanding
  numCitedBy: 55
  pid: 936227f7483938097cc1cdd3032016df54dbd5b6
  show_ref_link: false
  title: Learning to generalize to new compositions in image understanding
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: decorrelating-semantic-visual-attributes-by-resisting-the-urge-to-share
  numCitedBy: 139
  pid: 0fad544edfc2cd2a127436a2126bab7ad31ec333
  show_ref_link: false
  title: Decorrelating Semantic Visual Attributes by Resisting the Urge to Share
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-to-detect-unseen-object-classes-by-between-class-attribute-transfer
  numCitedBy: 1951
  pid: 0566bf06a0368b518b8b474166f7b1dfef3f9283
  show_ref_link: false
  title: Learning to detect unseen object classes by between-class attribute transfer
  year: 2009
- fieldsOfStudy:
  - Computer Science
  meta_key: glove-global-vectors-for-word-representation
  numCitedBy: 22534
  pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  show_ref_link: true
  title: GloVe - Global Vectors for Word Representation
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: very-deep-convolutional-networks-for-large-scale-image-recognition
  numCitedBy: 62221
  pid: eb42cf88027de515750f230b23b1a057dc782108
  show_ref_link: true
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: relevance-feedback-in-image-retrieval-a-comprehensive-review
  numCitedBy: 981
  pid: 62cec1ef9f1d9135884c2a61919d20fbb8eda589
  show_ref_link: false
  title: Relevance feedback in image retrieval - A comprehensive review
  year: 2003
- fieldsOfStudy:
  - Computer Science
  meta_key: torch7-a-matlab-like-environment-for-machine-learning
  numCitedBy: 1490
  pid: 3449b65008b27f6e60a73d80c1fd990f0481126b
  show_ref_link: true
  title: Torch7 - A Matlab-like Environment for Machine Learning
  year: 2011
slug: Don't-Just-Assume;-Look-and-Answer:-Overcoming-for-Agrawal-Batra
title: Don't Just Assume; Look and Answer - Overcoming Priors for Visual Question
  Answering
url: https://www.semanticscholar.org/paper/Don't-Just-Assume;-Look-and-Answer:-Overcoming-for-Agrawal-Batra/90873a97aa9a43775e5aeea01b03aea54b28bfbd?sort=total-citations
venue: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition
year: 2018
