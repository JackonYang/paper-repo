authors:
- Mengye Ren
- Ryan Kiros
- R. Zemel
badges:
- id: OPEN_ACCESS
corpusId: 78798
fieldsOfStudy:
- Computer Science
numCitedBy: 127
numCiting: 32
paperAbstract: This work aims to address the problem of imagebased question-answering
  (QA) with new models and datasets. In our work, we propose to use recurrent neural
  networks and visual semantic embeddings without intermediate stages such as object
  detection and image segmentation. Our model performs 1.8 times better than the recently
  published results on the same dataset. Another main contribution is an automatic
  question generation algorithm that converts the currently available image description
  dataset into QA form, resulting in a 10 times bigger dataset with more evenly distributed
  answers.
ref_count: 32
references:
- pid: 9814df8bd00ba999c4d1e305a7e9bca579dc7c75
  title: 'Framing Image Description as a Ranking Task: Data, Models and Evaluation
    Metrics (Extended Abstract)'
- pid: 123b9de009865472c660192f8072493a48352dc2
  title: Phrase-based Image Captioning
- pid: 7f1b111f0bb703b0bd97aba505728a9b0d9b2a54
  title: Deep Fragment Embeddings for Bidirectional Image Sentence Mapping
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 2e36ea91a3c8fbff92be2989325531b4002e2afc
  title: Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
- pid: f4af49a1ead3c81cc5d023878cb67c5646dd8a04
  title: Learning a Recurrent Visual Representation for Image Caption Generation
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: 82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9
  title: Explain Images with Multimodal Recurrent Neural Networks
- pid: 3d29e1c4f1c2b079cf6b5dd458fa6cee246955f9
  title: Towards a Visual Turing Challenge
- pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  title: 'Im2Text: Describing Images Using 1 Million Captioned Photographs'
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: e74f9b7f8eec6ba4704c206b93bc8079af3da4bd
  title: ImageNet Large Scale Visual Recognition Challenge
- pid: 3ecd3e00bbbfd94446c3adc9c6878de27e250f7c
  title: Learning Dependency-Based Compositional Semantics
- pid: 330da625c15427c6e42ccfa3b747fb29e5835bf0
  title: Efficient Estimation of Word Representations in Vector Space
- pid: c1994ba5946456fc70948c549daf62363f13fa2d
  title: Indoor Segmentation and Support Inference from RGBD Images
- pid: d87ceda3042f781c341ac17109d1e94a717f5f60
  title: 'WordNet : an electronic lexical database'
- pid: a600850ac0120cb09a0b7de7da80bb6a7a76de06
  title: Accurate Unlexicalized Parsing
- pid: 0e3e3c3d8ae5cb7c4636870d69967c197484d3bb
  title: Verb Semantics and Lexical Selection
- pid: 01a660ec8aa995a88a00bfb41cb86c022047a9db
  title: 'NLTK: The Natural Language Toolkit'
slug: Image-Question-Answering:-A-Visual-Semantic-Model-a-Ren-Kiros
title: 'Image Question Answering: A Visual Semantic Embedding Model and a New Dataset'
url: https://www.semanticscholar.org/paper/Image-Question-Answering:-A-Visual-Semantic-Model-a-Ren-Kiros/df4f851e3c37017822a683b1356c6c390b5b5487?sort=total-citations
venue: ArXiv
year: 2015
