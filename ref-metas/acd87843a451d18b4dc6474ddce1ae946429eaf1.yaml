authors:
- "Mart\xEDn Arjovsky"
- Soumith Chintala
- L. Bottou
badges:
- id: OPEN_ACCESS
corpusId: 2057420
fieldsOfStudy:
- Computer Science
numCitedBy: 3930
numCiting: 27
paperAbstract: We introduce a new algorithm named WGAN, an alternative to traditional
  GAN training. In this new model, we show that we can improve the stability of learning,
  get rid of problems like mode collapse, and provide meaningful learning curves useful
  for debugging and hyperparameter searches. Furthermore, we show that the corresponding
  optimization problem is sound, and provide extensive theoretical work highlighting
  the deep connections to different distances between distributions.
ref_count: 27
references:
- pid: 54e325aee6b2d476bbbb88615ac15e251c6e8214
  title: Generative Adversarial Nets
- pid: 8388f1be26329fa45e5807e968a641ce170ea078
  title: Unsupervised Representation Learning with Deep Convolutional Generative Adversarial
    Networks
- pid: 5f5dc5b9a2ba710937e2c413b37b053cd673df02
  title: Auto-Encoding Variational Bayes
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: 2f59406cce55c7bb9a78521bd14755a0db0aee7d
  title: Annealed importance sampling
slug: Wasserstein-Generative-Adversarial-Networks-Arjovsky-Chintala
title: Wasserstein Generative Adversarial Networks
url: https://www.semanticscholar.org/paper/Wasserstein-Generative-Adversarial-Networks-Arjovsky-Chintala/acd87843a451d18b4dc6474ddce1ae946429eaf1?sort=total-citations
venue: ICML
year: 2017
