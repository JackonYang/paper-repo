authors:
- Amanpreet Singh
- Vivek Natarajan
- Meet Shah
- Yu Jiang
- Xinlei Chen
- Dhruv Batra
- Devi Parikh
- Marcus Rohrbach
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 85553602
fieldsOfStudy:
- Computer Science
numCitedBy: 181
numCiting: 57
paperAbstract: "Studies have shown that a dominant class of questions asked by visually\
  \ impaired users on images of their surroundings involves reading text in the image.\
  \ But today\u2019s VQA models can not read! Our paper takes a first step towards\
  \ addressing this problem. First, we introduce a new \u201CTextVQA\u201D dataset\
  \ to facilitate progress on this important problem. Existing datasets either have\
  \ a small proportion of questions about text (e.g., the VQA dataset) or are too\
  \ small (e.g., the VizWiz dataset). TextVQA contains 45,336 questions on 28,408\
  \ images that require reasoning about text to answer. Second, we introduce a novel\
  \ model architecture that reads text in the image, reasons about it in the context\
  \ of the image and the question, and predicts an answer which might be a deduction\
  \ based on the text and the image or composed of the strings found in the image.\
  \ Consequently, we call our approach Look, Read, Reason & Answer (LoRRA). We show\
  \ that LoRRA outperforms existing state-of-the-art VQA models on our TextVQA dataset.\
  \ We find that the gap between human performance and machine performance is significantly\
  \ larger on TextVQA than on VQA 2.0, suggesting that TextVQA is well-suited to benchmark\
  \ progress along directions complementary to VQA 2.0."
ref_count: 57
references:
- pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  title: 'Making the V in VQA Matter: Elevating the Role of Image Understanding in
    Visual Question Answering'
- pid: def584565d05d6a8ba94de6621adab9e301d375d
  title: 'Visual7W: Grounded Question Answering in Images'
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b
  title: Hierarchical Question-Image Co-Attention for Visual Question Answering
- pid: 62a956d7600b10ca455076cd56e604dfd106072a
  title: Exploring Models and Data for Image Question Answering
- pid: 55ca9fe4ae98904bfe026d22dcf1420ff9c0dd86
  title: 'FigureQA: An Annotated Figure Dataset for Visual Reasoning'
- pid: 1cf6bc0866226c1f8e282463adc8b75d92fba9bb
  title: 'Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for
    Visual Question Answering'
- pid: 30a3eee5e9302108416f6234d739373dde68d373
  title: Learning to Count Objects in Natural Images for Visual Question Answering
- pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
- pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  title: Stacked Attention Networks for Image Question Answering
- pid: 0c0f41d3162e76500d4639557ff4463bd246e395
  title: 'Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for
    Visual Question Answering'
- pid: fddc15480d086629b960be5bff96232f967f2252
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
- pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
- pid: 8a960ea40fe7b32a1ee702a84f64ec1de5c3e7fe
  title: 'VizWiz: nearly real-time answers to visual questions'
- pid: aa5b35dcf8b024f5352db73cc3944e8fad4f3793
  title: Pointing the Unknown Words
- pid: 668db48c6a79826456341680ee1175dfc4cced71
  title: 'Get To The Point: Summarization with Pointer-Generator Networks'
- pid: bb5b2df137a4d54c3a9145fa363e66531b491580
  title: Scene Text Recognition using Higher Order Language Priors
- pid: b7325b788320f96f7b152768226f16e390ab6475
  title: 'COCO-Text: Dataset and Benchmark for Text Detection and Recognition in Natural
    Images'
- pid: 0d307221fa52e3939d46180cb5921ebbd92c8adb
  title: Word Spotting in the Wild
- pid: 21c99706bb26e9012bfb4d8d48009a3d45af59b2
  title: Neural Module Networks
- pid: 7289a240c9425bc7cad87b3b835e5f0cac22f488
  title: 'DVQA: Understanding Data Visualizations via Question Answering'
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: 03eb382e04cca8cca743f7799070869954f1402a
  title: 'CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual
    Reasoning'
- pid: 9b02f729e6d442f6872078f599fc9da5c3605cee
  title: ICDAR 2015 competition on Robust Reading
- pid: 36c3972569a6949ecca90bfa6f8e99883e092845
  title: 'Pythia v0.1: the Winning Entry to the VQA Challenge 2018'
- pid: e978d832a4d86571e1b52aa1685dc32ccb250f50
  title: Dynamic Coattention Networks For Question Answering
- pid: fde3ee5f9f8e217a4d6716013315614811820f21
  title: 'Rosetta: Large Scale System for Text Detection and Recognition in Images'
- pid: f37076f426023241f19cdc2fb0a0fd733a6fa7fa
  title: Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: ba30df190664193514d1d309cb673728ed48f449
  title: Incorporating Copying Mechanism in Sequence-to-Sequence Learning
- pid: a5d10341717c0519cf63151b496a6d2ed67aa05f
  title: Bilinear Attention Networks
- pid: 0d57ba12a6d958e178d83be4c84513f7e42b24e5
  title: 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
- pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: efbd381493bb9636f489b965a2034d529cd56bcd
  title: Pointer Sentinel Mixture Models
- pid: b36a5bb1707bb9c70025294b3a310138aae8327a
  title: Automatic differentiation in PyTorch
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 89d9aae7e0c8b6edd56d0d79b277c07b7ab66fda
  title: An Overview of the Tesseract OCR Engine
- pid: a8e8f3c8d4418c8d62e306538c9c1292635e9d27
  title: Backpropagation Applied to Handwritten Zip Code Recognition
- pid: 10d85561e4aafc516d10064f30dff05b41f70afe
  title: '[Et al].'
slug: Towards-VQA-Models-That-Can-Read-Singh-Natarajan
title: Towards VQA Models That Can Read
url: https://www.semanticscholar.org/paper/Towards-VQA-Models-That-Can-Read-Singh-Natarajan/af1f7739283bdbd2b7a94903041f6d6afd991907?sort=total-citations
venue: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2019
