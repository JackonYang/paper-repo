authors:
- Razvan Pascanu
- Tomas Mikolov
- Yoshua Bengio
badges:
- id: OPEN_ACCESS
corpusId: 16074905
fieldsOfStudy:
- Computer Science
numCitedBy: 460
numCiting: 23
paperAbstract: Training Recurrent Neural Networks is more troublesome than feedforward
  ones because of the vanishing and exploding gradient problems detailed in Bengio
  et al. (1994). In this paper we attempt to understand the fundamental issues underlying
  the exploding gradient problem by exploring it from an analytical, a geometric and
  a dynamical system perspective. Our analysis is used to justify the simple yet effective
  solution of norm clipping the exploded gradient. In the experimental section, the
  comparison between this heuristic solution and standard SGD provides empirical evidence
  towards our hypothesis as well as it shows that such a heuristic is required to
  reach state of the art results on a character prediction task and a polyphonic music
  prediction one.
ref_count: 23
references:
- pid: d0be39ee052d246ae99c082a565aba25b811be2d
  title: Learning long-term dependencies with gradient descent is difficult
- pid: 052b1d8ce63b07fec3de9dbb583772d860b7c769
  title: Learning representations by back-propagating errors
- pid: e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de
  title: Generating Text with Recurrent Neural Networks
- pid: ce9a21b93ba29d4145a8ef6bf401e77f261848de
  title: A Learning Algorithm for Continually Running Fully Recurrent Neural Networks
- pid: 413c1142de9d91804d6d11c67ff3fed59c9fc279
  title: Adaptive Subgradient Methods for Online Learning and Stochastic Optimization
- pid: 266e07d0dd9a75b61e3632e9469993dbaf063f1c
  title: Generalization of backpropagation with application to a recurrent gas market
    model
- pid: 1fd7fc06653723b05abe5f3d1de393ddcf6bdddb
  title: SUBWORD LANGUAGE MODELING WITH NEURAL NETWORKS
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 668087f0ae7ce1de6e0bd0965dbb480c08103260
  title: Finding Structure in Time
- pid: a49498e51840165d55b6badd4b52e34d17860bc0
  title: On the Computational Power of Neural Nets
- pid: 18c82d4b6cf94fb84ba6ea230e80cb07ed9a9cf8
  title: 'Modeling Temporal Dependencies in High-Dimensional Sequences: Application
    to Polyphonic Music Generation and Transcription'
- pid: 96364af2d208ea75ca3aeb71892d2f7ce7326b55
  title: Statistical Language Models Based on Neural Networks
- pid: 0e9a7789ec7cfc34a1bb953530a0e57bd0e8d018
  title: Ph
slug: Understanding-the-exploding-gradient-problem-Pascanu-Mikolov
title: Understanding the exploding gradient problem
url: https://www.semanticscholar.org/paper/Understanding-the-exploding-gradient-problem-Pascanu-Mikolov/c5145b1d15fea9340840cc8bb6f0e46e8934827f?sort=total-citations
venue: ArXiv
year: 2012
