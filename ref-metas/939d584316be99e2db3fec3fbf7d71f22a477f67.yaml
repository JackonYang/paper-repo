authors:
- Y. Freund
- D. Haussler
badges:
- id: OPEN_ACCESS
corpusId: 13456135
fieldsOfStudy:
- Computer Science
numCitedBy: 340
numCiting: 39
paperAbstract: We present a distribution model for binary vectors, called the influence
  combination model and show how this model can be used as the basis for unsupervised
  learning algorithms for feature selection. The model can be represented by a particular
  type of Boltzmann machine with a bipartite graph structure that we call the combination
  machine. This machine is closely related to the Harmonium model defined by Smolensky.
  In the first part of the paper we analyze properties of this distribution representation
  scheme. We show that arbitrary distributions of binary vectors can be approximated
  by the combination model. We show how the weight vectors in the model can be interpreted
  as high order correlation patterns among the input bits, and how the combination
  machine can be used as a mechanism for detecting these patterns. We compare the
  combination model with the mixture model and with principle component analysis.
  In the second part of the paper we present two algorithms for learning the combination
  model from examples. The first learning algorithm is the standard gradient ascent
  heuristic for computing maximum likelihood estimates for the parameters of the model.
  Here we give a closed form for this gradient that is significantly easier to compute
  than the corresponding gradient for the general Boltzmann machine. The second learning
  algorithm is a greedy method that creates the hidden units and computes their weights
  one at a time. This method is a variant of projection pursuit density estimation.
  In the third part of the paper we give experimental results for these learning methods
  on synthetic data and on natural data of handwritten digit images.
ref_count: 40
references:
- pid: a0d16f0e99f7ce5e6fb70b1a68c685e9ad610657
  title: A Learning Algorithm for Boltzmann Machines
- pid: 709b4bfc5198336ba5d70da987889a157f695c1e
  title: Optimal unsupervised learning in a single-layer linear feedforward neural
    network
- pid: 0eddb03e19bcf7555042508145426451da1d5c7f
  title: Neural Networks, Principal Components, and Subspaces
- pid: 57c4baa5528ba805fc27eee86613c99503978fed
  title: Maximum Likelihood Competitive Learning
- pid: 459b30a9a960080f3b313e41886b1aa0e51e882c
  title: Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration
    of Images
- pid: 98b4d4e24aab57ab4e1124ff8106909050645cfa
  title: Neural networks and physical systems with emergent collective computational
    abilities.
- pid: 136fc611e49e5f3676265a288b78e473a752783b
  title: Feature Extraction Using an Unsupervised Neural Network
- pid: cce218b91cf634413ef9a71f702bd37b1a9ad2a6
  title: Exploratory Projection Pursuit
- pid: 6c0cbbd275bb43e09f0527a31ddd61824eca295b
  title: Introduction to the theory of neural computation
- pid: ff2c2e3e83d1e8828695484728393c76ee07a101
  title: 'Parallel distributed processing: explorations in the microstructure of cognition,
    vol. 1: foundations'
- pid: b07ce649d6f6eb636872527104b0209d3edc8188
  title: Pattern classification and scene analysis
- pid: 70ef29e6f0ce082bb8a47fd85b9bfb7cc0f20c93
  title: Probabilistic reasoning in intelligent systems - networks of plausible inference
- pid: d36efb9ad91e00faa334b549ce989bfae7e2907a
  title: Maximum likelihood from incomplete data via the EM - algorithm plus discussions
    on the paper
- pid: 5bf6f01402e1648b7d1e6c9200ede6cb1af30123
  title: Probabilistic reasoning in intelligent systems
- pid: 607802a4067cb7738bac85d3ca3386f859e637b9
  title: A Mean Field Theory Learning Algorithm for Neural Networks
slug: Unsupervised-Learning-of-Distributions-of-Binary-Freund-Haussler
title: Unsupervised Learning of Distributions of Binary Vectors Using 2-Layer Networks
url: https://www.semanticscholar.org/paper/Unsupervised-Learning-of-Distributions-of-Binary-Freund-Haussler/939d584316be99e2db3fec3fbf7d71f22a477f67?sort=total-citations
venue: NIPS
year: 1991
