authors:
- Junyang Lin
- An Yang
- Yichang Zhang
- Jie Liu
- Jingren Zhou
- Hongxia Yang
badges:
- id: OPEN_ACCESS
corpusId: 214713564
fieldsOfStudy:
- Computer Science
numCitedBy: 26
numCiting: 53
paperAbstract: Multi-modal pretraining for learning high-level multi-modal representation
  is a further step towards deep learning and artificial intelligence. In this work,
  we propose a novel model, namely InterBERT (BERT for Interaction), which owns strong
  capability of modeling interaction between the information flows of different modalities.
  The single-stream interaction module is capable of effectively processing information
  of multiple modalilties, and the two-stream module on top preserves the independence
  of each modality to avoid performance downgrade in single-modal tasks. We pretrain
  the model with three pretraining tasks, including masked segment modeling (MSM),
  masked region modeling (MRM) and image-text matching (ITM); and finetune the model
  on a series of vision-and-language downstream tasks. Experimental results demonstrate
  that InterBERT outperforms a series of strong baselines, including the most recent
  multi-modal pretraining methods, and the analysis shows that MSM and MRM are effective
  for pretraining and our method can achieve performances comparable to BERT in single-modal
  tasks. Besides, we propose a large-scale dataset for multi-modal pretraining in
  Chinese, and we develop the Chinese InterBERT which is the first Chinese multi-modal
  pretrained model. We pretrain the Chinese InterBERT on our proposed dataset of 3.1M
  image-text pairs from the mobile Taobao, the largest Chinese e-commerce platform.
  We finetune the model for text-based image retrieval, and recently we deployed the
  model online for topic-based recommendation.
ref_count: 53
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1266
  pid: 65a9c7b0800c86a196bc14e7621ff895cc6ab287
  title: 'ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language
    Tasks'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 382
  pid: 2bc1c8bd00bbf7401afcb5460277840fd8bab029
  title: 'Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal
    Pre-training'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 916
  pid: 79c93274429d6355959f1e4374c2147bb81ea649
  title: 'LXMERT: Learning Cross-Modality Encoder Representations from Transformers'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 282
  pid: 54416048772b921720f19869ed11c2a360589d03
  title: 'UNITER: Learning UNiversal Image-TExt Representations'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 569
  pid: c41a11c0e9b8b92b4faaf97749841170b760760a
  title: 'VideoBERT: A Joint Model for Video and Language Representation Learning'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 630
  pid: 5aec474c31a2f4b74703c6f786c0a8ff85c450da
  title: 'VisualBERT: A Simple and Performant Baseline for Vision and Language'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 117
  pid: f259bc7ef31c4ec7dd041c94bfd6b2f93b99b47c
  title: Contrastive Bidirectional Transformer for Temporal Representation Learning
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 35148
  pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  title: Attention is All you Need
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 707
  pid: 2527626c11a84f15709e943fbfa2356e19930e3b
  title: 'VL-BERT: Pre-training of Generic Visual-Linguistic Representations'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 732
  pid: 1c71771c701aadfd72c5866170a9f5d71464bb88
  title: Unified Language Model Pre-training for Natural Language Understanding and
    Generation
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 4226
  pid: e0c6abdbdecf04ffac65c440da77fb9d66bb474c
  title: 'XLNet: Generalized Autoregressive Pretraining for Language Understanding'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2706
  pid: 7a064df1aeada7e69e5173f7d4c8606f4470365b
  title: 'ALBERT: A Lite BERT for Self-supervised Learning of Language Representations'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 62220
  pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 33744
  pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 80944
  pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
  year: 2012
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2275
  pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 14880
  pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
  year: 2014
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 32561
  pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  title: 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 582
  pid: b27e791e843c924ef052981b79490ab59fc0433d
  title: Learning Deep Structure-Preserving Image-Text Embeddings
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 95314
  pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 6284
  pid: 9405cc0d6169988371b2755e573cc28650d14dfe
  title: Language Models are Unsupervised Multitask Learners
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1162
  pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  title: 'Making the V in VQA Matter: Elevating the Role of Image Understanding in
    Visual Question Answering'
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 3533
  pid: cd18800a0fe0b668a1cc19f2ec95b5003d0a5035
  title: Improving Language Understanding by Generative Pre-Training
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 481
  pid: 45dd2a3cd7c27f2e9509b023d702408f5ac11c9d
  title: Stacked Cross Attention for Image-Text Matching
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 111
  pid: b82153bf85d5d1edd3f170aace830e5328ca9ed0
  title: Fusion of Detected Objects in Text for Visual Question Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 372
  pid: 6dfc2ff03534a4325d06c6f88c3144831996629b
  title: 'From Recognition to Cognition: Visual Commonsense Reasoning'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 7266
  pid: 077f8329a7b6fa3b7c877a57b81eb6c18b5f87de
  title: 'RoBERTa: A Robustly Optimized BERT Pretraining Approach'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2251
  pid: 1e077413b25c4d34945cc2707e17e46ed4fe784a
  title: Universal Language Model Fine-tuning for Text Classification
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2634
  pid: 93b8da28d006415866bf48f9a6e06b5242129195
  title: 'GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language
    Understanding'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1564
  pid: f37076f426023241f19cdc2fb0a0fd733a6fa7fa
  title: Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2772
  pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 879
  pid: 81f5810fbbab9b7203b9556f4ce3c741875407bc
  title: 'SpanBERT: Improving Pre-training by Representing and Predicting Spans'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2726
  pid: 1fa9ed2bea208511ae698a967875e943049f16b6
  title: 'HuggingFace''s Transformers: State-of-the-art Natural Language Processing'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 3049
  pid: 97fb4e3d45bb098e27e0071448b6152217bd35a5
  title: Layer Normalization
  year: 2016
- fieldsOfStudy:
  - Computer Science
  - Psychology
  numCitedBy: 934
  pid: a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096
  title: 'SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual
    Focused Evaluation'
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2108
  pid: 5082a1a13daea5c7026706738f8528391a1e6d59
  title: A Neural Attention Model for Abstractive Sentence Summarization
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 19339
  pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 4645
  pid: dbde7dfa6cae81df8ac19ef500c42db96c3d1edd
  title: 'Google''s Neural Machine Translation System: Bridging the Gap between Human
    and Machine Translation'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 19778
  pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
  year: 2014
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 7987
  pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  title: Deep Contextualized Word Representations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2887
  pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 5366
  pid: 687bac2d3320083eb4530bf18bb8f8f721477600
  title: Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank
  year: 2013
- fieldsOfStudy:
  - Computer Science
  - Environmental Science
  numCitedBy: 632
  pid: b4df354db88a70183a64dbc9e56cf14e7669a6c0
  title: 'Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic
    Image Captioning'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 10323
  pid: b36a5bb1707bb9c70025294b3a310138aae8327a
  title: Automatic differentiation in PyTorch
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 51691
  pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
  year: 1997
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 439
  pid: db8885a0037fe47d973ade79d696586453710233
  title: The Sixth PASCAL Recognizing Textual Entailment Challenge
  year: 2009
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 734
  pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  title: 'Im2Text: Describing Images Using 1 Million Captioned Photographs'
  year: 2011
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 27402
  pid: 1b47265245e8db53a553049dcb27ed3e495fd625
  title: 'ImageNet: A large-scale hierarchical image database'
  year: 2009
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 289
  pid: 4361e64f2d12d63476fdc88faf72a0f70d9a2ffb
  title: Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear
    Units
  year: 2016
- fieldsOfStudy:
  - Computer Science
  - Linguistics
  numCitedBy: 545
  pid: cb0f3ee1e98faf92429d601cdcd76c69c1e484eb
  title: Neural Network Acceptability Judgments
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 4263
  pid: 05dd7254b632376973f3a1b4d39485da17814df5
  title: 'SQuAD: 100,000+ Questions for Machine Comprehension of Text'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1323
  pid: 44040913380206991b1991daf1192942e038fe31
  title: 'From image descriptions to visual denotations: New similarity metrics for
    semantic inference over event descriptions'
  year: 2014
- fieldsOfStudy:
  - Biology
  numCitedBy: 19355
  pid: 111fd833a4ae576cfdbb27d87d2f8fc0640af355
  title: Learning internal representations by error propagation
  year: 1986
slug: InterBERT:-Vision-and-Language-Interaction-for-Lin-Yang
title: 'InterBERT: Vision-and-Language Interaction for Multi-modal Pretraining'
url: https://www.semanticscholar.org/paper/InterBERT:-Vision-and-Language-Interaction-for-Lin-Yang/b9779ddeb6a8a9de0f7e104d8742728aa14578d6?sort=total-citations
venue: ArXiv
year: 2020
