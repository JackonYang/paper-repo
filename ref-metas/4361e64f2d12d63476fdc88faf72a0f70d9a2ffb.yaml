authors:
- Dan Hendrycks
- Kevin Gimpel
badges:
- id: OPEN_ACCESS
corpusId: 2359786
fieldsOfStudy:
- Computer Science
numCitedBy: 289
numCiting: 24
paperAbstract: We propose the Gaussian Error Linear Unit (GELU), a high-performing
  neural network activation function. The GELU nonlinearity is the expected transformation
  of a stochastic regularizer which randomly applies the identity or zero map, combining
  the intuitions of dropout and zoneout while respecting neuron values. This connection
  suggests a new probabilistic understanding of nonlinearities. We perform an empirical
  evaluation of the GELU nonlinearity against the ReLU and ELU activations and find
  performance improvements across all tasks.
ref_count: 24
references:
- pid: 9f0687bcd0a7d7fc91b8c5d36c003a38b8853105
  title: 'Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations'
- pid: 99c970348b8f70ce23d6641e201904ea49266b6e
  title: Exact solutions to the nonlinear dynamics of learning in deep linear neural
    networks
- pid: f63e917638553414526a0cc8550de4ad2d83fe7a
  title: Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)
- pid: 367f2c63a6f6a10b3b64b8729d601e69337ee3cc
  title: Rectifier Nonlinearities Improve Neural Network Acoustic Models
- pid: ec92efde21707ddf4b81f301cd58e2051c1a2443
  title: Fast dropout training
- pid: a538b05ebb01a40323997629e171c91aa28b8e2f
  title: Rectified Linear Units Improve Restricted Boltzmann Machines
- pid: 3d2c6941a9b4608ba52b328369a3352db2092ae0
  title: 'Weight Normalization: A Simple Reparameterization to Accelerate Training
    of Deep Neural Networks'
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: 34f25a8704614163c4095b3ee2fc969b60de4698
  title: 'Dropout: a simple way to prevent neural networks from overfitting'
- pid: b022f2a277a4bf5f42382e86e4380b96340b9e86
  title: 'SGDR: Stochastic Gradient Descent with Warm Restarts'
- pid: 5d5d4f49d6443c8529a6f5ebef5c499d47a869da
  title: Improving Neural Networks with Dropout
- pid: 98b4d4e24aab57ab4e1124ff8106909050645cfa
  title: Neural networks and physical systems with emergent collective computational
    abilities.
- pid: 51db1f3c8dfc7d4077da39c96bb90a6358128111
  title: Deep Networks with Stochastic Depth
- pid: d2b62f77cb2864e465aa60bca6c26bb1d2f84963
  title: Acoustic Modeling Using Deep Belief Networks
- pid: 97dc8df45972e4ed7423fc992a5092ba25b33411
  title: All you need is a good init
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
slug: Bridging-Nonlinearities-and-Stochastic-Regularizers-Hendrycks-Gimpel
title: Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear
  Units
url: https://www.semanticscholar.org/paper/Bridging-Nonlinearities-and-Stochastic-Regularizers-Hendrycks-Gimpel/4361e64f2d12d63476fdc88faf72a0f70d9a2ffb?sort=total-citations
venue: ArXiv
year: 2016
