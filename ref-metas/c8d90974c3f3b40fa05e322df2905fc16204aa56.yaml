authors:
- R. Jacobs
- Michael I. Jordan
- S. Nowlan
- Geoffrey E. Hinton
badges:
- id: OPEN_ACCESS
corpusId: 572361
fieldsOfStudy:
- Computer Science
numCitedBy: 4007
numCiting: 55
paperAbstract: We present a new supervised learning procedure for systems composed
  of many separate networks, each of which learns to handle a subset of the complete
  set of training cases. The new procedure can be viewed either as a modular version
  of a multilayer supervised network, or as an associative version of competitive
  learning. It therefore provides a new link between these two apparently different
  approaches. We demonstrate that the learning procedure divides up a vowel discrimination
  task into appropriate subtasks, each of which can be solved by a very simple expert
  network.
ref_count: 55
references:
- pid: 1e7c4f513f24c3b82a1138b9f22ed87ed00cbe76
  title: Fast Learning in Networks of Locally-Tuned Processing Units
- pid: 57c4baa5528ba805fc27eee86613c99503978fed
  title: Maximum Likelihood Competitive Learning
- pid: 1ca97e1668e305fb719845f84a05a62dfb946a5d
  title: Local Learning Algorithms
- pid: 034a70c9fbe8e0075f5a5b3a7b06bdf7d3cab4a1
  title: 'Mixture models : inference and applications to clustering'
slug: Adaptive-Mixtures-of-Local-Experts-Jacobs-Jordan
title: Adaptive Mixtures of Local Experts
url: https://www.semanticscholar.org/paper/Adaptive-Mixtures-of-Local-Experts-Jacobs-Jordan/c8d90974c3f3b40fa05e322df2905fc16204aa56?sort=total-citations
venue: Neural Computation
year: 1991
