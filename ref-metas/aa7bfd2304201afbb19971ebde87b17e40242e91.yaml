authors:
- Ilya Sutskever
- James Martens
- George E. Dahl
- Geoffrey E. Hinton
badges:
- id: OPEN_ACCESS
corpusId: 10940950
fieldsOfStudy:
- Computer Science
numCitedBy: 3557
numCiting: 39
paperAbstract: "Deep and recurrent neural networks (DNNs and RNNs respectively) are\
  \ powerful models that were considered to be almost impossible to train using stochastic\
  \ gradient descent with momentum. In this paper, we show that when stochastic gradient\
  \ descent with momentum uses a well-designed random initialization and a particular\
  \ type of slowly increasing schedule for the momentum parameter, it can train both\
  \ DNNs and RNNs (on datasets with long-term dependencies) to levels of performance\
  \ that were previously achievable only with Hessian-Free optimization. We find that\
  \ both the initialization and the momentum are crucial since poorly initialized\
  \ networks cannot be trained with momentum and well-initialized networks perform\
  \ markedly worse when the momentum is absent or poorly tuned. \n \nOur success training\
  \ these models suggests that previous attempts to train deep and recurrent neural\
  \ networks from random initializations have likely failed due to poor initialization\
  \ schemes. Furthermore, carefully tuned momentum methods suffice for dealing with\
  \ the curvature issues in deep and recurrent network training objectives without\
  \ the need for sophisticated second-order methods."
ref_count: 39
references:
- pid: b71ac1e9fb49420d13e084ac67254a0bbd40f83f
  title: Understanding the difficulty of training deep feedforward neural networks
- pid: 0d6203718c15f137fda2f295c96269bc2b254644
  title: Learning Recurrent Neural Networks with Hessian-Free Optimization
- pid: b1a5961609c623fc816aaa77565ba38b25531a8e
  title: 'Neural Networks: Tricks of the Trade'
- pid: e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de
  title: Generating Text with Recurrent Neural Networks
- pid: 355d44f53428b1ac4fb2ab468d593c720640e5bd
  title: Greedy Layer-Wise Training of Deep Networks
- pid: b8ef1230a5cc9ea7cd8358f1ae7d1af97813ba14
  title: Deep Learning Made Easier by Linear Transformations in Perceptrons
- pid: d0be39ee052d246ae99c082a565aba25b811be2d
  title: Learning long-term dependencies with gradient descent is difficult
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: 8978cf7574ceb35f4c3096be768c7547b28a35d0
  title: A Fast Learning Algorithm for Deep Belief Nets
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 4c46347fbc272b21468efe3d9af34b4b2bad6684
  title: Deep learning via Hessian-free optimization
- pid: 6658bbf68995731b2083195054ff45b4eca38b3a
  title: Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech
    Recognition
- pid: b305c18d17fd6a17e8e52a21bcd680220d322cc3
  title: 'Neural Networks: Tricks of the Trade'
- pid: 7b4f3d0e4e2486a8d5d3f8e00549cf9a117bf88f
  title: Sequence Transduction with Recurrent Neural Networks
- pid: d2b62f77cb2864e465aa60bca6c26bb1d2f84963
  title: Acoustic Modeling Using Deep Belief Networks
- pid: 46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e
  title: Reducing the Dimensionality of Data with Neural Networks
- pid: e33cbb25a8c7390aec6a398e36381f4f7770c283
  title: Deep Neural Networks for Acoustic Modeling in Speech Recognition
- pid: 1fd7fc06653723b05abe5f3d1de393ddcf6bdddb
  title: SUBWORD LANGUAGE MODELING WITH NEURAL NETWORKS
- pid: 0d073966e48ffb6dccde1e4eb3f0380c10c6a766
  title: 'Harnessing Nonlinearity: Predicting Chaotic Systems and Saving Energy in
    Wireless Communication'
- pid: b87274e6d9aa4e6ba5148898aa92941617d2b6ed
  title: Efficient BackProp
slug: On-the-importance-of-initialization-and-momentum-in-Sutskever-Martens
title: On the importance of initialization and momentum in deep learning
url: https://www.semanticscholar.org/paper/On-the-importance-of-initialization-and-momentum-in-Sutskever-Martens/aa7bfd2304201afbb19971ebde87b17e40242e91?sort=total-citations
venue: ICML
year: 2013
