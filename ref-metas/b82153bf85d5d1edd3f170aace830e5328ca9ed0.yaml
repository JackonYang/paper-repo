authors:
- Chris Alberti
- Jeffrey Ling
- Michael Collins
- D. Reitter
badges:
- id: OPEN_ACCESS
corpusId: 199577634
fieldsOfStudy:
- Computer Science
numCitedBy: 111
numCiting: 32
paperAbstract: "To advance models of multimodal context, we introduce a simple yet\
  \ powerful neural architecture for data that combines vision and natural language.\
  \ The \u201CBounding Boxes in Text Transformer\u201D (B2T2) also leverages referential\
  \ information binding words to portions of the image in a single unified architecture.\
  \ B2T2 is highly effective on the Visual Commonsense Reasoning benchmark, achieving\
  \ a new state-of-the-art with a 25% relative reduction in error rate compared to\
  \ published baselines and obtaining the best performance to date on the public leaderboard\
  \ (as of May 22, 2019). A detailed ablation analysis shows that the early integration\
  \ of the visual features into the text analysis is key to the effectiveness of the\
  \ new architecture. A reference implementation of our models is provided."
ref_count: 32
references:
- pid: 5fa973b8d284145bf0ced9acf2913a74674260f6
  title: 'Yin and Yang: Balancing and Answering Binary Visual Questions'
- pid: 5aec474c31a2f4b74703c6f786c0a8ff85c450da
  title: 'VisualBERT: A Simple and Performant Baseline for Vision and Language'
- pid: 03eb382e04cca8cca743f7799070869954f1402a
  title: 'CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual
    Reasoning'
- pid: 65a9c7b0800c86a196bc14e7621ff895cc6ab287
  title: 'ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language
    Tasks'
- pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
- pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  title: 'Making the V in VQA Matter: Elevating the Role of Image Understanding in
    Visual Question Answering'
- pid: 2527626c11a84f15709e943fbfa2356e19930e3b
  title: 'VL-BERT: Pre-training of Generic Visual-Linguistic Representations'
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: 1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1
  title: 'GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question
    Answering'
- pid: 6dfc2ff03534a4325d06c6f88c3144831996629b
  title: 'From Recognition to Cognition: Visual Commonsense Reasoning'
- pid: c122fa378a774ba202d418cf71c5c356cf2f902f
  title: 'GQA: a new dataset for compositional question answering over real-world
    images'
- pid: c41a11c0e9b8b92b4faaf97749841170b760760a
  title: 'VideoBERT: A Joint Model for Video and Language Representation Learning'
- pid: 289fb3709475f5c87df8d97f129af54029d27fee
  title: Compositional Attention Networks for Machine Reasoning
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
- pid: ec9b27d019fefadb5e97c8174ac889e831f483d7
  title: 'The Neuro-Symbolic Concept Learner: Interpreting Scenes Words and Sentences
    from Natural Supervision'
- pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  title: Attention is All you Need
- pid: b4df354db88a70183a64dbc9e56cf14e7669a6c0
  title: 'Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic
    Image Captioning'
- pid: 2bc1c8bd00bbf7401afcb5460277840fd8bab029
  title: 'Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal
    Pre-training'
- pid: 87f40e6f3022adbc1f1905e3e506abad05a9964f
  title: Distributed Representations of Words and Phrases and their Compositionality
- pid: 51480ee8f067453c2878f0148ffcfa3a856a02dc
  title: 'WSABIE: Scaling Up to Large Vocabulary Image Annotation'
- pid: 77f0a39b8e02686fd85b01971f8feb7f60971f80
  title: Identity Mappings in Deep Residual Networks
- pid: decd9bc0385612bdf936928206d83730718e737e
  title: Distributional Structure
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: 20a80a7356859daa4170fb4da6b87b84adbb547f
  title: Indexing by Latent Semantic Analysis
- pid: 88b3959b6f5333e5358eac43970a5fa29b54642c
  title: A Synopsis of Linguistic Theory, 1930-1955
slug: Fusion-of-Detected-Objects-in-Text-for-Visual-Alberti-Ling
title: Fusion of Detected Objects in Text for Visual Question Answering
url: https://www.semanticscholar.org/paper/Fusion-of-Detected-Objects-in-Text-for-Visual-Alberti-Ling/b82153bf85d5d1edd3f170aace830e5328ca9ed0?sort=total-citations
venue: EMNLP
year: 2019
