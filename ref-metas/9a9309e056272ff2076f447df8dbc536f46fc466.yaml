authors:
- R. Schapire
- Y. Singer
badges:
- id: OPEN_ACCESS
corpusId: 2329907
fieldsOfStudy:
- Computer Science
numCitedBy: 1916
numCiting: 61
paperAbstract: We describe several improvements to Freund and Schapire's AdaBoost
  boosting algorithm, particularly in a setting in which hypotheses may assign confidences
  to each of their predictions. We give a simplified analysis of AdaBoost in this
  setting, and we show how this analysis can be used to find improved parameter settings
  as well as a refined criterion for training weak hypotheses. We give a specific
  method for assigning confidences to the predictions of decision trees, a method
  closely related to one used by Quinlan. This method also suggests a technique for
  growing decision trees which turns out to be identical to one proposed by Kearns
  and Mansour. We focus next on how to apply the new boosting algorithms to multiclass
  classification problems, particularly to the multi-label case in which each example
  may belong to more than one class. We give two boosting methods for this problem,
  plus a third method based on output coding. One of these leads to a new method for
  handling the single-label case which is simpler but as effective as techniques suggested
  by Freund and Schapire. Finally, we give some experimental results comparing a few
  of the algorithms discussed in this paper.
slug: Improved-Boosting-Algorithms-Using-Confidence-rated-Schapire-Singer
title: Improved Boosting Algorithms Using Confidence-rated Predictions
venue: COLT' 98
year: 1998
