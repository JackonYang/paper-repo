authors:
- Matthew Richardson
- C. Burges
- Erin Renshaw
badges:
- id: OPEN_ACCESS
corpusId: 2100831
fieldsOfStudy:
- Computer Science
numCitedBy: 595
numCiting: 28
paperAbstract: "We present MCTest, a freely available set of stories and associated\
  \ questions intended for research on the machine comprehension of text. Previous\
  \ work on machine comprehension (e.g., semantic modeling) has made great strides,\
  \ but primarily focuses either on limited-domain datasets, or on solving a more\
  \ restricted goal (e.g., open-domain relation extraction). In contrast, MCTest requires\
  \ machines to answer multiple-choice reading comprehension questions about fictional\
  \ stories, directly tackling the high-level goal of open-domain machine comprehension.\
  \ Reading comprehension can test advanced abilities such as causal reasoning and\
  \ understanding the world, yet, by being multiple-choice, still provide a clear\
  \ metric. By being fictional, the answer typically can be found only in the story\
  \ itself. The stories and questions are also carefully limited to those a young\
  \ child would understand, reducing the world knowledge that is required for the\
  \ task. We present the scalable crowd-sourcing methods that allow us to cheaply\
  \ construct a dataset of 500 stories and 2000 questions. By screening workers (with\
  \ grammar tests) and stories (with grading), we have ensured that the data is the\
  \ same quality as another set that we manually edited, but at one tenth the editing\
  \ cost. By being open-domain, yet carefully restricted, we hope MCTest will serve\
  \ to encourage research and provide a clear metric for advancement on the machine\
  \ comprehension of text. 1 Reading Comprehension A major goal for NLP is for machines\
  \ to be able to understand text as well as people. Several research disciplines\
  \ are focused on this problem: for example, information extraction, relation extraction,\
  \ semantic role labeling, and recognizing textual entailment. Yet these techniques\
  \ are necessarily evaluated individually, rather than by how much they advance us\
  \ towards the end goal. On the other hand, the goal of semantic parsing is the machine\
  \ comprehension of text (MCT), yet its evaluation requires adherence to a specific\
  \ knowledge representation, and it is currently unclear what the best representation\
  \ is, for open-domain text. We believe that it is useful to directly tackle the\
  \ top-level task of MCT. For this, we need a way to measure progress. One common\
  \ method for evaluating someone\u2019s understanding of text is by giving them a\
  \ multiple-choice reading comprehension test. This has the advantage that it is\
  \ objectively gradable (vs. essays) yet may test a range of abilities such as causal\
  \ or counterfactual reasoning, inference among relations, or just basic understanding\
  \ of the world in which the passage is set. Therefore, we propose a multiple-choice\
  \ reading comprehension task as a way to evaluate progress on MCT. We have built\
  \ a reading comprehension dataset containing 500 fictional stories, with 4 multiple\
  \ choice questions per story. It was built using methods which can easily scale\
  \ to at least 5000 stories, since the stories were created, and the curation was\
  \ done, using crowd sourcing almost entirely, at a total of $4.00 per story. We\
  \ plan to periodically update the dataset to ensure that methods are not overfitting\
  \ to the existing data. The dataset is open-domain, yet restricted to concepts and\
  \ words that a 7 year old is expected to understand. This task is still beyond the\
  \ capability of today\u2019s computers and algorithms."
ref_count: 28
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1762
  pid: de794d50713ea5f91a7c9da3d72041e2f5ef8452
  title: The PASCAL Recognising Textual Entailment Challenge
  year: 2005
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 194
  pid: 07216ee1119f61b351b69e94b2e7c3698d96b026
  title: Learning Context-Dependent Mappings from Sentences to Logical Form
  year: 2009
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 642
  pid: b7c0e47f8b768258b7d536c21b218e6c46ab8791
  title: Learning to Parse Database Queries Using Inductive Logic Programming
  year: 1996
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 261
  pid: f60d8dd8ca3a7dfa7d0a14988af73084ad93619d
  title: Using Multiple Clause Constructors in Inductive Logic Programming for Semantic
    Parsing
  year: 2001
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 76
  pid: d7add86884b03ded456bd0fd09fa28030f3d64d9
  title: Confidence Driven Unsupervised Semantic Parsing
  year: 2011
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 417
  pid: eb0ab2ee44ebf9c08bd2bf478c7444adfdcb2bd7
  title: The 2005 PASCAL Visual Object Classes Challenge
  year: 2005
slug: MCTest:-A-Challenge-Dataset-for-the-Open-Domain-of-Richardson-Burges
title: 'MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text'
url: https://www.semanticscholar.org/paper/MCTest:-A-Challenge-Dataset-for-the-Open-Domain-of-Richardson-Burges/564257469fa44cdb57e4272f85253efb9acfd69d?sort=total-citations
venue: EMNLP
year: 2013
