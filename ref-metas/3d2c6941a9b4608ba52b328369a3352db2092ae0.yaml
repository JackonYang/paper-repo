authors:
- Tim Salimans
- Diederik P. Kingma
badges:
- id: OPEN_ACCESS
corpusId: 151231
fieldsOfStudy:
- Computer Science
numCitedBy: 1289
numCiting: 39
paperAbstract: 'We present weight normalization: a reparameterization of the weight
  vectors in a neural network that decouples the length of those weight vectors from
  their direction. By reparameterizing the weights in this way we improve the conditioning
  of the optimization problem and we speed up convergence of stochastic gradient descent.
  Our reparameterization is inspired by batch normalization but does not introduce
  any dependencies between the examples in a minibatch. This means that our method
  can also be applied successfully to recurrent models such as LSTMs and to noise-sensitive
  applications such as deep reinforcement learning or generative models, for which
  batch normalization is less well suited. Although our method is much simpler, it
  still provides much of the speed-up of full batch normalization. In addition, the
  computational overhead of our method is lower, permitting more optimization steps
  to be taken in the same amount of time. We demonstrate the usefulness of our method
  on applications in supervised image recognition, generative modelling, and deep
  reinforcement learning.'
ref_count: 39
references:
- pid: 4d376d6978dad0374edfa6709c9556b42d3594d3
  title: 'Batch Normalization: Accelerating Deep Network Training by Reducing Internal
    Covariate Shift'
- pid: b8ef1230a5cc9ea7cd8358f1ae7d1af97813ba14
  title: Deep Learning Made Easier by Linear Transformations in Perceptrons
- pid: 97fb4e3d45bb098e27e0071448b6152217bd35a5
  title: Layer Normalization
- pid: 952454718139dba3aafc6b3b67c4f514ac3964af
  title: Recurrent Batch Normalization
- pid: aa7bfd2304201afbb19971ebde87b17e40242e91
  title: On the importance of initialization and momentum in deep learning
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: c3af47db3186691270192d5399bb5259e05c87a7
  title: Data-dependent Initializations of Convolutional Neural Networks
- pid: 97dc8df45972e4ed7423fc992a5092ba25b33411
  title: All you need is a good init
- pid: b71ac1e9fb49420d13e084ac67254a0bbd40f83f
  title: Understanding the difficulty of training deep feedforward neural networks
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: fb91db6aa4f710814f8aec28a7f3ecbc4e5ad4fd
  title: Deeply-Supervised Nets
- pid: 5e83ab70d0cbc003471e87ec306d27d9c80ecb16
  title: Network In Network
- pid: 0f84a81f431b18a78bd97f59ed4b9d8eda390970
  title: 'Striving for Simplicity: The All Convolutional Net'
- pid: 4c46347fbc272b21468efe3d9af34b4b2bad6684
  title: Deep learning via Hessian-free optimization
- pid: 5694e46284460a648fe29117cbc55f6c9be3fa3c
  title: Densely Connected Convolutional Networks
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 5d90f06bb70a0a3dced62413346235c02b1aa086
  title: Learning Multiple Layers of Features from Tiny Images
- pid: 5f5dc5b9a2ba710937e2c413b37b053cd673df02
  title: Auto-Encoding Variational Bayes
- pid: b7b915d508987b73b61eccd2b237e7ed099a2d29
  title: Maxout Networks
- pid: e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d
  title: Human-level control through deep reinforcement learning
- pid: 484ad17c926292fbe0d5211540832a8c8a8e958b
  title: Stochastic Backpropagation and Approximate Inference in Deep Generative Models
- pid: a2785f66c20fbdf30ec26c0931584c6d6a0f4fca
  title: 'DRAW: A Recurrent Neural Network For Image Generation'
- pid: 855d0f722d75cc56a66a00ede18ace96bafee6bd
  title: 'Theano: new features and speed improvements'
- pid: 8423a5782a1acda21a6f68c307ce5376ebef13c7
  title: Rank, Trace-Norm and Max-Norm
- pid: 6dc61f37ecc552413606d8c89ffbc46ec98ed887
  title: Acceleration of stochastic approximation by averaging
- pid: 4f8d648c52edf74e41b0996128aa536e13cc7e82
  title: Deep Learning
slug: Weight-Normalization:-A-Simple-Reparameterization-Salimans-Kingma
title: 'Weight Normalization: A Simple Reparameterization to Accelerate Training of
  Deep Neural Networks'
url: https://www.semanticscholar.org/paper/Weight-Normalization:-A-Simple-Reparameterization-Salimans-Kingma/3d2c6941a9b4608ba52b328369a3352db2092ae0?sort=total-citations
venue: NIPS
year: 2016
