authors:
- D. Mascharka
- Philip Tran
- R. Soklaski
- Arjun Majumdar
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 3863856
fieldsOfStudy:
- Computer Science
numCitedBy: 152
numCiting: 43
paperAbstract: Visual question answering requires high-order reasoning about an image,
  which is a fundamental capability needed by machine systems to follow complex directives.
  Recently, modular networks have been shown to be an effective framework for performing
  visual reasoning tasks. While modular networks were initially designed with a degree
  of model transparency, their performance on complex visual reasoning benchmarks
  was lacking. Current state-of-the-art approaches do not provide an effective mechanism
  for understanding the reasoning process. In this paper, we close the performance
  gap between interpretable models and state-of-the-art visual reasoning methods.
  We propose a set of visual-reasoning primitives which, when composed, manifest as
  a model capable of performing complex reasoning tasks in an explicitly-interpretable
  manner. The fidelity and interpretability of the primitives' outputs enable an unparalleled
  ability to diagnose the strengths and weaknesses of the resulting model. Critically,
  we show that these primitives are highly performant, achieving state-of-the-art
  accuracy of 99.1% on the CLEVR dataset. We also show that our model is able to effectively
  learn generalized representations when provided a small amount of data containing
  novel object attributes. Using the CoGenT generalization task, we show more than
  a 20 percentage point improvement over the current state of the art.
ref_count: 43
references:
- pid: 289fb3709475f5c87df8d97f129af54029d27fee
  title: Compositional Attention Networks for Machine Reasoning
- pid: 2e17cf6a339fd071ad222062f868e882ef4120a4
  title: Inferring and Executing Programs for Visual Reasoning
- pid: def584565d05d6a8ba94de6621adab9e301d375d
  title: 'Visual7W: Grounded Question Answering in Images'
- pid: 03eb382e04cca8cca743f7799070869954f1402a
  title: 'CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual
    Reasoning'
- pid: a396a6febdacb84340d139096455e67049ac1e22
  title: 'Learning to Reason: End-to-End Module Networks for Visual Question Answering'
- pid: 007112213ece771be72cbecfd59f048209facabd
  title: A simple neural network module for relational reasoning
- pid: 5823d18cd378898b12de537862d996443ce9c9e8
  title: Structured Attentions for Visual Question Answering
- pid: fddc15480d086629b960be5bff96232f967f2252
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
- pid: 1cf6bc0866226c1f8e282463adc8b75d92fba9bb
  title: 'Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for
    Visual Question Answering'
- pid: 58cb0c24c936b8a14ca7b2d56ba80de733c545b3
  title: 'Human Attention in Visual Question Answering: Do Humans and Deep Networks
    look at the same regions?'
- pid: 0ac8f1a3c679b90d22c1f840cdc8d61ffef750ac
  title: Deep Compositional Question Answering with Neural Module Networks
- pid: fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b
  title: Hierarchical Question-Image Co-Attention for Visual Question Answering
- pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  title: Stacked Attention Networks for Image Question Answering
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: 175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22
  title: 'Where to Look: Focus Regions for Visual Question Answering'
- pid: a79b694bd4ef51207787da1948ed473903b751ef
  title: Bottom-Up and Top-Down Attention for Image Captioning and VQA
- pid: 75ddc7ee15be14013a3462c01b38b0548486fbcb
  title: Learning to Compose Neural Networks for Question Answering
- pid: 30a3eee5e9302108416f6234d739373dde68d373
  title: Learning to Count Objects in Natural Images for Visual Question Answering
- pid: 8e9ad6f8b2bc97f0412fa0cc243ac6975864534a
  title: Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual
    Question Answering
- pid: b196bc11ad516c8e6ff96f83acfc443fd7161730
  title: 'ABC-CNN: An Attention Based Convolutional Neural Network for Visual Question
    Answering'
- pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: d6f2f611da110b5b5061731be3fc4c7f45d8ee23
  title: 'Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet
    Classification'
- pid: 7f5fc84819c0cf94b771fe15141f65b123f7b8ec
  title: Multi-Scale Context Aggregation by Dilated Convolutions
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
slug: Transparency-by-Design:-Closing-the-Gap-Between-and-Mascharka-Tran
title: 'Transparency by Design: Closing the Gap Between Performance and Interpretability
  in Visual Reasoning'
url: https://www.semanticscholar.org/paper/Transparency-by-Design:-Closing-the-Gap-Between-and-Mascharka-Tran/cd0a7c58964905ccfddbad1614165320ccc56393?sort=total-citations
venue: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition
year: 2018
