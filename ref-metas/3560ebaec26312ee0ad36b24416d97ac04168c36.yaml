authors:
- Yi-Fan Zhou
- Runhao Jiang
- Xiao Wu
- Jun-Yan He
- Shuang Weng
- Qiang Peng
badges: []
corpusId: 195488949
fieldsOfStudy:
- Computer Science
numCitedBy: 18
numCiting: 45
paperAbstract: Image-to-image translation is a fundamental task for a wide range of
  applications, such as image style transfer, video effect generation, cross-domain
  retrieval, etc. Due to the limited number of labeled data, complex scenes, abstract
  semantics and various involved domains, image translation remains a challenging
  task. Compared to the supervised approaches for image translation that need a large
  collection of paired images for training, the unsupervised methods can significantly
  reduce the training cost. In this paper, an unsupervised end-to-end generative adversarial
  network is proposed, named BranchGAN, for mutual image-to-image transfer between
  two domains. A structure with one single encoder and dual decoders is novelly proposed
  to capture the cross-domain distributions and generate the images in both domains.
  Three factors, that is, pixel-level overall style, region semantics, and domain
  distinguishability are comprehensively considered to constrain the training process
  of the proposed model, corresponding to reconstruction loss, encoding loss, and
  adversarial loss, respectively. Experiments conducted on three benchmark datasets
  demonstrate the effectiveness of the proposed method that outperforms the unsupervised
  state-of-the-art approaches and has the competitive performance as the supervised
  method.
ref_count: 45
references:
- pid: 8acbe90d5b852dadea7810345451a99608ee54c7
  title: Image-to-Image Translation with Conditional Adversarial Networks
- pid: 571b0750085ae3d939525e62af510ee2cee9d5ea
  title: Improved Techniques for Training GANs
- pid: 8388f1be26329fa45e5807e968a641ce170ea078
  title: Unsupervised Representation Learning with Deep Convolutional Generative Adversarial
    Networks
- pid: 9201bf6f8222c2335913002e13fbac640fc0f4ec
  title: Fully convolutional networks for semantic segmentation
- pid: ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1
  title: Generating Videos with Scene Dynamics
- pid: 353ecf7b66b3e9ff5e9f41145a147e899a2eea5c
  title: Conditional Generative Adversarial Nets
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: c8c494ee5488fe20e0aa01bddf3fc4632086d654
  title: The Cityscapes Dataset for Semantic Urban Scene Understanding
- pid: eae2e0fa72e898c289365c0af16daf57a7a6cf40
  title: 'Image quality assessment: from error visibility to structural similarity'
- pid: acd87843a451d18b4dc6474ddce1ae946429eaf1
  title: Wasserstein Generative Adversarial Networks
- pid: 5f5dc5b9a2ba710937e2c413b37b053cd673df02
  title: Auto-Encoding Variational Bayes
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e
  title: Reducing the Dimensionality of Data with Neural Networks
slug: BranchGAN:-Unsupervised-Mutual-Image-to-Image-With-Zhou-Jiang
title: 'BranchGAN: Unsupervised Mutual Image-to-Image Transfer With A Single Encoder
  and Dual Decoders'
url: https://www.semanticscholar.org/paper/BranchGAN:-Unsupervised-Mutual-Image-to-Image-With-Zhou-Jiang/3560ebaec26312ee0ad36b24416d97ac04168c36?sort=total-citations
venue: IEEE Transactions on Multimedia
year: 2019
