authors:
- H. Sak
- A. Senior
- F. Beaufays
badges:
- id: OPEN_ACCESS
corpusId: 6263878
fieldsOfStudy:
- Computer Science
numCitedBy: 1952
numCiting: 25
paperAbstract: 'Long Short-Term Memory (LSTM) is a specific recurrent neural network
  (RNN) architecture that was designed to model temporal sequences and their long-range
  dependencies more accurately than conventional RNNs. In this paper, we explore LSTM
  RNN architectures for large scale acoustic modeling in speech recognition. We recently
  showed that LSTM RNNs are more effective than DNNs and conventional RNNs for acoustic
  modeling, considering moderately-sized models trained on a single machine. Here,
  we introduce the first distributed training of LSTM RNNs using asynchronous stochastic
  gradient descent optimization on a large cluster of machines. We show that a two-layer
  deep LSTM RNN where each LSTM layer has a linear recurrent projection layer can
  exceed state-of-the-art speech recognition performance. This architecture makes
  more effective use of model parameters than the others considered, converges quickly,
  and outperforms a deep feed forward neural network having an order of magnitude
  more parameters. Index Terms: Long Short-Term Memory, LSTM, recurrent neural network,
  RNN, speech recognition, acoustic modeling.'
ref_count: 25
references:
- pid: 4177ec52d1b80ed57f2e72b0f9a42365f1a8598d
  title: Speech recognition with deep recurrent neural networks
- pid: 1149888d75af4ed5dffc25731b875651c3ccdeb2
  title: Hybrid speech recognition with Deep Bidirectional LSTM
- pid: f9a1b3850dfd837793743565a8af95973d395a4e
  title: LSTM Neural Networks for Language Modeling
- pid: 6658bbf68995731b2083195054ff45b4eca38b3a
  title: Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech
    Recognition
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 9819b600a828a57e1cde047bbe710d3446b30da5
  title: Recurrent neural network based language model
- pid: 2f83f6e1afadf0963153974968af6b8342775d82
  title: Framewise phoneme classification with bidirectional LSTM and other neural
    network architectures
- pid: b0b33aaed1d408d04fadf9ff2a080e47ef8cb7b1
  title: Training and Analysing Deep Recurrent Neural Networks
- pid: a4eb9f4fad5c5a1935c6d0532e2c765ee29b0b37
  title: Application of Pretrained Deep Neural Networks to Large Vocabulary Speech
    Recognition
- pid: 047655e733a9eed9a500afd916efa566915b9110
  title: Learning Precise Timing with LSTM Recurrent Networks
- pid: e33cbb25a8c7390aec6a398e36381f4f7770c283
  title: Deep Neural Networks for Acoustic Modeling in Speech Recognition
- pid: f828b401c86e0f8fddd8e77774e332dfd226cb05
  title: LSTM recurrent networks learn simple context-free and context-sensitive languages
- pid: d0be39ee052d246ae99c082a565aba25b811be2d
  title: Learning long-term dependencies with gradient descent is difficult
- pid: d2b62f77cb2864e465aa60bca6c26bb1d2f84963
  title: Acoustic Modeling Using Deep Belief Networks
- pid: 3127190433230b3dc1abd0680bb58dced4bcd90e
  title: Large Scale Distributed Deep Networks
- pid: 26bc0449360d7016f684eafae5b5d2feded32041
  title: An Efficient Gradient-Based Algorithm for On-Line Training of Recurrent Network
    Trajectories
- pid: 375214ac340226e23ec428e92ec499fb89f508b8
  title: A Novel Connectionist System for Unconstrained Handwriting Recognition
slug: Long-short-term-memory-recurrent-neural-network-for-Sak-Senior
title: Long short-term memory recurrent neural network architectures for large scale
  acoustic modeling
url: https://www.semanticscholar.org/paper/Long-short-term-memory-recurrent-neural-network-for-Sak-Senior/067e07b725ab012c80aa2f87857f6791c1407f6d?sort=total-citations
venue: INTERSPEECH
year: 2014
