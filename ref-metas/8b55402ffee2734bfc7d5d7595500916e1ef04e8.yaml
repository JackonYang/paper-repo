authors:
- Harsh Agrawal
- Karan Desai
- Yufei Wang
- Xinlei Chen
- Rishabh Jain
- Mark Johnson
- Dhruv Batra
- Devi Parikh
- Stefan Lee
- Peter Anderson
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 56517630
fieldsOfStudy:
- Computer Science
numCitedBy: 91
numCiting: 60
paperAbstract: "Image captioning models have achieved impressive results on datasets\
  \ containing limited visual concepts and large amounts of paired image-caption training\
  \ data. However, if these models are to ever function in the wild, a much larger\
  \ variety of visual concepts must be learned, ideally from less supervision. To\
  \ encourage the development of image captioning models that can learn visual concepts\
  \ from alternative data sources, such as object detection datasets, we present the\
  \ first large-scale benchmark for this task. Dubbed \u2018nocaps\u2019, for novel\
  \ object captioning at scale, our benchmark consists of 166,100 human-generated\
  \ captions describing 15,100 images from the Open Images validation and test sets.\
  \ The associated training data consists of COCO image-caption pairs, plus Open Images\
  \ image-level labels and object bounding boxes. Since Open Images contains many\
  \ more classes than COCO, nearly 400 object classes seen in test images have no\
  \ or very few associated training captions (hence, nocaps). We extend existing novel\
  \ object captioning models to establish strong baselines for this benchmark and\
  \ provide analysis to guide future work."
ref_count: 60
references:
- pid: b9aa3bafa9e8e21bb92908ae23b468fa248239b3
  title: Captioning Images with Diverse Objects
- pid: e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17
  title: 'Deep Compositional Captioning: Describing Novel Object Categories without
    Paired Training Data'
- pid: 086fa2fe3ee2a5b805aeaf9fbfe59ee8157dad5c
  title: Guided Open Vocabulary Image Captioning with Constrained Beam Search
- pid: d64f52b94977b71976327eeb3db702b246ee39ce
  title: Decoupled Novel Object Captioner
- pid: 10480a42957a8e08e4c543185e135d7c254583a5
  title: Incorporating Copying Mechanism in Image Captioning for Learning Novel Objects
- pid: 18f1143c64e6557c933b206fb8b2a7bd1f389afd
  title: Rich Image Captioning in the Wild
- pid: 3bf09b2e2639add154a9fe6ff98cc373d3e90e4e
  title: Neural Baby Talk
- pid: f77a604410d88307ec5c6331c8b6133272fbaa10
  title: Self-Critical Sequence Training for Image Captioning
- pid: b4df354db88a70183a64dbc9e56cf14e7669a6c0
  title: 'Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic
    Image Captioning'
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: 9814df8bd00ba999c4d1e305a7e9bca579dc7c75
  title: 'Framing Image Description as a Ranking Task: Data, Models and Evaluation
    Metrics (Extended Abstract)'
- pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  title: 'Im2Text: Describing Images Using 1 Million Captioned Photographs'
- pid: 9f4d7d622d1f7319cc511bfef661cd973e881a4c
  title: 'Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image
    Captioning'
- pid: 1c54acd7d9ed8017acdc5674c9b7faac738fd651
  title: 'SPICE: Semantic Propositional Image Caption Evaluation'
- pid: 163a474747fd63ab62ae586711fa5e5a2ac91bd8
  title: Improved Image Captioning via Policy Gradient optimization of SPIDEr
- pid: 258986132bf17755fe8263e42429fe73218c1534
  title: 'CIDEr: Consensus-based image description evaluation'
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: e74f9b7f8eec6ba4704c206b93bc8079af3da4bd
  title: ImageNet Large Scale Visual Recognition Challenge
- pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
- pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
- pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
- pid: cc18cb42289fd570a06896b5543b085ebabee57b
  title: Training and Evaluating Multimodal Word Embeddings with Large-scale Web Annotated
    Images
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: f6e0856b4a9199fa968ac00da612a9407b5cb85c
  title: Aggregated Residual Transformations for Deep Neural Networks
- pid: 1b47265245e8db53a553049dcb27ed3e495fd625
  title: 'ImageNet: A large-scale hierarchical image database'
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: 6c8353697cdbb98dfba4f493875778c4286d3e3a
  title: Self-Critical Sequence Training for Image Captioning
- pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  title: 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks'
- pid: a312a573ef81793d56401e932ef6c9498791a3d1
  title: Speed/Accuracy Trade-Offs for Modern Convolutional Object Detectors
- pid: 696ca58d93f6404fea0fc75c62d1d7b378f47628
  title: 'Microsoft COCO Captions: Data Collection and Evaluation Server'
- pid: 2e36ea91a3c8fbff92be2989325531b4002e2afc
  title: Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
- pid: 5cb6700d94c6118ee13f4f4fecac99f111189812
  title: 'BabyTalk: Understanding and Generating Simple Image Descriptions'
- pid: 61d2dda8d96a10a714636475c7589bd149bda053
  title: Review Networks for Caption Generation
- pid: 93b8da28d006415866bf48f9a6e06b5242129195
  title: 'GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language
    Understanding'
- pid: 1c46943103bd7b7a2c7be86859995a4144d1938b
  title: Visualizing Data using t-SNE
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
- pid: 44040913380206991b1991daf1192942e038fe31
  title: 'From image descriptions to visual denotations: New similarity metrics for
    semantic inference over event descriptions'
- pid: 60b05f32c32519a809f21642ef1eb3eaf3848008
  title: 'ROUGE: A Package for Automatic Evaluation of Summaries'
- pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  title: Deep Contextualized Word Representations
- pid: 34d7a07c493ca6336c92156806a2947e115caadc
  title: 'METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation
    with Human Judgments'
- pid: d7da009f457917aa381619facfa5ffae9329a6e9
  title: 'Bleu: a Method for Automatic Evaluation of Machine Translation'
- pid: d36efb9ad91e00faa334b549ce989bfae7e2907a
  title: Maximum likelihood from incomplete data via the EM - algorithm plus discussions
    on the paper
slug: nocaps:-novel-object-captioning-at-scale-Agrawal-Desai
title: 'nocaps: novel object captioning at scale'
url: https://www.semanticscholar.org/paper/nocaps:-novel-object-captioning-at-scale-Agrawal-Desai/8b55402ffee2734bfc7d5d7595500916e1ef04e8?sort=total-citations
venue: 2019 IEEE/CVF International Conference on Computer Vision (ICCV)
year: 2019
