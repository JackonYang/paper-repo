authors:
- M. Stinchcombe
- H. White
badges:
- id: OPEN_ACCESS
corpusId: 14470590
fieldsOfStudy:
- Computer Science
numCitedBy: 277
numCiting: 9
paperAbstract: 'K.M. Hornik, M. Stinchcombe, and H. White (Univ. of California at
  San Diego, Dept. of Economics Discussion Paper, June 1988; to appear in Neural Networks)
  showed that multilayer feedforward networks with as few as one hidden layer, no
  squashing at the output layer, and arbitrary sigmoid activation function at the
  hidden layer are universal approximators: they are capable of arbitrarily accurate
  approximation to arbitrary mappings, provided sufficiently many hidden units are
  available. The present authors obtain identical conclusions but do not require the
  hidden-unit activation to be sigmoid. Instead, it can be a rather general nonlinear
  function. Thus, multilayer feedforward networks possess universal approximation
  capabilities by virtue of the presence of intermediate layers with sufficiently
  many parallel processors; the properties of the intermediate-layer activation function
  are not so crucial. In particular, sigmoid activation functions are not necessary
  for universal approximation.<<ETX>>'
ref_count: 9
references:
- pid: 8da1dda34ecc96263102181448c94ec7d645d085
  title: Approximation by superpositions of a sigmoidal function
- pid: f22f6972e66bdd2e769fa64b0df0a13063c0c101
  title: Multilayer feedforward networks are universal approximators
slug: Universal-approximation-using-feedforward-networks-Stinchcombe-White
title: Universal approximation using feedforward networks with non-sigmoid hidden
  layer activation functions
url: https://www.semanticscholar.org/paper/Universal-approximation-using-feedforward-networks-Stinchcombe-White/ee7f0bc85b339d781c2e0c7e6db8e339b6b9fec2?sort=total-citations
venue: International 1989 Joint Conference on Neural Networks
year: 1989
