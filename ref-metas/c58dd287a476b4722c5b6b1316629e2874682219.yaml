authors:
- C. Goller
- "A. K\xFCchler"
badges:
- id: OPEN_ACCESS
corpusId: 6536466
fieldsOfStudy:
- Computer Science
numCitedBy: 578
numCiting: 19
paperAbstract: While neural networks are very successfully applied to the processing
  of fixed-length vectors and variable-length sequences, the current state of the
  art does not allow the efficient processing of structured objects of arbitrary shape
  (like logical terms, trees or graphs). We present a connectionist architecture together
  with a novel supervised learning scheme which is capable of solving inductive inference
  tasks on complex symbolic structures of arbitrary size. The most general structures
  that can be handled are labeled directed acyclic graphs. The major difference of
  our approach compared to others is that the structure-representations are exclusively
  tuned for the intended inference task. Our method is applied to tasks consisting
  in the classification of logical terms. These range from the detection of a certain
  subterm to the satisfaction of a specific unification pattern. Compared to previously
  known approaches we obtained superior results in that domain.
ref_count: 19
references:
- pid: 6a835df43fdc2f79126319f6fa033bb42147c6f6
  title: Recursive Distributed Representations
- pid: 1a3d22599028a05669e884f3eaf19a342e190a87
  title: 'Backpropagation Through Time: What It Does and How to Do It'
- pid: 111fd833a4ae576cfdbb27d87d2f8fc0640af355
  title: Learning internal representations by error propagation
slug: "Learning-task-dependent-distributed-representations-Goller-K\xFCchler"
title: Learning task-dependent distributed representations by backpropagation through
  structure
url: "https://www.semanticscholar.org/paper/Learning-task-dependent-distributed-representations-Goller-K\xFC\
  chler/c58dd287a476b4722c5b6b1316629e2874682219?sort=total-citations"
venue: Proceedings of International Conference on Neural Networks (ICNN'96)
year: 1996
