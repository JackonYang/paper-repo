authors:
- S. Soderland
badges: []
corpusId: 60585486
fieldsOfStudy:
- Computer Science
numCitedBy: 83
numCiting: 56
paperAbstract: 'An enormous amount of knowledge is needed to infer the meaning of
  unrestricted natural language. The problem can be reduced to a manageable size by
  restricting attention to a specific {\em domain}, which is a corpus of texts together
  with a predefined set of {\em concepts} that are of interest to that domain. Two
  widely different domains are used to illustrate this domain-specific approach. One
  domain is a collection of Wall Street Journal articles in which the target concept
  is management succession events: identifying persons moving into corporate management
  positions or moving out. A second domain is a collection of hospital discharge summaries
  in which the target concepts are various classes of diagnosis or symptom. The goal
  of an information extraction system is to identify references to the concept of
  interest for a particular domain. A key knowledge source for this purpose is a set
  of text analysis rules based on the vocabulary, semantic classes, and writing style
  peculiar to the domain. This thesis presents CRYSTAL, an implemented system that
  automatically induces domain-specific text analysis rules from training examples.
  CRYSTAL learns rules that approach the performance of hand-coded rules, are robust
  in the face of noise and inadequate features, and require only a modest amount of
  training data. CRYSTAL belongs to a class of machine learning algorithms called
  covering algorithms, and presents a novel control strategy with time and space complexities
  that are independent of the number of features. CRYSTAL navigates efficiently through
  an extremely large space of possible rules. CRYSTAL also demonstrates that expressive
  rule representation is essential for high performance, robust text analysis rules.
  While simple rules are adequate to capture the most salient regularities in the
  training data, high performance can only be achieved when rules are expressive enough
  to reflect the subtlety and variability of unrestricted natural language.'
ref_count: 56
references:
- pid: bdc08721414c972ab451f8ef3ef39d63c741b324
  title: Automatically Constructing a Dictionary for Information Extraction Tasks
- pid: 8245f6099f547008522ebbe6fb813d8132085746
  title: 'CRYSTAL: Inducing a Conceptual Dictionary'
- pid: acec622ca4fb7e01a56116522d35ded149969d0a
  title: Automatically Generating Extraction Patterns from Untagged Text
- pid: f0a14be7e7f5614b91d0f648ae5f2baafc6d7036
  title: Statistical Decision-Tree Models for Parsing
- pid: 1d922631a6bf8361d7602e12cafb9e15d421c827
  title: "Word-Sense Disambiguation Using Statistical Models of Roget\u2019s Categories\
    \ Trained on Large Corpora"
- pid: 6a7d1669748c30ef108d7874edaf4c8cac73a01c
  title: 'Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon'
- pid: 8dadbf2dfebe794ad4fc5022f8bb65195c8f0d5a
  title: Learning information extraction patterns from examples
- pid: 4bd970a37c59c97804ff93cbb2c108e081de3a37
  title: 'Introduction to WordNet: An On-line Lexical Database'
- pid: a7e084fe51a40eeaaf79bf0b78e837d5bc4a8e10
  title: A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text
- pid: 733234e097dceb9011baa8914930861996eb0b5e
  title: Some Advances in Transformation-Based Part of Speech Tagging
- pid: 7feb0fc888cd55360949554db032d7d1cba9e947
  title: Programs for Machine Learning
- pid: 0df1aac45ff562089a3bdbcb34e2481a71478651
  title: Generalization as Search
- pid: dd1d8628cb1dc1b1938aa12cf32fb2d4a85948df
  title: A theory and methodology of inductive learning
slug: Learning-text-analysis-rules-for-domain-specific-Soderland
title: Learning text analysis rules for domain-specific natural language processing
url: https://www.semanticscholar.org/paper/Learning-text-analysis-rules-for-domain-specific-Soderland/ca198cc81878fd036c7b97ee10441f1d09839f65?sort=total-citations
venue: ''
year: 1996
