authors:
- Thang Luong
- Hieu Pham
- Christopher D. Manning
badges:
- id: OPEN_ACCESS
corpusId: 1998416
fieldsOfStudy:
- Computer Science
meta_key: effective-approaches-to-attention-based-neural-machine-translation
numCitedBy: 5892
numCiting: 24
paperAbstract: "An attentional mechanism has lately been used to improve neural machine\
  \ translation (NMT) by selectively focusing on parts of the source sentence during\
  \ translation. However, there has been little work exploring useful architectures\
  \ for attention-based NMT. This paper examines two simple and effective classes\
  \ of attentional mechanism: a global approach which always attends to all source\
  \ words and a local one that only looks at a subset of source words at a time. We\
  \ demonstrate the effectiveness of both approaches on the WMT translation tasks\
  \ between English and German in both directions. With local attention, we achieve\
  \ a significant gain of 5.0 BLEU points over non-attentional systems that already\
  \ incorporate known techniques such as dropout. Our ensemble model using different\
  \ attention architectures yields a new state-of-the-art result in the WMT\u2019\
  15 English to German translation task with 25.9 BLEU points, an improvement of 1.0\
  \ BLEU points over the existing best system backed by NMT and an n-gram reranker.\
  \ 1"
ref_count: 24
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: addressing-the-rare-word-problem-in-neural-machine-translation
  numCitedBy: 679
  pid: 1956c239b3552e030db1b78951f64781101125ed
  show_ref_link: false
  title: Addressing the Rare Word Problem in Neural Machine Translation
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: on-using-very-large-target-vocabulary-for-neural-machine-translation
  numCitedBy: 857
  pid: 1938624bb9b0f999536dcc8d8f519810bb4e1b3b
  show_ref_link: false
  title: On Using Very Large Target Vocabulary for Neural Machine Translation
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: neural-machine-translation-by-jointly-learning-to-align-and-translate
  numCitedBy: 19339
  pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  show_ref_link: true
  title: Neural Machine Translation by Jointly Learning to Align and Translate
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: sequence-to-sequence-learning-with-neural-networks
  numCitedBy: 14880
  pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  show_ref_link: true
  title: Sequence to Sequence Learning with Neural Networks
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: recurrent-continuous-translation-models
  numCitedBy: 1235
  pid: 944a1cfd79dbfb6fef460360a0765ba790f4027a
  show_ref_link: true
  title: Recurrent Continuous Translation Models
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: statistical-phrase-based-translation
  numCitedBy: 3753
  pid: a4b828609b60b06e61bea7a4029cc9e1cad5df87
  show_ref_link: true
  title: Statistical Phrase-Based Translation
  year: 2003
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation
  numCitedBy: 15050
  pid: 0b544dfe355a5070b60986319a3f51fb45d1348e
  show_ref_link: true
  title: Learning Phrase Representations using RNN Encoder-Decoder for Statistical
    Machine Translation
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: show-attend-and-tell-neural-image-caption-generation-with-visual-attention
  numCitedBy: 7252
  pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  show_ref_link: true
  title: Show, Attend and Tell - Neural Image Caption Generation with Visual Attention
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: end-to-end-continuous-speech-recognition-using-attention-based-recurrent-nn-first-results
  numCitedBy: 375
  pid: 47d2dc34e1d02a8109f5c04bb6939725de23716d
  show_ref_link: false
  title: End-to-end Continuous Speech Recognition using Attention-based Recurrent
    NN - First Results
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: n-gram-counts-and-language-models-from-the-common-crawl
  numCitedBy: 145
  pid: 8e4fb17fff38a7834af5b4eaafcbbde02bf00975
  show_ref_link: false
  title: N-gram Counts and Language Models from the Common Crawl
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: measuring-word-alignment-quality-for-statistical-machine-translation
  numCitedBy: 224
  pid: 52805ca2a7f5f6e73dc90ff20f1ca2f198dd031b
  show_ref_link: false
  title: Measuring Word Alignment Quality for Statistical Machine Translation
  year: 2007
- fieldsOfStudy:
  - Computer Science
  meta_key: recurrent-neural-network-regularization
  numCitedBy: 1970
  pid: f264e8b33c0d49a692a6ce2c4bcb28588aeb7d97
  show_ref_link: true
  title: Recurrent Neural Network Regularization
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: bleu-a-method-for-automatic-evaluation-of-machine-translation
  numCitedBy: 16615
  pid: d7da009f457917aa381619facfa5ffae9329a6e9
  show_ref_link: true
  title: Bleu - a Method for Automatic Evaluation of Machine Translation
  year: 2002
- fieldsOfStudy:
  - Computer Science
  meta_key: recurrent-models-of-visual-attention
  numCitedBy: 2410
  pid: 8a756d4d25511d92a45d0f4545fa819de993851d
  show_ref_link: true
  title: Recurrent Models of Visual Attention
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: draw-a-recurrent-neural-network-for-image-generation
  numCitedBy: 1628
  pid: a2785f66c20fbdf30ec26c0931584c6d6a0f4fca
  show_ref_link: true
  title: DRAW - A Recurrent Neural Network For Image Generation
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: alignment-by-agreement
  numCitedBy: 501
  pid: f4f6bfacb4cd508df62540f5aa9ba30cd83dd127
  show_ref_link: false
  title: Alignment by Agreement
  year: 2006
slug: Effective-Approaches-to-Attention-based-Neural-Luong-Pham
title: Effective Approaches to Attention-based Neural Machine Translation
url: https://www.semanticscholar.org/paper/Effective-Approaches-to-Attention-based-Neural-Luong-Pham/93499a7c7f699b6630a86fad964536f9423bb6d0?sort=total-citations
venue: EMNLP
year: 2015
