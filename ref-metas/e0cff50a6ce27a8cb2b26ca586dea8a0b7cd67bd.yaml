authors:
- Xiaoyu Lin
- Devi Parikh
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 606971
fieldsOfStudy:
- Computer Science
numCitedBy: 64
numCiting: 61
paperAbstract: "Artificial agents today can answer factual questions. But they fall\
  \ short on questions that require common sense reasoning. Perhaps this is because\
  \ most existing common sense databases rely on text to learn and represent knowledge.\
  \ But much of common sense knowledge is unwritten - partly because it tends not\
  \ to be interesting enough to talk about, and partly because some common sense is\
  \ unnatural to articulate in text. While unwritten, it is not unseen. In this paper\
  \ we leverage semantic common sense knowledge learned from images - i.e. visual\
  \ common sense - in two textual tasks: fill-in-the-blank and visual paraphrasing.\
  \ We propose to \u201Cimagine\u201D the scene behind the text, and leverage visual\
  \ cues from the \u201Cimagined\u201D scenes in addition to textual cues while answering\
  \ these questions. We imagine the scenes as a visual abstraction. Our approach outperforms\
  \ a strong text-only baseline on these tasks. Our proposed tasks can serve as benchmarks\
  \ to quantitatively evaluate progress in solving tasks that go \u201Cbeyond recognition\u201D\
  . Our code and datasets are publicly available."
ref_count: 61
references:
- pid: dfe448d6297ea0a3d4deba21fbf1006bc35877d7
  title: Inferring the Why in Images
- pid: 564257469fa44cdb57e4272f85253efb9acfd69d
  title: 'MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of
    Text'
- pid: b0ab8aa7a5b684532b4ff30f8d34b35a99759a46
  title: 'Learning Everything about Anything: Webly-Supervised Visual Concept Learning'
- pid: d3ab56d83a616dba391a3373037aceb662bcda9d
  title: Zero-Shot Learning via Visual Abstraction
- pid: 6c39f56c3c21c3972c362f8e752be57a50c41f4f
  title: Learning the Visual Interpretation of Sentences
- pid: 051830b0ea58d1568f19ec3297e301d9789c9a76
  title: Bringing Semantics into Focus Using Visual Abstraction
- pid: eaaed23a2d94feb2f1c3ff22a25777c7a78f3141
  title: 'Every Picture Tells a Story: Generating Sentences from Images'
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: 050da5d159fb0dd96143948e1cffeb3dec814673
  title: Visual Turing test for computer vision systems
- pid: 8e523721feebeaee18e487607b7d0920ac6cd3b4
  title: 'Beyond Nouns: Exploiting Prepositions and Comparative Adjectives for Learning
    Visual Classifiers'
- pid: 5ce04063ecf83a6584813e1a09fb3d81642e5790
  title: Understanding and predicting importance in images
- pid: 71ae756c75ac89e2d731c9c79649562b5768ff39
  title: Memory Networks
- pid: 53e4ab9730e983242a3409c7bf1af945041a6563
  title: 'NEIL: Extracting Visual Knowledge from Web Data'
- pid: c99798fce885b41ab1de66bbacf04b7de7274f85
  title: Predicting Object Dynamics in Scenes
- pid: ea8fe33cc1596b2e493ddd87f22cd21f563664e8
  title: Reasoning about Object Affordances in a Knowledge Base Representation
- pid: 169b847e69c35cfd475eb4dcc561a24de11762ca
  title: 'Baby talk: Understanding and generating simple image descriptions'
- pid: 87f40e6f3022adbc1f1905e3e506abad05a9964f
  title: Distributed Representations of Words and Phrases and their Compositionality
- pid: 89d5b41b7fb0a122f811be270e6d5f72fc59d680
  title: 'PANDA: Pose Aligned Networks for Deep Attribute Modeling'
- pid: 52f86811b57034ba5c0478b37cab101d9a84024a
  title: Comparing Automatic Evaluation Measures for Image Description
- pid: 3ff2862a8121cc823a8eb72f3e0a97bbf25c82ec
  title: 'Building Watson: An Overview of the DeepQA Project'
- pid: 07ac2e342db42589322b28ef291c2702f4a793a8
  title: An empirical study of context in object detection
- pid: f7312b8568d63bbbb239583ed282f46cdc40978d
  title: Toward an Architecture for Never-Ending Language Learning
- pid: 0566bf06a0368b518b8b474166f7b1dfef3f9283
  title: Learning to detect unseen object classes by between-class attribute transfer
- pid: a14045a751f5d8ed387c8630a86a3a2861b90643
  title: A Fast and Accurate Dependency Parser using Neural Networks
- pid: 68c03788224000794d5491ab459be0b2a2c38677
  title: 'WordNet: A Lexical Database for English'
- pid: d2946a868682e4141beabc288d79253ae254c6e1
  title: DBpedia - A large-scale, multilingual knowledge base extracted from Wikipedia
- pid: e79272fe3d65197100eae8be9fec6469107969ae
  title: Object Detection with Discriminatively Trained Part Based Models
- pid: 4dfe43ddfcfbe00dd663a4d70b0df9dcc8c92184
  title: 'YAGO2: A Spatially and Temporally Enhanced Knowledge Base from Wikipedia:
    Extended Abstract'
- pid: 6def29d024457f8897c3a634fef8a03dcaedc9a0
  title: 'Seeing 3D Chairs: Exemplar Part-Based 2D-3D Alignment Using a Large Dataset
    of CAD Models'
- pid: b48d90cfebb8fbff29d161f6704d31b6909eb7ad
  title: 'IM2GPS: estimating geographic information from a single image'
- pid: 1976c9eeccc7115d18a04f1e7fb5145db6b96002
  title: 'Freebase: a collaboratively created graph database for structuring human
    knowledge'
slug: Don't-just-listen,-use-your-imagination:-Leveraging-Lin-Parikh
title: 'Don''t just listen, use your imagination: Leveraging visual common sense for
  non-visual tasks'
url: https://www.semanticscholar.org/paper/Don't-just-listen,-use-your-imagination:-Leveraging-Lin-Parikh/e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd?sort=total-citations
venue: 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2015
