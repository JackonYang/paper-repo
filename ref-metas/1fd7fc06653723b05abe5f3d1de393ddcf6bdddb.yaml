authors:
- Tomas Mikolov
- Ilya Sutskever
- Anoop Deoras
- H. Le
- Stefan Kombrink
- "J. Cernock\xFD"
badges:
- id: OPEN_ACCESS
corpusId: 46542477
fieldsOfStudy:
- Computer Science
numCitedBy: 180
numCiting: 23
paperAbstract: We explore the performance of several types of language mode ls on
  the word-level and the character-level language modelin g tasks. This includes two
  recently proposed recurrent neural netwo rk architectures, a feedforward neural
  network model, a maximum ent ropy model and the usual smoothed n-gram models. We
  then propose a simple technique for learning sub-word level units from th e data,
  and show that it combines advantages of both character and wo rdlevel models. Finally,
  we show that neural network based lan gu ge models can be order of magnitude smaller
  than compressed n-g ram models, at the same level of performance when applied to
  a Bro dcast news RT04 speech recognition task. By using sub-word un its, the size
  can be reduced even more.
ref_count: 23
references:
- pid: 9819b600a828a57e1cde047bbe710d3446b30da5
  title: Recurrent neural network based language model
- pid: a9fc84f8abe740cdc7ee82e69444d1d00dbe0ceb
  title: A Scalable Hierarchical Distributed Language Model
- pid: cb45e9217fe323fbc199d820e7735488fca2a9b3
  title: Strategies for training large scale neural network language models
- pid: 07ca885cb5cc4328895bfaec9ab752d5801b14cd
  title: Extensions of recurrent neural network language model
- pid: e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de
  title: Generating Text with Recurrent Neural Networks
- pid: 77dfe038a9bdab27c4505444931eaa976e9ec667
  title: Empirical Evaluation and Combination of Advanced Language Modeling Techniques
- pid: 6c2b28f9354f667cd5bd07afc0471d8334430da7
  title: A Neural Probabilistic Language Model
- pid: 399da68d3b97218b6c80262df7963baa89dcc71b
  title: SRILM - an extensible language modeling toolkit
- pid: 0d6203718c15f137fda2f295c96269bc2b254644
  title: Learning Recurrent Neural Networks with Hessian-Free Optimization
- pid: 668087f0ae7ce1de6e0bd0965dbb480c08103260
  title: Finding Structure in Time
- pid: 111fd833a4ae576cfdbb27d87d2f8fc0640af355
  title: Learning internal representations by error propagation
slug: SUBWORD-LANGUAGE-MODELING-WITH-NEURAL-NETWORKS-Mikolov-Sutskever
title: SUBWORD LANGUAGE MODELING WITH NEURAL NETWORKS
url: https://www.semanticscholar.org/paper/SUBWORD-LANGUAGE-MODELING-WITH-NEURAL-NETWORKS-Mikolov-Sutskever/1fd7fc06653723b05abe5f3d1de393ddcf6bdddb?sort=total-citations
venue: ''
year: 2011
