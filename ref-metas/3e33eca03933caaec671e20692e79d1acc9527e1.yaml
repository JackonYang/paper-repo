authors:
- A. Sperduti
- A. Starita
badges: []
corpusId: 5942593
fieldsOfStudy:
- Computer Science
numCitedBy: 486
numCiting: 46
paperAbstract: Standard neural networks and statistical methods are usually believed
  to be inadequate when dealing with complex structures because of their feature-based
  approach. In fact, feature-based approaches usually fail to give satisfactory solutions
  because of the sensitivity of the approach to the a priori selection of the features,
  and the incapacity to represent any specific information on the relationships among
  the components of the structures. However, we show that neural networks can, in
  fact, represent and classify structured patterns. The key idea underpinning our
  approach is the use of the so called "generalized recursive neuron", which is essentially
  a generalization to structures of a recurrent neuron. By using generalized recursive
  neurons, all the supervised networks developed for the classification of sequences,
  such as backpropagation through time networks, real-time recurrent networks, simple
  recurrent networks, recurrent cascade correlation networks, and neural trees can,
  on the whole, be generalized to structures. The results obtained by some of the
  above networks (with generalized recursive neurons) on the classification of logic
  terms are presented.
ref_count: 47
references:
- pid: 995a3b11cc8a4751d8e167abc4aa937abc934df0
  title: The Cascade-Correlation Learning Architecture
- pid: ce9a21b93ba29d4145a8ef6bf401e77f261848de
  title: A Learning Algorithm for Continually Running Fully Recurrent Neural Networks
- pid: 24b9eebe49cf7e00cf50cf7b7d9243386a23fe7c
  title: Neurons with graded response have collective computational properties like
    those of two-state neurons.
- pid: 6a835df43fdc2f79126319f6fa033bb42147c6f6
  title: Recursive Distributed Representations
- pid: 5146d7902132bcb0b2e6fe5f607358768fc47323
  title: Dynamics and architecture for neural computation
- pid: 668087f0ae7ce1de6e0bd0965dbb480c08103260
  title: Finding Structure in Time
- pid: 9e8cf03655d224b0994d0f9d4f5aa80bca07021a
  title: The Recurrent Cascade-Correlation Architecture
- pid: 249ce7a85b158c16ba108451070c07aa1156e7eb
  title: 'Parallel Distributed Processing: Explorations in the microstructures of
    cogni-'
- pid: 78f6f0ac3d501cb0073a7d94edde5267044a59ae
  title: 'Parallel Distributed Processing: Explorations in the Microstructure of Cognition,
    vol 1: Foundations, vol 2: Psychological and Biological Models'
- pid: 00e6b6ea28c0217d7c7e90824c17b37528f69104
  title: Absolute stability of global pattern formation and parallel memory storage
    by competitive neural networks
- pid: ff2c2e3e83d1e8828695484728393c76ee07a101
  title: 'Parallel distributed processing: explorations in the microstructure of cognition,
    vol. 1: foundations'
- pid: 8017699564136f93af21575810d557dba1ee6fc6
  title: Classification and Regression Trees
- pid: 8be3f21ab796bd9811382b560507c1c679fae37f
  title: A learning rule for asynchronous perceptrons with feedback in a combinatorial
    environment
- pid: 86dbe878a56e5052a66c036996416a782b4da618
  title: Syntactic pattern recognition and applications
slug: Supervised-neural-networks-for-the-classification-Sperduti-Starita
title: Supervised neural networks for the classification of structures
url: https://www.semanticscholar.org/paper/Supervised-neural-networks-for-the-classification-Sperduti-Starita/3e33eca03933caaec671e20692e79d1acc9527e1?sort=total-citations
venue: IEEE Trans. Neural Networks
year: 1997
