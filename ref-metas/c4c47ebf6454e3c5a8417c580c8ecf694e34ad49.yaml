authors:
- D. Mackay
badges:
- id: OPEN_ACCESS
corpusId: 12018209
fieldsOfStudy:
- Computer Science
numCitedBy: 287
numCiting: 44
paperAbstract: I examine two approximate methods for computational implementation
  of Bayesian hierarchical models, that is, models that include unknown hyperparameters
  such as regularization constants and noise levels. In the evidence framework, the
  model parameters are integrated over, and the resulting evidence is maximized over
  the hyperparameters. The optimized hyperparameters are used to define a gaussian
  approximation to the posterior distribution. In the alternative MAP method, the
  true posterior probability is found by integrating over the hyperparameters. The
  true posterior is then maximized over the model parameters, and a gaussian approximation
  is made. The similarities of the two approaches and their relative merits are discussed,
  and comparisons are made with the ideal hierarchical Bayesian solution. In moderately
  ill-posed problems, integration over hyperparameters yields a probability distribution
  with a skew peak, which causes signifi-cant biases to arise in the MAP method. In
  contrast, the evidence framework is shown to introduce negligible predictive error
  under straightforward conditions. General lessons are drawn concerning inference
  in many dimensions.
ref_count: 44
references:
- pid: 8e68c54f39e87daf3a8bdc0ee005aece3c652d11
  title: Bayesian Interpolation
- pid: 3d565fb42892f20c52b9fc615cc537835f30d094
  title: On the Use of Evidence in Neural Networks
- pid: b959164d1efca4b73986ba5d21e664aadbbc0457
  title: A Practical Bayesian Framework for Backpropagation Networks
- pid: c3fb617767f9e500e84ed03fb48acdcf088f33dc
  title: 'Ace of Bayes : Application of Neural'
- pid: 9f87a11a523e4680e61966e36ea2eac516096f23
  title: A View of the Em Algorithm that Justifies Incremental, Sparse, and other
    Variants
- pid: db869fa192a3222ae4f2d766674a378e47013b1b
  title: Bayesian Learning for Neural Networks
- pid: 7abda1941534d3bb558dd959025d67f1df526303
  title: The Evidence Framework Applied to Classification Networks
- pid: 82fa37d5be8e747131a5857992cc33bb95469ce3
  title: Developments in Maximum Entropy Data Analysis
- pid: 6272baf82e2e442edab4fb613ef2b7186bf5f1fb
  title: Bayesian Inductive Inference and Maximum Entropy
- pid: 25c9f33aceac6dcff357727cbe2faf145b01d13c
  title: Keeping the neural networks simple by minimizing the description length of
    the weights
- pid: d275cf94e620bf5b3776bba8a88acccdcfcd9a19
  title: Bayesian Learning via Stochastic Dynamics
- pid: c83684f6207697c12850db423fd9747572cf1784
  title: Bayesian Back-Propagation
- pid: b477dd12dd49e44a62c1a303501df5fb6706c7e9
  title: Smoothing noisy data with spline functions
- pid: a205103d4f25ae39f417bac7bd5142302d7f448c
  title: Bayesian inference in statistical analysis
- pid: 052b1d8ce63b07fec3de9dbb583772d860b7c769
  title: Learning representations by back-propagating errors
- pid: f707a81a278d1598cd0a4493ba73f22dcdf90639
  title: Generalization by Weight-Elimination with Application to Forecasting
- pid: dbc0a468ab103ae29717703d4aa9f682f6a2b664
  title: Neural Networks for Pattern Recognition
- pid: 88ce531f22108f687cbb576bcb0cd660b2a694bc
  title: A Comparison of GCV and GML for Choosing the Smoothing Parameter in the Generalized
    Spline Smoothing Problem
- pid: 8592e46a5435d18bba70557846f47290b34c1aa5
  title: Learning and relearning in Boltzmann machines
- pid: d36efb9ad91e00faa334b549ce989bfae7e2907a
  title: Maximum likelihood from incomplete data via the EM - algorithm plus discussions
    on the paper
- pid: 877a887e7af7daebcb685e4d7b5e80f764035581
  title: Pattern Recognition and Neural Networks
- pid: 418cc44768ff9d0ed8cf4cef79869f90ab672f7b
  title: A new view of the EM algorithm that justifies incremental and other variants
slug: Comparison-of-Approximate-Methods-for-Handling-Mackay
title: Comparison of Approximate Methods for Handling Hyperparameters
url: https://www.semanticscholar.org/paper/Comparison-of-Approximate-Methods-for-Handling-Mackay/c4c47ebf6454e3c5a8417c580c8ecf694e34ad49?sort=total-citations
venue: Neural Computation
year: 1999
