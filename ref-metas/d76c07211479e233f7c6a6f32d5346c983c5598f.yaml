authors:
- Minh-Thang Luong
- Quoc V. Le
- Ilya Sutskever
- Oriol Vinyals
- Lukasz Kaiser
badges:
- id: OPEN_ACCESS
corpusId: 6954272
fieldsOfStudy:
- Computer Science
numCitedBy: 683
numCiting: 50
paperAbstract: 'Sequence to sequence learning has recently emerged as a new paradigm
  in supervised learning. To date, most of its applications focused on only one task
  and not much work explored this framework for multiple tasks. This paper examines
  three multi-task learning (MTL) settings for sequence to sequence models: (a) the
  oneto-many setting - where the encoder is shared between several tasks such as machine
  translation and syntactic parsing, (b) the many-to-one setting - useful when only
  the decoder can be shared, as in the case of translation and image caption generation,
  and (c) the many-to-many setting - where multiple encoders and decoders are shared,
  which is the case with unsupervised objectives and translation. Our results show
  that training on a small amount of parsing and image caption data can improve the
  translation quality between English and German by up to 1.5 BLEU points over strong
  single-task baselines on the WMT benchmarks. Furthermore, we have established a
  new state-of-the-art result in constituent parsing with 93.0 F1. Lastly, we reveal
  interesting properties of the two unsupervised learning objectives, autoencoder
  and skip-thought, in the MTL context: autoencoder helps less in terms of perplexities
  but more on BLEU scores compared to skip-thought.'
ref_count: 50
references:
- pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
- pid: 4aa9f5150b46320f534de4747a2dd0cd7f3fe292
  title: Semi-supervised Sequence Learning
- pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
- pid: 93499a7c7f699b6630a86fad964536f9423bb6d0
  title: Effective Approaches to Attention-based Neural Machine Translation
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: c3b8367a80181e28c95630b9b63060d895de08ff
  title: Representation Learning Using Multi-Task Deep Neural Networks for Semantic
    Classification and Information Retrieval
- pid: dbb3342599c9b431a3152a0d5c813d3e56967a27
  title: Multi-Task Feature Learning
- pid: 6e795c6e9916174ae12349f5dc3f516570c17ce8
  title: Skip-Thought Vectors
- pid: 1938624bb9b0f999536dcc8d8f519810bb4e1b3b
  title: On Using Very Large Target Vocabulary for Neural Machine Translation
- pid: 47aaeb6dc682162dfe5659c2cad64e5d825ad910
  title: Multitask Learning
- pid: 1956c239b3552e030db1b78951f64781101125ed
  title: Addressing the Rare Word Problem in Neural Machine Translation
- pid: 944e1a7b2c5c62e952418d7684e3cade89c76f87
  title: A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled
    Data
- pid: 2f2d8f8072e5cc9b296fad551f65f183bdbff7aa
  title: Exploring the Limits of Language Modeling
- pid: 944a1cfd79dbfb6fef460360a0765ba790f4027a
  title: Recurrent Continuous Translation Models
- pid: e219a61354d972a28954e655a7c53373508a08b6
  title: Regularized multi--task learning
- pid: b8de958fead0d8a9619b55c7299df3257c624a96
  title: 'DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition'
- pid: 0b544dfe355a5070b60986319a3f51fb45d1348e
  title: "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical\
    \ Machine Translation"
- pid: 47570e7f63e296f224a0e7f9a0d08b0de3cbaf40
  title: Grammar as a Foreign Language
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 371c9dc680e916f79d9c78fcf6c894a2dd299095
  title: Is Learning The n-th Thing Any Easier Than Learning The First?
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: c0b624c46b51920dfec5aa02cc86323c0beb0df5
  title: Dropout Improves Recurrent Neural Networks for Handwriting Recognition
- pid: 0b44fcbeea9415d400c5f5789d6b892b6f98daff
  title: 'Building a Large Annotated Corpus of English: The Penn Treebank'
- pid: d7da009f457917aa381619facfa5ffae9329a6e9
  title: 'Bleu: a Method for Automatic Evaluation of Machine Translation'
- pid: 94e3e7bc3d23276f0ee2d1cb8f9d14aa19668d5f
  title: Under Review as a Conference Paper at Iclr 2017 Delving into Transferable
    Adversarial Ex- Amples and Black-box Attacks
- pid: bcd857d75841aa3e92cd4284a8818aba9f6c0c3f
  title: Published as a conference paper at ICLR 2018 S IMULATING A CTION D YNAMICS
    WITH N EURAL P ROCESS N ETWORKS
slug: Multi-task-Sequence-to-Sequence-Learning-Luong-Le
title: Multi-task Sequence to Sequence Learning
url: https://www.semanticscholar.org/paper/Multi-task-Sequence-to-Sequence-Learning-Luong-Le/d76c07211479e233f7c6a6f32d5346c983c5598f?sort=total-citations
venue: ICLR
year: 2016
