authors:
- Jiangying Zhou
- D. Lopresti
- Zhibin Lei
badges: []
corpusId: 29236195
fieldsOfStudy:
- Computer Science
numCitedBy: 31
numCiting: 10
paperAbstract: A significant amount of text now present in World Wide Web documents
  is embedded in image data, and a large portion of it does not appear elsewhere at
  all. To make this information available, we need to develop techniques for recovering
  textual information from in-line Web images. In this paper, we describe two methods
  for Web image OCR. Recognizing text extracted from in-line Web images is difficult
  because characters in these images are often rendered at a low spatial resolution.
  Such images are typically considered to be 'low quality' by traditional OCR technologies.
  Our proposed methods utilize the information contained in the color bits to compensate
  for the loss of information due to low sampling resolution. The first method uses
  a polynomial surface fitting technique for object recognition. The second method
  is based on the traditional n-tuple technique. We collected a small set of character
  samples from Web documents and tested the two algorithms. Preliminary experimental
  results show that our n-tuple method works quite well. However, the surface fitting
  method performs rather poorly due to the coarseness and small number of color shades
  used in the text.
ref_count: 10
references:
- pid: 3ef36b0186bb73619d08d02661616ce7df218ecd
  title: Extracting text from WWW images
- pid: f6e7311b9e560f3a12c895b751d275bac161b31b
  title: Pattern recognition and reading by machine
slug: OCR-for-World-Wide-Web-images-Zhou-Lopresti
title: OCR for World Wide Web images
url: https://www.semanticscholar.org/paper/OCR-for-World-Wide-Web-images-Zhou-Lopresti/b5f719c98abe9e3da61cb39ca1b836aeb09a4624?sort=total-citations
venue: Electronic Imaging
year: 1997
