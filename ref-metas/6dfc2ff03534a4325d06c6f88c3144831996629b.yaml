authors:
- Rowan Zellers
- Yonatan Bisk
- Ali Farhadi
- Yejin Choi
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 53734356
fieldsOfStudy:
- Computer Science
numCitedBy: 372
numCiting: 98
paperAbstract: 'Visual understanding goes well beyond object recognition. With one
  glance at an image, we can effortlessly imagine the world beyond the pixels: for
  instance, we can infer people''s actions, goals, and mental states. While this task
  is easy for humans, it is tremendously difficult for today''s vision systems, requiring
  higher-order cognition and commonsense reasoning about the world. We formalize this
  task as Visual Commonsense Reasoning. Given a challenging question about an image,
  a machine must answer correctly and then provide a rationale justifying its answer.
  Next, we introduce a new dataset, VCR, consisting of 290k multiple choice QA problems
  derived from 110k movie scenes. The key recipe for generating non-trivial and high-quality
  problems at scale is Adversarial Matching, a new approach to transform rich annotations
  into multiple choice questions with minimal bias. Experimental results show that
  while humans find VCR easy (over 90% accuracy), state-of-the-art vision models struggle
  (~45%). To move towards cognition-level understanding, we present a new reasoning
  engine, Recognition to Cognition Networks (R2C), that models the necessary layered
  inferences for grounding, contextualization, and reasoning. R2C helps narrow the
  gap between humans and machines (~65%); still, the challenge is far from solved,
  and we provide analysis that suggests avenues for future work.'
ref_count: 98
references:
- pid: dfe448d6297ea0a3d4deba21fbf1006bc35877d7
  title: Inferring the Why in Images
- pid: def584565d05d6a8ba94de6621adab9e301d375d
  title: 'Visual7W: Grounded Question Answering in Images'
- pid: 3c1bbd2672c11a796f1e6e6aa787257498ec8bec
  title: Revisiting Visual Question Answering Baselines
- pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
- pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  title: 'Making the V in VQA Matter: Elevating the Role of Image Understanding in
    Visual Question Answering'
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: 20dbdf02497aa84510970d0f5e8b599073bca1bc
  title: 'Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge
    from External Sources'
- pid: a58a582b95a07932cb248f1b739e4ad739ead6b9
  title: 'Visual Madlibs: Fill in the blank Image Generation and Question Answering'
- pid: 14c2321851fb5ae580a19726dd2753a525d6ad76
  title: Grounding of Textual Phrases in Images by Reconstruction
- pid: c94217efec8773ef947df2772f92df8c5726f855
  title: Leveraging Visual Question Answering for Image-Caption Ranking
- pid: e65142010431ffc089b272a1174214e00693e503
  title: Generation and Comprehension of Unambiguous Object Descriptions
- pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
- pid: fe466e84fa2e838adc3c37ee327cd68004ae08fe
  title: 'MUTAN: Multimodal Tucker Fusion for Visual Question Answering'
- pid: c611b9c82e234b344a232bcbbe5436e06da69f0b
  title: Explainable Neural Computation via Stack Neural Module Networks
- pid: 0302bb2d5476540cfb21467473f5eca843caf90b
  title: Unbiased look at dataset bias
- pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
- pid: 0612745dbd292fc0a548a16d39cd73e127faedde
  title: 'Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer
    Image-to-Sentence Models'
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: ce264a4e1490e959d84ddd60edbb0edcbfb3af38
  title: Modeling Relationships in Referential Expressions with Compositional Modular
    Networks
- pid: f04df4e20a18358ea2f689b4c129781628ef7fc1
  title: A large annotated corpus for learning natural language inference
- pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  title: 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks'
- pid: 29efbe391950ae438c63d86ad5c82b2942efb0b4
  title: Modeling Context in Referring Expressions
- pid: 0e6824e137847be0599bb0032e37042ed2ef5045
  title: 'Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching
    Movies and Reading Books'
- pid: 1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7
  title: 'MovieQA: Understanding Stories in Movies through Question-Answering'
- pid: 1b47265245e8db53a553049dcb27ed3e495fd625
  title: 'ImageNet: A large-scale hierarchical image database'
- pid: 93b4cc549a1bc4bc112189da36c318193d05d806
  title: 'AllenNLP: A Deep Semantic Natural Language Processing Platform'
- pid: 5ded2b8c64491b4a67f6d39ce473d4b9347a672e
  title: A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  title: Deep Contextualized Word Representations
- pid: 0c1f9ca23f4f09ecfc44bcc8ca1c2736624f4652
  title: A Theoretically Grounded Application of Dropout in Recurrent Neural Networks
- pid: 99c970348b8f70ce23d6641e201904ea49266b6e
  title: Exact solutions to the nonlinear dynamics of learning in deep linear neural
    networks
- pid: 3ca194773fe583661b988fbdf33f7680764438b3
  title: Exploring Nearest Neighbor Approaches for Image Captioning
- pid: 0b544dfe355a5070b60986319a3f51fb45d1348e
  title: "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical\
    \ Machine Translation"
- pid: 022dd244f2e25525eb37e9dda51abb9cd8ca8c30
  title: Mask R-CNN
slug: From-Recognition-to-Cognition:-Visual-Commonsense-Zellers-Bisk
title: 'From Recognition to Cognition: Visual Commonsense Reasoning'
url: https://www.semanticscholar.org/paper/From-Recognition-to-Cognition:-Visual-Commonsense-Zellers-Bisk/6dfc2ff03534a4325d06c6f88c3144831996629b?sort=total-citations
venue: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2019
