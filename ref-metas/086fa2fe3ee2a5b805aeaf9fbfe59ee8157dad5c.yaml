authors:
- Peter Anderson
- Basura Fernando
- Mark Johnson
- Stephen Gould
badges:
- id: OPEN_ACCESS
corpusId: 9662636
fieldsOfStudy:
- Computer Science
numCitedBy: 136
numCiting: 54
paperAbstract: Existing image captioning models do not generalize well to out-of-domain
  images containing novel scenes or objects. This limitation severely hinders the
  use of these models in real world applications dealing with images in the wild.
  We address this problem using a flexible approach that enables existing deep captioning
  architectures to take advantage of image taggers at test time, without re-training.
  Our method uses constrained beam search to force the inclusion of selected tag words
  in the output, and fixed, pretrained word embeddings to facilitate vocabulary expansion
  to previously unseen tag words. Using this approach we achieve state of the art
  results for out-of-domain captioning on MSCOCO (and improved results for in-domain
  captioning). Perhaps surprisingly, our results significantly outperform approaches
  that incorporate the same tag predictions into the learning algorithm. We also show
  that we can significantly improve the quality of generated ImageNet captions by
  leveraging ground-truth labels.
ref_count: 54
references:
- pid: b9aa3bafa9e8e21bb92908ae23b468fa248239b3
  title: Captioning Images with Diverse Objects
- pid: 18f1143c64e6557c933b206fb8b2a7bd1f389afd
  title: Rich Image Captioning in the Wild
- pid: e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17
  title: 'Deep Compositional Captioning: Describing Novel Object Categories without
    Paired Training Data'
- pid: 4aa4069693bee00d1b0759ca3df35e59284e9845
  title: 'DeViSE: A Deep Visual-Semantic Embedding Model'
- pid: f142c849ffef66f7520aff4e0b40ac964ccb8cc1
  title: 'Language Models for Image Captioning: The Quirks and What Works'
- pid: 00fe3d95d0fd5f1433d81405bee772c4fe9af9c6
  title: What Value Do Explicit High Level Concepts Have in Vision to Language Problems?
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: eb847564774394c484e701437dbcffbf040ff3cc
  title: 'Learning Like a Child: Fast Novel Visual Concept Learning from Sentence
    Descriptions of Images'
- pid: 1c54acd7d9ed8017acdc5674c9b7faac738fd651
  title: 'SPICE: Semantic Propositional Image Caption Evaluation'
- pid: 755e9f43ce398ae8737366720c5f82685b0c253e
  title: Zero-Shot Learning Through Cross-Modal Transfer
- pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: 54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745
  title: Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)
- pid: 46b8cbcdff87b842c2c1d4a003c831f845096ba7
  title: Order-Embeddings of Images and Language
- pid: 258986132bf17755fe8263e42429fe73218c1534
  title: 'CIDEr: Consensus-based image description evaluation'
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: 2a0d0f6c5a69b264710df0230696f47c5918e2f2
  title: Collective Generation of Natural Image Descriptions
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: 3ca194773fe583661b988fbdf33f7680764438b3
  title: Exploring Nearest Neighbor Approaches for Image Captioning
- pid: eaaed23a2d94feb2f1c3ff22a25777c7a78f3141
  title: 'Every Picture Tells a Story: Generating Sentences from Images'
- pid: 5cb6700d94c6118ee13f4f4fecac99f111189812
  title: 'BabyTalk: Understanding and Generating Simple Image Descriptions'
- pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  title: 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks'
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
- pid: e74f9b7f8eec6ba4704c206b93bc8079af3da4bd
  title: ImageNet Large Scale Visual Recognition Challenge
- pid: 6bdb186ec4726e00a8051119636d4df3b94043b5
  title: 'Caffe: Convolutional Architecture for Fast Feature Embedding'
- pid: 696ca58d93f6404fea0fc75c62d1d7b378f47628
  title: 'Microsoft COCO Captions: Data Collection and Evaluation Server'
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 44040913380206991b1991daf1192942e038fe31
  title: 'From image descriptions to visual denotations: New similarity metrics for
    semantic inference over event descriptions'
- pid: 26adb749fc5d80502a6d889966e50b31391560d3
  title: 'Meteor Universal: Language Specific Translation Evaluation for Any Target
    Language'
- pid: b3e89f05876d47b9bd6ece225aaeee457a6824e8
  title: Statistical Machine Translation
- pid: d87ceda3042f781c341ac17109d1e94a717f5f60
  title: 'WordNet : an electronic lexical database'
slug: Guided-Open-Vocabulary-Image-Captioning-with-Beam-Anderson-Fernando
title: Guided Open Vocabulary Image Captioning with Constrained Beam Search
url: https://www.semanticscholar.org/paper/Guided-Open-Vocabulary-Image-Captioning-with-Beam-Anderson-Fernando/086fa2fe3ee2a5b805aeaf9fbfe59ee8157dad5c?sort=total-citations
venue: EMNLP
year: 2017
