authors:
- A. Ratnaparkhi
- M. Marcus
badges:
- id: OPEN_ACCESS
corpusId: 2600845
fieldsOfStudy:
- Computer Science
numCitedBy: 554
numCiting: 89
paperAbstract: "This thesis demonstrates that several important kinds of natural language\
  \ ambiguities can be resolved to state-of-the-art accuracies using a single statistical\
  \ modeling technique based on the principle of maximum entropy. \nWe discuss the\
  \ problems of sentence boundary detection, part-of-speech tagging, prepositional\
  \ phrase attachment, natural language parsing, and text categorization under the\
  \ maximum entropy framework. In practice, we have found that maximum entropy models\
  \ offer the following advantages: \nState-of-the-art accuracy. The probability models\
  \ for all of the tasks discussed perform at or near state-of-the-art accuracies,\
  \ or outperform competing learning algorithms when trained and tested under similar\
  \ conditions. Methods which outperform those presented here require much more supervision\
  \ in the form of additional human involvement or additional supporting resources.\
  \ \nKnowledge-poor features. The facts used to model the data, or features, are\
  \ linguistically very simple, or \"knowledge-poor\", but yet succeed in approximating\
  \ complex linguistic relationships. \nReusable software technology. The mathematics\
  \ of the maximum entropy framework are essentially independent of any particular\
  \ task, and a single software implementation can be used for all of the probability\
  \ models in this thesis. \nThe experiments in this thesis suggest that experimenters\
  \ can obtain state-of-the-art accuracies on a wide range of natural language tasks,\
  \ with little task-specific effort, by using maximum entropy probability models."
ref_count: 89
references:
- pid: 6a94da952fb8ffc77881028081e90efb494f1c5d
  title: Coping with Ambiguity and Unknown Words through Probabilistic Models
- pid: d0ccae6c9f33e41de9c00053aac0bc6c615c7b4a
  title: 'Towards History-based Grammars: Using Richer Models for Probabilistic Parsing'
- pid: 4614650c3bb3e835c80612d3bca9586f81db95a3
  title: Tagging English Text with a Probabilistic Model
- pid: f0a14be7e7f5614b91d0f648ae5f2baafc6d7036
  title: Statistical Decision-Tree Models for Parsing
- pid: bf35ed0864ff6cf524a24f0a65aa6951f9d6f214
  title: A method for disambiguating word senses in a large corpus
- pid: 8ad8e98574a275930bf04a477ce3532fd13c503c
  title: Generalized Probabilistic LR Parsing of Natural Language (Corpora) with Unification-Based
    Grammars
- pid: 4f11e1b9d2656d8738329458ef3d325e6c6194a5
  title: A corpus-based approach to language learning
- pid: 9257779eed46107bcdce9f4dc86298572ff466ce
  title: Automated learning of decision rules for text categorization
- pid: 1504a9d5829033a8cb4cf37b8bb13dfd4baddc7b
  title: Enriching the Knowledge Sources Used in a Maximum Entropy Part-of-Speech
    Tagger
- pid: 49b2862ab73be40bf69ac3f457039f18d12df0ae
  title: Adaptive Language Modeling Using the Maximum Entropy Principle
- pid: 733234e097dceb9011baa8914930861996eb0b5e
  title: Some Advances in Transformation-Based Part of Speech Tagging
- pid: bc9e5bf851dc95369e26f1869c2637b1d8919e6c
  title: Prepositional Phrase Attachment through a Backed-off Model
- pid: adfef97814b292a09520d8c78a141e7a4baf8726
  title: 'Three New Probabilistic Models for Dependency Parsing: An Exploration'
- pid: fb486e03369a64de2d5b0df86ec0a7b55d3907db
  title: A Maximum Entropy Approach to Natural Language Processing
- pid: 3764baa7465201f054083d02b58fa75f883c4461
  title: A New Statistical Parser Based on Bigram Lexical Dependencies
- pid: 69859be3ea6cb8eb38434c80fef5d4997eaec2dc
  title: Representation and Learning in Information Retrieval
- pid: d9c71db75046473f0e3d3229950d7c84c09afd5e
  title: Text Chunking using Transformation-Based Learning
- pid: 7689778171dc100bb636fc0e4e2ce4063967d3c9
  title: A Procedure for Quantitatively Comparing the Syntactic Coverage of English
    Grammars
- pid: 00f20179b9087fbf24b6656008a9380c590d9ec9
  title: A Maximum Entropy Model for Prepositional Phrase Attachment
- pid: 3de5d40b60742e3dfa86b19e7f660962298492af
  title: Class-Based n-gram Models of Natural Language
- pid: a7e084fe51a40eeaaf79bf0b78e837d5bc4a8e10
  title: A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text
- pid: e9fd1a7ae0322d417ab2d32017e373dd50efc063
  title: A comparison of two learning algorithms for text categorization
- pid: 2a5e619f2c5f4220438b1357e596db5b1578398d
  title: Statistical Parsing with a Context-Free Grammar and Word Statistics
- pid: 2588593c42126e059fb8aad7673fa1736755f1e1
  title: Probabilistic Feature Grammars
- pid: b951b9f78b98a186ba259027996a48e4189d37e5
  title: Inducing Features of Random Fields
- pid: b0130277677e5b915d5cd86b3afafd77fd08eb2e
  title: Estimation of probabilities from sparse data for the language model component
    of a speech recognizer
- pid: 56d7826f3afaa374077f87ca3529709b1ca7e044
  title: Parsing By Chunks
- pid: 0b44fcbeea9415d400c5f5789d6b892b6f98daff
  title: 'Building a Large Annotated Corpus of English: The Penn Treebank'
- pid: 807c1f19047f96083e13614f7ce20f2ac98c239a
  title: 'C4.5: Programs for Machine Learning'
- pid: 0ffa423a5283396c88ff3d4033d541796bd039cc
  title: Three Generative, Lexicalised Models for Statistical Parsing
- pid: 5bfa91e7ec19c6401a763c73f2a2007c04836609
  title: Decision Tree Parsing using a Hidden Derivation Model
- pid: bdaf232c561f1f50e88b1d24097e214890b37e8b
  title: Structural Ambiguity and Lexical Relations
- pid: bd459cc59b09e612eeec5327d0690d1508ffe362
  title: A theory of syntactic recognition for natural language
- pid: 72b2aeeb76dbff312321ccbcc58e85009e0b57ae
  title: $I$-Divergence Geometry of Probability Distributions and Minimization Problems
- pid: ea8f1c73422b087738827a665b2aaf9b93d5c543
  title: A Rule-Based Approach to Prepositional Phrase Attachment Disambiguation
- pid: 7dbdb4209626fd92d2436a058663206216036e68
  title: Elements of Information Theory
- pid: d36910319d11359b995ff5413696aa9e9995e163
  title: \self-organized Language Modeling for Speech Recognition". In
- pid: b7f33d55d94e75a554251fe7dc07f1d7b4db8e1a
  title: 'Compilers: Principles, Techniques, and Tools'
- pid: 08b67692bc037eada8d3d7ce76cc70994e7c8116
  title: Information Theory and Statistical Mechanics
- pid: 602084417015618f112c796828786a6af72bf7d9
  title: Maximum Entropy for Hypothesis Formulation, Especially for Multidimensional
    Contingency Tables
- pid: 37c931cbaa9217b829596dd196520a838562a109
  title: Generalized Iterative Scaling for Log-Linear Models
- pid: 2a64dbd2fa289013b56d04621c5be72f14a44cf7
  title: A geometric interpretation of Darroch and Ratcliff's generalized iterative
    scaling
- pid: 729316fbded86763104f3412cadf98f00a9a3993
  title: 'FREQUENCY ANALYSIS OF ENGLISH USAGE: LEXICON AND GRAMMAR'
- pid: 9c2dff1c9b04da49f50fd85ba010d2a041fc5c39
  title: 'The tagged LOB Corpus : user''s manual'
- pid: f374db77b414bfdd142616434162a0aa88d5a551
  title: A maximum entropy model for parsing
slug: Maximum-entropy-models-for-natural-language-Ratnaparkhi-Marcus
title: Maximum entropy models for natural language ambiguity resolution
url: https://www.semanticscholar.org/paper/Maximum-entropy-models-for-natural-language-Ratnaparkhi-Marcus/b49db3ac26d96b6c5c081dc6c2cc24da93e633f1?sort=total-citations
venue: ''
year: 1998
