authors:
- J. Shawe-Taylor
- P. Bartlett
- R. C. Williamson
- M. Anthony
badges:
- id: OPEN_ACCESS
corpusId: 6789514
fieldsOfStudy:
- Computer Science
numCitedBy: 619
numCiting: 98
paperAbstract: The paper introduces some generalizations of Vapnik's (1982) method
  of structural risk minimization (SRM). As well as making explicit some of the details
  on SRM, it provides a result that allows one to trade off errors on the training
  sample against improved generalization performance. It then considers the more general
  case when the hierarchy of classes is chosen in response to the data. A result is
  presented on the generalization performance of classifiers with a "large margin".
  This theoretically explains the impressive generalization performance of the maximal
  margin hyperplane algorithm of Vapnik and co-workers (which is the basis for their
  support vector machines). The paper concludes with a more general result in terms
  of "luckiness" functions, which provides a quite general way for exploiting serendipitous
  simplicity in observed data to obtain better prediction accuracy from small training
  sets. Four examples are given of such functions, including the Vapnik-Chervonenkis
  (1971) dimension measured on the sample.
ref_count: 98
references:
- pid: 2599131a4bc2fa957338732a37c744cfe3e17b24
  title: A training algorithm for optimal margin classifiers
- pid: 67f9e3de2fb39f051ef23b8fbed6d72de7b02900
  title: A framework for structural risk minimisation
- pid: a1dace286582d91916fe470d08f30381cf453f20
  title: 'Learning Quickly When Irrelevant Attributes Abound: A New Linear-Threshold
    Algorithm'
- pid: 015999a72c70a960e59c51078b09c8f672af0d2c
  title: 'The Sample Complexity of Pattern Classification with Neural Networks: The
    Size of the Weights is More Important than the Size of the Network'
- pid: 907f58a77ef4909d0e96c352cd5c7379eb22d5f5
  title: Results on learnability and the Vapnik-Chervonenkis dimension
- pid: fedfc9fbcfe46d50b81078560bce724678f90176
  title: Decision Theoretic Generalizations of the PAC Model for Neural Net and Other
    Learning Applications
- pid: 04641b38cdab7b5b6c7d0d09193d3220ef40efc5
  title: Structural Risk Minimization for Character Recognition
- pid: eae2430d9a984120bf511655a03c15089b007499
  title: Regularization Theory and Neural Networks Architectures
- pid: 3ce9da2d2182a2fbc4b460bdb56d3c34110b3e39
  title: Probable networks and plausible predictions - a review of practical Bayesian
    methods for supervised neural networks
- pid: aab43c9c33af00b718cf2ae374b861d49862a563
  title: Machine learning
- pid: fca98082fa9ff8e9dbae9922491ae54976a0ccef
  title: Minimum complexity density estimation
- pid: 04a5241e96d0e7ac63eb44ed8cfbcdcda9df1583
  title: IEEE TRANSACTIONS ON INFORMATION THEORY
- pid: 7dbdb4209626fd92d2436a058663206216036e68
  title: Elements of Information Theory
- pid: a36b028d024bf358c4af1a5e1dc3ca0aed23b553
  title: 'Chervonenkis: On the uniform convergence of relative frequencies of events
    to their probabilities'
- pid: b07ce649d6f6eb636872527104b0209d3edc8188
  title: Pattern classification and scene analysis
- pid: 69d7086300e7f5322c06f2f242a565b3a182efb5
  title: In Advances in Neural Information Processing Systems
- pid: 8213dbed4db44e113af3ed17d6dad57471a0c048
  title: The Nature of Statistical Learning Theory
slug: Structural-Risk-Minimization-Over-Data-Dependent-Shawe-Taylor-Bartlett
title: Structural Risk Minimization Over Data-Dependent Hierarchies
url: https://www.semanticscholar.org/paper/Structural-Risk-Minimization-Over-Data-Dependent-Shawe-Taylor-Bartlett/1f5a3dc5867218b86ab29cbf0046f2a02ee6ded5?sort=total-citations
venue: IEEE Trans. Inf. Theory
year: 1998
