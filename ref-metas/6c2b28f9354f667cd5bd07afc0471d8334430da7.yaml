authors:
- Yoshua Bengio
- "R\xE9jean Ducharme"
- Pascal Vincent
- Christian Janvin
badges:
- id: OPEN_ACCESS
corpusId: 221275765
fieldsOfStudy:
- Computer Science
numCitedBy: 6011
numCiting: 54
paperAbstract: 'A goal of statistical language modeling is to learn the joint probability
  function of sequences of words in a language. This is intrinsically difficult because
  of the curse of dimensionality: a word sequence on which the model will be tested
  is likely to be different from all the word sequences seen during training. Traditional
  but very successful approaches based on n-grams obtain generalization by concatenating
  very short overlapping sequences seen in the training set. We propose to fight the
  curse of dimensionality by learning a distributed representation for words which
  allows each training sentence to inform the model about an exponential number of
  semantically neighboring sentences. The model learns simultaneously (1) a distributed
  representation for each word along with (2) the probability function for word sequences,
  expressed in terms of these representations. Generalization is obtained because
  a sequence of words that has never been seen before gets high probability if it
  is made of words that are similar (in the sense of having a nearby representation)
  to words forming an already seen sentence. Training such large models (with millions
  of parameters) within a reasonable time is itself a significant challenge. We report
  on experiments using neural networks for the probability function, showing on two
  text corpora that the proposed approach significantly improves on state-of-the-art
  n-gram models, and that the proposed approach allows to take advantage of longer
  contexts.'
ref_count: 55
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 156
  pid: e41498c05d4c68e4750fb84a380317a112d97b01
  title: Connectionist language modeling for large vocabulary continuous speech recognition
  year: 2002
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 3316
  pid: 3de5d40b60742e3dfa86b19e7f660962298492af
  title: Class-Based n-gram Models of Natural Language
  year: 1992
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 548
  pid: 09c76da2361d46689825c4efc37ad862347ca577
  title: A bit of progress in language modeling
  year: 2001
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1907
  pid: b0130277677e5b915d5cd86b3afafd77fd08eb2e
  title: Estimation of probabilities from sparse data for the language model component
    of a speech recognizer
  year: 1987
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1193
  pid: 5eb328cf7e94995199e4c82a1f4d0696430a80b5
  title: Distributional Clustering of English Words
  year: 1993
- fieldsOfStudy:
  - Psychology
  numCitedBy: 9860
  pid: 668087f0ae7ce1de6e0bd0965dbb480c08103260
  title: Finding Structure in Time
  year: 1990
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 86
  pid: bfab4ffa229c8af0174a683ff1eda524c4f59d00
  title: Can artificial neural networks learn language models?
  year: 2000
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1792
  pid: 9548ac30c113562a51e603dbbc8e9fa651cfd3ab
  title: Improved backing-off for M-gram language modeling
  year: 1995
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 3452
  pid: fb486e03369a64de2d5b0df86ec0a7b55d3907db
  title: A Maximum Entropy Approach to Natural Language Processing
  year: 1996
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 4569
  pid: 9360e5ce9c98166bb179ad479a9d2919ff13d022
  title: Training Products of Experts by Minimizing Contrastive Divergence
  year: 2002
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 307
  pid: 5d24afe3a62331ebfad400c3fec77c836d2b99db
  title: Word Space
  year: 1992
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 13574
  pid: d87ceda3042f781c341ac17109d1e94a717f5f60
  title: 'WordNet : an electronic lexical database'
  year: 2000
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 4996
  pid: 399da68d3b97218b6c80262df7963baa89dcc71b
  title: SRILM - an extensible language modeling toolkit
  year: 2002
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 123
  pid: 190e4800c67ef445e4bd0944a55debaccebcf43f
  title: Modeling High-Dimensional Discrete Data with Multi-Layer Neural Networks
  year: 1999
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 843
  pid: e733226b881f11f25c87e8bac8d602ba3d9c220e
  title: Distributional clustering of words for text classification
  year: 1998
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 7017
  pid: 20a80a7356859daa4170fb4da6b87b84adbb547f
  title: Indexing by Latent Semantic Analysis
  year: 1990
- fieldsOfStudy: []
  numCitedBy: 0
  pid: 769dbbe88801b57a9b44f89c5516264f16cbed60
  title: An empirical study of smoothing techniques for language modeling
  year: 1999
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1037
  pid: 6a923c9f89ed53b6e835b3807c0c1bd8d532687b
  title: Interpolated estimation of Markov source parameters from sparse data
  year: 1980
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 902
  pid: 4ade4934db522fe6d634ff6f48887da46eedb4d1
  title: Learning distributed representations of concepts.
  year: 1989
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 225
  pid: b9ed0b35c9eaba0328492de65c4cdc5545094df4
  title: Improved clustering techniques for class-based statistical language modelling
  year: 1993
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 65
  pid: 2928de5400a920a6a29af41821c680cef5d35f91
  title: A latent semantic analysis framework for large-Span language modeling
  year: 1997
slug: A-Neural-Probabilistic-Language-Model-Bengio-Ducharme
title: A Neural Probabilistic Language Model
url: https://www.semanticscholar.org/paper/A-Neural-Probabilistic-Language-Model-Bengio-Ducharme/6c2b28f9354f667cd5bd07afc0471d8334430da7?sort=total-citations
venue: J. Mach. Learn. Res.
year: 2000
