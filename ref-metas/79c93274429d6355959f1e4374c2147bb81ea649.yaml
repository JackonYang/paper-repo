authors:
- Hao Hao Tan
- Mohit Bansal
badges:
- id: OPEN_ACCESS
corpusId: 201103729
fieldsOfStudy:
- Computer Science
meta_key: lxmert-learning-cross-modality-encoder-representations-from-transformers
numCitedBy: 916
numCiting: 44
paperAbstract: 'Vision-and-language reasoning requires an understanding of visual
  concepts, language semantics, and, most importantly, the alignment and relationships
  between these two modalities. We thus propose the LXMERT (Learning Cross-Modality
  Encoder Representations from Transformers) framework to learn these vision-and-language
  connections. In LXMERT, we build a large-scale Transformer model that consists of
  three encoders: an object relationship encoder, a language encoder, and a cross-modality
  encoder. Next, to endow our model with the capability of connecting vision and language
  semantics, we pre-train the model with large amounts of image-and-sentence pairs,
  via five diverse representative pre-training tasks: masked language modeling, masked
  object prediction (feature regression and label classification), cross-modality
  matching, and image question answering. These tasks help in learning both intra-modality
  and cross-modality relationships. After fine-tuning from our pre-trained parameters,
  our model achieves the state-of-the-art results on two visual question answering
  datasets (i.e., VQA and GQA). We also show the generalizability of our pre-trained
  cross-modality model by adapting it to a challenging visual-reasoning task, NLVR2,
  and improve the previous best result by 22% absolute (54% to 76%). Lastly, we demonstrate
  detailed ablation studies to prove that both our novel model components and pre-training
  strategies significantly contribute to our strong results. Code and pre-trained
  models publicly available at: https://github.com/airsplay/lxmert'
ref_count: 44
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1266
  pid: 65a9c7b0800c86a196bc14e7621ff895cc6ab287
  show_ref_link: true
  title: 'ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language
    Tasks'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 33744
  pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  show_ref_link: true
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 22
  pid: a3d3df29fc98e0d674bf02bab69726795f4c7b78
  show_ref_link: false
  title: Multimodal Unified Attention Networks for Vision-and-Language Interactions
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 569
  pid: c41a11c0e9b8b92b4faaf97749841170b760760a
  show_ref_link: true
  title: 'VideoBERT: A Joint Model for Video and Language Representation Learning'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 35148
  pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  show_ref_link: true
  title: Attention is All you Need
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 591
  pid: def584565d05d6a8ba94de6621adab9e301d375d
  show_ref_link: true
  title: 'Visual7W: Grounded Question Answering in Images'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 47
  pid: cf5a0d3b67cf03c2441f7aa20f0ea499bd02acf6
  show_ref_link: false
  title: Multi-Modality Latent Interaction Network for Visual Question Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 630
  pid: 5aec474c31a2f4b74703c6f786c0a8ff85c450da
  show_ref_link: true
  title: 'VisualBERT: A Simple and Performant Baseline for Vision and Language'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 3533
  pid: cd18800a0fe0b668a1cc19f2ec95b5003d0a5035
  show_ref_link: true
  title: Improving Language Understanding by Generative Pre-Training
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 192
  pid: e9b13731027418ed38103d1dfc8a70f6881bc684
  show_ref_link: true
  title: Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question
    Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 323
  pid: 8a1744da011375d711ed75fc2d160c6fdca2cf89
  show_ref_link: true
  title: Deep Modular Co-Attention Networks for Visual Question Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 79
  pid: 327d7e55d64cb34d55bd3a3fe58233c238a312cd
  show_ref_link: false
  title: 'exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformer
    Models'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 266
  pid: 0c0f41d3162e76500d4639557ff4463bd246e395
  show_ref_link: true
  title: 'Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for
    Visual Question Answering'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1162
  pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  show_ref_link: true
  title: 'Making the V in VQA Matter: Elevating the Role of Image Understanding in
    Visual Question Answering'
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 408
  pid: a5d10341717c0519cf63151b496a6d2ed67aa05f
  show_ref_link: true
  title: Bilinear Attention Networks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2772
  pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  show_ref_link: true
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 831
  pid: 7cfa5c97164129ce3630511f639040d28db1d4b7
  show_ref_link: true
  title: 'FiLM: Visual Reasoning with a General Conditioning Layer'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1121
  pid: fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b
  show_ref_link: true
  title: Hierarchical Question-Image Co-Attention for Visual Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2634
  pid: 93b8da28d006415866bf48f9a6e06b5242129195
  show_ref_link: true
  title: 'GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language
    Understanding'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1509
  pid: ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc
  show_ref_link: true
  title: Cross-lingual Language Model Pretraining
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 430
  pid: a396a6febdacb84340d139096455e67049ac1e22
  show_ref_link: true
  title: 'Learning to Reason: End-to-End Module Networks for Visual Question Answering'
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 19339
  pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  show_ref_link: true
  title: Neural Machine Translation by Jointly Learning to Align and Translate
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 87
  pid: c122fa378a774ba202d418cf71c5c356cf2f902f
  show_ref_link: false
  title: 'GQA: a new dataset for compositional question answering over real-world
    images'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 93
  pid: 735a63b58349e07b84c2e31927ce1b1cfaf09980
  show_ref_link: false
  title: Cycle-Consistency for Robust Visual Question Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 7252
  pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  show_ref_link: true
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 4645
  pid: dbde7dfa6cae81df8ac19ef500c42db96c3d1edd
  show_ref_link: true
  title: 'Google''s Neural Machine Translation System: Bridging the Gap between Human
    and Machine Translation'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1722
  pid: 3a7b63b50c64f4ec3358477790e84cbd6be2a0b4
  show_ref_link: true
  title: Bidirectional Attention Flow for Machine Comprehension
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2275
  pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  show_ref_link: true
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2887
  pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  show_ref_link: true
  title: 'VQA: Visual Question Answering'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 7987
  pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  show_ref_link: true
  title: Deep Contextualized Word Representations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 95314
  pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  show_ref_link: true
  title: Deep Residual Learning for Image Recognition
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 17088
  pid: 2f4df08d9072fc2ac181b7fced6a245315ce05c8
  show_ref_link: true
  title: Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation
  year: 2014
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 211
  pid: cf336d272a30d6ad6141db67faa64deb8791cd61
  show_ref_link: true
  title: A Corpus for Reasoning about Natural Language Grounded in Photographs
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 29480
  pid: e15cf50aa89fee8535703b9f9512fca5bfc43327
  show_ref_link: true
  title: Going deeper with convolutions
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 62220
  pid: eb42cf88027de515750f230b23b1a057dc782108
  show_ref_link: true
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 140
  pid: 36c3972569a6949ecca90bfa6f8e99883e092845
  show_ref_link: true
  title: 'Pythia v0.1: the Winning Entry to the VQA Challenge 2018'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 647
  pid: d14c7e5f5cace4c925abc74c88baa474e9f31a28
  show_ref_link: false
  title: Gated Feedback Recurrent Neural Networks
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 32561
  pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  show_ref_link: true
  title: 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 90052
  pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  show_ref_link: true
  title: 'Adam: A Method for Stochastic Optimization'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 4263
  pid: 05dd7254b632376973f3a1b4d39485da17814df5
  show_ref_link: true
  title: 'SQuAD: 100,000+ Questions for Machine Comprehension of Text'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 19778
  pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  show_ref_link: true
  title: 'Microsoft COCO: Common Objects in Context'
  year: 2014
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 27402
  pid: 1b47265245e8db53a553049dcb27ed3e495fd625
  show_ref_link: true
  title: 'ImageNet: A large-scale hierarchical image database'
  year: 2009
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 289
  pid: 4361e64f2d12d63476fdc88faf72a0f70d9a2ffb
  show_ref_link: true
  title: Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear
    Units
  year: 2016
slug: LXMERT:-Learning-Cross-Modality-Encoder-from-Tan-Bansal
title: 'LXMERT: Learning Cross-Modality Encoder Representations from Transformers'
url: https://www.semanticscholar.org/paper/LXMERT:-Learning-Cross-Modality-Encoder-from-Tan-Bansal/79c93274429d6355959f1e4374c2147bb81ea649?sort=total-citations
venue: EMNLP
year: 2019
