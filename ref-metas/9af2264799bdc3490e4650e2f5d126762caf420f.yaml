authors:
- Suyoun Kim
- Takaaki Hori
- Shinji Watanabe
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 206742834
fieldsOfStudy:
- Computer Science
numCitedBy: 545
numCiting: 29
paperAbstract: "Recently, there has been an increasing interest in end-to-end speech\
  \ recognition that directly transcribes speech to text without any predefined alignments.\
  \ One approach is the attention-based encoder-decoder framework that learns a mapping\
  \ between variable-length input and output sequences in one step using a purely\
  \ data-driven method. The attention model has often been shown to improve the performance\
  \ over another end-to-end approach, the Connectionist Temporal Classification (CTC),\
  \ mainly because it explicitly uses the history of the target character without\
  \ any conditional independence assumptions. However, we observed that the performance\
  \ of the attention has shown poor results in noisy condition and is hard to learn\
  \ in the initial training stage with long input sequences. This is because the attention\
  \ model is too flexible to predict proper alignments in such cases due to the lack\
  \ of left-to-right constraints as used in CTC. This paper presents a novel method\
  \ for end-to-end speech recognition to improve robustness and achieve fast convergence\
  \ by using a joint CTC-attention model within the multi-task learning framework,\
  \ thereby mitigating the alignment issue. An experiment on the WSJ and CHiME-4 tasks\
  \ demonstrates its advantages over both the CTC and attention-based encoder-decoder\
  \ baselines, showing 5.4\u201314.6% relative improvements in Character Error Rate\
  \ (CER)."
ref_count: 29
references:
- pid: 878ba5458e9e51f0b341fd9117fa0b43ef4096d3
  title: End-to-end attention-based large vocabulary speech recognition
- pid: b624504240fa52ab76167acfe3156150ca01cf3b
  title: Attention-Based Models for Speech Recognition
- pid: 24741d280869ad9c60321f5ab6e5f01b7852507d
  title: 'Deep Speech: Scaling up end-to-end speech recognition'
- pid: 1149888d75af4ed5dffc25731b875651c3ccdeb2
  title: Hybrid speech recognition with Deep Bidirectional LSTM
- pid: 47d2dc34e1d02a8109f5c04bb6939725de23716d
  title: 'End-to-end Continuous Speech Recognition using Attention-based Recurrent
    NN: First Results'
- pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
- pid: 0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f
  title: Towards End-To-End Speech Recognition with Recurrent Neural Networks
- pid: dc555e8156c956f823587ebbff018863e6d2a95e
  title: Listen, Attend and Spell
- pid: 96494e722f58705fa20302fe6179d483f52705b4
  title: 'Connectionist temporal classification: labelling unsegmented sequence data
    with recurrent neural networks'
- pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
- pid: 31868290adf1c000c611dfc966b514d5a34e8d23
  title: 'Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared
    Views of Four Research Groups'
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: d2b62f77cb2864e465aa60bca6c26bb1d2f84963
  title: Acoustic Modeling Using Deep Belief Networks
- pid: 8729441d734782c3ed532a7d2d9611b438c0a09a
  title: 'ADADELTA: An Adaptive Learning Rate Method'
- pid: 84069287da0a6b488b8c933f3cb5be759cb6237e
  title: On the difficulty of training recurrent neural networks
slug: Joint-CTC-attention-based-end-to-end-speech-using-Kim-Hori
title: Joint CTC-attention based end-to-end speech recognition using multi-task learning
url: https://www.semanticscholar.org/paper/Joint-CTC-attention-based-end-to-end-speech-using-Kim-Hori/9af2264799bdc3490e4650e2f5d126762caf420f?sort=total-citations
venue: 2017 IEEE International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)
year: 2017
