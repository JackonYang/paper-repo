authors:
- A. McCallum
- Dayne Freitag
- Fernando C Pereira
badges:
- id: OPEN_ACCESS
corpusId: 775373
fieldsOfStudy:
- Computer Science
numCitedBy: 1551
numCiting: 31
paperAbstract: "Hidden Markov models (HMMs) are a powerful probabilistic tool for\
  \ modeling sequential data, and have been applied with success to many text-related\
  \ tasks, such as part-of-speech tagging, text segmentation and information extraction.\
  \ In these cases, the observations are usually modeled as multinomial distributions\
  \ over a discrete vocabulary, and the HMM parameters are set to maximize the likelihood\
  \ of the observations. This paper presents a new Markovian sequence model, closely\
  \ related to HMMs, that allows observations to be represented as arbitrary overlapping\
  \ features (such as word, capitalization, formatting, part-of-speech), and defines\
  \ the conditional probability of state sequences given observation sequences. It\
  \ does this by using the maximum entropy framework to fit a set of exponential models\
  \ that represent the probability of a state given an observation and the previous\
  \ state. We present positive experimental results on the segmentation of FAQ\u2019\
  s."
ref_count: 30
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 492
  pid: 352dbd26580856ba4b9877d43aeba304343af66d
  title: Robust part-of-speech tagging using a hidden Markov model
  year: 1992
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 417
  pid: 0b26fa1b848ed808a0511db34bce2426888f0b68
  title: Adaptive Statistical Language Modeling; A Maximum Entropy Approach
  year: 1994
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 554
  pid: b49db3ac26d96b6c5c081dc6c2cc24da93e633f1
  title: Maximum entropy models for natural language ambiguity resolution
  year: 1998
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 388
  pid: 0043ccb045bc7d07ea6c9b719a72a6a01df1ab0a
  title: A Gaussian Prior for Smoothing Maximum Entropy Models
  year: 1999
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1305
  pid: b951b9f78b98a186ba259027996a48e4189d37e5
  title: Inducing Features of Random Fields
  year: 1997
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 279
  pid: 4df361d65a15ca9a7fc27c58c38b04d1f41e6f62
  title: Exploiting Diverse Knowledge Sources via Maximum Entropy in Named Entity
    Recognition
  year: 1998
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 222
  pid: 3ed17a1114e2dc48597ab17cc8d5234006f525c9
  title: 'Learning to Resolve Natural Language Ambiguities: A Unified Approach'
  year: 1998
- fieldsOfStudy:
  - Materials Science
  numCitedBy: 1821
  pid: 2b2eb4a9bb146e3ffaa0b025fba0ed14240c683f
  title: 'Transformation-Based Error-Driven Learning and Natural Language Processing:
    A Case Study in Part-of-Speech Tagging'
  year: 1995
- fieldsOfStudy:
  - Geology
  numCitedBy: 24804
  pid: 8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5
  title: A Tutorial on Hidden Markov Models and Selected Applications
  year: 1989
- fieldsOfStudy:
  - Engineering
  numCitedBy: 48406
  pid: d36efb9ad91e00faa334b549ce989bfae7e2907a
  title: Maximum likelihood from incomplete data via the EM - algorithm plus discussions
    on the paper
  year: 1977
- fieldsOfStudy:
  - Mathematics
  numCitedBy: 1329
  pid: 37c931cbaa9217b829596dd196520a838562a109
  title: Generalized Iterative Scaling for Log-Linear Models
  year: 1972
slug: Maximum-Entropy-Markov-Models-for-Information-and-McCallum-Freitag
title: Maximum Entropy Markov Models for Information Extraction and Segmentation
url: https://www.semanticscholar.org/paper/Maximum-Entropy-Markov-Models-for-Information-and-McCallum-Freitag/bece46ed303f8eaef2affae2cba4e0aef51fe636?sort=total-citations
venue: ICML
year: 2000
