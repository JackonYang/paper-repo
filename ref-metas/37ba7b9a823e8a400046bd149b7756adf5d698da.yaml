authors:
- Xiangrong Chen
- A. Yuille
badges:
- id: OPEN_ACCESS
corpusId: 61234963
fieldsOfStudy:
- Computer Science
numCitedBy: 512
numCiting: 25
paperAbstract: This paper gives an algorithm for detecting and reading text in natural
  images. The algorithm is intended for use by blind and visually impaired subjects
  walking through city scenes. We first obtain a dataset of city images taken by blind
  and normally sighted subjects. From this dataset, we manually label and extract
  the text regions. Next we perform statistical analysis of the text regions to determine
  which image features are reliable indicators of text and have low entropy (i.e.
  feature response is similar for all text images). We obtain weak classifiers by
  using joint probabilities for feature responses on and off text. These weak classifiers
  are used as input to an AdaBoost machine learning algorithm to train a strong classifier.
  In practice, we trained a cascade with 4 strong classifiers containing 79 features.
  An adaptive binarization and extension algorithm is applied to those regions selected
  by the cascade classifier. Commercial OCR software is used to read the text or reject
  it as a non-text region. The overall algorithm has a success rate of over 90% (evaluated
  by complete detection and reading of the text) on the test set and the unread text
  is typically small and distant from the viewer.
slug: Detecting-and-reading-text-in-natural-scenes-Chen-Yuille
title: Detecting and reading text in natural scenes
venue: CVPR 2004
year: 2004
