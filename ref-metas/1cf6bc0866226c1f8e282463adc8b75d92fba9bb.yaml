authors:
- Huijuan Xu
- Kate Saenko
badges:
- id: OPEN_ACCESS
corpusId: 10363459
fieldsOfStudy:
- Computer Science
numCitedBy: 652
numCiting: 50
paperAbstract: We address the problem of Visual Question Answering (VQA), which requires
  joint image and language understanding to answer a question about a given photograph.
  Recent approaches have applied deep image captioning methods based on convolutional-recurrent
  networks to this problem, but have failed to model spatial inference. To remedy
  this, we propose a model we call the Spatial Memory Network and apply it to the
  VQA task. Memory networks are recurrent neural networks with an explicit attention
  mechanism that selects certain parts of the information stored in memory. Our Spatial
  Memory Network stores neuron activations from different spatial regions of the image
  in its memory, and uses the question to choose relevant regions for computing the
  answer, a process of which constitutes a single "hop" in the network. We propose
  a novel spatial attention architecture that aligns words with image patches in the
  first hop, and obtain improved results by adding a second attention hop which considers
  the whole question to choose visual evidence based on the results of the first hop.
  To better understand the inference process learned by the network, we design synthetic
  questions that specifically require spatial inference and visualize the attention
  weights. We evaluate our model on two published visual question answering datasets,
  DAQUAR [1] and VQA [2], and obtain improved results compared to a strong deep baseline
  model (iBOWIMG) which concatenates image and question features to predict the answer
  [3].
ref_count: 50
references:
- pid: bd7bd1d2945a58cdcc1797ba9698b8810fe68f60
  title: 'Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images'
- pid: 20dbdf02497aa84510970d0f5e8b599073bca1bc
  title: 'Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge
    from External Sources'
- pid: f96898d15a1bf1fa8925b1280d0e07a7a8e72194
  title: Dynamic Memory Networks for Visual and Textual Question Answering
- pid: def584565d05d6a8ba94de6621adab9e301d375d
  title: 'Visual7W: Grounded Question Answering in Images'
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: 62a956d7600b10ca455076cd56e604dfd106072a
  title: Exploring Models and Data for Image Question Answering
- pid: 98bd5dd1740f585bf25320ba504e2c1ae57f2e5f
  title: Learning to Answer Questions from Image Using Convolutional Neural Network
- pid: 175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22
  title: 'Where to Look: Focus Regions for Visual Question Answering'
- pid: 385c18cc4024a3b3206c508c512e037b9c00b8f3
  title: Image Question Answering Using Convolutional Neural Network with Dynamic
    Parameter Prediction
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: 5f425b7abf2ed3172ed060df85bb1885860a297e
  title: Describing Videos by Exploiting Temporal Structure
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: f142c849ffef66f7520aff4e0b40ac964ccb8cc1
  title: 'Language Models for Image Captioning: The Quirks and What Works'
- pid: 267fb4ac632449dbe84f7acf17c8c7527cb25b0d
  title: Simple Baseline for Visual Question Answering
- pid: 93499a7c7f699b6630a86fad964536f9423bb6d0
  title: Effective Approaches to Attention-based Neural Machine Translation
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: 4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e
  title: End-To-End Memory Networks
- pid: 71ae756c75ac89e2d731c9c79649562b5768ff39
  title: Memory Networks
- pid: abb33d75dc297993fcc3fb75e0f4498f413eb4f6
  title: 'Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks'
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: 7f1b111f0bb703b0bd97aba505728a9b0d9b2a54
  title: Deep Fragment Embeddings for Bidirectional Image Sentence Mapping
- pid: eaaed23a2d94feb2f1c3ff22a25777c7a78f3141
  title: 'Every Picture Tells a Story: Generating Sentences from Images'
- pid: e15cf50aa89fee8535703b9f9512fca5bfc43327
  title: Going deeper with convolutions
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: d1505c6123c102e53eb19dff312cb25cea840b72
  title: Teaching Machines to Read and Comprehend
- pid: 2935d8071583e46c5a895730c65d2bd213757c07
  title: Joint Video and Text Parsing for Understanding Events and Answering Queries
- pid: 33261d252218007147a71e40f8367ed152fa2fe0
  title: Question Answering with Subgraph Embeddings
- pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: 3d1d42c9435b419ac928ebf7bcf4c86a460d6ef4
  title: Semantic Parsing via Paraphrasing
- pid: 1b47265245e8db53a553049dcb27ed3e495fd625
  title: 'ImageNet: A large-scale hierarchical image database'
- pid: 6bdb186ec4726e00a8051119636d4df3b94043b5
  title: 'Caffe: Convolutional Architecture for Fast Feature Embedding'
- pid: 9d896605fbf93315b68d4ee03be0770077f84e40
  title: 'Baby Talk : Understanding and Generating Image Descriptions'
- pid: c1052027ddbacc24fc4a244d2c073f86aca62747
  title: Natural Language Questions for the Web of Data
- pid: c1994ba5946456fc70948c549daf62363f13fa2d
  title: Indoor Segmentation and Support Inference from RGBD Images
- pid: 0da353e79f666a3ae7dd0a5d28c75b852a7f60bf
  title: SHOW
- pid: c3823aacea60bc1f2cabb9283144690a3d015db5
  title: Neural Turing Machines
- pid: 10d85561e4aafc516d10064f30dff05b41f70afe
  title: '[Et al].'
slug: Ask,-Attend-and-Answer:-Exploring-Question-Guided-Xu-Saenko
title: 'Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual
  Question Answering'
url: https://www.semanticscholar.org/paper/Ask,-Attend-and-Answer:-Exploring-Question-Guided-Xu-Saenko/1cf6bc0866226c1f8e282463adc8b75d92fba9bb?sort=total-citations
venue: ECCV
year: 2016
