authors:
- Junhua Mao
- W. Xu
- Yi Yang
- Jiang Wang
- A. Yuille
badges:
- id: OPEN_ACCESS
corpusId: 3509328
fieldsOfStudy:
- Computer Science
numCitedBy: 1008
numCiting: 55
paperAbstract: 'In this paper, we present a multimodal Recurrent Neural Network (m-RNN)
  model for generating novel image captions. It directly models the probability distribution
  of generating a word given previous words and an image. Image captions are generated
  by sampling from this distribution. The model consists of two sub-networks: a deep
  recurrent neural network for sentences and a deep convolutional network for images.
  These two sub-networks interact with each other in a multimodal layer to form the
  whole m-RNN model. The effectiveness of our model is validated on four benchmark
  datasets (IAPR TC-12, Flickr 8K, Flickr 30K and MS COCO). Our model outperforms
  the state-of-the-art methods. In addition, we apply the m-RNN model to retrieval
  tasks for retrieving images or sentences, and achieves significant performance improvement
  over the state-of-the-art methods which directly optimize the ranking objective
  function for retrieval. The project page of this work is: www.stat.ucla.edu/~junhua.mao/m-RNN.html
  .'
ref_count: 55
references:
- pid: 82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9
  title: Explain Images with Multimodal Recurrent Neural Networks
- pid: f142c849ffef66f7520aff4e0b40ac964ccb8cc1
  title: 'Language Models for Image Captioning: The Quirks and What Works'
- pid: f4af49a1ead3c81cc5d023878cb67c5646dd8a04
  title: Learning a Recurrent Visual Representation for Image Caption Generation
- pid: 2e36ea91a3c8fbff92be2989325531b4002e2afc
  title: Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
- pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: 0ca7d208ff8d81377e0eaa9723820aeae7a7322d
  title: Grounded Compositional Semantics for Finding and Describing Images with Sentences
- pid: fad611e35b3731740b4d8b754241e77add5a70b9
  title: Multimodal Neural Language Models
- pid: 0b544dfe355a5070b60986319a3f51fb45d1348e
  title: "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical\
    \ Machine Translation"
- pid: 7f1b111f0bb703b0bd97aba505728a9b0d9b2a54
  title: Deep Fragment Embeddings for Bidirectional Image Sentence Mapping
- pid: 9814df8bd00ba999c4d1e305a7e9bca579dc7c75
  title: 'Framing Image Description as a Ranking Task: Data, Models and Evaluation
    Metrics (Extended Abstract)'
- pid: eb847564774394c484e701437dbcffbf040ff3cc
  title: 'Learning Like a Child: Fast Novel Visual Concept Learning from Sentence
    Descriptions of Images'
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: 5726c7b40fcc454b77d989656c085520bf6c15fa
  title: Multimodal learning with deep Boltzmann machines
- pid: 4aa4069693bee00d1b0759ca3df35e59284e9845
  title: 'DeViSE: A Deep Visual-Semantic Embedding Model'
- pid: 9819b600a828a57e1cde047bbe710d3446b30da5
  title: Recurrent neural network based language model
- pid: 944a1cfd79dbfb6fef460360a0765ba790f4027a
  title: Recurrent Continuous Translation Models
- pid: 85cb25e88d3b0548a26e7a70b6953e500d27eb9a
  title: Learning cross-modality similarity for multinomial data
- pid: 6a26268d2ba9d34e5b59ae6e5c11a83cdca1a85e
  title: Matching Words and Pictures
- pid: 2f4df08d9072fc2ac181b7fced6a245315ce05c8
  title: Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation
- pid: 07ca885cb5cc4328895bfaec9ab752d5801b14cd
  title: Extensions of recurrent neural network language model
- pid: 258986132bf17755fe8263e42429fe73218c1534
  title: 'CIDEr: Consensus-based image description evaluation'
- pid: 0ba87571341beaf6a5c9a30e049be7b1fc9a4c60
  title: Choosing Linguistics over Vision to Describe Images
- pid: 381929a8187010f6db940a23d78731c8e694c56c
  title: 'The IAPR TC-12 Benchmark: A New Evaluation Resource for Visual Information
    Systems'
- pid: 87f40e6f3022adbc1f1905e3e506abad05a9964f
  title: Distributed Representations of Words and Phrases and their Compositionality
- pid: eaaed23a2d94feb2f1c3ff22a25777c7a78f3141
  title: 'Every Picture Tells a Story: Generating Sentences from Images'
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 59927ded86ab4f7253fc32efb351e5a13e746ead
  title: 'TreeTalk: Composition and Compression of Trees for Image Descriptions'
- pid: bf60322f83714523e2d7c1d39983151fe9db7146
  title: "Collecting Image Annotations Using Amazon\u2019s Mechanical Turk"
- pid: 052b1d8ce63b07fec3de9dbb583772d860b7c769
  title: Learning representations by back-propagating errors
- pid: bd7d93193aad6c4b71cc8942e808753019e87706
  title: Three new graphical models for statistical language modelling
- pid: 3ca194773fe583661b988fbdf33f7680764438b3
  title: Exploring Nearest Neighbor Approaches for Image Captioning
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: 696ca58d93f6404fea0fc75c62d1d7b378f47628
  title: 'Microsoft COCO Captions: Data Collection and Evaluation Server'
- pid: 94e3e7bc3d23276f0ee2d1cb8f9d14aa19668d5f
  title: Under Review as a Conference Paper at Iclr 2017 Delving into Transferable
    Adversarial Ex- Amples and Black-box Attacks
- pid: e74f9b7f8eec6ba4704c206b93bc8079af3da4bd
  title: ImageNet Large Scale Visual Recognition Challenge
- pid: 668087f0ae7ce1de6e0bd0965dbb480c08103260
  title: Finding Structure in Time
- pid: 9d896605fbf93315b68d4ee03be0770077f84e40
  title: 'Baby Talk : Understanding and Generating Image Descriptions'
- pid: 355de7460120ddc1150d9ce3756f9848983f7ff4
  title: 'Midge: Generating Image Descriptions From Computer Vision Detections'
- pid: a538b05ebb01a40323997629e171c91aa28b8e2f
  title: Rectified Linear Units Improve Restricted Boltzmann Machines
- pid: 44040913380206991b1991daf1192942e038fe31
  title: 'From image descriptions to visual denotations: New similarity metrics for
    semantic inference over event descriptions'
- pid: d7da009f457917aa381619facfa5ffae9329a6e9
  title: 'Bleu: a Method for Automatic Evaluation of Machine Translation'
- pid: b87274e6d9aa4e6ba5148898aa92941617d2b6ed
  title: Efficient BackProp
slug: Deep-Captioning-with-Multimodal-Recurrent-Neural-Mao-Xu
title: Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)
url: https://www.semanticscholar.org/paper/Deep-Captioning-with-Multimodal-Recurrent-Neural-Mao-Xu/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745?sort=total-citations
venue: ICLR
year: 2015
