authors:
- Christian Szegedy
- Wojciech Zaremba
- Ilya Sutskever
- Joan Bruna
- D. Erhan
- Ian J. Goodfellow
- R. Fergus
badges:
- id: OPEN_ACCESS
corpusId: 604334
fieldsOfStudy:
- Computer Science
numCitedBy: 8881
numCiting: 19
paperAbstract: "Deep neural networks are highly expressive models that have recently\
  \ achieved state of the art performance on speech and visual recognition tasks.\
  \ While their expressiveness is the reason they succeed, it also causes them to\
  \ learn uninterpretable solutions that could have counter-intuitive properties.\
  \ In this paper we report two such properties. \nFirst, we find that there is no\
  \ distinction between individual high level units and random linear combinations\
  \ of high level units, according to various methods of unit analysis. It suggests\
  \ that it is the space, rather than the individual units, that contains of the semantic\
  \ information in the high layers of neural networks. \nSecond, we find that deep\
  \ neural networks learn input-output mappings that are fairly discontinuous to a\
  \ significant extend. We can cause the network to misclassify an image by applying\
  \ a certain imperceptible perturbation, which is found by maximizing the network's\
  \ prediction error. In addition, the specific nature of these perturbations is not\
  \ a random artifact of learning: the same perturbation can cause a different network,\
  \ that was trained on a different subset of the dataset, to misclassify the same\
  \ input."
ref_count: 19
references:
- pid: 3137bc367c61c0e507a5e3c1f8caeb26f292d79f
  title: Measuring Invariances in Deep Networks
- pid: 65d994fb778a8d9e0f632659fb33a082949a50d3
  title: Visualizing Higher-Layer Features of a Deep Network
- pid: e60ff004dde5c13ec53087872cfcdd12e85beb57
  title: Learning Deep Architectures for AI
- pid: 72e93aa6767ee683de7f001fa72f1314e40a8f35
  title: Building high-level features using large scale unsupervised learning
- pid: 1a2a770d23b4a171fa81de62a78a3deb0588f238
  title: Visualizing and Understanding Convolutional Networks
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: 860a9d55d87663ca88e74b3ca357396cd51733d0
  title: A discriminatively trained, multiscale, deformable part model
- pid: 2f4df08d9072fc2ac181b7fced6a245315ce05c8
  title: Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation
- pid: 31868290adf1c000c611dfc966b514d5a34e8d23
  title: 'Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared
    Views of Four Research Groups'
- pid: 330da625c15427c6e42ccfa3b747fb29e5835bf0
  title: Efficient Estimation of Word Representations in Vector Space
- pid: 1b47265245e8db53a553049dcb27ed3e495fd625
  title: 'ImageNet: A large-scale hierarchical image database'
- pid: dfbfcd288ed9b37106564bf6dc95041f6d33b6b2
  title: and
- pid: dc52d1ede1b90bf9d296bc5b34c9310b7eaa99a2
  title: The mnist database of handwritten digits
- pid: fc26b9c1afe81e1b20195123fe6f3ced9520abb6
  title: Visualizing and Understanding Convolutional Neural Networks
slug: Intriguing-properties-of-neural-networks-Szegedy-Zaremba
title: Intriguing properties of neural networks
url: https://www.semanticscholar.org/paper/Intriguing-properties-of-neural-networks-Szegedy-Zaremba/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad?sort=total-citations
venue: ICLR
year: 2014
