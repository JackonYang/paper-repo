authors:
- Diederik P. Kingma
- Jimmy Ba
badges:
- id: OPEN_ACCESS
corpusId: 6628106
fieldsOfStudy:
- Computer Science
meta_key: adam-a-method-for-stochastic-optimization
numCitedBy: 90052
numCiting: 30
paperAbstract: We introduce Adam, an algorithm for first-order gradient-based optimization
  of stochastic objective functions, based on adaptive estimates of lower-order moments.
  The method is straightforward to implement, is computationally efficient, has little
  memory requirements, is invariant to diagonal rescaling of the gradients, and is
  well suited for problems that are large in terms of data and/or parameters. The
  method is also appropriate for non-stationary objectives and problems with very
  noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations
  and typically require little tuning. Some connections to related algorithms, on
  which Adam was inspired, are discussed. We also analyze the theoretical convergence
  properties of the algorithm and provide a regret bound on the convergence rate that
  is comparable to the best known results under the online convex optimization framework.
  Empirical results demonstrate that Adam works well in practice and compares favorably
  to other stochastic optimization methods. Finally, we discuss AdaMax, a variant
  of Adam based on the infinity norm.
ref_count: 30
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: adaptive-subgradient-methods-for-online-learning-and-stochastic-optimization
  numCitedBy: 8025
  pid: 413c1142de9d91804d6d11c67ff3fed59c9fc279
  show_ref_link: true
  title: Adaptive Subgradient Methods for Online Learning and Stochastic Optimization
  year: 2010
- fieldsOfStudy:
  - Computer Science
  meta_key: fast-large-scale-optimization-by-unifying-stochastic-gradient-and-quasi-newton-methods
  numCitedBy: 99
  pid: af0ee019dcc1fe7eab918e3c670a6c47e48d17f6
  show_ref_link: false
  title: Fast large-scale optimization by unifying stochastic gradient and quasi-Newton
    methods
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: on-the-importance-of-initialization-and-momentum-in-deep-learning
  numCitedBy: 3556
  pid: aa7bfd2304201afbb19971ebde87b17e40242e91
  show_ref_link: true
  title: On the importance of initialization and momentum in deep learning
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: revisiting-natural-gradient-for-deep-networks
  numCitedBy: 280
  pid: e8f95ccfd13689f672c39dca3eccf1c484533bcc
  show_ref_link: false
  title: Revisiting Natural Gradient for Deep Networks
  year: 2014
- fieldsOfStudy:
  - Computer Science
  - Mathematics
  meta_key: non-asymptotic-analysis-of-stochastic-approximation-algorithms-for-machine-learning
  numCitedBy: 593
  pid: 7658cecad68afc970f18cadbf6390439b17def87
  show_ref_link: false
  title: Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Machine
    Learning
  year: 2011
- fieldsOfStudy:
  - Computer Science
  meta_key: auto-encoding-variational-bayes
  numCitedBy: 16774
  pid: 5f5dc5b9a2ba710937e2c413b37b053cd673df02
  show_ref_link: true
  title: Auto-Encoding Variational Bayes
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: identifying-and-attacking-the-saddle-point-problem-in-high-dimensional-non-convex-optimization
  numCitedBy: 1074
  pid: 981ce6b655cc06416ff6bf7fac8c6c2076fd7fac
  show_ref_link: true
  title: Identifying and attacking the saddle point problem in high-dimensional non-convex
    optimization
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: no-more-pesky-learning-rates
  numCitedBy: 410
  pid: e5a685f40338f9c2f3e68e142efa217aad16dd56
  show_ref_link: false
  title: No more pesky learning rates
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: a-fast-natural-newton-method
  numCitedBy: 52
  pid: f7cc843c318d8862357485488971b26527ef1a8e
  show_ref_link: false
  title: A fast natural Newton method
  year: 2010
- fieldsOfStudy:
  - Computer Science
  meta_key: natural-gradient-works-efficiently-in-learning
  numCitedBy: 2728
  pid: 5a767a341364de1f75bea85e0b12ba7d3586a461
  show_ref_link: false
  title: Natural Gradient Works Efficiently in Learning
  year: 1998
- fieldsOfStudy:
  - Physics
  - Computer Science
  meta_key: on-the-momentum-term-in-gradient-descent-learning-algorithms
  numCitedBy: 1526
  pid: 735d4220d5579cc6afe956d9f6ea501a96ae99e2
  show_ref_link: false
  title: On the momentum term in gradient descent learning algorithms
  year: 1999
- fieldsOfStudy:
  - Computer Science
  meta_key: fast-dropout-training
  numCitedBy: 377
  pid: ec92efde21707ddf4b81f301cd58e2051c1a2443
  show_ref_link: false
  title: Fast dropout training
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: adadelta-an-adaptive-learning-rate-method
  numCitedBy: 5464
  pid: 8729441d734782c3ed532a7d2d9611b438c0a09a
  show_ref_link: true
  title: 'ADADELTA: An Adaptive Learning Rate Method'
  year: 2012
- fieldsOfStudy:
  - Computer Science
  meta_key: imagenet-classification-with-deep-convolutional-neural-networks
  numCitedBy: 80938
  pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  show_ref_link: true
  title: ImageNet classification with deep convolutional neural networks
  year: 2012
- fieldsOfStudy:
  - Computer Science
  meta_key: speech-recognition-with-deep-recurrent-neural-networks
  numCitedBy: 6899
  pid: 4177ec52d1b80ed57f2e72b0f9a42365f1a8598d
  show_ref_link: true
  title: Speech recognition with deep recurrent neural networks
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: an-overview-of-gradient-descent-optimization-algorithms
  numCitedBy: 3406
  pid: 769ef3d5021cd71c37d2c403f231a53d1accf786
  show_ref_link: false
  title: An overview of gradient descent optimization algorithms
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: improving-neural-networks-by-preventing-co-adaptation-of-feature-detectors
  numCitedBy: 6191
  pid: 1366de5bb112746a555e9c0cd00de3ad8628aea8
  show_ref_link: true
  title: Improving neural networks by preventing co-adaptation of feature detectors
  year: 2012
- fieldsOfStudy:
  - Computer Science
  meta_key: reducing-the-dimensionality-of-data-with-neural-networks
  numCitedBy: 14640
  pid: 46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e
  show_ref_link: true
  title: Reducing the Dimensionality of Data with Neural Networks
  year: 2006
- fieldsOfStudy:
  - Computer Science
  meta_key: online-convex-programming-and-generalized-infinitesimal-gradient-ascent
  numCitedBy: 1942
  pid: e1f153c6df86d1ca8ecb9561daddfe7a54f901e7
  show_ref_link: false
  title: Online Convex Programming and Generalized Infinitesimal Gradient Ascent
  year: 2003
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-word-vectors-for-sentiment-analysis
  numCitedBy: 3007
  pid: 649d03490ef72c5274e3bccd03d7a299d2f8da91
  show_ref_link: true
  title: Learning Word Vectors for Sentiment Analysis
  year: 2011
- fieldsOfStudy:
  - Physics
  meta_key: reducing-the-dimensionality-of-data-with-neural
  numCitedBy: 283
  pid: c50dca78e97e335d362d6b991ae0e1448914e9a3
  show_ref_link: false
  title: Reducing the Dimensionality of Data with Neural
  year: 2008
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-neural-networks-for-acoustic-modeling-in-speech-recognition-the-shared-views-of-four-research-groups
  numCitedBy: 7452
  pid: 31868290adf1c000c611dfc966b514d5a34e8d23
  show_ref_link: true
  title: 'Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared
    Views of Four Research Groups'
  year: 2012
- fieldsOfStudy:
  - Computer Science
  meta_key: recent-advances-in-deep-learning-for-speech-research-at-microsoft
  numCitedBy: 673
  pid: 6bdccfe195bc49d218acc5be750aa49e41f408e4
  show_ref_link: false
  title: Recent advances in deep learning for speech research at Microsoft
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: generating-sequences-with-recurrent-neural-networks
  numCitedBy: 3151
  pid: 89b1f4740ae37fd04f6ac007577bdd34621f0861
  show_ref_link: true
  title: Generating Sequences With Recurrent Neural Networks
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: acceleration-of-stochastic-approximation-by-averaging
  numCitedBy: 1535
  pid: 6dc61f37ecc552413606d8c89ffbc46ec98ed887
  show_ref_link: false
  title: Acceleration of stochastic approximation by averaging
  year: 1992
- fieldsOfStudy:
  - Mathematics
  meta_key: efficient-estimations-from-a-slowly-convergent-robbins-monro-process
  numCitedBy: 320
  pid: 2991f9bb677b71c33945e89ac0c7dcf7a36fa198
  show_ref_link: false
  title: Efficient Estimations from a Slowly Convergent Robbins-Monro Process
  year: 1988
slug: Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba
title: 'Adam: A Method for Stochastic Optimization'
url: https://www.semanticscholar.org/paper/Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba/a6cb366736791bcccc5c8639de5a8f9636bf87e8?sort=total-citations
venue: ICLR
year: 2015
