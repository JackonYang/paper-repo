authors:
- S. Amari
badges: []
corpusId: 207585383
fieldsOfStudy:
- Computer Science
numCitedBy: 2730
numCiting: 78
paperAbstract: When a parameter space has a certain underlying structure, the ordinary
  gradient of a function does not represent its steepest direction, but the natural
  gradient does. Information geometry is used for calculating the natural gradients
  in the parameter space of perceptrons, the space of matrices (for blind source separation),
  and the space of linear dynamical systems (for blind source deconvolution). The
  dynamical behavior of natural gradient online learning is analyzed and is proved
  to be Fisher efficient, implying that it has asymptotically the same performance
  as the optimal batch estimation of parameters. This suggests that the plateau phenomenon,
  which appears in the backpropagation learning algorithm of multilayer perceptrons,
  might disappear or might not be so serious when the natural gradient is used. An
  adaptive method of updating the learning rate is proposed and analyzed.
ref_count: 78
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2220
  pid: fac0e753905d1498e0b3debf01431696e1f0c645
  title: A New Learning Algorithm for Blind Signal Separation
  year: 1995
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 8756
  pid: 1d7d0e8c4791700defd4b0df82a26b50055346e0
  title: An Information-Maximization Approach to Blind Separation and Blind Deconvolution
  year: 1995
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 451
  pid: 1339348aeef592802288d9d929a085cb3ae61c4b
  title: A Theory of Adaptive Pattern Classifiers
  year: 1967
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1501
  pid: 8637f042e3d2a2d45de41566b4203646987a8424
  title: Equivariant adaptive source separation
  year: 1996
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 282
  pid: 698aedd44c51da829228e2c7d243960345efeb94
  title: 'Nonlinear neurons in the low-noise limit: a factorial code maximizes information
    transfer Network 5'
  year: 1994
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 8327
  pid: 96a1effa4be3f8caa88270d6d258de418993d2e7
  title: Independent component analysis, A new concept?
  year: 1994
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2689
  pid: 2e73081ed096c62c073b3faa1b3b80aab89998c5
  title: 'Blind separation of sources, part I: An adaptive algorithm based on neuromimetic
    architecture'
  year: 1991
- fieldsOfStudy:
  - Mathematics
  numCitedBy: 948
  pid: 0009c5a2b4b07751a99bcf407d95e911a3064d0f
  title: wchastic. approximation methods for constrained and unconstrained systems
  year: 1978
- fieldsOfStudy:
  - Biology
  numCitedBy: 19356
  pid: 111fd833a4ae576cfdbb27d87d2f8fc0640af355
  title: Learning internal representations by error propagation
  year: 1986
- fieldsOfStudy:
  - Mathematics
  numCitedBy: 1490
  pid: 420322994c59e9081786b46b31e2c82a9753e23a
  title: Differential-geometrical methods in statistics
  year: 1985
slug: Natural-Gradient-Works-Efficiently-in-Learning-Amari
title: Natural Gradient Works Efficiently in Learning
url: https://www.semanticscholar.org/paper/Natural-Gradient-Works-Efficiently-in-Learning-Amari/5a767a341364de1f75bea85e0b12ba7d3586a461?sort=total-citations
venue: Neural Computation
year: 1998
