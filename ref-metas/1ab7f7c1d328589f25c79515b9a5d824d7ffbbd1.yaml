authors:
- Drew A. Hudson
- Christopher D. Manning
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 152282269
fieldsOfStudy:
- Computer Science
numCitedBy: 448
numCiting: 49
paperAbstract: We introduce GQA, a new dataset for real-world visual reasoning and
  compositional question answering, seeking to address key shortcomings of previous
  VQA datasets. We have developed a strong and robust question engine that leverages
  Visual Genome scene graph structures to create 22M diverse reasoning questions,
  which all come with functional programs that represent their semantics. We use the
  programs to gain tight control over the answer distribution and present a new tunable
  smoothing technique to mitigate question biases. Accompanying the dataset is a suite
  of new metrics that evaluate essential qualities such as consistency, grounding
  and plausibility. A careful analysis is performed for baselines as well as state-of-the-art
  models, providing fine-grained results for different question types and topologies.
  Whereas a blind LSTM obtains a mere 42.1%, and strong VQA models achieve 54.1%,
  human performance tops at 89.3%, offering ample opportunity for new research to
  explore. We hope GQA will provide an enabling resource for the next generation of
  models with enhanced robustness, improved consistency, and deeper semantic understanding
  of vision and language.
ref_count: 49
references:
- pid: 03eb382e04cca8cca743f7799070869954f1402a
  title: 'CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual
    Reasoning'
- pid: c7d007ba376faddf0046930ea7375ed59600cee9
  title: Graph-Structured Representations for Visual Question Answering
- pid: 5fa973b8d284145bf0ced9acf2913a74674260f6
  title: 'Yin and Yang: Balancing and Answering Binary Visual Questions'
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: 915b5b12f9bdebc321e970ecd713458c3479d70e
  title: An Analysis of Visual Question Answering Algorithms
- pid: 3c1bbd2672c11a796f1e6e6aa787257498ec8bec
  title: Revisiting Visual Question Answering Baselines
- pid: 90873a97aa9a43775e5aeea01b03aea54b28bfbd
  title: 'Don''t Just Assume; Look and Answer: Overcoming Priors for Visual Question
    Answering'
- pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  title: 'Making the V in VQA Matter: Elevating the Role of Image Understanding in
    Visual Question Answering'
- pid: def584565d05d6a8ba94de6621adab9e301d375d
  title: 'Visual7W: Grounded Question Answering in Images'
- pid: 6d92ce1c4f7f0ccfe068e663903e4dd614a15ede
  title: 'Visual question answering: Datasets, algorithms, and future challenges'
- pid: 21c99706bb26e9012bfb4d8d48009a3d45af59b2
  title: Neural Module Networks
- pid: 8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5
  title: Analyzing the Behavior of Visual Question Answering Models
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81
  title: 'Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge'
- pid: 289fb3709475f5c87df8d97f129af54029d27fee
  title: Compositional Attention Networks for Machine Reasoning
- pid: 58cb0c24c936b8a14ca7b2d56ba80de733c545b3
  title: 'Human Attention in Visual Question Answering: Do Humans and Deep Networks
    look at the same regions?'
- pid: fddc15480d086629b960be5bff96232f967f2252
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
- pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  title: Stacked Attention Networks for Image Question Answering
- pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
- pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
- pid: a79b694bd4ef51207787da1948ed473903b751ef
  title: Bottom-Up and Top-Down Attention for Image Captioning and VQA
- pid: cf336d272a30d6ad6141db67faa64deb8791cd61
  title: A Corpus for Reasoning about Natural Language Grounded in Photographs
- pid: 34b73c1aa158b892bbe41705b4ae5bf01ecaea86
  title: Scene Graph Generation by Iterative Message Passing
- pid: 0302bb2d5476540cfb21467473f5eca843caf90b
  title: Unbiased look at dataset bias
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: 85ae705ef4353c6854f5be4a4664269d6317c66b
  title: Image retrieval using scene graphs
- pid: 1b47265245e8db53a553049dcb27ed3e495fd625
  title: 'ImageNet: A large-scale hierarchical image database'
- pid: a6e695ddd07aad719001c0fc1129328452385949
  title: The New Data and New Challenges in Multimedia Research
- pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  title: 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks'
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: d13a04844e4a781e5180987118f732d93aa9f398
  title: The Earth Mover's Distance as a Metric for Image Retrieval
- pid: 68c03788224000794d5491ab459be0b2a2c38677
  title: 'WordNet: A Lexical Database for English'
- pid: 354c029c88be2bbc27dfd2e2e729c0ae622511e6
  title: 'YFCC100M: the new data in multimedia research'
slug: GQA:-A-New-Dataset-for-Real-World-Visual-Reasoning-Hudson-Manning
title: 'GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question
  Answering'
url: https://www.semanticscholar.org/paper/GQA:-A-New-Dataset-for-Real-World-Visual-Reasoning-Hudson-Manning/1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1?sort=total-citations
venue: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2019
