authors:
- Licheng Yu
- Zhe L. Lin
- Xiaohui Shen
- Jimei Yang
- Xin Lu
- Mohit Bansal
- Tamara L. Berg
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 3441497
fieldsOfStudy:
- Computer Science
numCitedBy: 369
numCiting: 37
paperAbstract: 'In this paper, we address referring expression comprehension: localizing
  an image region described by a natural language expression. While most recent work
  treats expressions as a single unit, we propose to decompose them into three modular
  components related to subject appearance, location, and relationship to other objects.
  This allows us to flexibly adapt to expressions containing different types of information
  in an end-to-end framework. In our model, which we call the Modular Attention Network
  (MAttNet), two types of attention are utilized: language-based attention that learns
  the module weights as well as the word/phrase attention that each module should
  focus on; and visual attention that allows the subject and relationship modules
  to focus on relevant image components. Module weights combine scores from all three
  modules dynamically to output an overall score. Experiments show that MAttNet outperforms
  previous state-of-the-art methods by a large margin on both bounding-box-level and
  pixel-level comprehension tasks. Demo1 and code2 are provided.'
ref_count: 37
references:
- pid: ce264a4e1490e959d84ddd60edbb0edcbfb3af38
  title: Modeling Relationships in Referential Expressions with Compositional Modular
    Networks
- pid: bf55591e09b58ea9ce8d66110d6d3000ee804bdd
  title: Image Captioning with Semantic Attention
- pid: b133e361e2f8af22b823d25060b2e7c47f690985
  title: Segmentation from Natural Language Expressions
- pid: a396a6febdacb84340d139096455e67049ac1e22
  title: 'Learning to Reason: End-to-End Module Networks for Visual Question Answering'
- pid: f865268b81eeb29d94775f22c6bc24dcc5e1b2e9
  title: Learning Two-Branch Neural Networks for Image-Text Matching Tasks
- pid: 29efbe391950ae438c63d86ad5c82b2942efb0b4
  title: Modeling Context in Referring Expressions
- pid: 14c2321851fb5ae580a19726dd2753a525d6ad76
  title: Grounding of Textual Phrases in Images by Reconstruction
- pid: 21c99706bb26e9012bfb4d8d48009a3d45af59b2
  title: Neural Module Networks
- pid: 5785466bc14529e94e54baa4ed051f7037f3b1d3
  title: Boosting Image Captioning with Attributes
- pid: d696a1923288e6c15422660de9553f6fdb6a4fae
  title: Natural Language Object Retrieval
- pid: e65142010431ffc089b272a1174214e00693e503
  title: Generation and Comprehension of Unambiguous Object Descriptions
- pid: b27e791e843c924ef052981b79490ab59fc0433d
  title: Learning Deep Structure-Preserving Image-Text Embeddings
- pid: 75ddc7ee15be14013a3462c01b38b0548486fbcb
  title: Learning to Compose Neural Networks for Question Answering
- pid: 317aee7fc081f2b137a85c4f20129007fd8e717e
  title: Fully Convolutional Networks for Semantic Segmentation
- pid: 455afd748e8834ef521e4b67c7c056d3c33429e2
  title: Hierarchical Attention Networks for Document Classification
- pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  title: 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks'
- pid: 92c141447f51b6732242376164ff961e464731c8
  title: 'ReferItGame: Referring to Objects in Photographs of Natural Scenes'
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: acc4e56c44771ebf69302a06af51498aeb0a6ac8
  title: Parsing with Compositional Vector Grammars
- pid: 2e17cf6a339fd071ad222062f868e882ef4120a4
  title: Inferring and Executing Programs for Visual Reasoning
- pid: 10d85561e4aafc516d10064f30dff05b41f70afe
  title: '[Et al].'
- pid: 032db195efd97fe2bcd20c4ad04628c70ff4e79c
  title: and a at
- pid: 022dd244f2e25525eb37e9dda51abb9cd8ca8c30
  title: Mask R-CNN
slug: MAttNet:-Modular-Attention-Network-for-Referring-Yu-Lin
title: 'MAttNet: Modular Attention Network for Referring Expression Comprehension'
url: https://www.semanticscholar.org/paper/MAttNet:-Modular-Attention-Network-for-Referring-Yu-Lin/fdce9cbe5c726201575b3c8a8c1af0752f1af53f?sort=total-citations
venue: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition
year: 2018
