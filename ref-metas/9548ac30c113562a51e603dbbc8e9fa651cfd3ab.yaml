authors:
- Reinhard Kneser
- H. Ney
badges:
- id: OPEN_ACCESS
corpusId: 9685476
fieldsOfStudy:
- Computer Science
numCitedBy: 1792
numCiting: 9
paperAbstract: In stochastic language modeling, backing-off is a widely used method
  to cope with the sparse data problem. In case of unseen events this method backs
  off to a less specific distribution. In this paper we propose to use distributions
  which are especially optimized for the task of backing-off. Two different theoretical
  derivations lead to distributions which are quite different from the probability
  distributions that are usually used for backing-off. Experiments show an improvement
  of about 10% in terms of perplexity and 5% in terms of word error rate.
ref_count: 9
references:
- pid: b0130277677e5b915d5cd86b3afafd77fd08eb2e
  title: Estimation of probabilities from sparse data for the language model component
    of a speech recognizer
- pid: b3e53b9c0e3a7a60e7a5295e9b08af74d6fb3dbf
  title: On structuring probabilistic dependences in stochastic language modelling
- pid: d36910319d11359b995ff5413696aa9e9995e163
  title: \self-organized Language Modeling for Speech Recognition". In
- pid: b07ce649d6f6eb636872527104b0209d3edc8188
  title: Pattern classification and scene analysis
- pid: b2986b25f50babd536dd0ecf2237d9eabf5843c2
  title: THE POPULATION FREQUENCIES OF SPECIES AND THE ESTIMATION OF POPULATION PARAMETERS
slug: Improved-backing-off-for-M-gram-language-modeling-Kneser-Ney
title: Improved backing-off for M-gram language modeling
url: https://www.semanticscholar.org/paper/Improved-backing-off-for-M-gram-language-modeling-Kneser-Ney/9548ac30c113562a51e603dbbc8e9fa651cfd3ab?sort=total-citations
venue: 1995 International Conference on Acoustics, Speech, and Signal Processing
year: 1995
