authors:
- A. Blum
- Tom. Mitchell
badges:
- id: OPEN_ACCESS
corpusId: 207228399
fieldsOfStudy:
- Computer Science
numCitedBy: 5471
numCiting: 24
paperAbstract: "We consider the problem of using a large unlabeled sample to boost\
  \ performance of a learning algorit,hrn when only a small set of labeled examples\
  \ is available. In particular, we consider a problem setting motivated by the task\
  \ of learning to classify web pages, in which the description of each example can\
  \ be partitioned into two distinct views. For example, the description of a web\
  \ page can be partitioned into the words occurring on that page, and the words occurring\
  \ in hyperlinks t,hat point to that page. We assume that either view of the example\
  \ would be sufficient for learning if we had enough labeled data, but our goal is\
  \ to use both views together to allow inexpensive unlabeled data to augment, a much\
  \ smaller set of labeled examples. Specifically, the presence of two distinct views\
  \ of each example suggests strategies in which two learning algorithms are trained\
  \ separately on each view, and then each algorithm\u2019s predictions on new unlabeled\
  \ examples are used to enlarge the training set of the other. Our goal in this paper\
  \ is to provide a PAC-style analysis for this setting, and, more broadly, a PAC-style\
  \ framework for the general problem of learning from both labeled and unlabeled\
  \ data. We also provide empirical results on real web-page data indicating that\
  \ this use of unlabeled examples can lead to significant improvement of hypotheses\
  \ in practice. *This research was supported in part by the DARPA HPKB program under\
  \ contract F30602-97-1-0215 and by NSF National Young investigator grant CCR-9357793.\
  \ Permission to make digital or hard copies of all or part of this work for personal\
  \ or classroom use is granted without fee provided that copies are not made or distributed\
  \ for profit or commercial advantage and that copies bear this notice and the full\
  \ citation on the first page. TO copy otherwise, to republish, to post on servers\
  \ or to redistribute to lists, requires prior specific permission and/or a fee.\
  \ COLT 98 Madison WI USA Copyright ACM 1998 l-58113-057--0/98/ 7...%5.00 92 Tom\
  \ Mitchell School of Computer Science Carnegie Mellon University Pittsburgh, PA\
  \ 15213-3891 mitchell+@cs.cmu.edu"
ref_count: 25
references:
- pid: f67e9a6bd7c688f1c9c653584a4fa1f9c7fda2a6
  title: On the exponential value of labeled samples
- pid: 8446830f3c05b97c4d12a0751c022d1ae6a5115b
  title: Learning to Extract Symbolic Knowledge from the World Wide Web
- pid: e9fd1a7ae0322d417ab2d32017e373dd50efc063
  title: A comparison of two learning algorithms for text categorization
- pid: 5db7dc2239f820eae498b07a955f31b3d113179f
  title: Supervised learning from incomplete data via an EM approach
- pid: 944cba683d10d8c1a902e05cd68e32a9f47b372e
  title: Unsupervised Word Sense Disambiguation Rivaling Supervised Methods
- pid: b07ce649d6f6eb636872527104b0209d3edc8188
  title: Pattern classification and scene analysis
- pid: d36efb9ad91e00faa334b549ce989bfae7e2907a
  title: Maximum likelihood from incomplete data via the EM - algorithm plus discussions
    on the paper
- pid: ecb37a4e32d6faef4ac99b45d9ab9b2d92693985
  title: Max-imum Likelihood from Incomplete Data
slug: Combining-labeled-and-unlabeled-data-with-Blum-Mitchell
title: Combining labeled and unlabeled data with co-training
url: https://www.semanticscholar.org/paper/Combining-labeled-and-unlabeled-data-with-Blum-Mitchell/278841ab0cb24c1abcb75e363aeed1fa741c8cc4?sort=total-citations
venue: COLT' 98
year: 1998
