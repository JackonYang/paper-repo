authors:
- T. Cover
- P. Hart
badges:
- id: OPEN_ACCESS
corpusId: 5246200
fieldsOfStudy:
- Computer Science
- Mathematics
numCitedBy: 10767
numCiting: 9
paperAbstract: The nearest neighbor decision rule assigns to an unclassified sample
  point the classification of the nearest of a set of previously classified points.
  This rule is independent of the underlying joint distribution on the sample points
  and their classifications, and hence the probability of error R of such a rule must
  be at least as great as the Bayes probability of error R^{\ast} --the minimum probability
  of error over all decision rules taking underlying probability structure into account.
  However, in a large sample analysis, we will show in the M -category case that R^{\ast}
  \leq R \leq R^{\ast}(2 --MR^{\ast}/(M-1)) , where these bounds are the tightest
  possible, for all suitably smooth underlying distributions. Thus for any number
  of categories, the probability of error of the nearest neighbor rule is bounded
  above by twice the Bayes probability of error. In this sense, it may be said that
  half the classification information in an infinite sample set is contained in the
  nearest neighbor.
ref_count: 9
references:
- pid: 4023ae0ba18eed43a97e8b8c9c8fcc9a671b7aa3
  title: 'The magical number seven plus or minus two: some limits on our capacity
    for processing information.'
slug: Nearest-neighbor-pattern-classification-Cover-Hart
title: Nearest neighbor pattern classification
url: https://www.semanticscholar.org/paper/Nearest-neighbor-pattern-classification-Cover-Hart/0efb841403aa6252b39ae6975c1cc5410554ef7b?sort=total-citations
venue: IEEE Trans. Inf. Theory
year: 1967
