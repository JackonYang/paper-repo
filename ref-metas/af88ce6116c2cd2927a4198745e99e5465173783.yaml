authors:
- Zhiheng Huang
- W. Xu
- Kai Yu
badges:
- id: OPEN_ACCESS
corpusId: 12740621
fieldsOfStudy:
- Computer Science
numCitedBy: 2424
numCiting: 39
paperAbstract: In this paper, we propose a variety of Long Short-Term Memory (LSTM)
  based models for sequence tagging. These models include LSTM networks, bidirectional
  LSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer (LSTM-CRF)
  and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work is the first to
  apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model to NLP benchmark sequence
  tagging data sets. We show that the BI-LSTM-CRF model can efficiently use both past
  and future input features thanks to a bidirectional LSTM component. It can also
  use sentence level tag information thanks to a CRF layer. The BI-LSTM-CRF model
  can produce state of the art (or close to) accuracy on POS, chunking and NER data
  sets. In addition, it is robust and has less dependence on word embedding as compared
  to previous observations.
ref_count: 39
references:
- pid: 2f83f6e1afadf0963153974968af6b8342775d82
  title: Framewise phoneme classification with bidirectional LSTM and other neural
    network architectures
- pid: d53d878cf1a3f0bed5d9c68c925994cb72f47304
  title: Lexicon Infused Phrase Embeddings for Named Entity Resolution
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: eb42a490cf4f186d3383c92963817d100afd81e2
  title: Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network
- pid: 4f410ab5c8b12b34b38421241366ee456bbebab9
  title: Incorporating Non-local Information into Information Extraction Systems by
    Gibbs Sampling
- pid: 4177ec52d1b80ed57f2e72b0f9a42365f1a8598d
  title: Speech recognition with deep recurrent neural networks
- pid: 897249c93f55ef1c0d2aa1e799eb67b414c6d4a6
  title: Shallow Parsing with Conditional Random Fields
- pid: f4ba954b0412773d047dc41231c733de0c1f4926
  title: 'Conditional Random Fields: Probabilistic Models for Segmenting and Labeling
    Sequence Data'
- pid: bece46ed303f8eaef2affae2cba4e0aef51fe636
  title: Maximum Entropy Markov Models for Information Extraction and Segmentation
- pid: bc1022b031dc6c7019696492e8116598097a8c12
  title: Natural Language Processing (Almost) from Scratch
- pid: 9819b600a828a57e1cde047bbe710d3446b30da5
  title: Recurrent neural network based language model
- pid: 87f40e6f3022adbc1f1905e3e506abad05a9964f
  title: Distributed Representations of Words and Phrases and their Compositionality
- pid: 944e1a7b2c5c62e952418d7684e3cade89c76f87
  title: A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled
    Data
- pid: 668087f0ae7ce1de6e0bd0965dbb480c08103260
  title: Finding Structure in Time
- pid: cb45e9217fe323fbc199d820e7735488fca2a9b3
  title: Strategies for training large scale neural network language models
- pid: a574e320d899e7e82e341eb64baef7dfe8a24642
  title: A Maximum Entropy Model for Part-Of-Speech Tagging
- pid: 2a6626dadb6b624011c39270cc7678ac98e162a3
  title: Semi-supervised condensed nearest neighbor for part-of-speech tagging
- pid: 03c03dec975554cb02aca1e076106178dbe0a8a0
  title: Named Entity Recognition with a Maximum Entropy Approach
- pid: d1ba322f795adbdc706651dbc76ad53b9c5f9468
  title: Named Entity Recognition through Classifier Combination
- pid: 6ffea7929f0e4bbee9e98755eb3d8fc09e89cf4e
  title: Chunking with Support Vector Machines
- pid: 8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5
  title: A Tutorial on Hidden Markov Models and Selected Applications
slug: Bidirectional-LSTM-CRF-Models-for-Sequence-Tagging-Huang-Xu
title: Bidirectional LSTM-CRF Models for Sequence Tagging
url: https://www.semanticscholar.org/paper/Bidirectional-LSTM-CRF-Models-for-Sequence-Tagging-Huang-Xu/af88ce6116c2cd2927a4198745e99e5465173783?sort=total-citations
venue: ArXiv
year: 2015
