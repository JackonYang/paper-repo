authors:
- Di Qi
- Lin Su
- Jianwei Song
- Edward Cui
- Taroon Bharti
- Arun Sacheti
badges:
- id: OPEN_ACCESS
corpusId: 210859480
fieldsOfStudy:
- Computer Science
meta_key: imagebert-cross-modal-pre-training-with-large-scale-weak-supervised-image-text-data
numCitedBy: 101
numCiting: 32
paperAbstract: 'In this paper, we introduce a new vision-language pre-trained model
  -- ImageBERT -- for image-text joint embedding. Our model is a Transformer-based
  model, which takes different modalities as input and models the relationship between
  them. The model is pre-trained on four tasks simultaneously: Masked Language Modeling
  (MLM), Masked Object Classification (MOC), Masked Region Feature Regression (MRFR),
  and Image Text Matching (ITM). To further enhance the pre-training quality, we have
  collected a Large-scale weAk-supervised Image-Text (LAIT) dataset from Web. We first
  pre-train the model on this dataset, then conduct a second stage pre-training on
  Conceptual Captions and SBU Captions. Our experiments show that multi-stage pre-training
  strategy outperforms single-stage pre-training. We also fine-tune and evaluate our
  pre-trained ImageBERT model on image retrieval and text retrieval tasks, and achieve
  new state-of-the-art results on both MSCOCO and Flickr30k datasets.'
ref_count: 32
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: uniter-learning-universal-image-text-representations
  numCitedBy: 282
  pid: 54416048772b921720f19869ed11c2a360589d03
  show_ref_link: true
  title: 'UNITER: Learning UNiversal Image-TExt Representations'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: unified-vision-language-pre-training-for-image-captioning-and-vqa
  numCitedBy: 355
  pid: 6648b4db5f12c30941ea78c695e77aded19672bb
  show_ref_link: true
  title: Unified Vision-Language Pre-Training for Image Captioning and VQA
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: unicoder-vl-a-universal-encoder-for-vision-and-language-by-cross-modal-pre-training
  numCitedBy: 382
  pid: 2bc1c8bd00bbf7401afcb5460277840fd8bab029
  show_ref_link: true
  title: 'Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal
    Pre-training'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: stacked-cross-attention-for-image-text-matching
  numCitedBy: 481
  pid: 45dd2a3cd7c27f2e9509b023d702408f5ac11c9d
  show_ref_link: true
  title: Stacked Cross Attention for Image-Text Matching
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: position-focused-attention-network-for-image-text-matching
  numCitedBy: 63
  pid: 48a7873681c6aa88b9e0e22a25c2a8245eaeb45f
  show_ref_link: false
  title: Position Focused Attention Network for Image-Text Matching
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: lxmert-learning-cross-modality-encoder-representations-from-transformers
  numCitedBy: 916
  pid: 79c93274429d6355959f1e4374c2147bb81ea649
  show_ref_link: true
  title: 'LXMERT: Learning Cross-Modality Encoder Representations from Transformers'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-residual-learning-for-image-recognition
  numCitedBy: 95324
  pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  show_ref_link: true
  title: Deep Residual Learning for Image Recognition
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks
  numCitedBy: 1266
  pid: 65a9c7b0800c86a196bc14e7621ff895cc6ab287
  show_ref_link: true
  title: 'ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language
    Tasks'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  - Environmental Science
  meta_key: conceptual-captions-a-cleaned-hypernymed-image-alt-text-dataset-for-automatic-image-captioning
  numCitedBy: 632
  pid: b4df354db88a70183a64dbc9e56cf14e7669a6c0
  show_ref_link: true
  title: 'Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic
    Image Captioning'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering
  numCitedBy: 2275
  pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  show_ref_link: true
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: knowledge-aware-semantic-concept-expansion-for-image-text-matching
  numCitedBy: 26
  pid: ad748d1772f893b3c8a3857a19292375be259daf
  show_ref_link: false
  title: Knowledge Aware Semantic Concept Expansion for Image-Text Matching
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: universal-language-model-fine-tuning-for-text-classification
  numCitedBy: 2251
  pid: 1e077413b25c4d34945cc2707e17e46ed4fe784a
  show_ref_link: true
  title: Universal Language Model Fine-tuning for Text Classification
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: attention-is-all-you-need
  numCitedBy: 35157
  pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  show_ref_link: true
  title: Attention is All you Need
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: visualbert-a-simple-and-performant-baseline-for-vision-and-language
  numCitedBy: 630
  pid: 5aec474c31a2f4b74703c6f786c0a8ff85c450da
  show_ref_link: true
  title: 'VisualBERT: A Simple and Performant Baseline for Vision and Language'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: vl-bert-pre-training-of-generic-visual-linguistic-representations
  numCitedBy: 707
  pid: 2527626c11a84f15709e943fbfa2356e19930e3b
  show_ref_link: true
  title: 'VL-BERT: Pre-training of Generic Visual-Linguistic Representations'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: towards-vqa-models-that-can-read
  numCitedBy: 180
  pid: af1f7739283bdbd2b7a94903041f6d6afd991907
  show_ref_link: true
  title: Towards VQA Models That Can Read
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding
  numCitedBy: 33754
  pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  show_ref_link: true
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: xlnet-generalized-autoregressive-pretraining-for-language-understanding
  numCitedBy: 4227
  pid: e0c6abdbdecf04ffac65c440da77fb9d66bb474c
  show_ref_link: true
  title: 'XLNet: Generalized Autoregressive Pretraining for Language Understanding'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: im2text-describing-images-using-1-million-captioned-photographs
  numCitedBy: 734
  pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  show_ref_link: false
  title: 'Im2Text: Describing Images Using 1 Million Captioned Photographs'
  year: 2011
- fieldsOfStudy:
  - Computer Science
  meta_key: multi-stage-multi-task-feature-learning
  numCitedBy: 133
  pid: d8feb336c1691aa82a7f655c4fb0f6751dbef277
  show_ref_link: false
  title: Multi-stage multi-task feature learning
  year: 2012
- fieldsOfStudy:
  - Computer Science
  meta_key: aligning-books-and-movies-towards-story-like-visual-explanations-by-watching-movies-and-reading-books
  numCitedBy: 1418
  pid: 0e6824e137847be0599bb0032e37042ed2ef5045
  show_ref_link: true
  title: 'Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching
    Movies and Reading Books'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: pythia-a-platform-for-vision-language-research
  numCitedBy: 48
  pid: d6dedf6d25df2a5cd727a019b613953afc9a0300
  show_ref_link: false
  title: Pythia-A platform for vision & language research
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: fusion-of-detected-objects-in-text-for-visual-question-answering
  numCitedBy: 111
  pid: b82153bf85d5d1edd3f170aace830e5328ca9ed0
  show_ref_link: true
  title: Fusion of Detected Objects in Text for Visual Question Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations
  numCitedBy: 2772
  pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  show_ref_link: true
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: densenet-implementing-efficient-convnet-descriptor-pyramids
  numCitedBy: 442
  pid: 5fc662287842e5cb2d23b5fa917354e957c573bf
  show_ref_link: false
  title: 'DenseNet: Implementing Efficient ConvNet Descriptor Pyramids'
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: roberta-a-robustly-optimized-bert-pretraining-approach
  numCitedBy: 7267
  pid: 077f8329a7b6fa3b7c877a57b81eb6c18b5f87de
  show_ref_link: true
  title: 'RoBERTa: A Robustly Optimized BERT Pretraining Approach'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: vqa-visual-question-answering
  numCitedBy: 2887
  pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  show_ref_link: true
  title: 'VQA: Visual Question Answering'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation
  numCitedBy: 4645
  pid: dbde7dfa6cae81df8ac19ef500c42db96c3d1edd
  show_ref_link: true
  title: 'Google''s Neural Machine Translation System: Bridging the Gap between Human
    and Machine Translation'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: from-recognition-to-cognition-visual-commonsense-reasoning
  numCitedBy: 372
  pid: 6dfc2ff03534a4325d06c6f88c3144831996629b
  show_ref_link: true
  title: 'From Recognition to Cognition: Visual Commonsense Reasoning'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: microsoft-coco-captions-data-collection-and-evaluation-server
  numCitedBy: 1178
  pid: 696ca58d93f6404fea0fc75c62d1d7b378f47628
  show_ref_link: true
  title: 'Microsoft COCO Captions: Data Collection and Evaluation Server'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: from-image-descriptions-to-visual-denotations-new-similarity-metrics-for-semantic-inference-over-event-descriptions
  numCitedBy: 1323
  pid: 44040913380206991b1991daf1192942e038fe31
  show_ref_link: true
  title: 'From image descriptions to visual denotations: New similarity metrics for
    semantic inference over event descriptions'
  year: 2014
slug: ImageBERT:-Cross-modal-Pre-training-with-Image-Text-Qi-Su
title: 'ImageBERT: Cross-modal Pre-training with Large-scale Weak-supervised Image-Text
  Data'
url: https://www.semanticscholar.org/paper/ImageBERT:-Cross-modal-Pre-training-with-Image-Text-Qi-Su/a9fd5511b42206a27748f373e0fdb7eb76a23055?sort=total-citations
venue: ArXiv
year: 2020
