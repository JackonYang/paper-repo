authors:
- James Martens
badges:
- id: OPEN_ACCESS
corpusId: 11154521
fieldsOfStudy:
- Computer Science
numCitedBy: 845
numCiting: 11
paperAbstract: We develop a 2nd-order optimization method based on the "Hessian-free"
  approach, and apply it to training deep auto-encoders. Without using pre-training,
  we obtain results superior to those reported by Hinton & Salakhutdinov (2006) on
  the same tasks they considered. Our method is practical, easy to use, scales nicely
  to very large datasets, and isn't limited in applicability to auto-encoders, or
  any specific model class. We also discuss the issue of "pathological curvature"
  as a possible explanation for the difficulty of deep-learning and how 2nd-order
  optimization, and our method in particular, effectively deals with it.
ref_count: 11
references:
- pid: 0d2336389dff3031910bd21dd1c44d1b4cd51725
  title: Why Does Unsupervised Pre-training Help Deep Learning?
- pid: 355d44f53428b1ac4fb2ab468d593c720640e5bd
  title: Greedy Layer-Wise Training of Deep Networks
- pid: 46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e
  title: Reducing the Dimensionality of Data with Neural Networks
- pid: ffa94bba647817fa5e8f8d3250fc977435b5ca76
  title: Fast Curvature Matrix-Vector Products for Second-Order Gradient Descent
- pid: c6867b6b564462d6b902f68e0bfa58f4717ca1cc
  title: Fast Exact Multiplication by the Hessian
- pid: bf86896c23300a46b7fc76298e365984c0b05105
  title: Numerical Optimization
- pid: b87274e6d9aa4e6ba5148898aa92941617d2b6ed
  title: Efficient BackProp
slug: Deep-learning-via-Hessian-free-optimization-Martens
title: Deep learning via Hessian-free optimization
url: https://www.semanticscholar.org/paper/Deep-learning-via-Hessian-free-optimization-Martens/4c46347fbc272b21468efe3d9af34b4b2bad6684?sort=total-citations
venue: ICML
year: 2010
