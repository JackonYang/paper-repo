authors:
- Abhishek Das
- Satwik Kottur
- Khushi Gupta
- Avi Singh
- Deshraj Yadav
- "Jos\xE9 M. F. Moura"
- Devi Parikh
- Dhruv Batra
badges:
- id: OPEN_ACCESS
corpusId: 1820614
fieldsOfStudy:
- Computer Science
numCitedBy: 529
numCiting: 98
paperAbstract: We introduce the task of Visual Dialog, which requires an AI agent
  to hold a meaningful dialog with humans in natural, conversational language about
  visual content. Specifically, given an image, a dialog history, and a question about
  the image, the agent has to ground the question in image, infer context from history,
  and answer the question accurately. Visual Dialog is disentangled enough from a
  specific downstream task so as to serve as a general test of machine intelligence,
  while being grounded in vision enough to allow objective evaluation of individual
  responses and benchmark progress. We develop a novel two-person chat data-collection
  protocol to curate a large-scale Visual Dialog dataset (VisDial). VisDial contains
  1 dialog (10 question-answer pairs) on ~140k images from the COCO dataset, with
  a total of ~1.4M dialog question-answer pairs. We introduce a family of neural encoder-decoder
  models for Visual Dialog with 3 encoders (Late Fusion, Hierarchical Recurrent Encoder
  and Memory Network) and 2 decoders (generative and discriminative), which outperform
  a number of sophisticated baselines. We propose a retrieval-based evaluation protocol
  for Visual Dialog where the AI agent is asked to sort a set of candidate answers
  and evaluated on metrics such as mean-reciprocal-rank of human response. We quantify
  gap between machine and human performance on the Visual Dialog task via human studies.
  Our dataset, code, and trained models will be released publicly at https://visualdialog.org.
  Putting it all together, we demonstrate the first visual chatbot!.
ref_count: 98
references:
- pid: bd7bd1d2945a58cdcc1797ba9698b8810fe68f60
  title: 'Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images'
- pid: def584565d05d6a8ba94de6621adab9e301d375d
  title: 'Visual7W: Grounded Question Answering in Images'
- pid: 5fa973b8d284145bf0ced9acf2913a74674260f6
  title: 'Yin and Yang: Balancing and Answering Binary Visual Questions'
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 3c1bbd2672c11a796f1e6e6aa787257498ec8bec
  title: Revisiting Visual Question Answering Baselines
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: 14c2321851fb5ae580a19726dd2753a525d6ad76
  title: Grounding of Textual Phrases in Images by Reconstruction
- pid: 85315b64a4c73cb86f156ef5b0a085d6ebc8a65d
  title: A Neural Conversational Model
- pid: 2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1
  title: Are You Talking to a Machine? Dataset and Methods for Multilingual Image
    Question
- pid: fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b
  title: Hierarchical Question-Image Co-Attention for Visual Question Answering
- pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
- pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  title: 'Making the V in VQA Matter: Elevating the Role of Image Understanding in
    Visual Question Answering'
- pid: abb33d75dc297993fcc3fb75e0f4498f413eb4f6
  title: 'Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks'
- pid: 21c99706bb26e9012bfb4d8d48009a3d45af59b2
  title: Neural Module Networks
- pid: 58cb0c24c936b8a14ca7b2d56ba80de733c545b3
  title: 'Human Attention in Visual Question Answering: Do Humans and Deep Networks
    look at the same regions?'
- pid: 43795b7bac3d921c4e579964b54187bdbf6c6330
  title: Translating Videos to Natural Language Using Deep Recurrent Neural Networks
- pid: a58a582b95a07932cb248f1b739e4ad739ead6b9
  title: 'Visual Madlibs: Fill in the blank Image Generation and Question Answering'
- pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  title: Stacked Attention Networks for Image Question Answering
- pid: b133e361e2f8af22b823d25060b2e7c47f690985
  title: Segmentation from Natural Language Expressions
- pid: 8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5
  title: Analyzing the Behavior of Visual Question Answering Models
- pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: 1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7
  title: 'MovieQA: Understanding Stories in Movies through Question-Answering'
- pid: e58a110fa1e4ddf247d5c614d117d64bfbe135c4
  title: Sequence to Sequence -- Video to Text
- pid: 75ddc7ee15be14013a3462c01b38b0548486fbcb
  title: Learning to Compose Neural Networks for Question Answering
- pid: 62a956d7600b10ca455076cd56e604dfd106072a
  title: Exploring Models and Data for Image Question Answering
- pid: 050da5d159fb0dd96143948e1cffeb3dec814673
  title: Visual Turing test for computer vision systems
- pid: 0612745dbd292fc0a548a16d39cd73e127faedde
  title: 'Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer
    Image-to-Sentence Models'
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: 13549b4e6fffbb7932b7a83a8eb6be27e6a60eca
  title: What Are You Talking About? Text-to-Image Coreference
- pid: 6e565308c8081e807709cb4a917443b737e6cdb4
  title: Large-scale Simple Question Answering with Memory Networks
- pid: 05dd7254b632376973f3a1b4d39485da17814df5
  title: 'SQuAD: 100,000+ Questions for Machine Comprehension of Text'
- pid: a5ea0da7b93452bec54b5034706f2255bfb5a8f3
  title: A dataset for Movie Description
- pid: 2935d8071583e46c5a895730c65d2bd213757c07
  title: Joint Video and Text Parsing for Understanding Events and Answering Queries
- pid: d1505c6123c102e53eb19dff312cb25cea840b72
  title: Teaching Machines to Read and Comprehend
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: 4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0
  title: 'SSD: Single Shot MultiBox Detector'
- pid: 8a960ea40fe7b32a1ee702a84f64ec1de5c3e7fe
  title: 'VizWiz: nearly real-time answers to visual questions'
- pid: e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d
  title: Human-level control through deep reinforcement learning
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: 846aedd869a00c09b40f1f1f35673cb22bc87490
  title: Mastering the game of Go with deep neural networks and tree search
- pid: 10d85561e4aafc516d10064f30dff05b41f70afe
  title: '[Et al].'
slug: Visual-Dialog-Das-Kottur
title: Visual Dialog
url: https://www.semanticscholar.org/paper/Visual-Dialog-Das-Kottur/2231f44be9a8472a46d8e8a628b4e52b9a8f44e0?sort=total-citations
venue: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2017
