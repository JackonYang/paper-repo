authors:
- H. White
badges: []
corpusId: 43711678
fieldsOfStudy:
- Computer Science
numCitedBy: 1012
numCiting: 83
paperAbstract: The premise of this article is that learning procedures used to train
  artificial neural networks are inherently statistical techniques. It follows that
  statistical theory can provide considerable insight into the properties, advantages,
  and disadvantages of different network learning methods. We review concepts and
  analytical results from the literatures of mathematical statistics, econometrics,
  systems identification, and optimization theory relevant to the analysis of learning
  in artificial neural networks. Because of the considerable variety of available
  learning procedures and necessary limitations of space, we cannot provide a comprehensive
  treatment. Our focus is primarily on learning procedures for feedforward networks.
  However, many of the concepts and issues arising in this framework are also quite
  broadly relevant to other network learning paradigms. In addition to providing useful
  insights, the material reviewed here suggests some potentially useful new training
  methods for artificial neural networks.
ref_count: 83
references:
- pid: 72d761afbe35634213849419ff63fad5bc9fabeb
  title: Statistical properties of artificial neural networks
- pid: b10440620da8a43a1b97e3da4b1ff13746306475
  title: 'Consistent inference of probabilities in layered networks: predictions and
    generalizations'
- pid: 77fdd39ab366b65a617015a72fe8dc9d0b394d64
  title: 'Connectionist nonparametric regression: Multilayer feedforward networks
    can learn arbitrary mappings'
- pid: ee7f0bc85b339d781c2e0c7e6db8e339b6b9fec2
  title: Universal approximation using feedforward networks with non-sigmoid hidden
    layer activation functions
- pid: 8da1dda34ecc96263102181448c94ec7d645d085
  title: Approximation by superpositions of a sigmoidal function
- pid: 386cbc45ceb59a7abb844b5078e5c944f17723b4
  title: On the approximate realization of continuous mappings by neural networks
- pid: 25406e6733a698bfc4ac836f8e74f458e75dad4f
  title: What Size Net Gives Valid Generalization?
- pid: 2e62d1345b340d5fda3b092c460264b9543bc4b5
  title: Genetic Algorithms in Search Optimization and Machine Learning
- pid: d474299d7a51b89a1d7394d426cf881a89b8013d
  title: Efficient distribution-free learning of probabilistic concepts
- pid: f22f6972e66bdd2e769fa64b0df0a13063c0c101
  title: Multilayer feedforward networks are universal approximators
- pid: 4b4279db68b16e20fbc56f9d41980a950191d30a
  title: Adaptation in natural and artificial systems
- pid: dd5061631a4d11fa394f4421700ebf7e78dcbc59
  title: Optimization by Simulated Annealing
- pid: ef098e0154da4b210a6ee11b84ca30bd3e445ac6
  title: Iterative solution of nonlinear equations in several variables
- pid: 0009c5a2b4b07751a99bcf407d95e911a3064d0f
  title: wchastic. approximation methods for constrained and unconstrained systems
- pid: 37807e97c624fb846df7e559553b32539ba2ea5d
  title: Universal approximation of an unknown mapping and its derivatives using multilayer
    feedforward networks
- pid: 111fd833a4ae576cfdbb27d87d2f8fc0640af355
  title: Learning internal representations by error propagation
- pid: 555a7921231b86464a8db34ada9edade765bf8f0
  title: Stochastic Approximation
- pid: 7b28610d2d681a11398eb614de0d70d7de41c20c
  title: "Cross\u2010Validatory Choice and Assessment of Statistical Predictions"
- pid: 56623a496727d5c71491850e04512ddf4152b487
  title: 'Beyond Regression : "New Tools for Prediction and Analysis in the Behavioral
    Sciences'
slug: Learning-in-Artificial-Neural-Networks:-A-White
title: 'Learning in Artificial Neural Networks: A Statistical Perspective'
url: https://www.semanticscholar.org/paper/Learning-in-Artificial-Neural-Networks:-A-White/656a33c1db546da8490d6eba259e2a849d73a001?sort=total-citations
venue: Neural Computation
year: 1989
