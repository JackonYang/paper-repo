authors:
- R. Lippmann
badges:
- id: OPEN_ACCESS
corpusId: 8275028
fieldsOfStudy:
- Computer Science
numCitedBy: 3816
numCiting: 44
paperAbstract: Artificial neural net models have been studied for many years in the
  hope of achieving human-like performance in the fields of speech and image recognition.
  These models are composed of many nonlinear computational elements operating in
  parallel and arranged in patterns reminiscent of biological neural nets. Computational
  elements or nodes are connected via weights that are typically adapted during use
  to improve performance. There has been a recent resurgence in the field of artificial
  neural nets caused by new net topologies and algorithms, analog VLSI implementation
  techniques, and the belief that massive parallelism is essential for high performance
  speech and image recognition. This paper provides an introduction to the field of
  artificial neural nets by reviewing six important neural net models that can be
  used for pattern classification. These nets are highly parallel building blocks
  that illustrate neural net components and design principles and can be used to construct
  more complex systems. In addition to describing these nets, a major emphasis is
  placed on exploring how some existing classification and clustering algorithms can
  be performed using simple neuron-like components. Single-layer nets can implement
  algorithms required by Gaussian maximum-likelihood classifiers and optimum minimum-error
  classifiers for binary patterns corrupted by noise. More generally, the decision
  regions required by any classification algorithm can be generated in a straightforward
  manner by three-layer feed-forward nets.
ref_count: 44
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 288
  pid: c86590e947c28e8791d1e8bab8fc8ab53302341f
  title: Learning the hidden structure of speech.
  year: 1988
- fieldsOfStudy:
  - Biology
  numCitedBy: 6274
  pid: 24b9eebe49cf7e00cf50cf7b7d9243386a23fe7c
  title: Neurons with graded response have collective computational properties like
    those of two-state neurons.
  year: 1984
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 16692
  pid: 98b4d4e24aab57ab4e1124ff8106909050645cfa
  title: Neural networks and physical systems with emergent collective computational
    abilities.
  year: 1982
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 903
  pid: a3f073ac7513183a9bf3a76154dcd245748d2ab6
  title: Vector quantization in speech coding
  year: 1985
- fieldsOfStudy:
  - Mathematics
  numCitedBy: 2238
  pid: 00e6b6ea28c0217d7c7e90824c17b37528f69104
  title: Absolute stability of global pattern formation and parallel memory storage
    by competitive neural networks
  year: 1983
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 16926
  pid: b07ce649d6f6eb636872527104b0209d3edc8188
  title: Pattern classification and scene analysis
  year: 1973
- fieldsOfStudy:
  - Biology
  numCitedBy: 19356
  pid: 111fd833a4ae576cfdbb27d87d2f8fc0640af355
  title: Learning internal representations by error propagation
  year: 1986
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2797
  pid: 6e163fb03f549ab2bb1dbbf746005553ea15a575
  title: Information Theory and Reliable Communication
  year: 1969
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2603
  pid: 2e14b2ff9dc2234df94fc24d89fc25e797d0e9e7
  title: Adaptive switching circuits
  year: 1988
slug: An-introduction-to-computing-with-neural-nets-Lippmann
title: An introduction to computing with neural nets
url: https://www.semanticscholar.org/paper/An-introduction-to-computing-with-neural-nets-Lippmann/b8778bb692cf105254fe767ef11a3a8afac4a068?sort=total-citations
venue: IEEE ASSP Magazine
year: 1987
