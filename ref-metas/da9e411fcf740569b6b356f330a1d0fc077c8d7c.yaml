authors:
- K. Soomro
- A. Zamir
- M. Shah
badges:
- id: OPEN_ACCESS
corpusId: 7197134
fieldsOfStudy:
- Computer Science
numCitedBy: 3637
numCiting: 21
paperAbstract: We introduce UCF101 which is currently the largest dataset of human
  actions. It consists of 101 action classes, over 13k clips and 27 hours of video
  data. The database consists of realistic user uploaded videos containing camera
  motion and cluttered background. Additionally, we provide baseline action recognition
  results on this new dataset using standard bag of words approach with overall performance
  of 44.5%. To the best of our knowledge, UCF101 is currently the most challenging
  dataset of actions due to its large number of classes, large number of clips and
  also unconstrained nature of such clips.
ref_count: 21
references:
- pid: 8b3b8848a311c501e704c45c6d50430ab7068956
  title: 'HMDB: A large video database for human motion recognition'
- pid: aca29d7bbbf54078f842c8ca1d75d8d8c68191d2
  title: "Recognizing realistic actions from videos \u201Cin the wild\u201D"
- pid: b786e478cf0be6fcfaeb7812e25da85523236855
  title: 'Recognizing human actions: a local SVM approach'
- pid: b705317a618911b5f6e611181eeeece0a7079f80
  title: Actions in context
- pid: 1a9eb04b9b07d4a58aa78eb9f68a77ade0199fab
  title: Actions as space-time shapes
- pid: 994a7b903b937f8b177c035db86852091fd26aa7
  title: Modeling Temporal Structure of Decomposable Motion Segments for Activity
    Classification
- pid: 1c2629d53fd73ee42fb9a67b4d656688ef6a005f
  title: Action MACH a spatio-temporal Maximum Average Correlation Height filter for
    action recognition
- pid: 32fad849f86bb99d824150e9373c352219edd4ed
  title: Detecting Carried Objects in Short Video Sequences
slug: UCF101:-A-Dataset-of-101-Human-Actions-Classes-From-Soomro-Zamir
title: 'UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild'
url: https://www.semanticscholar.org/paper/UCF101:-A-Dataset-of-101-Human-Actions-Classes-From-Soomro-Zamir/da9e411fcf740569b6b356f330a1d0fc077c8d7c?sort=total-citations
venue: ArXiv
year: 2012
