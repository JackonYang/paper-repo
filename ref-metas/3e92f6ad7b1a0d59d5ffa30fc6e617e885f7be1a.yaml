authors:
- Huaizu Jiang
- Ishan Misra
- Marcus Rohrbach
- E. Learned-Miller
- Xinlei Chen
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 210156985
fieldsOfStudy:
- Computer Science
meta_key: in-defense-of-grid-features-for-visual-question-answering
numCitedBy: 112
numCiting: 64
paperAbstract: Popularized as `bottom-up' attention, bounding box (or region) based
  visual features have recently surpassed vanilla grid-based convolutional features
  as the de facto standard for vision and language tasks like visual question answering
  (VQA). However, it is not clear whether the advantages of regions (e.g. better localization)
  are the key reasons for the success of bottom-up attention. In this paper, we revisit
  grid features for VQA, and find they can work surprisingly well -- running more
  than an order of magnitude faster with the same accuracy (e.g. if pre-trained in
  a similar fashion). Through extensive experiments, we verify that this observation
  holds true across different VQA models (reporting a state-of-the-art accuracy on
  VQA 2.0 test-std, 72.71), datasets, and generalizes well to other tasks like image
  captioning. As grid features make the model design and training process much simpler,
  this enables us to train them end-to-end and also use a more flexible network design.
  We learn VQA models end-to-end, from pixels directly to answers, and show that strong
  performance is achievable without using any region annotations in pre-training.
  We hope our findings help further improve the scientific understanding and the practical
  application of VQA. Code and features will be made available.
ref_count: 64
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering
  numCitedBy: 2275
  pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  show_ref_link: true
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: making-the-v-in-vqa-matter-elevating-the-role-of-image-understanding-in-visual-question-answering
  numCitedBy: 1162
  pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  show_ref_link: true
  title: 'Making the V in VQA Matter: Elevating the Role of Image Understanding in
    Visual Question Answering'
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: answer-them-all-toward-universal-visual-question-answering-models
  numCitedBy: 53
  pid: d9344534ab39544a3a3c173b27628e0d9c5d4dc5
  show_ref_link: false
  title: Answer Them All! Toward Universal Visual Question Answering Models
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-to-count-objects-in-natural-images-for-visual-question-answering
  numCitedBy: 148
  pid: 30a3eee5e9302108416f6234d739373dde68d373
  show_ref_link: true
  title: Learning to Count Objects in Natural Images for Visual Question Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-modular-co-attention-networks-for-visual-question-answering
  numCitedBy: 323
  pid: 8a1744da011375d711ed75fc2d160c6fdca2cf89
  show_ref_link: true
  title: Deep Modular Co-Attention Networks for Visual Question Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: beyond-bilinear-generalized-multimodal-factorized-high-order-pooling-for-visual-question-answering
  numCitedBy: 266
  pid: 0c0f41d3162e76500d4639557ff4463bd246e395
  show_ref_link: true
  title: 'Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for
    Visual Question Answering'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: unified-vision-language-pre-training-for-image-captioning-and-vqa
  numCitedBy: 355
  pid: 6648b4db5f12c30941ea78c695e77aded19672bb
  show_ref_link: true
  title: Unified Vision-Language Pre-Training for Image Captioning and VQA
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: multimodal-compact-bilinear-pooling-for-visual-question-answering-and-visual-grounding
  numCitedBy: 1086
  pid: fddc15480d086629b960be5bff96232f967f2252
  show_ref_link: true
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: towards-vqa-models-that-can-read
  numCitedBy: 180
  pid: af1f7739283bdbd2b7a94903041f6d6afd991907
  show_ref_link: true
  title: Towards VQA Models That Can Read
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: tips-and-tricks-for-visual-question-answering-learnings-from-the-2017-challenge
  numCitedBy: 286
  pid: b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81
  show_ref_link: true
  title: 'Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: vqa-visual-question-answering
  numCitedBy: 2887
  pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  show_ref_link: true
  title: 'VQA: Visual Question Answering'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: show-and-tell-a-neural-image-caption-generator
  numCitedBy: 4510
  pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  show_ref_link: true
  title: 'Show and tell: A neural image caption generator'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: feature-pyramid-networks-for-object-detection
  numCitedBy: 9352
  pid: b9b4e05faa194e5022edd9eb9dd07e3d675c2b36
  show_ref_link: true
  title: Feature Pyramid Networks for Object Detection
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: vizwiz-grand-challenge-answering-visual-questions-from-blind-people
  numCitedBy: 202
  pid: a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c
  show_ref_link: false
  title: 'VizWiz Grand Challenge: Answering Visual Questions from Blind People'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: interpretable-counting-for-visual-question-answering
  numCitedBy: 45
  pid: 0605a012aeeee9bef773812a533c4f3cb7fa5a5f
  show_ref_link: false
  title: Interpretable Counting for Visual Question Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: very-deep-convolutional-networks-for-large-scale-image-recognition
  numCitedBy: 62220
  pid: eb42cf88027de515750f230b23b1a057dc782108
  show_ref_link: true
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: uniter-learning-universal-image-text-representations
  numCitedBy: 282
  pid: 54416048772b921720f19869ed11c2a360589d03
  show_ref_link: true
  title: 'UNITER: Learning UNiversal Image-TExt Representations'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations
  numCitedBy: 2772
  pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  show_ref_link: true
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks
  numCitedBy: 1266
  pid: 65a9c7b0800c86a196bc14e7621ff895cc6ab287
  show_ref_link: true
  title: 'ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language
    Tasks'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: uniter-universal-image-text-representation-learning
  numCitedBy: 577
  pid: d8a305b9366608d54452ac30459ee57b4f5cf1c9
  show_ref_link: true
  title: 'UNITER: UNiversal Image-TExt Representation Learning'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: visualbert-a-simple-and-performant-baseline-for-vision-and-language
  numCitedBy: 630
  pid: 5aec474c31a2f4b74703c6f786c0a8ff85c450da
  show_ref_link: true
  title: 'VisualBERT: A Simple and Performant Baseline for Vision and Language'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: pythia-v0-1-the-winning-entry-to-the-vqa-challenge-2018
  numCitedBy: 140
  pid: 36c3972569a6949ecca90bfa6f8e99883e092845
  show_ref_link: true
  title: 'Pythia v0.1: the Winning Entry to the VQA Challenge 2018'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: vl-bert-pre-training-of-generic-visual-linguistic-representations
  numCitedBy: 707
  pid: 2527626c11a84f15709e943fbfa2356e19930e3b
  show_ref_link: true
  title: 'VL-BERT: Pre-training of Generic Visual-Linguistic Representations'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: show-attend-and-tell-neural-image-caption-generation-with-visual-attention
  numCitedBy: 7252
  pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  show_ref_link: true
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: stacked-attention-networks-for-image-question-answering
  numCitedBy: 1474
  pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  show_ref_link: true
  title: Stacked Attention Networks for Image Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: film-visual-reasoning-with-a-general-conditioning-layer
  numCitedBy: 831
  pid: 7cfa5c97164129ce3630511f639040d28db1d4b7
  show_ref_link: true
  title: 'FiLM: Visual Reasoning with a General Conditioning Layer'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: neural-symbolic-vqa-disentangling-reasoning-from-vision-and-language-understanding
  numCitedBy: 301
  pid: 9d15ebe3f5aaf32a9f835f88703241461324c35b
  show_ref_link: true
  title: 'Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: attention-is-all-you-need
  numCitedBy: 35148
  pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  show_ref_link: true
  title: Attention is All you Need
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-residual-learning-for-image-recognition
  numCitedBy: 95314
  pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  show_ref_link: true
  title: Deep Residual Learning for Image Recognition
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding
  numCitedBy: 33744
  pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  show_ref_link: true
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: aggregated-residual-transformations-for-deep-neural-networks
  numCitedBy: 5483
  pid: f6e0856b4a9199fa968ac00da612a9407b5cb85c
  show_ref_link: true
  title: Aggregated Residual Transformations for Deep Neural Networks
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks
  numCitedBy: 32561
  pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  show_ref_link: true
  title: 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: bilinear-attention-networks
  numCitedBy: 408
  pid: a5d10341717c0519cf63151b496a6d2ed67aa05f
  show_ref_link: true
  title: Bilinear Attention Networks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: microsoft-coco-common-objects-in-context
  numCitedBy: 19778
  pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  show_ref_link: true
  title: 'Microsoft COCO: Common Objects in Context'
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: long-term-recurrent-convolutional-networks-for-visual-recognition-and-description
  numCitedBy: 4084
  pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  show_ref_link: true
  title: Long-term recurrent convolutional networks for visual recognition and description
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: cider-consensus-based-image-description-evaluation
  numCitedBy: 2153
  pid: 258986132bf17755fe8263e42429fe73218c1534
  show_ref_link: true
  title: 'CIDEr: Consensus-based image description evaluation'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: ssd-single-shot-multibox-detector
  numCitedBy: 15423
  pid: 4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0
  show_ref_link: true
  title: 'SSD: Single Shot MultiBox Detector'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: focal-loss-for-dense-object-detection
  numCitedBy: 8230
  pid: 72564a69bf339ff1d16a639c86a764db2321caab
  show_ref_link: true
  title: Focal Loss for Dense Object Detection
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: focal-loss-for-dense-object-detection
  numCitedBy: 3953
  pid: 79cfb51a51fc093f66aac8e858afe2e14d4a1f20
  show_ref_link: true
  title: Focal Loss for Dense Object Detection
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-visual-semantic-alignments-for-generating-image-descriptions
  numCitedBy: 2575
  pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  show_ref_link: true
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: deformable-convnets-v2-more-deformable-better-results
  numCitedBy: 683
  pid: 987b2db58fbe0bda771f11a046cd23de1ce92b39
  show_ref_link: true
  title: 'Deformable ConvNets V2: More Deformable, Better Results'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: spice-semantic-propositional-image-caption-evaluation
  numCitedBy: 912
  pid: 1c54acd7d9ed8017acdc5674c9b7faac738fd651
  show_ref_link: true
  title: 'SPICE: Semantic Propositional Image Caption Evaluation'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: pyramid-scene-parsing-network
  numCitedBy: 5543
  pid: 1031a69923b80ad01cf3fbb703d10757a80e699b
  show_ref_link: true
  title: Pyramid Scene Parsing Network
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: lxmert-learning-cross-modality-encoder-representations-from-transformers
  numCitedBy: 916
  pid: 79c93274429d6355959f1e4374c2147bb81ea649
  show_ref_link: true
  title: 'LXMERT: Learning Cross-Modality Encoder Representations from Transformers'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: a-simple-neural-network-module-for-relational-reasoning
  numCitedBy: 1197
  pid: 007112213ece771be72cbecfd59f048209facabd
  show_ref_link: true
  title: A simple neural network module for relational reasoning
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: clevr-a-diagnostic-dataset-for-compositional-language-and-elementary-visual-reasoning
  numCitedBy: 1223
  pid: 03eb382e04cca8cca743f7799070869954f1402a
  show_ref_link: true
  title: 'CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual
    Reasoning'
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: unified-perceptual-parsing-for-scene-understanding
  numCitedBy: 425
  pid: aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1
  show_ref_link: false
  title: Unified Perceptual Parsing for Scene Understanding
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: adam-a-method-for-stochastic-optimization
  numCitedBy: 90052
  pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  show_ref_link: true
  title: 'Adam: A Method for Stochastic Optimization'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: glove-global-vectors-for-word-representation
  numCitedBy: 22534
  pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  show_ref_link: true
  title: 'GloVe: Global Vectors for Word Representation'
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: imagenet-a-large-scale-hierarchical-image-database
  numCitedBy: 27402
  pid: 1b47265245e8db53a553049dcb27ed3e495fd625
  show_ref_link: true
  title: 'ImageNet: A large-scale hierarchical image database'
  year: 2009
- fieldsOfStudy:
  - Computer Science
  meta_key: referitgame-referring-to-objects-in-photographs-of-natural-scenes
  numCitedBy: 563
  pid: 92c141447f51b6732242376164ff961e464731c8
  show_ref_link: false
  title: 'ReferItGame: Referring to Objects in Photographs of Natural Scenes'
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: exploring-nearest-neighbor-approaches-for-image-captioning
  numCitedBy: 166
  pid: 3ca194773fe583661b988fbdf33f7680764438b3
  show_ref_link: false
  title: Exploring Nearest Neighbor Approaches for Image Captioning
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: microsoft-coco-captions-data-collection-and-evaluation-server
  numCitedBy: 1178
  pid: 696ca58d93f6404fea0fc75c62d1d7b378f47628
  show_ref_link: true
  title: 'Microsoft COCO Captions: Data Collection and Evaluation Server'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: meteor-an-automatic-metric-for-mt-evaluation-with-high-levels-of-correlation-with-human-judgments
  numCitedBy: 809
  pid: 34d7a07c493ca6336c92156806a2947e115caadc
  show_ref_link: false
  title: 'METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation
    with Human Judgments'
  year: 2007
- fieldsOfStudy:
  - Computer Science
  meta_key: bleu-a-method-for-automatic-evaluation-of-machine-translation
  numCitedBy: 16615
  pid: d7da009f457917aa381619facfa5ffae9329a6e9
  show_ref_link: true
  title: 'Bleu: a Method for Automatic Evaluation of Machine Translation'
  year: 2002
- fieldsOfStudy:
  - Computer Science
  meta_key: yfcc100m-the-new-data-in-multimedia-research
  numCitedBy: 914
  pid: 354c029c88be2bbc27dfd2e2e729c0ae622511e6
  show_ref_link: true
  title: 'YFCC100M: the new data in multimedia research'
  year: 2016
- fieldsOfStudy:
  - Psychology
  meta_key: symbol-grounding-problem
  numCitedBy: 1523
  pid: 026ff33083c647bd3a3734d41904d880a6525d13
  show_ref_link: false
  title: Symbol grounding problem
  year: 2007
- fieldsOfStudy:
  - Computer Science
  meta_key: mask-r-cnn
  numCitedBy: 9771
  pid: 022dd244f2e25525eb37e9dda51abb9cd8ca8c30
  show_ref_link: true
  title: Mask R-CNN
  year: 2020
slug: In-Defense-of-Grid-Features-for-Visual-Question-Jiang-Misra
title: In Defense of Grid Features for Visual Question Answering
url: https://www.semanticscholar.org/paper/In-Defense-of-Grid-Features-for-Visual-Question-Jiang-Misra/3e92f6ad7b1a0d59d5ffa30fc6e617e885f7be1a?sort=total-citations
venue: 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2020
