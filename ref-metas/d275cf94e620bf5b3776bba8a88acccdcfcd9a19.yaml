authors:
- Radford M. Neal
badges:
- id: OPEN_ACCESS
corpusId: 16302605
fieldsOfStudy:
- Computer Science
numCitedBy: 213
numCiting: 6
paperAbstract: The attempt to find a single "optimal" weight vector in conventional
  network training can lead to overfitting and poor generalization. Bayesian methods
  avoid this, without the need for a validation set, by averaging the outputs of many
  networks with weights sampled from the posterior distribution given the training
  data. This sample can be obtained by simulating a stochastic dynamical system that
  has the posterior as its stationary distribution.
ref_count: 6
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2590
  pid: b959164d1efca4b73986ba5d21e664aadbbc0457
  title: A Practical Bayesian Framework for Backpropagation Networks
  year: 1992
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 376
  pid: c83684f6207697c12850db423fd9747572cf1784
  title: Bayesian Back-Propagation
  year: 1991
- fieldsOfStudy:
  - Physics
  numCitedBy: 2584
  pid: 22ea20339015130099017185e7f36e87933c6a43
  title: Hybrid Monte Carlo
  year: 1987
- fieldsOfStudy:
  - Physics
  numCitedBy: 32417
  pid: f6a13f116e270dde9d67848495f801cdb8efa25d
  title: Equation of state calculations by fast computing machines
  year: 1953
slug: Bayesian-Learning-via-Stochastic-Dynamics-Neal
title: Bayesian Learning via Stochastic Dynamics
url: https://www.semanticscholar.org/paper/Bayesian-Learning-via-Stochastic-Dynamics-Neal/d275cf94e620bf5b3776bba8a88acccdcfcd9a19?sort=total-citations
venue: NIPS
year: 1992
