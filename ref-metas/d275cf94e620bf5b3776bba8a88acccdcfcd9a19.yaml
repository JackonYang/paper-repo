authors:
- Radford M. Neal
badges:
- id: OPEN_ACCESS
corpusId: 16302605
fieldsOfStudy:
- Computer Science
numCitedBy: 213
numCiting: 6
paperAbstract: The attempt to find a single "optimal" weight vector in conventional
  network training can lead to overfitting and poor generalization. Bayesian methods
  avoid this, without the need for a validation set, by averaging the outputs of many
  networks with weights sampled from the posterior distribution given the training
  data. This sample can be obtained by simulating a stochastic dynamical system that
  has the posterior as its stationary distribution.
ref_count: 6
references:
- pid: b959164d1efca4b73986ba5d21e664aadbbc0457
  title: A Practical Bayesian Framework for Backpropagation Networks
- pid: c83684f6207697c12850db423fd9747572cf1784
  title: Bayesian Back-Propagation
- pid: 22ea20339015130099017185e7f36e87933c6a43
  title: Hybrid Monte Carlo
- pid: f6a13f116e270dde9d67848495f801cdb8efa25d
  title: Equation of state calculations by fast computing machines
slug: Bayesian-Learning-via-Stochastic-Dynamics-Neal
title: Bayesian Learning via Stochastic Dynamics
url: https://www.semanticscholar.org/paper/Bayesian-Learning-via-Stochastic-Dynamics-Neal/d275cf94e620bf5b3776bba8a88acccdcfcd9a19?sort=total-citations
venue: NIPS
year: 1992
