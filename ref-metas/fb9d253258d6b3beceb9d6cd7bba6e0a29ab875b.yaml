authors:
- Jiasen Lu
- Jianwei Yang
- Dhruv Batra
- Devi Parikh
badges:
- id: OPEN_ACCESS
corpusId: 868693
fieldsOfStudy:
- Computer Science
numCitedBy: 1121
numCiting: 32
paperAbstract: A number of recent works have proposed attention models for Visual
  Question Answering (VQA) that generate spatial maps highlighting image regions relevant
  to answering the question. In this paper, we argue that in addition to modeling
  "where to look" or visual attention, it is equally important to model "what words
  to listen to" or question attention. We present a novel co-attention model for VQA
  that jointly reasons about image and question attention. In addition, our model
  reasons about the question (and consequently the image via the co-attention mechanism)
  in a hierarchical fashion via a novel 1-dimensional convolution neural networks
  (CNN). Our model improves the state-of-the-art on the VQA dataset from 60.3% to
  60.5%, and from 61.6% to 63.3% on the COCO-QA dataset. By using ResNet, the performance
  is further improved to 62.1% for VQA and 65.4% for COCO-QA.
ref_count: 32
references:
- pid: 1cf6bc0866226c1f8e282463adc8b75d92fba9bb
  title: 'Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for
    Visual Question Answering'
- pid: 7214daf035ab005b3d1e739750dd597b4f4513fa
  title: A Focused Dynamic Attention Model for Visual Question Answering
- pid: def584565d05d6a8ba94de6621adab9e301d375d
  title: 'Visual7W: Grounded Question Answering in Images'
- pid: 58cb0c24c936b8a14ca7b2d56ba80de733c545b3
  title: 'Human Attention in Visual Question Answering: Do Humans and Deep Networks
    look at the same regions?'
- pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  title: Stacked Attention Networks for Image Question Answering
- pid: bd7bd1d2945a58cdcc1797ba9698b8810fe68f60
  title: 'Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images'
- pid: 62a956d7600b10ca455076cd56e604dfd106072a
  title: Exploring Models and Data for Image Question Answering
- pid: 5fa973b8d284145bf0ced9acf2913a74674260f6
  title: 'Yin and Yang: Balancing and Answering Binary Visual Questions'
- pid: 98bd5dd1740f585bf25320ba504e2c1ae57f2e5f
  title: Learning to Answer Questions from Image Using Convolutional Neural Network
- pid: fddc15480d086629b960be5bff96232f967f2252
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: f96898d15a1bf1fa8925b1280d0e07a7a8e72194
  title: Dynamic Memory Networks for Visual and Textual Question Answering
- pid: 2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1
  title: Are You Talking to a Machine? Dataset and Methods for Multilingual Image
    Question
- pid: 0ac8f1a3c679b90d22c1f840cdc8d61ffef750ac
  title: Deep Compositional Question Answering with Neural Module Networks
- pid: 175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22
  title: 'Where to Look: Focus Regions for Visual Question Answering'
- pid: 1afb710a5b35a2352a6495e4bf6eef66808daf1b
  title: Multimodal Residual Learning for Visual QA
- pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: 2846e83d405cbe3bf2f0f3b5f635dd8b3c680c45
  title: Reasoning about Entailment with Neural Attention
- pid: 9f08b01251cb99f4ffae8c7b3e4468d3af9c98d3
  title: Convolutional Neural Network Architectures for Matching Natural Language
    Sentences
- pid: e15cf50aa89fee8535703b9f9512fca5bfc43327
  title: Going deeper with convolutions
- pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
- pid: d1505c6123c102e53eb19dff312cb25cea840b72
  title: Teaching Machines to Read and Comprehend
- pid: 0e3e3c3d8ae5cb7c4636870d69967c197484d3bb
  title: Verb Semantics and Lexical Selection
- pid: 3449b65008b27f6e60a73d80c1fd990f0481126b
  title: 'Torch7: A Matlab-like Environment for Machine Learning'
slug: Hierarchical-Question-Image-Co-Attention-for-Visual-Lu-Yang
title: Hierarchical Question-Image Co-Attention for Visual Question Answering
url: https://www.semanticscholar.org/paper/Hierarchical-Question-Image-Co-Attention-for-Visual-Lu-Yang/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b?sort=total-citations
venue: NIPS
year: 2016
