authors:
- Yukun Zhu
- Ryan Kiros
- R. Zemel
- R. Salakhutdinov
- R. Urtasun
- A. Torralba
- S. Fidler
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 6866988
fieldsOfStudy:
- Computer Science
numCitedBy: 1419
numCiting: 52
paperAbstract: Books are a rich source of both fine-grained information, how a character,
  an object or a scene looks like, as well as high-level semantics, what someone is
  thinking, feeling and how these states evolve through a story. This paper aims to
  align books to their movie releases in order to provide rich descriptive explanations
  for visual content that go semantically far beyond the captions available in the
  current datasets. To align movies and books we propose a neural sentence embedding
  that is trained in an unsupervised way from a large corpus of books, as well as
  a video-text neural embedding for computing similarities between movie clips and
  sentences in the book. We propose a context-aware CNN to combine information from
  multiple sources. We demonstrate good quantitative performance for movie/book alignment
  and show several qualitative examples that showcase the diversity of tasks our model
  can be used for.
ref_count: 52
references:
- pid: a5ea0da7b93452bec54b5034706f2255bfb5a8f3
  title: A dataset for Movie Description
- pid: c980b058f98dc1904ad328c2341a47c31479d076
  title: 'Movie/Script: Alignment and Parsing of Video and Text Transcription'
- pid: eaaed23a2d94feb2f1c3ff22a25777c7a78f3141
  title: 'Every Picture Tells a Story: Generating Sentences from Images'
- pid: 6e795c6e9916174ae12349f5dc3f516570c17ce8
  title: Skip-Thought Vectors
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
- pid: 9814df8bd00ba999c4d1e305a7e9bca579dc7c75
  title: 'Framing Image Description as a Ranking Task: Data, Models and Evaluation
    Metrics (Extended Abstract)'
- pid: 2e36ea91a3c8fbff92be2989325531b4002e2afc
  title: Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
- pid: 0ca7d208ff8d81377e0eaa9723820aeae7a7322d
  title: Grounded Compositional Semantics for Finding and Describing Images with Sentences
- pid: 13549b4e6fffbb7932b7a83a8eb6be27e6a60eca
  title: What Are You Talking About? Text-to-Image Coreference
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: 43795b7bac3d921c4e579964b54187bdbf6c6330
  title: Translating Videos to Natural Language Using Deep Recurrent Neural Networks
- pid: e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd
  title: 'Don''t just listen, use your imagination: Leveraging visual common sense
    for non-visual tasks'
- pid: 82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9
  title: Explain Images with Multimodal Recurrent Neural Networks
- pid: 7afd833f484c8032e7fdc5f53188d2ebb0fb9934
  title: 'Visual Semantic Search: Retrieving Videos via Complex Textual Queries'
- pid: dfe448d6297ea0a3d4deba21fbf1006bc35877d7
  title: Inferring the Why in Images
- pid: 169b847e69c35cfd475eb4dcc561a24de11762ca
  title: 'Baby talk: Understanding and generating simple image descriptions'
- pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
- pid: 944a1cfd79dbfb6fef460360a0765ba790f4027a
  title: Recurrent Continuous Translation Models
- pid: a4aba56927d7841c0aaedf5c73d42ccfadd75124
  title: Hello! My name is... Buffy'' -- Automatic Naming of Characters in TV Video
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: 9667f8264745b626c6173b1310e2ff0298b09cfc
  title: Learning Deep Features for Scene Recognition using Places Database
- pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
- pid: 8e523721feebeaee18e487607b7d0920ac6cd3b4
  title: 'Beyond Nouns: Exploiting Prepositions and Comparative Adjectives for Learning
    Visual Classifiers'
- pid: 0b544dfe355a5070b60986319a3f51fb45d1348e
  title: "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical\
    \ Machine Translation"
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: e15cf50aa89fee8535703b9f9512fca5bfc43327
  title: Going deeper with convolutions
- pid: 330da625c15427c6e42ccfa3b747fb29e5835bf0
  title: Efficient Estimation of Word Representations in Vector Space
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: adfcf065e15fd3bc9badf6145034c84dfb08f204
  title: Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling
- pid: d7da009f457917aa381619facfa5ffae9329a6e9
  title: 'Bleu: a Method for Automatic Evaluation of Machine Translation'
slug: Aligning-Books-and-Movies:-Towards-Story-Like-by-Zhu-Kiros
title: 'Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching
  Movies and Reading Books'
url: https://www.semanticscholar.org/paper/Aligning-Books-and-Movies:-Towards-Story-Like-by-Zhu-Kiros/0e6824e137847be0599bb0032e37042ed2ef5045?sort=total-citations
venue: 2015 IEEE International Conference on Computer Vision (ICCV)
year: 2015
