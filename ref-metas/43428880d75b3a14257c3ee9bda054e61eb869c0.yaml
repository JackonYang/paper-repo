authors:
- Jonas Gehring
- Michael Auli
- David Grangier
- Denis Yarats
- Yann Dauphin
badges:
- id: OPEN_ACCESS
corpusId: 3648736
fieldsOfStudy:
- Computer Science
numCitedBy: 2422
numCiting: 52
paperAbstract: The prevalent approach to sequence to sequence learning maps an input
  sequence to a variable length output sequence via recurrent neural networks. We
  introduce an architecture based entirely on convolutional neural networks. Compared
  to recurrent models, computations over all elements can be fully parallelized during
  training and optimization is easier since the number of non-linearities is fixed
  and independent of the input length. Our use of gated linear units eases gradient
  propagation and we equip each decoder layer with a separate attention module. We
  outperform the accuracy of the deep LSTM setup of Wu et al. (2016) on both WMT'14
  English-German and WMT'14 English-French translation at an order of magnitude faster
  speed, both on GPU and CPU.
ref_count: 52
references:
- pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
- pid: 88caa4a0253a8b0076176745ebc072864eab66e1
  title: Language Modeling with Gated Convolutional Networks
- pid: 4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e
  title: End-To-End Memory Networks
- pid: b60abe57bc195616063be10638c6437358c81d1e
  title: Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation
- pid: 41f1d50c85d3180476c4c7b3eea121278b0d8474
  title: Pixel Recurrent Neural Networks
- pid: 3d2c6941a9b4608ba52b328369a3352db2092ae0
  title: 'Weight Normalization: A Simple Reparameterization to Accelerate Training
    of Deep Neural Networks'
- pid: 0b544dfe355a5070b60986319a3f51fb45d1348e
  title: "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical\
    \ Machine Translation"
- pid: 510e26733aaff585d65701b9f1be7ca9d5afc586
  title: 'Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts
    Layer'
- pid: 0936352b78a52bc5d2b5e3f04233efc56664af51
  title: Conditional Image Generation with PixelCNN Decoders
- pid: f37076f426023241f19cdc2fb0a0fd733a6fa7fa
  title: Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond
- pid: aa7bfd2304201afbb19971ebde87b17e40242e91
  title: On the importance of initialization and momentum in deep learning
- pid: 4d376d6978dad0374edfa6709c9556b42d3594d3
  title: 'Batch Normalization: Accelerating Deep Network Training by Reducing Internal
    Covariate Shift'
- pid: 84069287da0a6b488b8c933f3cb5be759cb6237e
  title: On the difficulty of training recurrent neural networks
- pid: b624504240fa52ab76167acfe3156150ca01cf3b
  title: Attention-Based Models for Speech Recognition
- pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: dbde7dfa6cae81df8ac19ef500c42db96c3d1edd
  title: 'Google''s Neural Machine Translation System: Bridging the Gap between Human
    and Machine Translation'
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 93499a7c7f699b6630a86fad964536f9423bb6d0
  title: Effective Approaches to Attention-based Neural Machine Translation
- pid: d6f2f611da110b5b5061731be3fc4c7f45d8ee23
  title: 'Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet
    Classification'
- pid: 34f25a8704614163c4095b3ee2fc969b60de4698
  title: 'Dropout: a simple way to prevent neural networks from overfitting'
- pid: 1af68821518f03568f913ab03fc02080247a27ff
  title: Neural Machine Translation of Rare Words with Subword Units
- pid: b71ac1e9fb49420d13e084ac67254a0bbd40f83f
  title: Understanding the difficulty of training deep feedforward neural networks
- pid: 5082a1a13daea5c7026706738f8528391a1e6d59
  title: A Neural Attention Model for Abstractive Sentence Summarization
- pid: cd62c9976534a6a2096a38244f6cbb03635a127e
  title: Phoneme recognition using time-delay neural networks
- pid: 3449b65008b27f6e60a73d80c1fd990f0481126b
  title: 'Torch7: A Matlab-like Environment for Machine Learning'
- pid: 668087f0ae7ce1de6e0bd0965dbb480c08103260
  title: Finding Structure in Time
- pid: 7b5e31257f01aba987f16e175a3e49e00a5bd3bb
  title: A Simple, Fast, and Effective Reparameterization of IBM Model 2
- pid: 60b05f32c32519a809f21642ef1eb3eaf3848008
  title: 'ROUGE: A Package for Automatic Evaluation of Summaries'
- pid: 3fa4a8191e37b601877716858e6b1026e66e3c5c
  title: Linguistic Data Consortium
- pid: 563e821bb5ea825efb56b77484f5287f08cf3753
  title: Convolutional networks for images, speech, and time series
slug: Convolutional-Sequence-to-Sequence-Learning-Gehring-Auli
title: Convolutional Sequence to Sequence Learning
url: https://www.semanticscholar.org/paper/Convolutional-Sequence-to-Sequence-Learning-Gehring-Auli/43428880d75b3a14257c3ee9bda054e61eb869c0?sort=total-citations
venue: ICML
year: 2017
