authors:
- Volodymyr Mnih
- K. Kavukcuoglu
- David Silver
- Andrei A. Rusu
- J. Veness
- Marc G. Bellemare
- A. Graves
- Martin A. Riedmiller
- A. Fidjeland
- Georg Ostrovski
- Stig Petersen
- Charlie Beattie
- A. Sadik
- Ioannis Antonoglou
- Helen King
- D. Kumaran
- Daan Wierstra
- S. Legg
- D. Hassabis
badges:
- id: OPEN_ACCESS
corpusId: 205242740
fieldsOfStudy:
- Computer Science
numCitedBy: 16186
numCiting: 36
paperAbstract: 'The theory of reinforcement learning provides a normative account,
  deeply rooted in psychological and neuroscientific perspectives on animal behaviour,
  of how agents may optimize their control of an environment. To use reinforcement
  learning successfully in situations approaching real-world complexity, however,
  agents are confronted with a difficult task: they must derive efficient representations
  of the environment from high-dimensional sensory inputs, and use these to generalize
  past experience to new situations. Remarkably, humans and other animals seem to
  solve this problem through a harmonious combination of reinforcement learning and
  hierarchical sensory processing systems, the former evidenced by a wealth of neural
  data revealing notable parallels between the phasic signals emitted by dopaminergic
  neurons and temporal difference reinforcement learning algorithms. While reinforcement
  learning agents have achieved some successes in a variety of domains, their applicability
  has previously been limited to domains in which useful features can be handcrafted,
  or to domains with fully observed, low-dimensional state spaces. Here we use recent
  advances in training deep neural networks to develop a novel artificial agent, termed
  a deep Q-network, that can learn successful policies directly from high-dimensional
  sensory inputs using end-to-end reinforcement learning. We tested this agent on
  the challenging domain of classic Atari 2600 games. We demonstrate that the deep
  Q-network agent, receiving only the pixels and the game score as inputs, was able
  to surpass the performance of all previous algorithms and achieve a level comparable
  to that of a professional human games tester across a set of 49 games, using the
  same algorithm, network architecture and hyperparameters. This work bridges the
  divide between high-dimensional sensory inputs and actions, resulting in the first
  artificial agent that is capable of learning to excel at a diverse array of challenging
  tasks.'
ref_count: 36
references:
- pid: 97efafdb4a3942ab3efba53ded7413199f79c054
  title: 'Reinforcement Learning: An Introduction'
- pid: e60ff004dde5c13ec53087872cfcdd12e85beb57
  title: Learning Deep Architectures for AI
- pid: 69e68bfaadf2dccff800158749f5a50fe82d173b
  title: 'Neocognitron: A self-organizing neural network model for a mechanism of
    pattern recognition unaffected by shift in position'
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: 46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e
  title: Reducing the Dimensionality of Data with Neural Networks
- pid: ff2c2e3e83d1e8828695484728393c76ee07a101
  title: 'Parallel distributed processing: explorations in the microstructure of cognition,
    vol. 1: foundations'
- pid: 040c23e5a409fbdedd5032263dfcb1a4d7dfd200
  title: Object recognition with features inspired by visual cortex
- pid: d7fb932bca642615fcbcf3f5d26b2c26666603d3
  title: Shape and arrangement of columns in cat's striate cortex
- pid: 162d958ff885f1462aeda91cd72582323fd6a1f4
  title: Gradient-based learning applied to document recognition
- pid: a538b05ebb01a40323997629e171c91aa28b8e2f
  title: Rectified Linear Units Improve Restricted Boltzmann Machines
- pid: 1f88427d7aa8225e47f946ac41a0667d7b69ac52
  title: What is the best multi-stage architecture for object recognition?
- pid: 1c46943103bd7b7a2c7be86859995a4144d1938b
  title: Visualizing Data using t-SNE
slug: Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu
title: Human-level control through deep reinforcement learning
url: https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d?sort=total-citations
venue: Nature
year: 2015
