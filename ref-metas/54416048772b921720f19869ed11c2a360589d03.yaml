authors:
- Yen-Chun Chen
- Linjie Li
- Licheng Yu
- Ahmed El Kholy
- Faisal Ahmed
- Zhe Gan
- Yu Cheng
- Jingjing Liu
badges:
- id: OPEN_ACCESS
corpusId: 202889174
fieldsOfStudy:
- Computer Science
numCitedBy: 282
numCiting: 56
paperAbstract: 'Joint image-text embedding is the bedrock for most Vision-and-Language
  (V+L) tasks, where multimodality inputs are jointly processed for visual and textual
  understanding. In this paper, we introduce UNITER, a UNiversal Image-TExt Representation,
  learned through large-scale pre-training over four image-text datasets (COCO, Visual
  Genome, Conceptual Captions, and SBU Captions), which can power heterogeneous downstream
  V+L tasks with joint multimodal embeddings. We design three pre-training tasks:
  Masked Language Modeling (MLM), Image-Text Matching (ITM), and Masked Region Modeling
  (MRM, with three variants). Different from concurrent work on multimodal pre-training
  that apply joint random masking to both modalities, we use conditioned masking on
  pre-training tasks (i.e., masked language/region modeling is conditioned on full
  observation of image/text). Comprehensive analysis shows that conditioned masking
  yields better performance than unconditioned masking. We also conduct a thorough
  ablation study to find an optimal setting for the combination of pre-training tasks.
  Extensive experiments show that UNITER achieves new state of the art across six
  V+L tasks (over nine datasets), including Visual Question Answering, Image-Text
  Retrieval, Referring Expression Comprehension, Visual Commonsense Reasoning, Visual
  Entailment, and NLVR2.'
ref_count: 57
references:
- pid: 2bc1c8bd00bbf7401afcb5460277840fd8bab029
  title: 'Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal
    Pre-training'
- pid: b27e791e843c924ef052981b79490ab59fc0433d
  title: Learning Deep Structure-Preserving Image-Text Embeddings
- pid: 45dd2a3cd7c27f2e9509b023d702408f5ac11c9d
  title: Stacked Cross Attention for Image-Text Matching
- pid: 65a9c7b0800c86a196bc14e7621ff895cc6ab287
  title: 'ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language
    Tasks'
- pid: fddc15480d086629b960be5bff96232f967f2252
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
- pid: c41a11c0e9b8b92b4faaf97749841170b760760a
  title: 'VideoBERT: A Joint Model for Video and Language Representation Learning'
- pid: fdce9cbe5c726201575b3c8a8c1af0752f1af53f
  title: 'MAttNet: Modular Attention Network for Referring Expression Comprehension'
- pid: 7d0effebfa4bed19b6ba41f3af5b7e5b6890de87
  title: 'Context Encoders: Feature Learning by Inpainting'
- pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
- pid: 79c93274429d6355959f1e4374c2147bb81ea649
  title: 'LXMERT: Learning Cross-Modality Encoder Representations from Transformers'
- pid: 6548a60a6bcdf6c402d9de1c05ba7afe4f49fee9
  title: '12-in-1: Multi-Task Vision and Language Representation Learning'
- pid: 8a1744da011375d711ed75fc2d160c6fdca2cf89
  title: Deep Modular Co-Attention Networks for Visual Question Answering
- pid: 5aec474c31a2f4b74703c6f786c0a8ff85c450da
  title: 'VisualBERT: A Simple and Performant Baseline for Vision and Language'
- pid: 3c54b796cc10cb530f77caa4d18e1c80ac863822
  title: 'Visual Entailment: A Novel Task for Fine-Grained Image Understanding'
- pid: 2527626c11a84f15709e943fbfa2356e19930e3b
  title: 'VL-BERT: Pre-training of Generic Visual-Linguistic Representations'
- pid: b4df354db88a70183a64dbc9e56cf14e7669a6c0
  title: 'Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic
    Image Captioning'
- pid: fc1b1c9364c58ec406f494dd944b609a6a038ba6
  title: Unsupervised Visual Representation Learning by Context Prediction
- pid: aab368284210c1bb917ec2d31b84588e3d2d7eb4
  title: Unsupervised Representation Learning by Predicting Image Rotations
- pid: 0612745dbd292fc0a548a16d39cd73e127faedde
  title: 'Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer
    Image-to-Sentence Models'
- pid: 9405cc0d6169988371b2755e573cc28650d14dfe
  title: Language Models are Unsupervised Multitask Learners
- pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  title: Attention is All you Need
- pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
- pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
- pid: 2ec8f7e0257a07d3914322b36072d1bbcd58a1e0
  title: Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles
- pid: b82153bf85d5d1edd3f170aace830e5328ca9ed0
  title: Fusion of Detected Objects in Text for Visual Question Answering
- pid: 7a064df1aeada7e69e5173f7d4c8606f4470365b
  title: 'ALBERT: A Lite BERT for Self-supervised Learning of Language Representations'
- pid: a5d10341717c0519cf63151b496a6d2ed67aa05f
  title: Bilinear Attention Networks
- pid: e0c6abdbdecf04ffac65c440da77fb9d66bb474c
  title: 'XLNet: Generalized Autoregressive Pretraining for Language Understanding'
- pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
- pid: 6dfc2ff03534a4325d06c6f88c3144831996629b
  title: 'From Recognition to Cognition: Visual Commonsense Reasoning'
- pid: 8201e6e687f2de477258e9be53ba7b73ee30d7de
  title: Colorful Image Colorization
- pid: 025a0dc4a2a98742f1b410b6318a46de2c854b22
  title: Learning Video Representations using Contrastive Bidirectional Transformer
- pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  title: Deep Contextualized Word Representations
- pid: a1bc7d90564c342beb75cedf36fd921de89d94ad
  title: Learning Generative Models with Sinkhorn Divergences
- pid: 29efbe391950ae438c63d86ad5c82b2942efb0b4
  title: Modeling Context in Referring Expressions
- pid: 8e86dd59429e8b7fd34b6893c2dea3921974c328
  title: NLVR2 Visual Bias Analysis
- pid: 1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1
  title: 'GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question
    Answering'
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: bf8fe437f779f2098f9af82b534aa51dc9edb06f
  title: Scaling Neural Machine Translation
- pid: dbde7dfa6cae81df8ac19ef500c42db96c3d1edd
  title: 'Google''s Neural Machine Translation System: Bridging the Gap between Human
    and Machine Translation'
- pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  title: 'Im2Text: Describing Images Using 1 Million Captioned Photographs'
- pid: 0c908739fbff75f03469d13d4a1a07de3414ee19
  title: Distilling the Knowledge in a Neural Network
- pid: 077f8329a7b6fa3b7c877a57b81eb6c18b5f87de
  title: 'RoBERTa: A Robustly Optimized BERT Pretraining Approach'
- pid: cf336d272a30d6ad6141db67faa64deb8791cd61
  title: A Corpus for Reasoning about Natural Language Grounded in Photographs
- pid: d78aed1dac6656affa4a04cbf225ced11a83d103
  title: Revealing the Dark Secrets of BERT
- pid: 92c141447f51b6732242376164ff961e464731c8
  title: 'ReferItGame: Referring to Objects in Photographs of Natural Scenes'
- pid: d07284a6811f1b2745d91bdb06b040b57f226882
  title: Decoupled Weight Decay Regularization
- pid: 69902406e7d08f8865f02185699978db499d25e7
  title: Improving GANs Using Optimal Transport
- pid: b36a5bb1707bb9c70025294b3a310138aae8327a
  title: Automatic differentiation in PyTorch
- pid: 7b54a851675cc73367cd28c296d393564ebe55f5
  title: A Fast Proximal Point Method for Wasserstein Distance
- pid: acd87843a451d18b4dc6474ddce1ae946429eaf1
  title: Wasserstein Generative Adversarial Networks
- pid: 0080118b0eb02af581ff32b85a1bb6aed7081f45
  title: 'Sinkhorn Distances: Lightspeed Computation of Optimal Transport'
- pid: 8e51d68250db5637cd6bc1de98a99396441399b2
  title: Computational Optimal Transport
- pid: 5466ee5f16fc3c776fd1da667917592e5fd06720
  title: 'Selfie: Self-supervised Pretraining for Image Embedding'
- pid: 784da2a7b53a16d2243f747e14946cc5e3476af0
  title: 'VQA: Visual Question Answering'
slug: UNITER:-Learning-UNiversal-Image-TExt-Chen-Li
title: 'UNITER: Learning UNiversal Image-TExt Representations'
url: https://www.semanticscholar.org/paper/UNITER:-Learning-UNiversal-Image-TExt-Chen-Li/54416048772b921720f19869ed11c2a360589d03?sort=total-citations
venue: ECCV 2020
year: 2019
