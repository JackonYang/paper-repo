authors:
- R. Memisevic
- Geoffrey E. Hinton
badges:
- id: OPEN_ACCESS
corpusId: 7778133
fieldsOfStudy:
- Computer Science
numCitedBy: 213
numCiting: 30
paperAbstract: We describe a probabilistic model for learning rich, distributed representations
  of image transformations. The basic model is defined as a gated conditional random
  field that is trained to predict transformations of its inputs using a factorial
  set of latent variables. Inference in the model consists in extracting the transformation,
  given a pair of images, and can be performed exactly and efficiently. We show that,
  when trained on natural videos, the model develops domain specific motion features,
  in the form of fields of locally transformed edge filters. When trained on affine,
  or more general, transformations of still images, the model develops codes for these
  transformations, and can subsequently perform recognition tasks that are invariant
  under these transformations. It can also fantasize new transformations on previously
  unseen images. We describe several variations of the basic model and provide experimental
  results that demonstrate its applicability to a variety of tasks.
ref_count: 31
references:
- pid: 2077d0f30507d51a0d3bbec4957d55e817d66a59
  title: 'Fields of Experts: a framework for learning image priors'
- pid: 7aac1045e6943b4a7978e260a3035662d5b3bf8d
  title: Learning from one example through shared densities on transforms
- pid: 363b56f85e12389017ba8894056a1b309e46a5f7
  title: Multiscale conditional random fields for image labeling
- pid: cfaae9b6857b834043606df3342d8dc97524aa9d
  title: Learning a similarity metric discriminatively, with application to face verification
- pid: 7e85f7d59e37972ec52cbabfef0512588d87f125
  title: Separating Style and Content with Bilinear Models
- pid: 923562d216386a88947d40da310d94bbb1376a41
  title: Image analogies
- pid: 052b1d8ce63b07fec3de9dbb583772d860b7c769
  title: Learning representations by back-propagating errors
- pid: 9360e5ce9c98166bb179ad479a9d2919ff13d022
  title: Training Products of Experts by Minimizing Contrastive Divergence
- pid: f4ba954b0412773d047dc41231c733de0c1f4926
  title: 'Conditional Random Fields: Probabilistic Models for Segmenting and Labeling
    Sequence Data'
- pid: b5b27b9b7eb35fa913715a404c3a3d06f4899530
  title: Independent component analysis of natural image sequences yields spatio-temporal
    filters similar to simple cells in primary visual cortex
- pid: f6d8a7fc2e2d53923832f9404376512068ca2a57
  title: Hierarchical mixtures of experts and the EM algorithm
- pid: 162d958ff885f1462aeda91cd72582323fd6a1f4
  title: Gradient-based learning applied to document recognition
- pid: 2184fb6d32bc46f252b940035029273563c4fc82
  title: Exponential Family Harmoniums with an Application to Information Retrieval
- pid: ae3fe34be9230c98b04d68b4621c89b7dbc2d717
  title: Learning representations by backpropagating errors
- pid: 46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e
  title: Reducing the Dimensionality of Data with Neural Networks
slug: Unsupervised-Learning-of-Image-Transformations-Memisevic-Hinton
title: Unsupervised Learning of Image Transformations
url: https://www.semanticscholar.org/paper/Unsupervised-Learning-of-Image-Transformations-Memisevic-Hinton/2ac91e028cdc602695b46bd1f372c03b4d2776cf?sort=total-citations
venue: 2007 IEEE Conference on Computer Vision and Pattern Recognition
year: 2007
