authors:
- Ning Xie
- Farley Lai
- Derek Doran
- Asim Kadav
badges:
- id: OPEN_ACCESS
corpusId: 58981654
fieldsOfStudy:
- Computer Science
numCitedBy: 99
numCiting: 99
paperAbstract: "Existing visual reasoning datasets such as Visual Question Answering\
  \ (VQA), often suffer from biases conditioned on the question, image or answer distributions.\
  \ The recently proposed CLEVR dataset addresses these limitations and requires fine-grained\
  \ reasoning but the dataset is synthetic and consists of similar objects and sentence\
  \ structures across the dataset. \nIn this paper, we introduce a new inference task,\
  \ Visual Entailment (VE) - consisting of image-sentence pairs whereby a premise\
  \ is defined by an image, rather than a natural language sentence as in traditional\
  \ Textual Entailment tasks. The goal of a trained VE model is to predict whether\
  \ the image semantically entails the text. To realize this task, we build a dataset\
  \ SNLI-VE based on the Stanford Natural Language Inference corpus and Flickr30k\
  \ dataset. We evaluate various existing VQA baselines and build a model called Explainable\
  \ Visual Entailment (EVE) system to address the VE task. EVE achieves up to 71%\
  \ accuracy and outperforms several other state-of-the-art VQA based models. Finally,\
  \ we demonstrate the explainability of EVE through cross-modal attention visualizations.\
  \ The SNLI-VE dataset is publicly available at this https URL necla-ml/SNLI-VE."
ref_count: 99
references:
- pid: def584565d05d6a8ba94de6621adab9e301d375d
  title: 'Visual7W: Grounded Question Answering in Images'
- pid: 88c307c51594c6d802080a0780d0d654e2e2891f
  title: 'Visual question answering: A survey of methods and datasets'
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  title: 'Making the V in VQA Matter: Elevating the Role of Image Understanding in
    Visual Question Answering'
- pid: 2846e83d405cbe3bf2f0f3b5f635dd8b3c680c45
  title: Reasoning about Entailment with Neural Attention
- pid: 62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e
  title: 'Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge'
- pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
- pid: 2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1
  title: Are You Talking to a Machine? Dataset and Methods for Multilingual Image
    Question
- pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
- pid: fddc15480d086629b960be5bff96232f967f2252
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
- pid: 4aa4069693bee00d1b0759ca3df35e59284e9845
  title: 'DeViSE: A Deep Visual-Semantic Embedding Model'
- pid: 62a956d7600b10ca455076cd56e604dfd106072a
  title: Exploring Models and Data for Image Question Answering
- pid: 996901b08a6b6f401146204f2db0d54aaf8749c8
  title: Visual Translation Embedding Network for Visual Relation Detection
- pid: 1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7
  title: 'MovieQA: Understanding Stories in Movies through Question-Answering'
- pid: f04df4e20a18358ea2f689b4c129781628ef7fc1
  title: A large annotated corpus for learning natural language inference
- pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
- pid: a396a6febdacb84340d139096455e67049ac1e22
  title: 'Learning to Reason: End-to-End Module Networks for Visual Question Answering'
- pid: fa0cc5fcd2faa4591dd53504d0c5115783a2d2b6
  title: Improving Image-Sentence Embeddings Using Large Weakly Annotated Photo Collections
- pid: d7ce5665a72c0b607f484c1b448875f02ddfac3b
  title: 'DenseCap: Fully Convolutional Localization Networks for Dense Captioning'
- pid: 03eb382e04cca8cca743f7799070869954f1402a
  title: 'CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual
    Reasoning'
- pid: 58cb0c24c936b8a14ca7b2d56ba80de733c545b3
  title: 'Human Attention in Visual Question Answering: Do Humans and Deep Networks
    look at the same regions?'
- pid: abb33d75dc297993fcc3fb75e0f4498f413eb4f6
  title: 'Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks'
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: 88513e738a95840de05a62f0e43d30a67b3c542e
  title: 'SCA-CNN: Spatial and Channel-Wise Attention in Convolutional Networks for
    Image Captioning'
- pid: ce264a4e1490e959d84ddd60edbb0edcbfb3af38
  title: Modeling Relationships in Referential Expressions with Compositional Modular
    Networks
- pid: 5fcd93997b7dde90594dc1caa27ba9d560bbe63d
  title: Detecting Visual Relationships with Deep Relational Networks
- pid: 007112213ece771be72cbecfd59f048209facabd
  title: A simple neural network module for relational reasoning
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: 289fb3709475f5c87df8d97f129af54029d27fee
  title: Compositional Attention Networks for Machine Reasoning
- pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  title: Attention is All you Need
- pid: b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81
  title: 'Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge'
- pid: 3d3f789a56dca288b2c8e23ef047a2b342184950
  title: Bilinear CNN Models for Fine-Grained Visual Recognition
- pid: 44040913380206991b1991daf1192942e038fe31
  title: 'From image descriptions to visual denotations: New similarity metrics for
    semantic inference over event descriptions'
- pid: 85ae705ef4353c6854f5be4a4664269d6317c66b
  title: Image retrieval using scene graphs
- pid: 34b73c1aa158b892bbe41705b4ae5bf01ecaea86
  title: Scene Graph Generation by Iterative Message Passing
- pid: 7cfa5c97164129ce3630511f639040d28db1d4b7
  title: 'FiLM: Visual Reasoning with a General Conditioning Layer'
- pid: de794d50713ea5f91a7c9da3d72041e2f5ef8452
  title: The PASCAL Recognising Textual Entailment Challenge
- pid: a5d10341717c0519cf63151b496a6d2ed67aa05f
  title: Bilinear Attention Networks
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
- pid: 1a2a770d23b4a171fa81de62a78a3deb0588f238
  title: Visualizing and Understanding Convolutional Networks
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: 36c3972569a6949ecca90bfa6f8e99883e092845
  title: 'Pythia v0.1: the Winning Entry to the VQA Challenge 2018'
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: 2e17cf6a339fd071ad222062f868e882ef4120a4
  title: Inferring and Executing Programs for Visual Reasoning
- pid: 327dc2fd203a7049f3409479ab68e5e2a83cd352
  title: Compact Bilinear Pooling
- pid: e15cf50aa89fee8535703b9f9512fca5bfc43327
  title: Going deeper with convolutions
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: adfcf065e15fd3bc9badf6145034c84dfb08f204
  title: Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling
- pid: 0da353e79f666a3ae7dd0a5d28c75b852a7f60bf
  title: SHOW
- pid: 10d85561e4aafc516d10064f30dff05b41f70afe
  title: '[Et al].'
- pid: 022dd244f2e25525eb37e9dda51abb9cd8ca8c30
  title: Mask R-CNN
- pid: e03d300581e16f6664157d2c1c6ceec33ec528ce
  title: Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object
    Classification, and Recognising Tectual Entailment
- pid: 45fd483402290ad4cae059a4e20cd586c019c3da
  title: (b)
slug: Visual-Entailment:-A-Novel-Task-for-Fine-Grained-Xie-Lai
title: 'Visual Entailment: A Novel Task for Fine-Grained Image Understanding'
url: https://www.semanticscholar.org/paper/Visual-Entailment:-A-Novel-Task-for-Fine-Grained-Xie-Lai/3c54b796cc10cb530f77caa4d18e1c80ac863822?sort=total-citations
venue: ArXiv
year: 2019
