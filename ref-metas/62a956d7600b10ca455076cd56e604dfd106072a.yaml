authors:
- Mengye Ren
- Ryan Kiros
- R. Zemel
badges:
- id: OPEN_ACCESS
corpusId: 2950705
fieldsOfStudy:
- Computer Science
numCitedBy: 530
numCiting: 37
paperAbstract: This work aims to address the problem of image-based question-answering
  (QA) with new models and datasets. In our work, we propose to use neural networks
  and visual semantic embeddings, without intermediate stages such as object detection
  and image segmentation, to predict answers to simple questions about images. Our
  model performs 1.8 times better than the only published results on an existing image
  QA dataset. We also present a question generation algorithm that converts image
  descriptions, which are widely available, into QA form. We used this algorithm to
  produce an order-of-magnitude larger dataset, with more evenly distributed answers.
  A suite of baseline results on this new dataset are also presented.
ref_count: 37
references:
- pid: 98bd5dd1740f585bf25320ba504e2c1ae57f2e5f
  title: Learning to Answer Questions from Image Using Convolutional Neural Network
- pid: bd7bd1d2945a58cdcc1797ba9698b8810fe68f60
  title: 'Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images'
- pid: 2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1
  title: Are You Talking to a Machine? Dataset and Methods for Multilingual Image
    Question
- pid: 9814df8bd00ba999c4d1e305a7e9bca579dc7c75
  title: 'Framing Image Description as a Ranking Task: Data, Models and Evaluation
    Metrics (Extended Abstract)'
- pid: 123b9de009865472c660192f8072493a48352dc2
  title: Phrase-based Image Captioning
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 4aa4069693bee00d1b0759ca3df35e59284e9845
  title: 'DeViSE: A Deep Visual-Semantic Embedding Model'
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: 7f1b111f0bb703b0bd97aba505728a9b0d9b2a54
  title: Deep Fragment Embeddings for Bidirectional Image Sentence Mapping
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: f4af49a1ead3c81cc5d023878cb67c5646dd8a04
  title: Learning a Recurrent Visual Representation for Image Caption Generation
- pid: 82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9
  title: Explain Images with Multimodal Recurrent Neural Networks
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: 3d29e1c4f1c2b079cf6b5dd458fa6cee246955f9
  title: Towards a Visual Turing Challenge
- pid: 2e36ea91a3c8fbff92be2989325531b4002e2afc
  title: Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  title: 'Im2Text: Describing Images Using 1 Million Captioned Photographs'
- pid: e74f9b7f8eec6ba4704c206b93bc8079af3da4bd
  title: ImageNet Large Scale Visual Recognition Challenge
- pid: 3ca194773fe583661b988fbdf33f7680764438b3
  title: Exploring Nearest Neighbor Approaches for Image Captioning
- pid: 3ecd3e00bbbfd94446c3adc9c6878de27e250f7c
  title: Learning Dependency-Based Compositional Semantics
- pid: 696ca58d93f6404fea0fc75c62d1d7b378f47628
  title: 'Microsoft COCO Captions: Data Collection and Evaluation Server'
- pid: 330da625c15427c6e42ccfa3b747fb29e5835bf0
  title: Efficient Estimation of Word Representations in Vector Space
- pid: c1994ba5946456fc70948c549daf62363f13fa2d
  title: Indoor Segmentation and Support Inference from RGBD Images
- pid: 4898e0c5bb8d93443f2f168c31e3f1827c9129de
  title: Fisher Vectors Derived from Hybrid Gaussian-Laplacian Mixture Models for
    Image Annotation
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: a600850ac0120cb09a0b7de7da80bb6a7a76de06
  title: Accurate Unlexicalized Parsing
- pid: 0e3e3c3d8ae5cb7c4636870d69967c197484d3bb
  title: Verb Semantics and Lexical Selection
- pid: d87ceda3042f781c341ac17109d1e94a717f5f60
  title: 'WordNet : an electronic lexical database'
- pid: 01a660ec8aa995a88a00bfb41cb86c022047a9db
  title: 'NLTK: The Natural Language Toolkit'
slug: Exploring-Models-and-Data-for-Image-Question-Ren-Kiros
title: Exploring Models and Data for Image Question Answering
url: https://www.semanticscholar.org/paper/Exploring-Models-and-Data-for-Image-Question-Ren-Kiros/62a956d7600b10ca455076cd56e604dfd106072a?sort=total-citations
venue: NIPS
year: 2015
