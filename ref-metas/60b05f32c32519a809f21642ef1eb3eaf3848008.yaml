authors:
- Chin-Yew Lin
badges:
- id: OPEN_ACCESS
corpusId: 964287
fieldsOfStudy:
- Computer Science
numCitedBy: 6943
numCiting: 16
paperAbstract: 'ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation.
  It includes measures to automatically determine the quality of a summary by comparing
  it to other (ideal) summaries created by humans. The measures count the number of
  overlapping units such as n-gram, word sequences, and word pairs between the computer-generated
  summary to be evaluated and the ideal summaries created by humans. This paper introduces
  four different ROUGE measures: ROUGE-N, ROUGE-L, ROUGE-W, and ROUGE-S included in
  the ROUGE summarization evaluation package and their evaluations. Three of them
  have been used in the Document Understanding Conference (DUC) 2004, a large-scale
  summarization evaluation sponsored by NIST.'
ref_count: 16
references:
- pid: c63bb976dc0d3a897f3b0920170a4c573ef904c6
  title: Automatic Evaluation of Summaries Using N-gram Co-occurrence Statistics
- pid: 9ca86842aad16797d0fe0323358f3beb1ac6a5c6
  title: Automatic Evaluation of Machine Translation Quality Using Longest Common
    Subsequence and Skip-Bigram Statistics
- pid: d7da009f457917aa381619facfa5ffae9329a6e9
  title: 'Bleu: a Method for Automatic Evaluation of Machine Translation'
slug: ROUGE:-A-Package-for-Automatic-Evaluation-of-Lin
title: 'ROUGE: A Package for Automatic Evaluation of Summaries'
url: https://www.semanticscholar.org/paper/ROUGE:-A-Package-for-Automatic-Evaluation-of-Lin/60b05f32c32519a809f21642ef1eb3eaf3848008?sort=total-citations
venue: ACL 2004
year: 2004
