authors:
- Zihao Wang
- Xihui Liu
- Hongsheng Li
- Lu Sheng
- Junjie Yan
- Xiaogang Wang
- Jing Shao
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 202565460
fieldsOfStudy:
- Computer Science
meta_key: camp-cross-modal-adaptive-message-passing-for-text-image-retrieval
numCitedBy: 100
numCiting: 36
paperAbstract: Text-image cross-modal retrieval is a challenging task in the field
  of language and vision. Most previous approaches independently embed images and
  sentences into a joint embedding space and compare their similarities. However,
  previous approaches rarely explore the interactions between images and sentences
  before calculating similarities in the joint space. Intuitively, when matching between
  images and sentences, human beings would alternatively attend to regions in images
  and words in sentences, and select the most salient information considering the
  interaction between both modalities. In this paper, we propose Cross-modal Adaptive
  Message Passing (CAMP), which adaptively controls the information flow for message
  passing across modalities. Our approach not only takes comprehensive and fine-grained
  cross-modal interactions into account, but also properly handles negative pairs
  and irrelevant information with an adaptive gating scheme. Moreover, instead of
  conventional joint embedding approaches for text-image matching, we infer the matching
  score based on the fused features, and propose a hardest negative binary cross-entropy
  loss for training. Results on COCO and Flickr30k significantly surpass state-of-the-art
  methods, demonstrating the effectiveness of our approach.
ref_count: 36
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: stacked-cross-attention-for-image-text-matching
  numCitedBy: 481
  pid: 45dd2a3cd7c27f2e9509b023d702408f5ac11c9d
  show_ref_link: true
  title: Stacked Cross Attention for Image-Text Matching
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: look-imagine-and-match-improving-textual-visual-cross-modal-retrieval-with-generative-models
  numCitedBy: 220
  pid: 724b253a55e86ad230ba05c7eb78f249e09258d9
  show_ref_link: true
  title: Look, Imagine and Match - Improving Textual-Visual Cross-Modal Retrieval
    with Generative Models
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: dual-path-convolutional-image-text-embedding
  numCitedBy: 58
  pid: 40a943746d3a6156f9ca477e437263c7841118ac
  show_ref_link: false
  title: Dual-Path Convolutional Image-Text Embedding
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-cross-modal-projection-learning-for-image-text-matching
  numCitedBy: 150
  pid: 1a86eb42952412ee02e3f6da06f874f1946eff6b
  show_ref_link: true
  title: Deep Cross-Modal Projection Learning for Image-Text Matching
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: improving-referring-expression-grounding-with-cross-modal-attention-guided-erasing
  numCitedBy: 85
  pid: cd961afa9d75e1e7a657a9e11d6f6d3b968282a0
  show_ref_link: false
  title: Improving Referring Expression Grounding With Cross-Modal Attention-Guided
    Erasing
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: hierarchical-multimodal-lstm-for-dense-visual-semantic-embedding
  numCitedBy: 113
  pid: ad5dc94b28bee087a34f52114c52bd09d2acd8cb
  show_ref_link: true
  title: Hierarchical Multimodal LSTM for Dense Visual-Semantic Embedding
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-semantic-concepts-and-order-for-image-and-sentence-matching
  numCitedBy: 167
  pid: f322eef6a4c965910e03f6997b1bc2acd413e273
  show_ref_link: true
  title: Learning Semantic Concepts and Order for Image and Sentence Matching
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: conditional-image-text-embedding-networks
  numCitedBy: 74
  pid: e5bfebd3774c44580463cda8e611487ae3639cd7
  show_ref_link: false
  title: Conditional Image-Text Embedding Networks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: unifying-visual-semantic-embeddings-with-multimodal-neural-language-models
  numCitedBy: 1055
  pid: 2e36ea91a3c8fbff92be2989325531b4002e2afc
  show_ref_link: true
  title: Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: improved-fusion-of-visual-and-language-representations-by-dense-symmetric-co-attention-for-visual-question-answering
  numCitedBy: 171
  pid: f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622
  show_ref_link: true
  title: Improved Fusion of Visual and Language Representations by Dense Symmetric
    Co-attention for Visual Question Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-deep-structure-preserving-image-text-embeddings
  numCitedBy: 582
  pid: b27e791e843c924ef052981b79490ab59fc0433d
  show_ref_link: true
  title: Learning Deep Structure-Preserving Image-Text Embeddings
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: dual-attention-networks-for-multimodal-reasoning-and-matching
  numCitedBy: 469
  pid: f651593fa6c83d717fc961482696a53b6fca5ab5
  show_ref_link: true
  title: Dual Attention Networks for Multimodal Reasoning and Matching
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: knowing-when-to-look-adaptive-attention-via-a-visual-sentinel-for-image-captioning
  numCitedBy: 961
  pid: 9f4d7d622d1f7319cc511bfef661cd973e881a4c
  show_ref_link: true
  title: Knowing When to Look - Adaptive Attention via a Visual Sentinel for Image
    Captioning
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: multimodal-compact-bilinear-pooling-for-visual-question-answering-and-visual-grounding
  numCitedBy: 1086
  pid: fddc15480d086629b960be5bff96232f967f2252
  show_ref_link: true
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: show-tell-and-discriminate-image-captioning-by-self-retrieval-with-partially-labeled-data
  numCitedBy: 93
  pid: caab1c1d53718315f54bc4df42eb9a727fa18483
  show_ref_link: false
  title: Show, Tell and Discriminate - Image Captioning by Self-retrieval with Partially
    Labeled Data
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: multi-level-attention-networks-for-visual-question-answering
  numCitedBy: 174
  pid: d740d0a960368633ed32fc84877b8391993acdca
  show_ref_link: true
  title: Multi-level Attention Networks for Visual Question Answering
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: from-captions-to-visual-concepts-and-back
  numCitedBy: 1107
  pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  show_ref_link: true
  title: From captions to visual concepts and back
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: linking-image-and-text-with-2-way-nets
  numCitedBy: 135
  pid: 2616e0fbce43362a338acedcbb5cd80db7bbb7e5
  show_ref_link: true
  title: Linking Image and Text with 2-Way Nets
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering
  numCitedBy: 2275
  pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  show_ref_link: true
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: structured-attentions-for-visual-question-answering
  numCitedBy: 86
  pid: 5823d18cd378898b12de537862d996443ce9c9e8
  show_ref_link: false
  title: Structured Attentions for Visual Question Answering
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: bottom-up-and-top-down-attention-for-image-captioning-and-vqa
  numCitedBy: 292
  pid: a79b694bd4ef51207787da1948ed473903b751ef
  show_ref_link: true
  title: Bottom-Up and Top-Down Attention for Image Captioning and VQA
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: hierarchical-question-image-co-attention-for-visual-question-answering
  numCitedBy: 1121
  pid: fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b
  show_ref_link: true
  title: Hierarchical Question-Image Co-Attention for Visual Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: sca-cnn-spatial-and-channel-wise-attention-in-convolutional-networks-for-image-captioning
  numCitedBy: 1004
  pid: 88513e738a95840de05a62f0e43d30a67b3c542e
  show_ref_link: true
  title: SCA-CNN - Spatial and Channel-Wise Attention in Convolutional Networks for
    Image Captioning
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: associating-neural-word-embeddings-with-deep-image-representations-using-fisher-vectors
  numCitedBy: 251
  pid: 51239b320c73f3f2219286bf62f24d6763379328
  show_ref_link: false
  title: Associating neural word embeddings with deep image representations using
    Fisher Vectors
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: ask-attend-and-answer-exploring-question-guided-spatial-attention-for-visual-question-answering
  numCitedBy: 652
  pid: 1cf6bc0866226c1f8e282463adc8b75d92fba9bb
  show_ref_link: true
  title: Ask, Attend and Answer - Exploring Question-Guided Spatial Attention for
    Visual Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: vse-improved-visual-semantic-embeddings
  numCitedBy: 150
  pid: faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1
  show_ref_link: true
  title: VSE++ - Improved Visual-Semantic Embeddings
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: bilinear-attention-networks
  numCitedBy: 408
  pid: a5d10341717c0519cf63151b496a6d2ed67aa05f
  show_ref_link: true
  title: Bilinear Attention Networks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: vse-improving-visual-semantic-embeddings-with-hard-negatives
  numCitedBy: 508
  pid: f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8
  show_ref_link: true
  title: VSE++ - Improving Visual-Semantic Embeddings with Hard Negatives
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: stacked-attention-networks-for-image-question-answering
  numCitedBy: 1474
  pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  show_ref_link: true
  title: Stacked Attention Networks for Image Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: microsoft-coco-common-objects-in-context
  numCitedBy: 19778
  pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  show_ref_link: true
  title: Microsoft COCO - Common Objects in Context
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: order-embeddings-of-images-and-language
  numCitedBy: 433
  pid: 46b8cbcdff87b842c2c1d4a003c831f845096ba7
  show_ref_link: true
  title: Order-Embeddings of Images and Language
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks
  numCitedBy: 32561
  pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  show_ref_link: true
  title: Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: compact-bilinear-pooling
  numCitedBy: 582
  pid: 327dc2fd203a7049f3409479ab68e5e2a83cd352
  show_ref_link: true
  title: Compact Bilinear Pooling
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: from-image-descriptions-to-visual-denotations-new-similarity-metrics-for-semantic-inference-over-event-descriptions
  numCitedBy: 1323
  pid: 44040913380206991b1991daf1192942e038fe31
  show_ref_link: true
  title: From image descriptions to visual denotations - New similarity metrics for
    semantic inference over event descriptions
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: empirical-evaluation-of-gated-recurrent-neural-networks-on-sequence-modeling
  numCitedBy: 7376
  pid: adfcf065e15fd3bc9badf6145034c84dfb08f204
  show_ref_link: true
  title: Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling
  year: 2014
slug: CAMP:-Cross-Modal-Adaptive-Message-Passing-for-Wang-Liu
title: CAMP - Cross-Modal Adaptive Message Passing for Text-Image Retrieval
url: https://www.semanticscholar.org/paper/CAMP:-Cross-Modal-Adaptive-Message-Passing-for-Wang-Liu/19c630ad5a9de227f6357479fc95c62667be17f6?sort=total-citations
venue: 2019 IEEE/CVF International Conference on Computer Vision (ICCV)
year: 2019
