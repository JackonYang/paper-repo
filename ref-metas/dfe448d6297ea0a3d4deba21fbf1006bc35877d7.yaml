authors:
- H. Pirsiavash
- Carl Vondrick
- A. Torralba
badges:
- id: OPEN_ACCESS
corpusId: 16732164
fieldsOfStudy:
- Computer Science
numCitedBy: 33
numCiting: 44
paperAbstract: 'Abstract : Humans have the remarkable capability to infer the motivations
  of other people''s actions, likely due to cognitive skills known in psychophysics
  as the theory of mind. In this paper, we strive to build a computational model that
  predicts the motivation behind the actions of people from images. To our knowledge,
  this challenging problem has not yet been extensively explored in computer vision.
  We present a novel learning based framework that uses high-level visual recognition
  to infer why people are performing an actions in images. However, the information
  in an image alone may not be sufficient to automatically solve this task. Since
  humans can rely on their own experiences to infer motivation, we propose to give
  computer vision systems access to some of these experiences by using recently developed
  natural language models to mine knowledge stored in massive amounts of text. While
  we are still far away from automatically inferring motivation, our results suggest
  that transferring knowledge from language into vision can help machines understand
  why a person might be performing an action in an image.'
ref_count: 45
references:
- pid: 051830b0ea58d1568f19ec3297e301d9789c9a76
  title: Bringing Semantics into Focus Using Visual Abstraction
- pid: b0ab8aa7a5b684532b4ff30f8d34b35a99759a46
  title: 'Learning Everything about Anything: Webly-Supervised Visual Concept Learning'
- pid: 6c39f56c3c21c3972c362f8e752be57a50c41f4f
  title: Learning the Visual Interpretation of Sentences
- pid: cc0bb8f933e514dd9441e3082a34a9f129e35500
  title: 'Patch to the Future: Unsupervised Visual Prediction'
- pid: a251dac6589a83e0bbcf9bef9a80c21222aeecbb
  title: Learning Models for Object Recognition from Natural Language Descriptions
- pid: 169b847e69c35cfd475eb4dcc561a24de11762ca
  title: 'Baby talk: Understanding and generating simple image descriptions'
- pid: 0d8a5addbd17d2c7c8043d8877234675da19938a
  title: Activity Forecasting
- pid: 53e4ab9730e983242a3409c7bf1af945041a6563
  title: 'NEIL: Extracting Visual Knowledge from Web Data'
- pid: 82635fb63640ae95f90ee9bdc07832eb461ca881
  title: The Pascal Visual Object Classes (VOC) Challenge
- pid: 6286a82f72f632672c1890f3dd6bbb15b8e5168b
  title: 'Object Bank: A High-Level Image Representation for Scene Classification
    & Semantic Feature Sparsification'
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: 6bdb186ec4726e00a8051119636d4df3b94043b5
  title: 'Caffe: Convolutional Architecture for Fast Feature Embedding'
- pid: f30aba767d71c1db5ea70b041d9fcc2b9b1ddad4
  title: Cutting-plane training of structural SVMs
- pid: cfc6d0c8260594ebc5dd20ee558d29b1014ed41a
  title: On the Algorithmic Implementation of Multiclass Kernel-based Vector Machines
- pid: 8e4fb17fff38a7834af5b4eaafcbbde02bf00975
  title: N-gram Counts and Language Models from the Common Crawl
- pid: 68c03788224000794d5491ab459be0b2a2c38677
  title: 'WordNet: A Lexical Database for English'
- pid: 0ec48ac86456cea3d6d6172ca81ef68e98b21a61
  title: The PASCAL Visual Object Classes Challenge
slug: Inferring-the-Why-in-Images-Pirsiavash-Vondrick
title: Inferring the Why in Images
url: https://www.semanticscholar.org/paper/Inferring-the-Why-in-Images-Pirsiavash-Vondrick/dfe448d6297ea0a3d4deba21fbf1006bc35877d7?sort=total-citations
venue: ArXiv
year: 2014
