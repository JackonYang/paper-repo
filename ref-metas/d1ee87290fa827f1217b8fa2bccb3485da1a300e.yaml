authors:
- L. Breiman
badges:
- id: OPEN_ACCESS
corpusId: 47328136
fieldsOfStudy:
- Computer Science
numCitedBy: 15183
numCiting: 16
paperAbstract: Bagging predictors is a method for generating multiple versions of
  a predictor and using these to get an aggregated predictor. The aggregation averages
  over the versions when predicting a numerical outcome and does a plurality vote
  when predicting a class. The multiple versions are formed by making bootstrap replicates
  of the learning set and using these as new learning sets. Tests on real and simulated
  data sets using classification and regression trees and subset selection in linear
  regression show that bagging can give substantial gains in accuracy. The vital element
  is the instability of the prediction method. If perturbing the learning set can
  cause significant changes in the predictor constructed, then bagging can improve
  accuracy.
ref_count: 16
references:
- pid: 61039fd2773a00e111d2121a63982a7b7d0b9f92
  title: Learning classification trees
- pid: fad1bd501aa769f7701c1016f8a4d1473ca77601
  title: Machine Learning, Neural and Statistical Classification
slug: Bagging-predictors-Breiman
title: Bagging predictors
url: https://www.semanticscholar.org/paper/Bagging-predictors-Breiman/d1ee87290fa827f1217b8fa2bccb3485da1a300e?sort=total-citations
venue: Machine Learning
year: 2004
