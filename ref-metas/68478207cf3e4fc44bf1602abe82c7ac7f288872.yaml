authors:
- Yingwei Pan
- Tao Mei
- Ting Yao
- Houqiang Li
- Y. Rui
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 14432549
fieldsOfStudy:
- Computer Science
numCitedBy: 459
numCiting: 57
paperAbstract: 'Automatically describing video content with natural language is a
  fundamental challenge of computer vision. Re-current Neural Networks (RNNs), which
  models sequence dynamics, has attracted increasing attention on visual interpretation.
  However, most existing approaches generate a word locally with the given previous
  words and the visual content, while the relationship between sentence semantics
  and visual content is not holistically exploited. As a result, the generated sentences
  may be contextually correct but the semantics (e.g., subjects, verbs or objects)
  are not true. This paper presents a novel unified framework, named Long Short-Term
  Memory with visual-semantic Embedding (LSTM-E), which can simultaneously explore
  the learning of LSTM and visual-semantic embedding. The former aims to locally maximize
  the probability of generating the next word given previous words and visual content,
  while the latter is to create a visual-semantic embedding space for enforcing the
  relationship between the semantics of the entire sentence and visual content. The
  experiments on YouTube2Text dataset show that our proposed LSTM-E achieves to-date
  the best published performance in generating natural sentences: 45.3% and 31.0%
  in terms of BLEU@4 and METEOR, respectively. Superior performances are also reported
  on two movie description datasets (M-VAD and MPII-MD). In addition, we demonstrate
  that LSTM-E outperforms several state-of-the-art techniques in predicting Subject-Verb-Object
  (SVO) triplets.'
ref_count: 57
references:
- pid: 2e36ea91a3c8fbff92be2989325531b4002e2afc
  title: Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
- pid: e8cd37fbd8bd5e690eef5861cf92af8e002d4533
  title: Translating Video Content to Natural Language Descriptions
- pid: 20ab42c9b93b6e41f6e1d7b546f87c5a871db020
  title: Integrating Language and Vision to Generate Natural Language Descriptions
    of Videos in the Wild
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 43795b7bac3d921c4e579964b54187bdbf6c6330
  title: Translating Videos to Natural Language Using Deep Recurrent Neural Networks
- pid: 5f425b7abf2ed3172ed060df85bb1885860a297e
  title: Describing Videos by Exploiting Temporal Structure
- pid: a72b8bbd039989db39769da836cdb287737deb92
  title: 'Mind''s eye: A recurrent visual representation for image caption generation'
- pid: 82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9
  title: Explain Images with Multimodal Recurrent Neural Networks
- pid: 54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745
  title: Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)
- pid: e58a110fa1e4ddf247d5c614d117d64bfbe135c4
  title: Sequence to Sequence -- Video to Text
- pid: f142c849ffef66f7520aff4e0b40ac964ccb8cc1
  title: 'Language Models for Image Captioning: The Quirks and What Works'
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: 6eb3a15108dfdec25b46522ed94b866aeb156de9
  title: 'Connecting modalities: Semi-supervised segmentation and annotation of images
    using unaligned text corpora'
- pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
- pid: d6a7a563640bf53953c4fda0997e4db176488510
  title: 'YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic
    Hierarchies and Zero-Shot Recognition'
- pid: 194e9a6f02fd5f39226dc9848213479fec5f1821
  title: Automatic Caption Generation for News Images
- pid: fad611e35b3731740b4d8b754241e77add5a70b9
  title: Multimodal Neural Language Models
- pid: 85cb25e88d3b0548a26e7a70b6953e500d27eb9a
  title: Learning cross-modality similarity for multinomial data
- pid: 0ba87571341beaf6a5c9a30e049be7b1fc9a4c60
  title: Choosing Linguistics over Vision to Describe Images
- pid: 6a26268d2ba9d34e5b59ae6e5c11a83cdca1a85e
  title: Matching Words and Pictures
- pid: 5cb6700d94c6118ee13f4f4fecac99f111189812
  title: 'BabyTalk: Understanding and Generating Simple Image Descriptions'
- pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: bd243d77076b3b8fe046bd3dc6e8a02aa9b38d62
  title: 'C3D: Generic Features for Video Analysis'
- pid: a5ea0da7b93452bec54b5034706f2255bfb5a8f3
  title: A dataset for Movie Description
- pid: eaaed23a2d94feb2f1c3ff22a25777c7a78f3141
  title: 'Every Picture Tells a Story: Generating Sentences from Images'
- pid: 0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f
  title: Towards End-To-End Speech Recognition with Recurrent Neural Networks
- pid: 6d4c9c923e9f145d1c01a2de2afc38ec23c44253
  title: Large-Scale Video Classification with Convolutional Neural Networks
- pid: 0d0b3ff23fbf1ec7a0dfebd923a3ef224306491a
  title: Learning to Execute
- pid: 169b847e69c35cfd475eb4dcc561a24de11762ca
  title: 'Baby talk: Understanding and generating simple image descriptions'
- pid: 2f83f6e1afadf0963153974968af6b8342775d82
  title: Framewise phoneme classification with bidirectional LSTM and other neural
    network architectures
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: e15cf50aa89fee8535703b9f9512fca5bfc43327
  title: Going deeper with convolutions
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: 0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7
  title: 'METEOR: An Automatic Metric for MT Evaluation with Improved Correlation
    with Human Judgments'
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 0d6203718c15f137fda2f295c96269bc2b254644
  title: Learning Recurrent Neural Networks with Hessian-Free Optimization
- pid: d25c65d261ea0e6a458be4c50c40ffe5bc508f77
  title: Learning Spatiotemporal Features with 3D Convolutional Networks
- pid: 554a31ce91189cf6022ac677413ef2f8b9b40ca7
  title: Collecting Highly Parallel Data for Paraphrase Evaluation
- pid: e74f9b7f8eec6ba4704c206b93bc8079af3da4bd
  title: ImageNet Large Scale Visual Recognition Challenge
- pid: d0be39ee052d246ae99c082a565aba25b811be2d
  title: Learning long-term dependencies with gradient descent is difficult
- pid: d7da009f457917aa381619facfa5ffae9329a6e9
  title: 'Bleu: a Method for Automatic Evaluation of Machine Translation'
slug: Jointly-Modeling-Embedding-and-Translation-to-Video-Pan-Mei
title: Jointly Modeling Embedding and Translation to Bridge Video and Language
url: https://www.semanticscholar.org/paper/Jointly-Modeling-Embedding-and-Translation-to-Video-Pan-Mei/68478207cf3e4fc44bf1602abe82c7ac7f288872?sort=total-citations
venue: 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2016
