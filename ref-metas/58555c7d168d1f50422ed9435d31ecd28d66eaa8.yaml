authors:
- Zhedong Zheng
- Liang Zheng
- Michael Garrett
- Yi Yang
- Mingliang Xu
- Yi-Dong Shen
badges:
- id: OPEN_ACCESS
corpusId: 49867191
fieldsOfStudy:
- Computer Science
numCitedBy: 147
numCiting: 112
paperAbstract: Matching images and sentences demands a fine understanding of both
  modalities. In this article, we propose a new system to discriminatively embed the
  image and text to a shared visual-textual space. In this field, most existing works
  apply the ranking loss to pull the positive image/text pairs close and push the
  negative pairs apart from each other. However, directly deploying the ranking loss
  on heterogeneous features (i.e., text and image features) is less effective, because
  it is hard to find appropriate triplets at the beginning. So the naive way of using
  the ranking loss may compromise the network from learning inter-modal relationship.
  To address this problem, we propose the instance loss, which explicitly considers
  the intra-modal data distribution. It is based on an unsupervised assumption that
  each image/text group can be viewed as a class. So the network can learn the fine
  granularity from every image/text group. The experiment shows that the instance
  loss offers better weight initialization for the ranking loss, so that more discriminative
  embeddings can be learned. Besides, existing works usually apply the off-the-shelf
  features, i.e., word2vec and fixed visual feature. So in a minor contribution, this
  article constructs an end-to-end dual-path convolutional network to learn the image
  and text representations. End-to-end learning allows the system to directly learn
  from the data and fully utilize the supervision. On two generic retrieval datasets
  (Flickr30k and MSCOCO), experiments demonstrate that our method yields competitive
  accuracy compared to state-of-the-art methods. Moreover, in language-based person
  retrieval, we improve the state of the art by a large margin. The code has been
  made publicly available.
ref_count: 92
references:
- pid: f865268b81eeb29d94775f22c6bc24dcc5e1b2e9
  title: Learning Two-Branch Neural Networks for Image-Text Matching Tasks
- pid: b27e791e843c924ef052981b79490ab59fc0433d
  title: Learning Deep Structure-Preserving Image-Text Embeddings
- pid: 45dd2a3cd7c27f2e9509b023d702408f5ac11c9d
  title: Stacked Cross Attention for Image-Text Matching
- pid: ad5dc94b28bee087a34f52114c52bd09d2acd8cb
  title: Hierarchical Multimodal LSTM for Dense Visual-Semantic Embedding
- pid: 4aa4069693bee00d1b0759ca3df35e59284e9845
  title: 'DeViSE: A Deep Visual-Semantic Embedding Model'
- pid: faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1
  title: 'VSE++: Improved Visual-Semantic Embeddings'
- pid: e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0
  title: Instance-Aware Image and Sentence Matching with Selective Multimodal LSTM
- pid: f322eef6a4c965910e03f6997b1bc2acd413e273
  title: Learning Semantic Concepts and Order for Image and Sentence Matching
- pid: 9814df8bd00ba999c4d1e305a7e9bca579dc7c75
  title: 'Framing Image Description as a Ranking Task: Data, Models and Evaluation
    Metrics (Extended Abstract)'
- pid: 51239b320c73f3f2219286bf62f24d6763379328
  title: Associating neural word embeddings with deep image representations using
    Fisher Vectors
- pid: 724b253a55e86ad230ba05c7eb78f249e09258d9
  title: 'Look, Imagine and Match: Improving Textual-Visual Cross-Modal Retrieval
    with Generative Models'
- pid: 2616e0fbce43362a338acedcbb5cd80db7bbb7e5
  title: Linking Image and Text with 2-Way Nets
- pid: 7f1b111f0bb703b0bd97aba505728a9b0d9b2a54
  title: Deep Fragment Embeddings for Bidirectional Image Sentence Mapping
- pid: 62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e
  title: 'Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge'
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 153d6feb7149e063b33e8ee437b74e4a2def8057
  title: Multimodal Convolutional Neural Networks for Matching Image and Sentence
- pid: 54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745
  title: Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)
- pid: cab372bc3824780cce20d9dd1c22d4df39ed081a
  title: 'DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous
    Convolution, and Fully Connected CRFs'
- pid: efb0e69bc640171d1f115bb286d865bec6f21a7f
  title: Deep correlation for matching images and text
- pid: c94217efec8773ef947df2772f92df8c5726f855
  title: Leveraging Visual Question Answering for Image-Caption Ranking
- pid: f651593fa6c83d717fc961482696a53b6fca5ab5
  title: Dual Attention Networks for Multimodal Reasoning and Matching
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: 98bb60748eb8ef7a671cdd22faa87e377fd13060
  title: Part-Based R-CNNs for Fine-Grained Category Detection
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: f797fd44b9ddd5845611eb7a705ca9464a8819d1
  title: Very Deep Convolutional Networks for Text Classification
- pid: bf60322f83714523e2d7c1d39983151fe9db7146
  title: "Collecting Image Annotations Using Amazon\u2019s Mechanical Turk"
- pid: 9f08b01251cb99f4ffae8c7b3e4468d3af9c98d3
  title: Convolutional Neural Network Architectures for Matching Natural Language
    Sentences
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: e74f9b7f8eec6ba4704c206b93bc8079af3da4bd
  title: ImageNet Large Scale Visual Recognition Challenge
- pid: 51a55df1f023571a7e07e338ee45a3e3d66ef73e
  title: Character-level Convolutional Networks for Text Classification
- pid: 04b8a1d2498a7c8bd90a5465a02b2e8e178177c5
  title: RNN Fisher Vectors for Action Recognition and Image Annotation
- pid: 43428880d75b3a14257c3ee9bda054e61eb869c0
  title: Convolutional Sequence to Sequence Learning
- pid: 2b669398c4cf2ebe04375c8b1beae20f4ac802fa
  title: Improving Word Representations via Global Context and Multiple Word Prototypes
- pid: dbde7dfa6cae81df8ac19ef500c42db96c3d1edd
  title: 'Google''s Neural Machine Translation System: Bridging the Gap between Human
    and Machine Translation'
- pid: 1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba
  title: Convolutional Neural Networks for Sentence Classification
- pid: b71ac1e9fb49420d13e084ac67254a0bbd40f83f
  title: Understanding the difficulty of training deep feedforward neural networks
- pid: 44040913380206991b1991daf1192942e038fe31
  title: 'From image descriptions to visual denotations: New similarity metrics for
    semantic inference over event descriptions'
- pid: a6b5b20151c752beb74508f813699fa5216dedfa
  title: 'Canonical Correlation Analysis: An Overview with Application to Learning
    Methods'
- pid: 802e85172bb1418bdfb8211062aa3049e9bd765d
  title: Framing image description as a ranking task
- pid: 0bde8d9367d1004c7396dd69cb27ed97dc2f8d77
  title: 'MatConvNet: Convolutional Neural Networks for MATLAB'
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 330da625c15427c6e42ccfa3b747fb29e5835bf0
  title: Efficient Estimation of Word Representations in Vector Space
- pid: 9819b600a828a57e1cde047bbe710d3446b30da5
  title: Recurrent neural network based language model
slug: Dual-path-Convolutional-Image-Text-Embeddings-with-Zheng-Zheng
title: Dual-path Convolutional Image-Text Embeddings with Instance Loss
url: https://www.semanticscholar.org/paper/Dual-path-Convolutional-Image-Text-Embeddings-with-Zheng-Zheng/58555c7d168d1f50422ed9435d31ecd28d66eaa8?sort=total-citations
venue: ACM Trans. Multim. Comput. Commun. Appl.
year: 2020
