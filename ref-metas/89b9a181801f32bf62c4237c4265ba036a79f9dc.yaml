authors:
- J. Schmidhuber
badges:
- id: OPEN_ACCESS
corpusId: 11761172
fieldsOfStudy:
- Computer Science
numCitedBy: 136
numCiting: 12
paperAbstract: The real-time recurrent learning (RTRL) algorithm (Robinson and Fallside
  1987; Williams and Zipser 1989) requires O(n4) computations per time step, where
  n is the number of noninput units. I describe a method suited for on-line learning
  that computes exactly the same gradient and requires fixed-size storage of the same
  order but has an average time complexity per time step of O(n3).
ref_count: 12
references:
- pid: 424710825d726e10b016204ed2bc979e2a342d10
  title: Experimental Analysis of the Real-time Recurrent Learning Algorithm
- pid: 50c770b425a5bb25c77387f687a9910a9d130722
  title: Learning Complex, Extended Sequences Using the Principle of History Compression
- pid: 26bc0449360d7016f684eafae5b5d2feded32041
  title: An Efficient Gradient-Based Algorithm for On-Line Training of Recurrent Network
    Trajectories
- pid: 006c42929dcd480490fdb367fd7478b2956dbc99
  title: A learning algorithm for analog, fully recurrent neural networks
- pid: 34468c0aa95a7aea212d8738ab899a69b2fc14c6
  title: Learning State Space Trajectories in Recurrent Neural Networks
slug: A-Fixed-Size-Storage-O(n3)-Time-Complexity-Learning-Schmidhuber
title: A Fixed Size Storage O(n3) Time Complexity Learning Algorithm for Fully Recurrent
  Continually Running Networks
url: https://www.semanticscholar.org/paper/A-Fixed-Size-Storage-O(n3)-Time-Complexity-Learning-Schmidhuber/89b9a181801f32bf62c4237c4265ba036a79f9dc?sort=total-citations
venue: Neural Computation
year: 1992
