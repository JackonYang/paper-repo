authors:
- Yang Xu
- Yiheng Xu
- Tengchao Lv
- Lei Cui
- Furu Wei
- Guoxin Wang
- Yijuan Lu
- "D. Flor\xEAncio"
- Cha Zhang
- Wanxiang Che
- Min Zhang
- Lidong Zhou
badges:
- id: OPEN_ACCESS
corpusId: 229923949
fieldsOfStudy:
- Computer Science
numCitedBy: 77
numCiting: 47
paperAbstract: Pre-training of text and layout has proved effective in a variety of
  visually-rich document understanding tasks due to its effective model architecture
  and the advantage of large-scale unlabeled scanned/digital-born documents. We propose
  LayoutLMv2 architecture with new pre-training tasks to model the interaction among
  text, layout, and image in a single multi-modal framework. Specifically, with a
  two-stream multi-modal Transformer encoder, LayoutLMv2 uses not only the existing
  masked visual-language modeling task but also the new text-image alignment and text-image
  matching tasks, which make it better capture the cross-modality interaction in the
  pre-training stage. Meanwhile, it also integrates a spatial-aware self-attention
  mechanism into the Transformer architecture so that the model can fully understand
  the relative positional relationship among different text blocks. Experiment results
  show that LayoutLMv2 outperforms LayoutLM by a large margin and achieves new state-of-the-art
  results on a wide variety of downstream visually-rich document understanding tasks,
  including FUNSD (0.7895 to 0.8420), CORD (0.9493 to 0.9601), SROIE (0.9524 to 0.9781),
  Kleister-NDA (0.8340 to 0.8520), RVL-CDIP (0.9443 to 0.9564), and DocVQA (0.7295
  to 0.8672).
ref_count: 47
references:
- pid: 3465c06c872d8c48d628c5fc2d484087719351b6
  title: 'LayoutLM: Pre-training of Text and Layout for Document Image Understanding'
- pid: aa111c8920e963195968360f59c9de271ae470c2
  title: 'BROS: A PRE-TRAINED LANGUAGE MODEL'
- pid: a03407e7e8a4530d9bb96672e425cfa067f92b76
  title: Robust Layout-aware IE for Visually Rich Documents with Pre-trained Language
    Models
- pid: d8a305b9366608d54452ac30459ee57b4f5cf1c9
  title: 'UNITER: UNiversal Image-TExt Representation Learning'
- pid: bcaf74be62f42c84a604ebd055eec0d4bdc00c45
  title: Deterministic Routing between Layout Abstractions for Multi-Scale Classification
    of Visually Rich Documents
- pid: ba5ed98c4546fada5c732bced4a1c1615f1a4c16
  title: 'PICK: Processing Key Information Extraction from Documents using Improved
    Graph Learning-Convolutional Networks'
- pid: 04df8c70257b5280b9d303502c9d7ddf946f181b
  title: Graph Convolution for Multimodal Information Extraction from Visually Rich
    Documents
- pid: cdcdf4df32a753523d82dd5c2daa55b11ac73749
  title: Fast CNN-Based Document Layout Analysis
- pid: 9baae0bdc2884bcf0aa4063914b87d60952cb678
  title: Learning to Extract Semantic Structure from Documents Using Multimodal Fully
    Convolutional Neural Networks
- pid: e0211c1a138724238359bcd3e0f3012e3a49845b
  title: Visual Detection with Context for Document Layout Analysis
- pid: 617f5151f59848d24fe971cf1cf6bb0caec65ea4
  title: 'TRIE: End-to-End Text Reading and Information Extraction for Document Understanding'
- pid: dcf7fb34ae0be4eb7a838679b6bef0736375bbac
  title: 'ZeroShotCeres: Zero-Shot Relation Extraction from Semi-Structured Webpages'
- pid: 65a9c7b0800c86a196bc14e7621ff895cc6ab287
  title: 'ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language
    Tasks'
- pid: e2d2f64b3bb200c2c3db5ddc367b06311c369341
  title: 'Kleister: A novel task for Information Extraction involving Long Documents
    with Complex Layout'
- pid: c41a11c0e9b8b92b4faaf97749841170b760760a
  title: 'VideoBERT: A Joint Model for Video and Language Representation Learning'
- pid: b5799d10df17de3232540e990da69553800d6376
  title: 'PubLayNet: Largest Dataset Ever for Document Layout Analysis'
- pid: 3cfb319689f06bf04c2e28399361f414ca32c4b3
  title: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
- pid: 2527626c11a84f15709e943fbfa2356e19930e3b
  title: 'VL-BERT: Pre-training of Generic Visual-Linguistic Representations'
- pid: 58c793e278cdbf669a615b2c2479cd69ff785d63
  title: 'FUNSD: A Dataset for Form Understanding in Noisy Scanned Documents'
- pid: 79c93274429d6355959f1e4374c2147bb81ea649
  title: 'LXMERT: Learning Cross-Modality Encoder Representations from Transformers'
- pid: bd86b4b551b9d3fb498f62008b037e7599365018
  title: Evaluation of deep convolutional nets for document image classification and
    retrieval
- pid: c8efcc854d97dfc2a42b83316a2109f9d166e43f
  title: Self-Attention with Relative Position Representations
- pid: f64e1d6bc13aae99aab5449fc9ae742a9ba7761e
  title: 'UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training'
- pid: 20d0564fd3fdbc24f266ca2076826a2271c3ea08
  title: Spatial Dependency Parsing for Semi-Structured Document Information Extraction
- pid: 15aae08159856cdbf0ce539357d473a04dcbb7f3
  title: 'Chargrid: Towards Understanding 2D Documents'
- pid: af8785b368ed988b8dbd4cb34f52dd36eb535c3d
  title: Document Image Classification with Intra-Domain Transfer Learning and Stacked
    Generalization of Deep Convolutional Neural Networks
- pid: f6e0856b4a9199fa968ac00da612a9407b5cb85c
  title: Aggregated Residual Transformations for Deep Neural Networks
- pid: b40bfcf339de3f0dba08fabb2b58b9368ff4c51a
  title: 'DocVQA: A Dataset for VQA on Document Images'
- pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
- pid: 3526555fa0178c101ee9896252c818f9e03532a5
  title: 'Cutting the Error by Half: Investigation of Very Deep CNN and Advanced Training
    Strategies for Document Image Classification'
- pid: def5415149fa48ed7c821c0a6640f3c6a5b8af69
  title: Learning nongenerative grammatical models for document analysis
- pid: 022dd244f2e25525eb37e9dda51abb9cd8ca8c30
  title: Mask R-CNN
- pid: b5c26ab8767d046cb6e32d959fdf726aee89bb62
  title: Inception-v4, Inception-ResNet and the Impact of Residual Connections on
    Learning
- pid: af3f67b6639a50fd094e1467a2f3b6b8fef7c7c2
  title: 'Transformers: State-of-the-Art Natural Language Processing'
- pid: cd4faf2bad343b6498aad54a93169cd3371d03dc
  title: Artificial neural networks for document analysis and recognition
- pid: 58877aa9aa2d09585a4ff4881b02cb1c7ff9bc28
  title: Representation Learning for Information Extraction from Form-like Documents
- pid: c69942bf1b4f75e53cb62d0c5126c1cb4a5aa7bc
  title: 'CORD: A Consolidated Receipt Dataset for Post-OCR Parsing'
- pid: dbde7dfa6cae81df8ac19ef500c42db96c3d1edd
  title: 'Google''s Neural Machine Translation System: Bridging the Gap between Human
    and Machine Translation'
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: d00cbb0c05c1dc922126fe72c1078b773d01c688
  title: ICDAR2019 Competition on Scanned Receipt OCR and Information Extraction
- pid: 05dd7254b632376973f3a1b4d39485da17814df5
  title: 'SQuAD: 100,000+ Questions for Machine Comprehension of Text'
- pid: 96d3343023994c9acdd377464feba073b63d66e8
  title: Modular Multimodal Architecture for Document Classification
- pid: 47c6d10fe8a29fcd1727e805a2b9f804c12e0d4d
  title: Building a test collection for complex document information processing
- pid: d07284a6811f1b2745d91bdb06b040b57f226882
  title: Decoupled Weight Decay Regularization
- pid: 9050b13a07f94430631a7729652c6ad873789d0b
  title: Evaluation of SVM, MLP and GMM Classifiers for Layout Analysis of Historical
    Documents
slug: LayoutLMv2:-Multi-modal-Pre-training-for-Document-Xu-Xu
title: 'LayoutLMv2: Multi-modal Pre-training for Visually-rich Document Understanding'
url: https://www.semanticscholar.org/paper/LayoutLMv2%3A-Multi-modal-Pre-training-for-Document-Xu-Xu/0197abda042e6de87b5f716caa708a6a459f078c
venue: ACL
year: 2021
