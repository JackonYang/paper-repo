authors:
- R. Rosenfeld
badges:
- id: OPEN_ACCESS
corpusId: 18261416
fieldsOfStudy:
- Computer Science
numCitedBy: 69
numCiting: 11
paperAbstract: Introduces a new kind of language model, which models whole sentences
  or utterances directly using the maximum entropy (ME) paradigm. The new model is
  conceptually simpler, and more naturally suited to modeling whole-sentence phenomena,
  than the conditional ME models proposed to date. By avoiding the chain rule, the
  model treats each sentence or utterance as a "bag of features", where features are
  arbitrary computable properties of the sentence. The model is unnormalizable, but
  this does not interfere with training (done via sampling) or with use. Using the
  model is computationally straightforward. The main computational cost of training
  the model is in generating sample sentences from a Gibbs distribution. Interestingly,
  this cost has different dependencies, and is potentially lower than in the comparable
  conditional ME model.
ref_count: 11
references:
- pid: 076fa8d095c37c657f2aff39cf90bc2ea883b7cb
  title: A maximum entropy approach to adaptive statistical language modelling
- pid: 6e58b5f825df9fb0b00465a66598f302c30b080a
  title: 'Trigger-based language models: a maximum entropy approach'
- pid: eadf7d20852caa92310d0cb582269b94226b1e58
  title: Adaptive Language Modeling Using Minimum Discriminant Estimation
- pid: b951b9f78b98a186ba259027996a48e4189d37e5
  title: Inducing Features of Random Fields
- pid: fb486e03369a64de2d5b0df86ec0a7b55d3907db
  title: A Maximum Entropy Approach to Natural Language Processing
- pid: 00f20179b9087fbf24b6656008a9380c590d9ec9
  title: A Maximum Entropy Model for Prepositional Phrase Attachment
- pid: 459b30a9a960080f3b313e41886b1aa0e51e882c
  title: Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration
    of Images
- pid: 08b67692bc037eada8d3d7ce76cc70994e7c8116
  title: Information Theory and Statistical Mechanics
- pid: 37c931cbaa9217b829596dd196520a838562a109
  title: Generalized Iterative Scaling for Log-Linear Models
slug: A-whole-sentence-maximum-entropy-language-model-Rosenfeld
title: A whole sentence maximum entropy language model
url: https://www.semanticscholar.org/paper/A-whole-sentence-maximum-entropy-language-model-Rosenfeld/f72084efcae8b2007e590b0c5a8f1decb61ef935?sort=total-citations
venue: 1997 IEEE Workshop on Automatic Speech Recognition and Understanding Proceedings
year: 1997
