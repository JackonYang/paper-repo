authors:
- Zhicheng Huang
- Zhaoyang Zeng
- Bei Liu
- Dongmei Fu
- Jianlong Fu
badges:
- id: OPEN_ACCESS
corpusId: 214775221
fieldsOfStudy:
- Computer Science
meta_key: pixel-bert-aligning-image-pixels-with-text-by-deep-multi-modal-transformers
numCitedBy: 148
numCiting: 40
paperAbstract: We propose Pixel-BERT to align image pixels with text by deep multi-modal
  transformers that jointly learn visual and language embedding in a unified end-to-end
  framework. We aim to build a more accurate and thorough connection between image
  pixels and language semantics directly from image and sentence pairs instead of
  using region-based image features as the most recent vision and language tasks.
  Our Pixel-BERT which aligns semantic connection in pixel and text level solves the
  limitation of task-specific visual representation for vision and language tasks.
  It also relieves the cost of bounding box annotations and overcomes the unbalance
  between semantic labels in visual task and language semantic. To provide a better
  representation for down-stream tasks, we pre-train a universal end-to-end model
  with image and sentence pairs from Visual Genome dataset and MS-COCO dataset. We
  propose to use a random pixel sampling mechanism to enhance the robustness of visual
  representation and to apply the Masked Language Model and Image-Text Matching as
  pre-training tasks. Extensive experiments on downstream tasks with our pre-trained
  model show that our approach makes the most state-of-the-arts in downstream tasks,
  including Visual Question Answering (VQA), image-text retrieval, Natural Language
  for Visual Reasoning for Real (NLVR). Particularly, we boost the performance of
  a single model in VQA task by 2.17 points compared with SOTA under fair comparison.
ref_count: 40
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: uniter-learning-universal-image-text-representations
  numCitedBy: 282
  pid: 54416048772b921720f19869ed11c2a360589d03
  show_ref_link: true
  title: UNITER - Learning UNiversal Image-TExt Representations
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: a-corpus-for-reasoning-about-natural-language-grounded-in-photographs
  numCitedBy: 211
  pid: cf336d272a30d6ad6141db67faa64deb8791cd61
  show_ref_link: true
  title: A Corpus for Reasoning about Natural Language Grounded in Photographs
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: making-the-v-in-vqa-matter-elevating-the-role-of-image-understanding-in-visual-question-answering
  numCitedBy: 1162
  pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  show_ref_link: true
  title: Making the V in VQA Matter - Elevating the Role of Image Understanding in
    Visual Question Answering
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-residual-learning-for-image-recognition
  numCitedBy: 95324
  pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  show_ref_link: true
  title: Deep Residual Learning for Image Recognition
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: vl-bert-pre-training-of-generic-visual-linguistic-representations
  numCitedBy: 707
  pid: 2527626c11a84f15709e943fbfa2356e19930e3b
  show_ref_link: true
  title: VL-BERT - Pre-training of Generic Visual-Linguistic Representations
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: lxmert-learning-cross-modality-encoder-representations-from-transformers
  numCitedBy: 916
  pid: 79c93274429d6355959f1e4374c2147bb81ea649
  show_ref_link: true
  title: LXMERT - Learning Cross-Modality Encoder Representations from Transformers
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: visualbert-a-simple-and-performant-baseline-for-vision-and-language
  numCitedBy: 630
  pid: 5aec474c31a2f4b74703c6f786c0a8ff85c450da
  show_ref_link: true
  title: VisualBERT - A Simple and Performant Baseline for Vision and Language
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks
  numCitedBy: 1266
  pid: 65a9c7b0800c86a196bc14e7621ff895cc6ab287
  show_ref_link: true
  title: ViLBERT - Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language
    Tasks
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding
  numCitedBy: 33754
  pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  show_ref_link: true
  title: BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: imagebert-cross-modal-pre-training-with-large-scale-weak-supervised-image-text-data
  numCitedBy: 101
  pid: a9fd5511b42206a27748f373e0fdb7eb76a23055
  show_ref_link: true
  title: ImageBERT - Cross-modal Pre-training with Large-scale Weak-supervised Image-Text
    Data
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: unicoder-vl-a-universal-encoder-for-vision-and-language-by-cross-modal-pre-training
  numCitedBy: 382
  pid: 2bc1c8bd00bbf7401afcb5460277840fd8bab029
  show_ref_link: true
  title: Unicoder-VL - A Universal Encoder for Vision and Language by Cross-modal
    Pre-training
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering
  numCitedBy: 2275
  pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  show_ref_link: true
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: aggregated-residual-transformations-for-deep-neural-networks
  numCitedBy: 5483
  pid: f6e0856b4a9199fa968ac00da612a9407b5cb85c
  show_ref_link: true
  title: Aggregated Residual Transformations for Deep Neural Networks
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks
  numCitedBy: 32562
  pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  show_ref_link: true
  title: Faster R-CNN - Towards Real-Time Object Detection with Region Proposal Networks
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: why-adam-beats-sgd-for-attention-models
  numCitedBy: 49
  pid: b16ff8329e6b10914fd7908f22bda355130e9ba8
  show_ref_link: false
  title: Why ADAM Beats SGD for Attention Models
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: unified-vision-language-pre-training-for-image-captioning-and-vqa
  numCitedBy: 355
  pid: 6648b4db5f12c30941ea78c695e77aded19672bb
  show_ref_link: true
  title: Unified Vision-Language Pre-Training for Image Captioning and VQA
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: fusion-of-detected-objects-in-text-for-visual-question-answering
  numCitedBy: 111
  pid: b82153bf85d5d1edd3f170aace830e5328ca9ed0
  show_ref_link: true
  title: Fusion of Detected Objects in Text for Visual Question Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: knowledge-aware-semantic-concept-expansion-for-image-text-matching
  numCitedBy: 26
  pid: ad748d1772f893b3c8a3857a19292375be259daf
  show_ref_link: false
  title: Knowledge Aware Semantic Concept Expansion for Image-Text Matching
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: position-focused-attention-network-for-image-text-matching
  numCitedBy: 63
  pid: 48a7873681c6aa88b9e0e22a25c2a8245eaeb45f
  show_ref_link: false
  title: Position Focused Attention Network for Image-Text Matching
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: pythia-a-platform-for-vision-language-research
  numCitedBy: 48
  pid: d6dedf6d25df2a5cd727a019b613953afc9a0300
  show_ref_link: false
  title: Pythia-A platform for vision & language research
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: videobert-a-joint-model-for-video-and-language-representation-learning
  numCitedBy: 569
  pid: c41a11c0e9b8b92b4faaf97749841170b760760a
  show_ref_link: true
  title: VideoBERT - A Joint Model for Video and Language Representation Learning
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: cross-lingual-language-model-pretraining
  numCitedBy: 1510
  pid: ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc
  show_ref_link: true
  title: Cross-lingual Language Model Pretraining
  year: 2019
- fieldsOfStudy:
  - Computer Science
  - Environmental Science
  meta_key: conceptual-captions-a-cleaned-hypernymed-image-alt-text-dataset-for-automatic-image-captioning
  numCitedBy: 632
  pid: b4df354db88a70183a64dbc9e56cf14e7669a6c0
  show_ref_link: true
  title: Conceptual Captions - A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic
    Image Captioning
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: improving-language-understanding-by-generative-pre-training
  numCitedBy: 3533
  pid: cd18800a0fe0b668a1cc19f2ec95b5003d0a5035
  show_ref_link: true
  title: Improving Language Understanding by Generative Pre-Training
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: bilinear-attention-networks
  numCitedBy: 408
  pid: a5d10341717c0519cf63151b496a6d2ed67aa05f
  show_ref_link: true
  title: Bilinear Attention Networks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: imagenet-a-large-scale-hierarchical-image-database
  numCitedBy: 27406
  pid: 1b47265245e8db53a553049dcb27ed3e495fd625
  show_ref_link: true
  title: ImageNet - A large-scale hierarchical image database
  year: 2009
- fieldsOfStudy:
  - Computer Science
  meta_key: stacked-cross-attention-for-image-text-matching
  numCitedBy: 481
  pid: 45dd2a3cd7c27f2e9509b023d702408f5ac11c9d
  show_ref_link: true
  title: Stacked Cross Attention for Image-Text Matching
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: vse-improving-visual-semantic-embeddings-with-hard-negatives
  numCitedBy: 508
  pid: f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8
  show_ref_link: true
  title: VSE++ - Improving Visual-Semantic Embeddings with Hard Negatives
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: attention-is-all-you-need
  numCitedBy: 35157
  pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  show_ref_link: true
  title: Attention is All you Need
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: mutan-multimodal-tucker-fusion-for-visual-question-answering
  numCitedBy: 387
  pid: fe466e84fa2e838adc3c37ee327cd68004ae08fe
  show_ref_link: true
  title: MUTAN - Multimodal Tucker Fusion for Visual Question Answering
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation
  numCitedBy: 4645
  pid: dbde7dfa6cae81df8ac19ef500c42db96c3d1edd
  show_ref_link: true
  title: Google's Neural Machine Translation System - Bridging the Gap between Human
    and Machine Translation
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: layer-normalization
  numCitedBy: 3050
  pid: 97fb4e3d45bb098e27e0071448b6152217bd35a5
  show_ref_link: true
  title: Layer Normalization
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: visual-genome-connecting-language-and-vision-using-crowdsourced-dense-image-annotations
  numCitedBy: 2772
  pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  show_ref_link: true
  title: Visual Genome - Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: vqa-visual-question-answering
  numCitedBy: 2887
  pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  show_ref_link: true
  title: VQA - Visual Question Answering
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: show-and-tell-a-neural-image-caption-generator
  numCitedBy: 4510
  pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  show_ref_link: true
  title: Show and tell - A neural image caption generator
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-visual-semantic-alignments-for-generating-image-descriptions
  numCitedBy: 2575
  pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  show_ref_link: true
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: dropout-a-simple-way-to-prevent-neural-networks-from-overfitting
  numCitedBy: 28149
  pid: 34f25a8704614163c4095b3ee2fc969b60de4698
  show_ref_link: true
  title: Dropout - a simple way to prevent neural networks from overfitting
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: microsoft-coco-common-objects-in-context
  numCitedBy: 19779
  pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  show_ref_link: true
  title: Microsoft COCO - Common Objects in Context
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: show-attend-and-tell-neural-image-caption-generation-with-visual-attention
  numCitedBy: 7252
  pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  show_ref_link: true
  title: Show, Attend and Tell - Neural Image Caption Generation with Visual Attention
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: going-deeper-with-convolutions
  numCitedBy: 29482
  pid: e15cf50aa89fee8535703b9f9512fca5bfc43327
  show_ref_link: true
  title: Going deeper with convolutions
  year: 2015
slug: Pixel-BERT:-Aligning-Image-Pixels-with-Text-by-Deep-Huang-Zeng
title: Pixel-BERT - Aligning Image Pixels with Text by Deep Multi-Modal Transformers
url: https://www.semanticscholar.org/paper/Pixel-BERT:-Aligning-Image-Pixels-with-Text-by-Deep-Huang-Zeng/598a2ee223e2949c3b28389e922c1892b4717d2a?sort=total-citations
venue: ArXiv
year: 2020
