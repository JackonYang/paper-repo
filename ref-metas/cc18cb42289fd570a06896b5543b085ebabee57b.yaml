authors:
- Junhua Mao
- Jiajing Xu
- Yushi Jing
- A. Yuille
badges:
- id: OPEN_ACCESS
corpusId: 9461243
fieldsOfStudy:
- Computer Science
numCitedBy: 33
numCiting: 37
paperAbstract: 'In this paper, we focus on training and evaluating effective word
  embeddings with both text and visual information. More specifically, we introduce
  a large-scale dataset with 300 million sentences describing over 40 million images
  crawled and downloaded from publicly available Pins (i.e. an image with sentence
  descriptions uploaded by users) on Pinterest. This dataset is more than 200 times
  larger than MS COCO, the standard large-scale image dataset with sentence descriptions.
  In addition, we construct an evaluation dataset to directly assess the effectiveness
  of word embeddings in terms of finding semantically similar or related words and
  phrases. The word/phrase pairs in this evaluation dataset are collected from the
  click data with millions of users in an image search system, thus contain rich semantic
  relationships. Based on these datasets, we propose and compare several Recurrent
  Neural Networks (RNNs) based multimodal (text and image) models. Experiments show
  that our model benefits from incorporating the visual information into the word
  embeddings, and a weight sharing strategy is crucial for learning such multimodal
  embeddings. The project page is: http://www.stat.ucla.edu/~junhua.mao/multimodal_embedding.html
  (The datasets introduced in this work will be gradually released on the project
  page.).'
ref_count: 37
references:
- pid: 2e36ea91a3c8fbff92be2989325531b4002e2afc
  title: Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
- pid: 9814df8bd00ba999c4d1e305a7e9bca579dc7c75
  title: 'Framing Image Description as a Ranking Task: Data, Models and Evaluation
    Metrics (Extended Abstract)'
- pid: 54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745
  title: Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)
- pid: f4af49a1ead3c81cc5d023878cb67c5646dd8a04
  title: Learning a Recurrent Visual Representation for Image Caption Generation
- pid: eb847564774394c484e701437dbcffbf040ff3cc
  title: 'Learning Like a Child: Fast Novel Visual Concept Learning from Sentence
    Descriptions of Images'
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: 1938624bb9b0f999536dcc8d8f519810bb4e1b3b
  title: On Using Very Large Target Vocabulary for Neural Machine Translation
- pid: 87f40e6f3022adbc1f1905e3e506abad05a9964f
  title: Distributed Representations of Words and Phrases and their Compositionality
- pid: 5eb1a272f9933a11d113cf63fe659e073942bce5
  title: Neural Probabilistic Language Models
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: 0b544dfe355a5070b60986319a3f51fb45d1348e
  title: "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical\
    \ Machine Translation"
- pid: 1c46943103bd7b7a2c7be86859995a4144d1938b
  title: Visualizing Data using t-SNE
- pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  title: 'Im2Text: Describing Images Using 1 Million Captioned Photographs'
- pid: 7a96765c147c9c814803c8c9de28a1dd069271da
  title: 'SimLex-999: Evaluating Semantic Models With (Genuine) Similarity Estimation'
- pid: 381929a8187010f6db940a23d78731c8e694c56c
  title: 'The IAPR TC-12 Benchmark: A New Evaluation Resource for Visual Information
    Systems'
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: 44040913380206991b1991daf1192942e038fe31
  title: 'From image descriptions to visual denotations: New similarity metrics for
    semantic inference over event descriptions'
- pid: e0c01df98a6b633b25c96c1a99b713ac96f1c5be
  title: 'Placing search in context: the concept revisited'
- pid: 668087f0ae7ce1de6e0bd0965dbb480c08103260
  title: Finding Structure in Time
- pid: a538b05ebb01a40323997629e171c91aa28b8e2f
  title: Rectified Linear Units Improve Restricted Boltzmann Machines
- pid: 354c029c88be2bbc27dfd2e2e729c0ae622511e6
  title: 'YFCC100M: the new data in multimedia research'
slug: Training-and-Evaluating-Multimodal-Word-Embeddings-Mao-Xu
title: Training and Evaluating Multimodal Word Embeddings with Large-scale Web Annotated
  Images
url: https://www.semanticscholar.org/paper/Training-and-Evaluating-Multimodal-Word-Embeddings-Mao-Xu/cc18cb42289fd570a06896b5543b085ebabee57b?sort=total-citations
venue: NIPS
year: 2016
