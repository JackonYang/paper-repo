authors:
- Robik Shrestha
- Kushal Kafle
- Christopher Kanan
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 67855410
fieldsOfStudy:
- Computer Science
numCitedBy: 53
numCiting: 60
paperAbstract: 'Visual Question Answering (VQA) research is split into two camps:
  the first focuses on VQA datasets that require natural image understanding and the
  second focuses on synthetic datasets that test reasoning. A good VQA algorithm should
  be capable of both, but only a few VQA algorithms are tested in this manner. We
  compare five state-of-the-art VQA algorithms across eight VQA datasets covering
  both domains. To make the comparison fair, all of the models are standardized as
  much as possible, e.g., they use the same visual features, answer vocabularies,
  etc. We find that methods do not generalize across the two domains. To address this
  problem, we propose a new VQA algorithm that rivals or exceeds the state-of-the-art
  for both domains.'
ref_count: 60
references:
- pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  title: 'Making the V in VQA Matter: Elevating the Role of Image Understanding in
    Visual Question Answering'
- pid: 915b5b12f9bdebc321e970ecd713458c3479d70e
  title: An Analysis of Visual Question Answering Algorithms
- pid: 6d92ce1c4f7f0ccfe068e663903e4dd614a15ede
  title: 'Visual question answering: Datasets, algorithms, and future challenges'
- pid: 88c307c51594c6d802080a0780d0d654e2e2891f
  title: 'Visual question answering: A survey of methods and datasets'
- pid: ebe5081b8a24b4740db929b6eae75f28f8edbc58
  title: Answer-Type Prediction for Visual Question Answering
- pid: 90873a97aa9a43775e5aeea01b03aea54b28bfbd
  title: 'Don''t Just Assume; Look and Answer: Overcoming Priors for Visual Question
    Answering'
- pid: 30a3eee5e9302108416f6234d739373dde68d373
  title: Learning to Count Objects in Natural Images for Visual Question Answering
- pid: a3d071d2a5c11329aa324b2cae6b7b6ca7800213
  title: 'C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0
    Dataset'
- pid: f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622
  title: Improved Fusion of Visual and Language Representations by Dense Symmetric
    Co-attention for Visual Question Answering
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: 6ac33d3dcecbed17580509a34bccdff2425f7ed8
  title: Learning Conditioned Graph Structures for Interpretable Visual Question Answering
- pid: 8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5
  title: Analyzing the Behavior of Visual Question Answering Models
- pid: fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b
  title: Hierarchical Question-Image Co-Attention for Visual Question Answering
- pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  title: Stacked Attention Networks for Image Question Answering
- pid: 0ac8f1a3c679b90d22c1f840cdc8d61ffef750ac
  title: Deep Compositional Question Answering with Neural Module Networks
- pid: fddc15480d086629b960be5bff96232f967f2252
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
- pid: fe466e84fa2e838adc3c37ee327cd68004ae08fe
  title: 'MUTAN: Multimodal Tucker Fusion for Visual Question Answering'
- pid: 03eb382e04cca8cca743f7799070869954f1402a
  title: 'CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual
    Reasoning'
- pid: b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81
  title: 'Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge'
- pid: f651593fa6c83d717fc961482696a53b6fca5ab5
  title: Dual Attention Networks for Multimodal Reasoning and Matching
- pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
- pid: a396a6febdacb84340d139096455e67049ac1e22
  title: 'Learning to Reason: End-to-End Module Networks for Visual Question Answering'
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: 2231f44be9a8472a46d8e8a628b4e52b9a8f44e0
  title: Visual Dialog
- pid: b58e08741fb9803fa2a870eee139137d3bade332
  title: Training Recurrent Answering Units with Joint Loss Minimization for VQA
- pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
- pid: 75ddc7ee15be14013a3462c01b38b0548486fbcb
  title: Learning to Compose Neural Networks for Question Answering
- pid: 9d15ebe3f5aaf32a9f835f88703241461324c35b
  title: 'Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding'
- pid: 7289a240c9425bc7cad87b3b835e5f0cac22f488
  title: 'DVQA: Understanding Data Visualizations via Question Answering'
- pid: afe3a0d463e2f099305c745ddbf943844583795d
  title: Learning Visual Question Answering by Bootstrapping Hard Attention
- pid: a5d10341717c0519cf63151b496a6d2ed67aa05f
  title: Bilinear Attention Networks
- pid: 007112213ece771be72cbecfd59f048209facabd
  title: A simple neural network module for relational reasoning
- pid: cd0a7c58964905ccfddbad1614165320ccc56393
  title: 'Transparency by Design: Closing the Gap Between Performance and Interpretability
    in Visual Reasoning'
- pid: 7cfa5c97164129ce3630511f639040d28db1d4b7
  title: 'FiLM: Visual Reasoning with a General Conditioning Layer'
- pid: 289fb3709475f5c87df8d97f129af54029d27fee
  title: Compositional Attention Networks for Machine Reasoning
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
- pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  title: 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks'
- pid: 2e17cf6a339fd071ad222062f868e882ef4120a4
  title: Inferring and Executing Programs for Visual Reasoning
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: 36eff562f65125511b5dfab68ce7f7a943c27478
  title: Semi-Supervised Classification with Graph Convolutional Networks
- pid: 7ffdbc358b63378f07311e883dddacc9faeeaf4b
  title: Fast R-CNN
slug: Answer-Them-All!-Toward-Universal-Visual-Question-Shrestha-Kafle
title: Answer Them All! Toward Universal Visual Question Answering Models
url: https://www.semanticscholar.org/paper/Answer-Them-All!-Toward-Universal-Visual-Question-Shrestha-Kafle/d9344534ab39544a3a3c173b27628e0d9c5d4dc5?sort=total-citations
venue: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2019
