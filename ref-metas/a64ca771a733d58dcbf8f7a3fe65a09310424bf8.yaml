authors:
- Raymond L. Watrous
- G. Kuhn
badges: []
corpusId: 32480997
fieldsOfStudy:
- Computer Science
numCitedBy: 215
numCiting: 10
paperAbstract: Second-order recurrent networks that recognize simple finite state
  languages over {0,1}* are induced from positive and negative examples. Using the
  complete gradient of the recurrent network and sufficient training examples to constrain
  the definition of the language to be induced, solutions are obtained that correctly
  recognize strings of arbitrary length.
ref_count: 10
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 513
  pid: bd46c1b5948abe04e565a8bae6454da63a1b021e
  title: Finite State Automata and Simple Recurrent Networks
  year: 1989
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 3832
  pid: ce9a21b93ba29d4145a8ef6bf401e77f261848de
  title: A Learning Algorithm for Continually Running Fully Recurrent Neural Networks
  year: 1989
- fieldsOfStudy:
  - Psychology
  numCitedBy: 9858
  pid: 668087f0ae7ce1de6e0bd0965dbb480c08103260
  title: Finding Structure in Time
  year: 1990
slug: Induction-of-Finite-State-Languages-Using-Recurrent-Watrous-Kuhn
title: Induction of Finite-State Languages Using Second-Order Recurrent Networks
url: https://www.semanticscholar.org/paper/Induction-of-Finite-State-Languages-Using-Recurrent-Watrous-Kuhn/a64ca771a733d58dcbf8f7a3fe65a09310424bf8?sort=total-citations
venue: Neural Computation
year: 1992
