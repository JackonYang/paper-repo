authors:
- Kuniaki Saito
- Andrew Shin
- Y. Ushiku
- T. Harada
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 5805515
fieldsOfStudy:
- Computer Science
numCitedBy: 46
numCiting: 30
paperAbstract: "Visual question answering (VQA) tasks use two types of images: abstract\
  \ (illustrations) and real. Domain-specific differences exist between the two types\
  \ of images with respect to \u201Cobjectness,\u201D \u201Ctexture,\u201D and \u201C\
  color.\u201D Therefore, achieving similar performance by applying methods developed\
  \ for real images to abstract images, and vice versa, is difficult. This is a critical\
  \ problem in VQA, because image features are crucial clues for correctly answering\
  \ the questions about the images. However, an effective, domain-invariant method\
  \ can provide insight into the high-level reasoning required for VQA. We thus propose\
  \ a method called DualNet that demonstrates performance that is invariant to the\
  \ differences in real and abstract scene domains. Experimental results show that\
  \ DualNet outperforms state-of-the-art methods, especially for the abstract images\
  \ category."
ref_count: 30
references:
- pid: 7214daf035ab005b3d1e739750dd597b4f4513fa
  title: A Focused Dynamic Attention Model for Visual Question Answering
- pid: 5fa973b8d284145bf0ced9acf2913a74674260f6
  title: 'Yin and Yang: Balancing and Answering Binary Visual Questions'
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: 1cf6bc0866226c1f8e282463adc8b75d92fba9bb
  title: 'Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for
    Visual Question Answering'
- pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  title: Stacked Attention Networks for Image Question Answering
- pid: f96898d15a1bf1fa8925b1280d0e07a7a8e72194
  title: Dynamic Memory Networks for Visual and Textual Question Answering
- pid: 175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22
  title: 'Where to Look: Focus Regions for Visual Question Answering'
- pid: fddc15480d086629b960be5bff96232f967f2252
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
- pid: 98bd5dd1740f585bf25320ba504e2c1ae57f2e5f
  title: Learning to Answer Questions from Image Using Convolutional Neural Network
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 1afb710a5b35a2352a6495e4bf6eef66808daf1b
  title: Multimodal Residual Learning for Visual QA
- pid: d696a1923288e6c15422660de9553f6fdb6a4fae
  title: Natural Language Object Retrieval
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: 385c18cc4024a3b3206c508c512e037b9c00b8f3
  title: Image Question Answering Using Convolutional Neural Network with Dynamic
    Parameter Prediction
- pid: 1b47265245e8db53a553049dcb27ed3e495fd625
  title: 'ImageNet: A large-scale hierarchical image database'
- pid: 75ddc7ee15be14013a3462c01b38b0548486fbcb
  title: Learning to Compose Neural Networks for Question Answering
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: 6bdb186ec4726e00a8051119636d4df3b94043b5
  title: 'Caffe: Convolutional Architecture for Fast Feature Embedding'
- pid: 7ffdbc358b63378f07311e883dddacc9faeeaf4b
  title: Fast R-CNN
- pid: 1c46943103bd7b7a2c7be86859995a4144d1938b
  title: Visualizing Data using t-SNE
- pid: 11540131eae85b2e11d53df7f1360eeb6476e7f4
  title: 'Learning to Forget: Continual Prediction with LSTM'
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
slug: DualNet:-Domain-invariant-network-for-visual-Saito-Shin
title: 'DualNet: Domain-invariant network for visual question answering'
url: https://www.semanticscholar.org/paper/DualNet:-Domain-invariant-network-for-visual-Saito-Shin/121a9a160f1f2819a01edbe522024b58dbfee798?sort=total-citations
venue: 2017 IEEE International Conference on Multimedia and Expo (ICME)
year: 2017
