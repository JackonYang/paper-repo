authors:
- H. Barlow
- T. P. Kaushal
- G. Mitchison
badges: []
corpusId: 28107770
fieldsOfStudy:
- Computer Science
numCitedBy: 203
numCiting: 10
paperAbstract: To determine whether a particular sensory event is a reliable predictor
  of reward or punishment it is necessary to know the prior probability of that event.
  If the variables of a sensory representation normally occur independently of each
  other, then it is possible to derive the prior probability of any logical function
  of the variables from the prior probabilities of the individual variables, without
  any additional knowledge; hence such a representation enormously enlarges the scope
  of definable events that can be searched for reliable predictors. Finding a Minimum
  Entropy Code is a possible method of forming such a representation, and methods
  for doing this are explored in this paper. The main results are (1) to show how
  to find such a code when the probabilities of the input states form a geometric
  progression, as is shown to be nearly true for keyboard characters in normal text;
  (2) to show how a Minimum Entropy Code can be approximated by repeatedly recoding
  pairs, triples, etc. of an original 7-bit code for keyboard characters; (3) to prove
  that in some cases enlarging the capacity of the output channel can lower the entropy.
ref_count: 10
references:
- pid: 6d0198460198fdb49b89d1646049712b3a0683df
  title: Some informational aspects of visual perception.
- pid: b7780f292c48e504e3a2724e54c205e6c6221932
  title: Computational analysis of present-day American English
- pid: 7947b19f7d5488b8d76664c8b2d70daff350babd
  title: Adaptation and decorrelation in the cortex
slug: Finding-Minimum-Entropy-Codes-Barlow-Kaushal
title: Finding Minimum Entropy Codes
url: https://www.semanticscholar.org/paper/Finding-Minimum-Entropy-Codes-Barlow-Kaushal/5074f2219ddac70995f0a5e81ee2e892cb884b56?sort=total-citations
venue: Neural Computation
year: 1989
