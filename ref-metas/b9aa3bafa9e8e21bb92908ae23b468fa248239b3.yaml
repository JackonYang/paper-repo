authors:
- Subhashini Venugopalan
- Lisa Anne Hendricks
- Marcus Rohrbach
- R. Mooney
- Trevor Darrell
- Kate Saenko
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 8457705
fieldsOfStudy:
- Computer Science
numCitedBy: 138
numCiting: 33
paperAbstract: Recent captioning models are limited in their ability to scale and
  describe concepts unseen in paired image-text corpora. We propose the Novel Object
  Captioner (NOC), a deep visual semantic captioning model that can describe a large
  number of object categories not present in existing image-caption datasets. Our
  model takes advantage of external sources &#x2013; labeled images from object recognition
  datasets, and semantic knowledge extracted from unannotated text. We propose minimizing
  a joint objective which can learn from these diverse data sources and leverage distributional
  semantic embeddings, enabling the model to generalize and describe novel objects
  outside of image-caption datasets. We demonstrate that our model exploits semantic
  information to generate captions for hundreds of object categories in the ImageNet
  object recognition dataset that are not observed in MSCOCO image-caption training
  data, as well as many categories that are observed very rarely. Both automatic evaluations
  and human judgements show that our model considerably outperforms prior work in
  being able to describe many more categories of objects.
ref_count: 33
references:
- pid: e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17
  title: 'Deep Compositional Captioning: Describing Novel Object Categories without
    Paired Training Data'
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: 4aa4069693bee00d1b0759ca3df35e59284e9845
  title: 'DeViSE: A Deep Visual-Semantic Embedding Model'
- pid: eb847564774394c484e701437dbcffbf040ff3cc
  title: 'Learning Like a Child: Fast Novel Visual Concept Learning from Sentence
    Descriptions of Images'
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: 2e36ea91a3c8fbff92be2989325531b4002e2afc
  title: Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
- pid: 54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745
  title: Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)
- pid: 0ca7d208ff8d81377e0eaa9723820aeae7a7322d
  title: Grounded Compositional Semantics for Finding and Describing Images with Sentences
- pid: 59927ded86ab4f7253fc32efb351e5a13e746ead
  title: 'TreeTalk: Composition and Compression of Trees for Image Descriptions'
- pid: 76a1dca3a9c2b0229c1b12c95752dcf40dc95a11
  title: Corpus-Guided Sentence Generation of Natural Images
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: fad611e35b3731740b4d8b754241e77add5a70b9
  title: Multimodal Neural Language Models
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
- pid: 355de7460120ddc1150d9ce3756f9848983f7ff4
  title: 'Midge: Generating Image Descriptions From Computer Vision Detections'
- pid: f9a1b3850dfd837793743565a8af95973d395a4e
  title: LSTM Neural Networks for Language Modeling
- pid: 26adb749fc5d80502a6d889966e50b31391560d3
  title: 'Meteor Universal: Language Specific Translation Evaluation for Any Target
    Language'
- pid: 2f5102ec3f70d0dea98c957cc2cab4d15d83a2da
  title: The Stanford CoreNLP Natural Language Processing Toolkit
- pid: 10d85561e4aafc516d10064f30dff05b41f70afe
  title: '[Et al].'
slug: Captioning-Images-with-Diverse-Objects-Venugopalan-Hendricks
title: Captioning Images with Diverse Objects
url: https://www.semanticscholar.org/paper/Captioning-Images-with-Diverse-Objects-Venugopalan-Hendricks/b9aa3bafa9e8e21bb92908ae23b468fa248239b3?sort=total-citations
venue: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2017
