authors:
- Clifford B. Miller
- C. Lee Giles
badges:
- id: OPEN_ACCESS
corpusId: 6095811
fieldsOfStudy:
- Computer Science
numCitedBy: 64
numCiting: 0
paperAbstract: "There has been much interest in increasing the computational power\
  \ of neural networks. In addition there has been much interest in \u201Cdesigning\u201D\
  \ neural networks better suited to particular problems. Increasing the \u201Corder\u201D\
  \ of the connectivity of a neural network permits both. Though order has played\
  \ a significant role in feedforward neural networks, its role in dynamically driven\
  \ recurrent networks is still being understood. This work explores the effect of\
  \ order in learning grammars. We present an experimental comparison of first order\
  \ and second order recurrent neural networks, as applied to the task of grammatical\
  \ inference. We show that for the small grammars studied these two neural net architectures\
  \ have comparable learning and generalization power, and that both are reasonably\
  \ capable of extracting the correct finite state automata for the language in question.\
  \ However, for a larger randomly-generated ten-state grammar, second order networks\
  \ significantly outperformed the first order networks, both in convergence time\
  \ and generalization capability. We show that these networks learn faster the more\
  \ neurons they have (our experiments used up to 10 hidden neurons), but that the\
  \ solutions found by smaller networks are usually of better quality (in terms of\
  \ generalization performance after training). Second order nets have the advantage\
  \ that they converge more quickly to a solution and can find it more reliably than\
  \ first order nets, but that the second order solutions tend to be of poorer quality\
  \ than those of the first order if both architectures are trained to the same error\
  \ tolerance. Despite this, second order nets can more successfully extract finite\
  \ state machines using heuristic clustering techniques applied to the internal state\
  \ representations. We speculate that this may be due to restrictions on the ability\
  \ of first order architecture to fully make use of its internal state representation\
  \ power and that this may have implications for the performance of the two architectures\
  \ when scaled up to larger problems."
ref_count: 0
references: []
slug: Experimental-Comparison-of-the-Effect-of-Order-in-Miller-Giles
title: Experimental Comparison of the Effect of Order in Recurrent Neural Networks
url: https://www.semanticscholar.org/paper/Experimental-Comparison-of-the-Effect-of-Order-in-Miller-Giles/34f8c5769899dfd9450bb13c3f52c18c88444515?sort=total-citations
venue: Int. J. Pattern Recognit. Artif. Intell.
year: 1993
