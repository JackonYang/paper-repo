authors:
- Yann Dauphin
- Angela Fan
- Michael Auli
- David Grangier
badges:
- id: OPEN_ACCESS
corpusId: 16119010
fieldsOfStudy:
- Computer Science
meta_key: language-modeling-with-gated-convolutional-networks
numCitedBy: 1284
numCiting: 42
paperAbstract: The pre-dominant approach to language modeling to date is based on
  recurrent neural networks. Their success on this task is often linked to their ability
  to capture unbounded context. In this paper we develop a finite context approach
  through stacked convolutions, which can be more efficient since they allow parallelization
  over sequential tokens. We propose a novel simplified gating mechanism that outperforms
  Oord et al (2016) and investigate the impact of key architectural decisions. The
  proposed approach achieves state-of-the-art on the WikiText-103 benchmark, even
  though it features long-term dependencies, as well as competitive results on the
  Google Billion Words benchmark. Our model reduces the latency to score a sentence
  by an order of magnitude compared to a recurrent baseline. To our knowledge, this
  is the first time a non-recurrent approach is competitive with strong recurrent
  models on these large scale language tasks.
ref_count: 42
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: gencnn-a-convolutional-architecture-for-word-sequence-prediction
  numCitedBy: 20
  pid: b7cfccf123f86785476a06c8039889a2eb1e2d73
  show_ref_link: false
  title: genCNN - A Convolutional Architecture for Word Sequence Prediction
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: exploring-the-limits-of-language-modeling
  numCitedBy: 951
  pid: 2f2d8f8072e5cc9b296fad551f65f183bdbff7aa
  show_ref_link: true
  title: Exploring the Limits of Language Modeling
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: blackout-speeding-up-recurrent-neural-network-language-models-with-very-large-vocabularies
  numCitedBy: 70
  pid: 12a5b7190b981bf478b4c9c04d3c0d41f13b9023
  show_ref_link: false
  title: BlackOut - Speeding up Recurrent Neural Network Language Models With Very
    Large Vocabularies
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: pointer-sentinel-mixture-models
  numCitedBy: 1042
  pid: efbd381493bb9636f489b965a2034d529cd56bcd
  show_ref_link: true
  title: Pointer Sentinel Mixture Models
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: one-billion-word-benchmark-for-measuring-progress-in-statistical-language-modeling
  numCitedBy: 903
  pid: 5d833331b0e22ff359db05c62a8bca18c4f04b68
  show_ref_link: false
  title: One billion word benchmark for measuring progress in statistical language
    modeling
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: outrageously-large-neural-networks-the-sparsely-gated-mixture-of-experts-layer
  numCitedBy: 862
  pid: 510e26733aaff585d65701b9f1be7ca9d5afc586
  show_ref_link: true
  title: Outrageously Large Neural Networks - The Sparsely-Gated Mixture-of-Experts
    Layer
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: skip-gram-language-modeling-using-sparse-non-negative-matrix-probability-estimation
  numCitedBy: 12
  pid: 0dc9eb7d17f2def56ad930945f2521653f04c3fa
  show_ref_link: false
  title: Skip-gram Language Modeling Using Sparse Non-negative Matrix Probability
    Estimation
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: improving-neural-language-models-with-a-continuous-cache
  numCitedBy: 241
  pid: 2d7782c225e0fc123d6e227f2cb253e58279ac73
  show_ref_link: false
  title: Improving Neural Language Models with a Continuous Cache
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: hierarchical-probabilistic-neural-network-language-model
  numCitedBy: 942
  pid: c19fbefdeead6a4154a22a9c8551a18b1530033a
  show_ref_link: false
  title: Hierarchical Probabilistic Neural Network Language Model
  year: 2005
- fieldsOfStudy:
  - Computer Science
  meta_key: strategies-for-training-large-vocabulary-neural-language-models
  numCitedBy: 127
  pid: 759956bb98689dbcc891528636d8994e54318f85
  show_ref_link: false
  title: Strategies for Training Large Vocabulary Neural Language Models
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: recurrent-neural-network-based-language-model
  numCitedBy: 4900
  pid: 9819b600a828a57e1cde047bbe710d3446b30da5
  show_ref_link: true
  title: Recurrent neural network based language model
  year: 2010
- fieldsOfStudy:
  - Computer Science
  meta_key: efficient-softmax-approximation-for-gpus
  numCitedBy: 196
  pid: 9ec499af9b85f30bdbdd6cdfbb07d484808c526a
  show_ref_link: false
  title: Efficient softmax approximation for GPUs
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: weight-normalization-a-simple-reparameterization-to-accelerate-training-of-deep-neural-networks
  numCitedBy: 1290
  pid: 3d2c6941a9b4608ba52b328369a3352db2092ae0
  show_ref_link: true
  title: Weight Normalization - A Simple Reparameterization to Accelerate Training
    of Deep Neural Networks
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: on-the-importance-of-initialization-and-momentum-in-deep-learning
  numCitedBy: 3557
  pid: aa7bfd2304201afbb19971ebde87b17e40242e91
  show_ref_link: true
  title: On the importance of initialization and momentum in deep learning
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: a-neural-probabilistic-language-model
  numCitedBy: 6009
  pid: 6c2b28f9354f667cd5bd07afc0471d8334430da7
  show_ref_link: false
  title: A Neural Probabilistic Language Model
  year: 2000
- fieldsOfStudy:
  - Computer Science
  meta_key: long-short-term-memory
  numCitedBy: 51694
  pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  show_ref_link: true
  title: Long Short-Term Memory
  year: 1997
- fieldsOfStudy:
  - Computer Science
  meta_key: pixel-recurrent-neural-networks
  numCitedBy: 1748
  pid: 41f1d50c85d3180476c4c7b3eea121278b0d8474
  show_ref_link: true
  title: Pixel Recurrent Neural Networks
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: improved-backing-off-for-m-gram-language-modeling
  numCitedBy: 1792
  pid: 9548ac30c113562a51e603dbbc8e9fa651cfd3ab
  show_ref_link: false
  title: Improved backing-off for M-gram language modeling
  year: 1995
- fieldsOfStudy:
  - Computer Science
  meta_key: on-the-difficulty-of-training-recurrent-neural-networks
  numCitedBy: 3802
  pid: 84069287da0a6b488b8c933f3cb5be759cb6237e
  show_ref_link: true
  title: On the difficulty of training recurrent neural networks
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: three-new-graphical-models-for-statistical-language-modelling
  numCitedBy: 606
  pid: bd7d93193aad6c4b71cc8942e808753019e87706
  show_ref_link: false
  title: Three new graphical models for statistical language modelling
  year: 2007
- fieldsOfStudy:
  - Computer Science
  meta_key: factorization-tricks-for-lstm-networks
  numCitedBy: 91
  pid: 79baf48bd560060549998d7b61751286de062e2a
  show_ref_link: false
  title: Factorization tricks for LSTM networks
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-classification
  numCitedBy: 12381
  pid: d6f2f611da110b5b5061731be3fc4c7f45d8ee23
  show_ref_link: true
  title: Delving Deep into Rectifiers - Surpassing Human-Level Performance on ImageNet
    Classification
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-residual-learning-for-image-recognition
  numCitedBy: 95326
  pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  show_ref_link: true
  title: Deep Residual Learning for Image Recognition
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: understanding-the-difficulty-of-training-deep-feedforward-neural-networks
  numCitedBy: 12433
  pid: b71ac1e9fb49420d13e084ac67254a0bbd40f83f
  show_ref_link: true
  title: Understanding the difficulty of training deep feedforward neural networks
  year: 2010
- fieldsOfStudy:
  - Computer Science
  meta_key: predicting-distributions-with-linearizing-belief-networks
  numCitedBy: 15
  pid: c58a0c5fccea5781a3e4d3282e024b9d20a24623
  show_ref_link: false
  title: Predicting distributions with Linearizing Belief Networks
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: conditional-image-generation-with-pixelcnn-decoders
  numCitedBy: 1607
  pid: 0936352b78a52bc5d2b5e3f04233efc56664af51
  show_ref_link: true
  title: Conditional Image Generation with PixelCNN Decoders
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: statistical-machine-translation
  numCitedBy: 769
  pid: b3e89f05876d47b9bd6ece225aaeee457a6824e8
  show_ref_link: false
  title: Statistical Machine Translation
  year: 2010
- fieldsOfStudy:
  - Computer Science
  meta_key: automatic-speech-recognition-a-deep-learning-approach
  numCitedBy: 485
  pid: 08c13be14da51f2ed531ffe980bb993e45042e41
  show_ref_link: false
  title: Automatic Speech Recognition - A Deep Learning Approach
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: torch7-a-matlab-like-environment-for-machine-learning
  numCitedBy: 1490
  pid: 3449b65008b27f6e60a73d80c1fd990f0481126b
  show_ref_link: true
  title: Torch7 - A Matlab-like Environment for Machine Learning
  year: 2011
- fieldsOfStudy:
  - Computer Science
  meta_key: foundations-of-statistical-natural-language-processing
  numCitedBy: 7801
  pid: 084c55d6432265785e3ff86a2e900a49d501c00a
  show_ref_link: true
  title: Foundations of statistical natural language processing
  year: 2002
- fieldsOfStudy:
  - Computer Science
  meta_key: noise-contrastive-estimation-a-new-estimation-principle-for-unnormalized-statistical-models
  numCitedBy: 1227
  pid: e3ce36b9deb47aa6bb2aa19c4bfa71283b505025
  show_ref_link: false
  title: Noise-contrastive estimation - A new estimation principle for unnormalized
    statistical models
  year: 2010
- fieldsOfStudy:
  - Linguistics
  meta_key: syntactic-process
  numCitedBy: 911
  pid: ce8cca19455e8d3055c57a9bafe882984c95a201
  show_ref_link: false
  title: Syntactic Process
  year: 1979
- fieldsOfStudy:
  - Computer Science
  meta_key: an-empirical-study-of-smoothing-techniques-for-language-modeling
  numCitedBy: 2861
  pid: d4e8bed3b50a035e1eabad614fe4218a34b3b178
  show_ref_link: false
  title: An empirical study of smoothing techniques for language modeling
  year: 1999
- fieldsOfStudy:
  - Mathematics
  meta_key: convolutional-networks-for-images-speech-and-time-series
  numCitedBy: 4091
  pid: 563e821bb5ea825efb56b77484f5287f08cf3753
  show_ref_link: false
  title: Convolutional networks for images, speech, and time series
  year: 1998
slug: Language-Modeling-with-Gated-Convolutional-Networks-Dauphin-Fan
title: Language Modeling with Gated Convolutional Networks
url: https://www.semanticscholar.org/paper/Language-Modeling-with-Gated-Convolutional-Networks-Dauphin-Fan/88caa4a0253a8b0076176745ebc072864eab66e1?sort=total-citations
venue: ICML
year: 2017
