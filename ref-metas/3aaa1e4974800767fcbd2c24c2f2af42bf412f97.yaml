authors:
- H. Le
- I. Oparin
- A. Allauzen
- J. Gauvain
- "Fran\xE7ois Yvon"
badges:
- id: OPEN_ACCESS
corpusId: 14828669
fieldsOfStudy:
- Computer Science
numCitedBy: 157
numCiting: 15
paperAbstract: 'This paper introduces a new neural network language model (NNLM) based
  on word clustering to structure the output vocabulary: Structured Output Layer NNLM.
  This model is able to handle vocabularies of arbitrary size, hence dispensing with
  the design of short-lists that are commonly used in NNLMs. Several softmax layers
  replace the standard output layer in this model. The output structure depends on
  the word clustering which uses the continuous word representation induced by a NNLM.
  The GALE Mandarin data was used to carry out the speech-to-text experiments and
  evaluate the NNLMs. On this data the well tuned baseline system has a character
  error rate under 10%. Our model achieves consistent improvements over the combination
  of an n-gram model and classical short-list NNLMs both in terms of perplexity and
  recognition accuracy.'
ref_count: 15
references:
- pid: 0fcc184b3b90405ec3ceafd6a4007c749df7c363
  title: Continuous space language models
- pid: 9819b600a828a57e1cde047bbe710d3446b30da5
  title: Recurrent neural network based language model
- pid: e41498c05d4c68e4750fb84a380317a112d97b01
  title: Connectionist language modeling for large vocabulary continuous speech recognition
- pid: a9fc84f8abe740cdc7ee82e69444d1d00dbe0ceb
  title: A Scalable Hierarchical Distributed Language Model
- pid: 6c2b28f9354f667cd5bd07afc0471d8334430da7
  title: A Neural Probabilistic Language Model
- pid: 3de5d40b60742e3dfa86b19e7f660962298492af
  title: Class-Based n-gram Models of Natural Language
slug: Structured-Output-Layer-neural-network-language-Le-Oparin
title: Structured Output Layer neural network language model
url: https://www.semanticscholar.org/paper/Structured-Output-Layer-neural-network-language-Le-Oparin/3aaa1e4974800767fcbd2c24c2f2af42bf412f97?sort=total-citations
venue: 2011 IEEE International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)
year: 2011
