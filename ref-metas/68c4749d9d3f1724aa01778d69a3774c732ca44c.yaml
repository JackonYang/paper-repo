authors:
- E. Osuna
- R. Freund
- F. Girosi
badges:
- id: OPEN_ACCESS
corpusId: 15140283
fieldsOfStudy:
- Computer Science
numCitedBy: 844
numCiting: 24
paperAbstract: The Support Vector Machine (SVM) is a new and very promising classification
  technique developed by Vapnik and his group at AT\&T Bell Labs. This new learning
  algorithm can be seen as an alternative training technique for Polynomial, Radial
  Basis Function and Multi-Layer Perceptron classifiers. An interesting property of
  this approach is that it is an approximate implementation of the Structural Risk
  Minimization (SRM) induction principle. The derivation of Support Vector Machines,
  its relationship with SRM, and its geometrical insight, are discussed in this paper.
  Training a SVM is equivalent to solve a quadratic programming problem with linear
  and box constraints in a number of variables equal to the number of data points.
  When the number of data points exceeds few thousands the problem is very challenging,
  because the quadratic form is completely dense, so the memory needed to store the
  problem grows with the square of the number of data points. Therefore, training
  problems arising in some real applications with large data sets are impossible to
  load into memory, and cannot be solved using standard non-linear constrained optimization
  algorithms. We present a decomposition algorithm that can be used to train SVM''s
  over large data sets. The main idea behind the decomposition is the iterative solution
  of sub-problems and the evaluation of, and also establish the stopping criteria
  for the algorithm. We present previous approaches, as well as results and important
  details of our implementation of the algorithm using a second-order variant of the
  Reduced Gradient Method as the solver of the sub-problems. As an application of
  SVM''s, we present preliminary results we obtained applying SVM to the problem of
  detecting frontal human faces in real images.
ref_count: 24
references:
- pid: 1061ff8a216a8d00f5f189d7ea593c6f0703b771
  title: Simplified Support Vector Decision Rules
- pid: d27c7569fdbcbb57ff511f5293e32b547acca7b3
  title: An Equivalence Between Sparse Approximation and Support Vector Machines
- pid: 2599131a4bc2fa957338732a37c744cfe3e17b24
  title: A training algorithm for optimal margin classifiers
- pid: f3317b98195fe0be4acf7b450f015c1abca13ab9
  title: Learning and example selection for object and pattern detection
- pid: 400ca5d045588b887ec8949662dff5436bbc2461
  title: Positive definite functions and generalizations, an historical survey
- pid: e49ad8354bdd2fd6e8babd348df9e9a5b30bf3a6
  title: Probabilistic visual learning for object detection
- pid: 088eb2d102c6bb486f5270d0b2adff76961994cf
  title: Example-Based Learning for View-Based Human Face Detection
- pid: f6af749b2b813af20c2f26962249fafdccdc6a1e
  title: Human Face Detection in Visual Scenes
- pid: 2bb1ba70d48561ce8c3fbf59739fabc95e7b3d50
  title: Human face detection in a complex background
- pid: 1cdb510aed4f8b04b73240287da954f9eff39318
  title: Detection and localization of faces on digital images
slug: Support-Vector-Machines:-Training-and-Applications-Osuna-Freund
title: 'Support Vector Machines: Training and Applications'
url: https://www.semanticscholar.org/paper/Support-Vector-Machines:-Training-and-Applications-Osuna-Freund/68c4749d9d3f1724aa01778d69a3774c732ca44c?sort=total-citations
venue: ''
year: 1997
