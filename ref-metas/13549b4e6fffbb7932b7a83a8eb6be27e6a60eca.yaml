authors:
- Chen Kong
- Dahua Lin
- Mohit Bansal
- R. Urtasun
- S. Fidler
badges:
- id: OPEN_ACCESS
corpusId: 3015754
fieldsOfStudy:
- Computer Science
numCitedBy: 164
numCiting: 37
paperAbstract: In this paper we exploit natural sentential descriptions of RGB-D scenes
  in order to improve 3D semantic parsing. Importantly, in doing so, we reason about
  which particular object each noun/pronoun is referring to in the image. This allows
  us to utilize visual information in order to disambiguate the so-called coreference
  resolution problem that arises in text. Towards this goal, we propose a structure
  prediction model that exploits potentials computed from text and RGB-D imagery to
  reason about the class of the 3D objects, the scene type, as well as to align the
  nouns/pronouns with the referred visual objects. We demonstrate the effectiveness
  of our approach on the challenging NYU-RGBD v2 dataset, which we enrich with natural
  lingual descriptions. We show that our approach significantly improves 3D detection
  and scene classification accuracy, and is able to reliably estimate the text-to-image
  alignment. Furthermore, by using textual and visual information, we are also able
  to successfully deal with coreference in text, improving upon the state-of-the-art
  Stanford coreference system [15].
ref_count: 37
references:
- pid: eaaed23a2d94feb2f1c3ff22a25777c7a78f3141
  title: 'Every Picture Tells a Story: Generating Sentences from Images'
- pid: eed4e6967c7a96e4cc2c590db40269cd97c8c98e
  title: 'Towards total scene understanding: Classification, annotation and segmentation
    in an automatic framework'
- pid: 8687d2dc63fa7b9d085712910d0e3b663b76ca0c
  title: 'Describing the scene as a whole: Joint object detection, scene classification
    and semantic segmentation'
- pid: 8e523721feebeaee18e487607b7d0920ac6cd3b4
  title: 'Beyond Nouns: Exploiting Prepositions and Comparative Adjectives for Learning
    Visual Classifiers'
- pid: 169b847e69c35cfd475eb4dcc561a24de11762ca
  title: 'Baby talk: Understanding and generating simple image descriptions'
- pid: 6eb3a15108dfdec25b46522ed94b866aeb156de9
  title: 'Connecting modalities: Semi-supervised segmentation and annotation of images
    using unaligned text corpora'
- pid: 6d9f55b445f36578802e7eef4393cfa914b11620
  title: 'Object Recognition as Machine Translation: Learning a Lexicon for a Fixed
    Image Vocabulary'
- pid: 7afd833f484c8032e7fdc5f53188d2ebb0fb9934
  title: 'Visual Semantic Search: Retrieving Videos via Complex Textual Queries'
- pid: 23c6cb079b9ec45ae462cae743e01a1185fc4c2c
  title: Learning Visual Representations using Images with Captions
- pid: 6a26268d2ba9d34e5b59ae6e5c11a83cdca1a85e
  title: Matching Words and Pictures
- pid: 793c1c908672ea71aef9e1b41a46272aa27598f7
  title: Video In Sentences Out
- pid: f3cd7890d3ad50cd1947d099bbd16f6da3b33a78
  title: Deterministic Coreference Resolution Based on Entity-Centric, Precision-Ranked
    Rules
- pid: 2a0d0f6c5a69b264710df0230696f47c5918e2f2
  title: Collective Generation of Natural Image Descriptions
- pid: 28fa525ca1e101335e877bb1f6999b6ccf476959
  title: Semantic Segmentation with Second-Order Pooling
- pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  title: 'Im2Text: Describing Images Using 1 Million Captioned Photographs'
- pid: cb2115a6765e8484830865b8ad5e6cc5dd29b48d
  title: 'CPMC: Automatic Object Segmentation Using Constrained Parametric Min-Cuts'
- pid: 908091b4a8757c3b2f7d9cfa2c4f616ee12c5157
  title: 'SUN database: Large-scale scene recognition from abbey to zoo'
- pid: c1994ba5946456fc70948c549daf62363f13fa2d
  title: Indoor Segmentation and Support Inference from RGBD Images
- pid: 96a0320ef14877038906947b684011cf7378c440
  title: Grounded Language Learning from Video Described with Sentences
- pid: 58bd0afc8a1b98e16a67ebda436e60c6f6410f56
  title: A Joint Model of Language and Perception for Grounded Attribute Learning
- pid: eb42a490cf4f186d3383c92963817d100afd81e2
  title: Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network
- pid: 5726c7b40fcc454b77d989656c085520bf6c15fa
  title: Multimodal learning with deep Boltzmann machines
- pid: 3cc228402f31ca749112197720b9ef6af0c16790
  title: Generating Typed Dependency Parses from Phrase Structure Parses
slug: What-Are-You-Talking-About-Text-to-Image-Kong-Lin
title: What Are You Talking About? Text-to-Image Coreference
url: https://www.semanticscholar.org/paper/What-Are-You-Talking-About-Text-to-Image-Kong-Lin/13549b4e6fffbb7932b7a83a8eb6be27e6a60eca?sort=total-citations
venue: 2014 IEEE Conference on Computer Vision and Pattern Recognition
year: 2014
