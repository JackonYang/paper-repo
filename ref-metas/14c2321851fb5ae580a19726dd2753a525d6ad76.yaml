authors:
- Anna Rohrbach
- Marcus Rohrbach
- Ronghang Hu
- Trevor Darrell
- B. Schiele
badges:
- id: OPEN_ACCESS
corpusId: 9926549
fieldsOfStudy:
- Computer Science
numCitedBy: 377
numCiting: 63
paperAbstract: Grounding (i.e. localizing) arbitrary, free-form textual phrases in
  visual content is a challenging problem with many applications for human-computer
  interaction and image-text reference resolution. Few datasets provide the ground
  truth spatial localization of phrases, thus it is desirable to learn from data with
  no or little grounding supervision. We propose a novel approach which learns grounding
  by reconstructing a given phrase using an attention mechanism, which can be either
  latent or optimized directly. During training our approach encodes the phrase using
  a recurrent network language model and then learns to attend to the relevant image
  region in order to reconstruct the input phrase. At test time, the correct attention,
  i.e., the grounding, is evaluated. If grounding supervision is available it can
  be directly applied via a loss over the attention mechanism. We demonstrate the
  effectiveness of our approach on the Flickr 30k Entities and ReferItGame datasets
  with different levels of supervision, ranging from no supervision over partial supervision
  to full supervision. Our supervised variant improves by a large margin over the
  state-of-the-art on both datasets.
ref_count: 63
references:
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 56ffece2817a0363f551210733a611830ba1155d
  title: 'Aligning where to see and what to tell: image caption with region-based
    attention and scene factorization'
- pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
- pid: b0ab8aa7a5b684532b4ff30f8d34b35a99759a46
  title: 'Learning Everything about Anything: Webly-Supervised Visual Concept Learning'
- pid: fa0cc5fcd2faa4591dd53504d0c5115783a2d2b6
  title: Improving Image-Sentence Embeddings Using Large Weakly Annotated Photo Collections
- pid: a72b8bbd039989db39769da836cdb287737deb92
  title: 'Mind''s eye: A recurrent visual representation for image caption generation'
- pid: 5f425b7abf2ed3172ed060df85bb1885860a297e
  title: Describing Videos by Exploiting Temporal Structure
- pid: d696a1923288e6c15422660de9553f6fdb6a4fae
  title: Natural Language Object Retrieval
- pid: b27e791e843c924ef052981b79490ab59fc0433d
  title: Learning Deep Structure-Preserving Image-Text Embeddings
- pid: 7f1b111f0bb703b0bd97aba505728a9b0d9b2a54
  title: Deep Fragment Embeddings for Bidirectional Image Sentence Mapping
- pid: e65142010431ffc089b272a1174214e00693e503
  title: Generation and Comprehension of Unambiguous Object Descriptions
- pid: 13549b4e6fffbb7932b7a83a8eb6be27e6a60eca
  title: What Are You Talking About? Text-to-Image Coreference
- pid: 495015d21c26eac9a6bd64c836ee3370283641ec
  title: 'VisKE: Visual knowledge extraction and question answering by visual verification
    of relation phrases'
- pid: 0e6824e137847be0599bb0032e37042ed2ef5045
  title: 'Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching
    Movies and Reading Books'
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: 21b3007f967d39e1346bc91e0fc8b3f16121300c
  title: Grounding Action Descriptions in Videos
- pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
- pid: c45fd881bcc20bc1a754ee4b446d99aaff1d3dd5
  title: 'Jointly Learning to Parse and Perceive: Connecting Natural Language to the
    Physical World'
- pid: 7afd833f484c8032e7fdc5f53188d2ebb0fb9934
  title: 'Visual Semantic Search: Retrieving Videos via Complex Textual Queries'
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: d6f2f611da110b5b5061731be3fc4c7f45d8ee23
  title: 'Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet
    Classification'
- pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
- pid: d2c733e34d48784a37d717fe43d9e93277a8c53e
  title: 'ImageNet: A large-scale hierarchical image database'
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: 85ae705ef4353c6854f5be4a4664269d6317c66b
  title: Image retrieval using scene graphs
- pid: 96a0320ef14877038906947b684011cf7378c440
  title: Grounded Language Learning from Video Described with Sentences
- pid: 92c141447f51b6732242376164ff961e464731c8
  title: 'ReferItGame: Referring to Objects in Photographs of Natural Scenes'
- pid: 38b6540ddd5beebffd05047c78183f7575559fb2
  title: Selective Search for Object Recognition
- pid: 58bd0afc8a1b98e16a67ebda436e60c6f6410f56
  title: A Joint Model of Language and Perception for Grounded Attribute Learning
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: 4d376d6978dad0374edfa6709c9556b42d3594d3
  title: 'Batch Normalization: Accelerating Deep Network Training by Reducing Internal
    Covariate Shift'
- pid: 843959ffdccf31c6694d135fad07425924f785b1
  title: Extracting and composing robust features with denoising autoencoders
- pid: a6e695ddd07aad719001c0fc1129328452385949
  title: The New Data and New Challenges in Multimedia Research
- pid: 6bdb186ec4726e00a8051119636d4df3b94043b5
  title: 'Caffe: Convolutional Architecture for Fast Feature Embedding'
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 82635fb63640ae95f90ee9bdc07832eb461ca881
  title: The Pascal Visual Object Classes (VOC) Challenge
- pid: 44040913380206991b1991daf1192942e038fe31
  title: 'From image descriptions to visual denotations: New similarity metrics for
    semantic inference over event descriptions'
- pid: b183947ee15718b45546eda6b01e179b9a95421f
  title: 'Edge Boxes: Locating Object Proposals from Edges'
- pid: b71ac1e9fb49420d13e084ac67254a0bbd40f83f
  title: Understanding the difficulty of training deep feedforward neural networks
- pid: 7ffdbc358b63378f07311e883dddacc9faeeaf4b
  title: Fast R-CNN
slug: Grounding-of-Textual-Phrases-in-Images-by-Rohrbach-Rohrbach
title: Grounding of Textual Phrases in Images by Reconstruction
url: https://www.semanticscholar.org/paper/Grounding-of-Textual-Phrases-in-Images-by-Rohrbach-Rohrbach/14c2321851fb5ae580a19726dd2753a525d6ad76?sort=total-citations
venue: ECCV
year: 2016
