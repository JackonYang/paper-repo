authors:
- Holger Schwenk
- M. Milgram
badges:
- id: OPEN_ACCESS
corpusId: 14541582
fieldsOfStudy:
- Computer Science
numCitedBy: 75
numCiting: 11
paperAbstract: When training neural networks by the classical backpropagation algorithm
  the whole problem to learn must be expressed by a set of inputs and desired outputs.
  However, we often have high-level knowledge about the learning problem. In optical
  character recognition (OCR), for instance, we know that the classification should
  be invariant under a set of transformations like rotation or translation. We propose
  a new modular classification system based on several autoassociative multilayer
  perceptrons which allows the efficient incorporation of such knowledge. Results
  are reported on the NIST database of upper case handwritten letters and compared
  to other approaches to the invariance problem.
ref_count: 11
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 581
  pid: 8314dda1ec43ce57ff877f8f02ed89acb68ca035
  title: Efficient Pattern Recognition Using a New Transformation Distance
  year: 1992
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 286
  pid: ff32cebbdb8a436ccd8ae797647428615ae32d74
  title: Tangent Prop - A Formalism for Specifying Selected Invariances in an Adaptive
    Network
  year: 1991
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 129
  pid: 9dea20c1e5bbb1f543ff08113ffde5380c679f1f
  title: Recognizing Handwritten Digits Using Mixtures of Linear Models
  year: 1994
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 228
  pid: 843ffb9898cedf899ddcdb9c4bdd10881c122429
  title: Boosting Performance in Neural Networks
  year: 1993
slug: Transformation-Invariant-Autoassociation-with-to-Schwenk-Milgram
title: Transformation Invariant Autoassociation with Application to Handwritten Character
  Recognition
url: https://www.semanticscholar.org/paper/Transformation-Invariant-Autoassociation-with-to-Schwenk-Milgram/00eeec9338ea922bc1e88707fd721c25677d38e1?sort=total-citations
venue: NIPS
year: 1994
