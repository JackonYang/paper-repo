authors:
- Mengxi Wei
- Yifan He
- Qiong Zhang
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 218862990
fieldsOfStudy:
- Computer Science
numCitedBy: 12
numCiting: 54
paperAbstract: 'Many business documents processed in modern NLP and IR pipelines are
  visually rich: in addition to text, their semantics can also be captured by visual
  traits such as layout, format, and fonts. We study the problem of information extraction
  from visually rich documents (VRDs) and present a model that combines the power
  of large pre-trained language models and graph neural networks to efficiently encode
  both textual and visual information in business documents. We further introduce
  new fine-tuning objectives to improve in-domain unsupervised fine-tuning to better
  utilize large amount of unlabeled in-domain data. We experiment on real world invoice
  and resume data sets and show that the proposed method outperforms strong text-based
  RoBERTa baselines by 6.3% absolute F1 on invoices and 4.7% absolute F1 on resumes.
  When evaluated in a few-shot setting, our method requires up to 30x less annotation
  data than the baseline to achieve the same level of performance at ~90% F1.'
ref_count: 44
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 86
  pid: 04df8c70257b5280b9d303502c9d7ddf946f181b
  title: Graph Convolution for Multimodal Information Extraction from Visually Rich
    Documents
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 164
  pid: 3465c06c872d8c48d628c5fc2d484087719351b6
  title: 'LayoutLM: Pre-training of Text and Layout for Document Image Understanding'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 3533
  pid: cd18800a0fe0b668a1cc19f2ec95b5003d0a5035
  title: Improving Language Understanding by Generative Pre-Training
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2251
  pid: 1e077413b25c4d34945cc2707e17e46ed4fe784a
  title: Universal Language Model Fine-tuning for Text Classification
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 608
  pid: c3a3c163f25b9181f1fb7e71a32482a7393d2088
  title: Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 33744
  pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 63
  pid: 1da8e1ad1814d81f69433ac877ef70caa950e4e6
  title: 'GraphIE: A Graph-Based Framework for Information Extraction'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 7987
  pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  title: Deep Contextualized Word Representations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 100
  pid: 15aae08159856cdbf0ce539357d473a04dcbb7f3
  title: 'Chargrid: Towards Understanding 2D Documents'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 3736
  pid: be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6
  title: Matching Networks for One Shot Learning
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 35148
  pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  title: Attention is All you Need
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2727
  pid: 1fa9ed2bea208511ae698a967875e943049f16b6
  title: 'HuggingFace''s Transformers: State-of-the-art Natural Language Processing'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 18
  pid: 631971c31f5ff9b2ab645d9d748c379205f79df6
  title: Field Extraction by Hybrid Incremental and A-Priori Structural Templates
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 5524
  pid: 33998aff64ce51df8dee45989cdca4b6b1329ec4
  title: Graph Attention Networks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 916
  pid: 06894f06b6411af67a0ffde61d27efd86a5d31c7
  title: Information Extraction
  year: 2002
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 49
  pid: 87dee6b4a5fcbab541b45a967c24030df6cee29b
  title: Intellix -- End-User Trained Information Extraction for Document Archiving
  year: 2013
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 95318
  pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 41
  pid: 3170d280095b2198570073eaa068d6b2946334e3
  title: Field Extraction from Administrative Documents by Incremental Structural
    Templates
  year: 2013
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 7266
  pid: 077f8329a7b6fa3b7c877a57b81eb6c18b5f87de
  title: 'RoBERTa: A Robustly Optimized BERT Pretraining Approach'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 11719
  pid: 36eff562f65125511b5dfab68ce7f7a943c27478
  title: Semi-Supervised Classification with Graph Convolutional Networks
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 381
  pid: 7aac1045e6943b4a7978e260a3035662d5b3bf8d
  title: Learning from one example through shared densities on transforms
  year: 2000
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 90052
  pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 3667
  pid: f63e917638553414526a0cc8550de4ad2d83fe7a
  title: Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2365
  pid: 812355cec91fa30bb50e9e992a3549af39e4f6eb
  title: One-shot learning of object categories
  year: 2006
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 5377
  pid: e23c34414e66118ecd9b08cf0cd4d016f59b0b85
  title: Bidirectional recurrent neural networks
  year: 1997
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 3687
  pid: bb66ae5f36bc84243979c522d8e3f93539cb6a9f
  title: IEEE Transactions on Pattern Analysis and Machine Intelligence
  year: 2004
slug: Robust-Layout-aware-IE-for-Visually-Rich-Documents-Wei-He
title: Robust Layout-aware IE for Visually Rich Documents with Pre-trained Language
  Models
url: https://www.semanticscholar.org/paper/Robust-Layout-aware-IE-for-Visually-Rich-Documents-Wei-He/a03407e7e8a4530d9bb96672e425cfa067f92b76?sort=total-citations
venue: SIGIR
year: 2020
