authors:
- Xiaowei Hu
- Xi Yin
- Kevin Lin
- Lijuan Wang
- L. Zhang
- Jianfeng Gao
- Zicheng Liu
badges:
- id: OPEN_ACCESS
corpusId: 221995614
fieldsOfStudy:
- Computer Science
numCitedBy: 40
numCiting: 57
paperAbstract: "It is highly desirable yet challenging to generate image captions\
  \ that can describe novel objects which are unseen in caption-labeled training data,\
  \ a capability that is evaluated in the novel object captioning challenge (nocaps).\
  \ In this challenge, no additional image-caption training data, other than COCO\
  \ Captions, is allowed for model training. Thus, conventional Vision-Language Pre-training\
  \ (VLP) methods cannot be applied. This paper presents VIsual VOcabulary pre-training\
  \ (VIVO) that performs pre-training in the absence of caption annotations. By breaking\
  \ the dependency of paired image-caption training data in VLP, VIVO can leverage\
  \ large amounts of paired image-tag data to learn a visual vocabulary. This is done\
  \ by pre-training a multi-layer Transformer model that learns to align image-level\
  \ tags with their corresponding image region features. To address the unordered\
  \ nature of image tags, VIVO uses a Hungarian matching loss with masked tag prediction\
  \ to conduct pre-training. \nWe validate the effectiveness of VIVO by fine-tuning\
  \ the pre-trained model for image captioning. In addition, we perform an analysis\
  \ of the visual-text alignment inferred by our model. The results show that our\
  \ model can not only generate fluent image captions that describe novel objects,\
  \ but also identify the locations of these objects. Our single model has achieved\
  \ new state-of-the-art results on nocaps and surpassed the human CIDEr score."
ref_count: 57
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 138
  pid: b9aa3bafa9e8e21bb92908ae23b468fa248239b3
  title: Captioning Images with Diverse Objects
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 136
  pid: 086fa2fe3ee2a5b805aeaf9fbfe59ee8157dad5c
  title: Guided Open Vocabulary Image Captioning with Constrained Beam Search
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 91
  pid: 8b55402ffee2734bfc7d5d7595500916e1ef04e8
  title: 'nocaps: novel object captioning at scale'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 233
  pid: e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17
  title: 'Deep Compositional Captioning: Describing Novel Object Categories without
    Paired Training Data'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 45
  pid: d64f52b94977b71976327eeb3db702b246ee39ce
  title: Decoupled Novel Object Captioner
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 118
  pid: 10480a42957a8e08e4c543185e135d7c254583a5
  title: Incorporating Copying Mechanism in Image Captioning for Learning Novel Objects
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 306
  pid: 3bf09b2e2639add154a9fe6ff98cc373d3e90e4e
  title: Neural Baby Talk
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 355
  pid: 6648b4db5f12c30941ea78c695e77aded19672bb
  title: Unified Vision-Language Pre-Training for Image Captioning and VQA
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 901
  pid: d7ce5665a72c0b607f484c1b448875f02ddfac3b
  title: 'DenseCap: Fully Convolutional Localization Networks for Dense Captioning'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 534
  pid: 818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57
  title: 'Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 105
  pid: 18f1143c64e6557c933b206fb8b2a7bd1f389afd
  title: Rich Image Captioning in the Wild
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 282
  pid: 54416048772b921720f19869ed11c2a360589d03
  title: 'UNITER: Learning UNiversal Image-TExt Representations'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1107
  pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 45
  pid: 33eadd4e666a894306a22ba0839c5e0cef77280e
  title: 'TextCaps: a Dataset for Image Captioning with Reading Comprehension'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  - Environmental Science
  numCitedBy: 632
  pid: b4df354db88a70183a64dbc9e56cf14e7669a6c0
  title: 'Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic
    Image Captioning'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1266
  pid: 65a9c7b0800c86a196bc14e7621ff895cc6ab287
  title: 'ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language
    Tasks'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 153
  pid: 4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0
  title: X-Linear Attention Networks for Image Captioning
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 307
  pid: 4c163d4942117179d3e97182e1b280027d7d60a9
  title: Attention on Attention for Image Captioning
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2275
  pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2575
  pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 3533
  pid: cd18800a0fe0b668a1cc19f2ec95b5003d0a5035
  title: Improving Language Understanding by Generative Pre-Training
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 707
  pid: 2527626c11a84f15709e943fbfa2356e19930e3b
  title: 'VL-BERT: Pre-training of Generic Visual-Linguistic Representations'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1029
  pid: 6c8353697cdbb98dfba4f493875778c4286d3e3a
  title: Self-Critical Sequence Training for Image Captioning
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 916
  pid: 79c93274429d6355959f1e4374c2147bb81ea649
  title: 'LXMERT: Learning Cross-Modality Encoder Representations from Transformers'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 137
  pid: c5ff974a69fd0c760b4855b819e61e89f31cfffe
  title: 'Objects365: A Large-Scale, High-Quality Dataset for Object Detection'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 35148
  pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  title: Attention is All you Need
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 33744
  pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 530
  pid: 5cb6700d94c6118ee13f4f4fecac99f111189812
  title: 'BabyTalk: Understanding and Generating Simple Image Descriptions'
  year: 2013
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 356
  pid: 76a1dca3a9c2b0229c1b12c95752dcf40dc95a11
  title: Corpus-Guided Sentence Generation of Natural Images
  year: 2011
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 986
  pid: eaaed23a2d94feb2f1c3ff22a25777c7a78f3141
  title: 'Every Picture Tells a Story: Generating Sentences from Images'
  year: 2010
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 32561
  pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  title: 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 319
  pid: 2a0d0f6c5a69b264710df0230696f47c5918e2f2
  title: Collective Generation of Natural Image Descriptions
  year: 2012
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 364
  pid: ef0a32525869ac3a2bd4cbacb18343d737c5916d
  title: End-to-End People Detection in Crowded Scenes
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 27402
  pid: 1b47265245e8db53a553049dcb27ed3e495fd625
  title: 'ImageNet: A large-scale hierarchical image database'
  year: 2009
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1178
  pid: 696ca58d93f6404fea0fc75c62d1d7b378f47628
  title: 'Microsoft COCO Captions: Data Collection and Evaluation Server'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 4645
  pid: dbde7dfa6cae81df8ac19ef500c42db96c3d1edd
  title: 'Google''s Neural Machine Translation System: Bridging the Gap between Human
    and Machine Translation'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 383
  pid: 355de7460120ddc1150d9ce3756f9848983f7ff4
  title: 'Midge: Generating Image Descriptions From Computer Vision Detections'
  year: 2012
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1323
  pid: 44040913380206991b1991daf1192942e038fe31
  title: 'From image descriptions to visual denotations: New similarity metrics for
    semantic inference over event descriptions'
  year: 2014
slug: VIVO:-Surpassing-Human-Performance-in-Novel-Object-Hu-Yin
title: 'VIVO: Surpassing Human Performance in Novel Object Captioning with Visual
  Vocabulary Pre-Training'
url: https://www.semanticscholar.org/paper/VIVO:-Surpassing-Human-Performance-in-Novel-Object-Hu-Yin/f147279c9d1edddda57f1f21f23b3b58998bad74?sort=total-citations
venue: ArXiv
year: 2020
