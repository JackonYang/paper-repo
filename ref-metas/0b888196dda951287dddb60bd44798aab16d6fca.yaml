authors:
- Ramakrishna Vedantam
- Xiaoyu Lin
- Tanmay Batra
- C. L. Zitnick
- Devi Parikh
badges:
- id: OPEN_ACCESS
corpusId: 6974607
fieldsOfStudy:
- Computer Science
numCitedBy: 72
numCiting: 44
paperAbstract: Common sense is essential for building intelligent machines. While
  some commonsense knowledge is explicitly stated in human-generated text and can
  be learnt by mining the web, much of it is unwritten. It is often unnecessary and
  even unnatural to write about commonsense facts. While unwritten, this commonsense
  knowledge is not unseen! The visual world around us is full of structure modeled
  by commonsense knowledge. Can machines learn common sense simply by observing our
  visual world? Unfortunately, this requires automatic and accurate detection of objects,
  their attributes, poses, and interactions between objects, which remain challenging
  problems. Our key insight is that while visual common sense is depicted in visual
  content, it is the semantic features that are relevant and not low-level pixel information.
  In other words, photorealism is not necessary to learn common sense. We explore
  the use of human-generated abstract scenes made from clipart for learning common
  sense. In particular, we reason about the plausibility of an interaction or relation
  between a pair of nouns by measuring the similarity of the relation and nouns with
  other relations and nouns we have seen in abstract scenes. We show that the commonsense
  knowledge we learn is complementary to what can be learnt from sources of text.
ref_count: 44
references:
- pid: e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd
  title: 'Don''t just listen, use your imagination: Leveraging visual common sense
    for non-visual tasks'
- pid: dfe448d6297ea0a3d4deba21fbf1006bc35877d7
  title: Inferring the Why in Images
- pid: 051830b0ea58d1568f19ec3297e301d9789c9a76
  title: Bringing Semantics into Focus Using Visual Abstraction
- pid: 495015d21c26eac9a6bd64c836ee3370283641ec
  title: 'VisKE: Visual knowledge extraction and question answering by visual verification
    of relation phrases'
- pid: b0ab8aa7a5b684532b4ff30f8d34b35a99759a46
  title: 'Learning Everything about Anything: Webly-Supervised Visual Concept Learning'
- pid: f8403bf4e3060487cbc8acceb1fb256a4f1cfc76
  title: Adopting Abstract Images for Semantic Scene Understanding
- pid: d3ab56d83a616dba391a3373037aceb662bcda9d
  title: Zero-Shot Learning via Visual Abstraction
- pid: 6c39f56c3c21c3972c362f8e752be57a50c41f4f
  title: Learning the Visual Interpretation of Sentences
- pid: 53e4ab9730e983242a3409c7bf1af945041a6563
  title: 'NEIL: Extracting Visual Knowledge from Web Data'
- pid: ea8fe33cc1596b2e493ddd87f22cd21f563664e8
  title: Reasoning about Object Affordances in a Knowledge Base Representation
- pid: c99798fce885b41ab1de66bbacf04b7de7274f85
  title: Predicting Object Dynamics in Scenes
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: 5ce04063ecf83a6584813e1a09fb3d81642e5790
  title: Understanding and predicting importance in images
- pid: 8e523721feebeaee18e487607b7d0920ac6cd3b4
  title: 'Beyond Nouns: Exploiting Prepositions and Comparative Adjectives for Learning
    Visual Classifiers'
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: cf5ea582bccc7cb21a2ebeb7a0987f79652bde8d
  title: 'Knowledge vault: a web-scale approach to probabilistic knowledge fusion'
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
- pid: 87f40e6f3022adbc1f1905e3e506abad05a9964f
  title: Distributed Representations of Words and Phrases and their Compositionality
- pid: 85ae705ef4353c6854f5be4a4664269d6317c66b
  title: Image retrieval using scene graphs
- pid: 4dfe43ddfcfbe00dd663a4d70b0df9dcc8c92184
  title: 'YAGO2: A Spatially and Temporally Enhanced Knowledge Base from Wikipedia:
    Extended Abstract'
- pid: 07ac2e342db42589322b28ef291c2702f4a793a8
  title: An empirical study of context in object detection
- pid: f7312b8568d63bbbb239583ed282f46cdc40978d
  title: Toward an Architecture for Never-Ending Language Learning
- pid: d2946a868682e4141beabc288d79253ae254c6e1
  title: DBpedia - A large-scale, multilingual knowledge base extracted from Wikipedia
- pid: 3ff2862a8121cc823a8eb72f3e0a97bbf25c82ec
  title: 'Building Watson: An Overview of the DeepQA Project'
- pid: 68c03788224000794d5491ab459be0b2a2c38677
  title: 'WordNet: A Lexical Database for English'
- pid: b48d90cfebb8fbff29d161f6704d31b6909eb7ad
  title: 'IM2GPS: estimating geographic information from a single image'
- pid: 1976c9eeccc7115d18a04f1e7fb5145db6b96002
  title: 'Freebase: a collaboratively created graph database for structuring human
    knowledge'
slug: Learning-Common-Sense-through-Visual-Abstraction-Vedantam-Lin
title: Learning Common Sense through Visual Abstraction
url: https://www.semanticscholar.org/paper/Learning-Common-Sense-through-Visual-Abstraction-Vedantam-Lin/0b888196dda951287dddb60bd44798aab16d6fca?sort=total-citations
venue: 2015 IEEE International Conference on Computer Vision (ICCV)
year: 2015
