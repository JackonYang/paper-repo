authors:
- Meet Shah
- Xinlei Chen
- Marcus Rohrbach
- Devi Parikh
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 62902119
fieldsOfStudy:
- Computer Science
numCitedBy: 93
numCiting: 54
paperAbstract: "Despite significant progress in Visual Question Answer-ing over the\
  \ years, robustness of today\u2019s VQA models leave much to be desired. We introduce\
  \ a new evaluation protocol and associated dataset (VQA-Rephrasings) and show that\
  \ state-of-the-art VQA models are notoriously brittle to linguistic variations in\
  \ questions. VQA-Rephrasings contains 3 human-provided rephrasings for 40k questions-image\
  \ pairs from the VQA v2.0 validation dataset. As a step towards improving robustness\
  \ of VQA models, we propose a model-agnostic framework that exploits cycle consistency.\
  \ Specifically, we train a model to not only answer a question, but also generate\
  \ a question conditioned on the answer, such that the answer predicted for the generated\
  \ question is the same as the ground truth answer to the original question. Without\
  \ the use of additional supervision, we show that our approach is significantly\
  \ more robust to linguistic variations than state-of-the-art VQA models, when evaluated\
  \ on the VQA-Rephrasings dataset. In addition, our approach also outperforms state-of-the-art\
  \ approaches on the standard VQA and Visual Question Generation tasks on the challenging\
  \ VQA v2.0 dataset. Code and models will be made publicly available."
ref_count: 54
references:
- pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  title: 'Making the V in VQA Matter: Elevating the Role of Image Understanding in
    Visual Question Answering'
- pid: 8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5
  title: Analyzing the Behavior of Visual Question Answering Models
- pid: 5fa973b8d284145bf0ced9acf2913a74674260f6
  title: 'Yin and Yang: Balancing and Answering Binary Visual Questions'
- pid: fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b
  title: Hierarchical Question-Image Co-Attention for Visual Question Answering
- pid: a396a6febdacb84340d139096455e67049ac1e22
  title: 'Learning to Reason: End-to-End Module Networks for Visual Question Answering'
- pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
- pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  title: Stacked Attention Networks for Image Question Answering
- pid: fe466e84fa2e838adc3c37ee327cd68004ae08fe
  title: 'MUTAN: Multimodal Tucker Fusion for Visual Question Answering'
- pid: 36c3972569a6949ecca90bfa6f8e99883e092845
  title: 'Pythia v0.1: the Winning Entry to the VQA Challenge 2018'
- pid: 75ddc7ee15be14013a3462c01b38b0548486fbcb
  title: Learning to Compose Neural Networks for Question Answering
- pid: 6e795c6e9916174ae12349f5dc3f516570c17ce8
  title: Skip-Thought Vectors
- pid: 258986132bf17755fe8263e42429fe73218c1534
  title: 'CIDEr: Consensus-based image description evaluation'
- pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
- pid: 7cfa5c97164129ce3630511f639040d28db1d4b7
  title: 'FiLM: Visual Reasoning with a General Conditioning Layer'
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: a5d10341717c0519cf63151b496a6d2ed67aa05f
  title: Bilinear Attention Networks
- pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  title: 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks'
- pid: 60b05f32c32519a809f21642ef1eb3eaf3848008
  title: 'ROUGE: A Package for Automatic Evaluation of Summaries'
- pid: 2e17cf6a339fd071ad222062f868e882ef4120a4
  title: Inferring and Executing Programs for Visual Reasoning
- pid: d7da009f457917aa381619facfa5ffae9329a6e9
  title: 'Bleu: a Method for Automatic Evaluation of Machine Translation'
- pid: 26adb749fc5d80502a6d889966e50b31391560d3
  title: 'Meteor Universal: Language Specific Translation Evaluation for Any Target
    Language'
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 9784fbf77295860b2e412137b86356d70b25e3c0
  title: 'The Natural Language Decathlon: Multitask Learning as Question Answering'
- pid: 162d958ff885f1462aeda91cd72582323fd6a1f4
  title: Gradient-based learning applied to document recognition
- pid: f42b865e20e61a954239f421b42007236e671f19
  title: GradientBased Learning Applied to Document Recognition
- pid: 10d85561e4aafc516d10064f30dff05b41f70afe
  title: '[Et al].'
slug: Cycle-Consistency-for-Robust-Visual-Question-Shah-Chen
title: Cycle-Consistency for Robust Visual Question Answering
url: https://www.semanticscholar.org/paper/Cycle-Consistency-for-Robust-Visual-Question-Shah-Chen/735a63b58349e07b84c2e31927ce1b1cfaf09980?sort=total-citations
venue: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2019
