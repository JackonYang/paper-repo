authors:
- "Fran\xE7ois Chollet"
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 2375110
fieldsOfStudy:
- Computer Science
numCitedBy: 6595
numCiting: 32
paperAbstract: We present an interpretation of Inception modules in convolutional
  neural networks as being an intermediate step in-between regular convolution and
  the depthwise separable convolution operation (a depthwise convolution followed
  by a pointwise convolution). In this light, a depthwise separable convolution can
  be understood as an Inception module with a maximally large number of towers. This
  observation leads us to propose a novel deep convolutional neural network architecture
  inspired by Inception, where Inception modules have been replaced with depthwise
  separable convolutions. We show that this architecture, dubbed Xception, slightly
  outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed
  for), and significantly outperforms Inception V3 on a larger image classification
  dataset comprising 350 million images and 17,000 classes. Since the Xception architecture
  has the same number of parameters as Inception V3, the performance gains are not
  due to increased capacity but rather to a more efficient use of model parameters.
ref_count: 32
references:
- pid: e15cf50aa89fee8535703b9f9512fca5bfc43327
  title: Going deeper with convolutions
- pid: b5c26ab8767d046cb6e32d959fdf726aee89bb62
  title: Inception-v4, Inception-ResNet and the Impact of Residual Connections on
    Learning
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: 5e83ab70d0cbc003471e87ec306d27d9c80ecb16
  title: Network In Network
- pid: 23ffaa0fe06eae05817f527a47ac3291077f9e58
  title: Rethinking the Inception Architecture for Computer Vision
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: 1a2a770d23b4a171fa81de62a78a3deb0588f238
  title: Visualizing and Understanding Convolutional Networks
- pid: 4d376d6978dad0374edfa6709c9556b42d3594d3
  title: 'Batch Normalization: Accelerating Deep Network Training by Reducing Internal
    Covariate Shift'
- pid: f63e917638553414526a0cc8550de4ad2d83fe7a
  title: Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)
- pid: 3647d6d0f151dc05626449ee09cc7bce55be497e
  title: 'MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications'
- pid: 0c908739fbff75f03469d13d4a1a07de3414ee19
  title: Distilling the Knowledge in a Neural Network
- pid: e74f9b7f8eec6ba4704c206b93bc8079af3da4bd
  title: ImageNet Large Scale Visual Recognition Challenge
- pid: 842dd6d0f4b72ce0e8f3ac8e6861637c1f4645ea
  title: 'Learning algorithms for classification: A comparison on handwritten digit
    recognition'
- pid: 6dc61f37ecc552413606d8c89ffbc46ec98ed887
  title: Acceleration of stochastic approximation by averaging
slug: Xception:-Deep-Learning-with-Depthwise-Separable-Chollet
title: 'Xception: Deep Learning with Depthwise Separable Convolutions'
url: https://www.semanticscholar.org/paper/Xception:-Deep-Learning-with-Depthwise-Separable-Chollet/5b6ec746d309b165f9f9def873a2375b6fb40f3d?sort=total-citations
venue: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2017
