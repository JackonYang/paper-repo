authors:
- M. Sundermeyer
- "R. Schl\xFCter"
- H. Ney
badges:
- id: OPEN_ACCESS
corpusId: 18939716
fieldsOfStudy:
- Computer Science
numCitedBy: 1491
numCiting: 18
paperAbstract: Neural networks have become increasingly popular for the task of language
  modeling. Whereas feed-forward networks only exploit a fixed context length to predict
  the next word of a sequence, conceptually, standard recurrent neural networks can
  take into account all of the predecessor words. On the other hand, it is well known
  that recurrent networks are difficult to train and therefore are unlikely to show
  the full potential of recurrent models. These problems are addressed by a the Long
  Short-Term Memory neural network architecture. In this work, we analyze this type
  of network on an English and a large French language modeling task. Experiments
  show improvements of about 8 % relative in perplexity over standard recurrent neural
  network LMs. In addition, we gain considerable improvements in WER on top of a state-of-the-art
  speech recognition system.
ref_count: 18
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 4902
  pid: 9819b600a828a57e1cde047bbe710d3446b30da5
  title: Recurrent neural network based language model
  year: 2010
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 942
  pid: c19fbefdeead6a4154a22a9c8551a18b1530033a
  title: Hierarchical Probabilistic Neural Network Language Model
  year: 2005
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1423
  pid: 07ca885cb5cc4328895bfaec9ab752d5801b14cd
  title: Extensions of recurrent neural network language model
  year: 2011
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 554
  pid: 0fcc184b3b90405ec3ceafd6a4007c749df7c363
  title: Continuous space language models
  year: 2007
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 3296
  pid: 2f83f6e1afadf0963153974968af6b8342775d82
  title: Framewise phoneme classification with bidirectional LSTM and other neural
    network architectures
  year: 2005
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 6144
  pid: d0be39ee052d246ae99c082a565aba25b811be2d
  title: Learning long-term dependencies with gradient descent is difficult
  year: 1994
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 6011
  pid: 6c2b28f9354f667cd5bd07afc0471d8334430da7
  title: A Neural Probabilistic Language Model
  year: 2000
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1270
  pid: 047655e733a9eed9a500afd916efa566915b9110
  title: Learning Precise Timing with LSTM Recurrent Networks
  year: 2002
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 585
  pid: 0d6203718c15f137fda2f295c96269bc2b254644
  title: Learning Recurrent Neural Networks with Hessian-Free Optimization
  year: 2011
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 233
  pid: 4af41f4d838daa7ca6995aeb4918b61989d1ed80
  title: Classes for fast maximum entropy training
  year: 2001
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 51704
  pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
  year: 1997
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 20332
  pid: 052b1d8ce63b07fec3de9dbb583772d860b7c769
  title: Learning representations by back-propagating errors
  year: 1986
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1792
  pid: 9548ac30c113562a51e603dbbc8e9fa651cfd3ab
  title: Improved backing-off for M-gram language modeling
  year: 1995
- fieldsOfStudy:
  - Psychology
  numCitedBy: 9863
  pid: 668087f0ae7ce1de6e0bd0965dbb480c08103260
  title: Finding Structure in Time
  year: 1990
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 8595
  pid: b9b1b1654ce0eea729c4160bfedcbb3246460b1d
  title: Neural networks for pattern recognition
  year: 1995
slug: "LSTM-Neural-Networks-for-Language-Modeling-Sundermeyer-Schl\xFCter"
title: LSTM Neural Networks for Language Modeling
url: "https://www.semanticscholar.org/paper/LSTM-Neural-Networks-for-Language-Modeling-Sundermeyer-Schl\xFC\
  ter/f9a1b3850dfd837793743565a8af95973d395a4e?sort=total-citations"
venue: INTERSPEECH
year: 2012
