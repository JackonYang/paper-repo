authors:
- Nal Kalchbrenner
- P. Blunsom
badges:
- id: OPEN_ACCESS
corpusId: 12639289
fieldsOfStudy:
- Computer Science
numCitedBy: 1235
numCiting: 18
paperAbstract: We introduce a class of probabilistic continuous translation models
  called Recurrent Continuous Translation Models that are purely based on continuous
  representations for words, phrases and sentences and do not rely on alignments or
  phrasal translation units. The models have a generation and a conditioning aspect.
  The generation of the translation is modelled with a target Recurrent Language Model,
  whereas the conditioning on the source sentence is modelled with a Convolutional
  Sentence Model. Through various experiments, we show first that our models obtain
  a perplexity with respect to gold translations that is > 43% lower than that of
  stateof-the-art alignment-based translation models. Secondly, we show that they
  are remarkably sensitive to the word order, syntax, and meaning of the source sentence
  despite lacking alignments. Finally we show that they match a state-of-the-art system
  when rescoring n-best lists of translations.
ref_count: 18
references:
- pid: 5f08df805f14baa826dbddcb002277b15d3f1556
  title: Continuous Space Translation Models for Phrase-Based Statistical Machine
    Translation
- pid: d4a258df43cc14e46988de9a4a7b2f0ea817529b
  title: Continuous Space Language Models for Statistical Machine Translation
- pid: cd96a6e0b6bb099c515be8770764d2fd18e7b878
  title: Recurrent Convolutional Neural Networks for Discourse Compositionality
- pid: d1275b2a2ab53013310e759e5c6878b96df643d4
  title: Context dependent recurrent neural network language model
- pid: ab7b5917515c460b90451e67852171a531671ab8
  title: 'The Mathematics of Statistical Machine Translation: Parameter Estimation'
- pid: 6c2b28f9354f667cd5bd07afc0471d8334430da7
  title: A Neural Probabilistic Language Model
- pid: 27e38351e48fe4b7da2775bf94341738bc4da07e
  title: Semantic Compositionality through Recursive Matrix-Vector Spaces
- pid: 79c0b2f44bbc2bc51de554b88ebe46204413f884
  title: The Role of Syntax in Vector Space Models of Compositional Semantics
- pid: 57458bc1cffe5caa45a885af986d70f723f406b4
  title: 'A unified architecture for natural language processing: deep neural networks
    with multitask learning'
- pid: ae5e6c6f5513613a161b2c85563f9708bf2e9178
  title: Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection
- pid: e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de
  title: Generating Text with Recurrent Neural Networks
- pid: 9819b600a828a57e1cde047bbe710d3446b30da5
  title: Recurrent neural network based language model
- pid: 07ca885cb5cc4328895bfaec9ab752d5801b14cd
  title: Extensions of recurrent neural network language model
- pid: 7b5e31257f01aba987f16e175a3e49e00a5bd3bb
  title: A Simple, Fast, and Effective Reparameterization of IBM Model 2
- pid: 413c1142de9d91804d6d11c67ff3fed59c9fc279
  title: Adaptive Subgradient Methods for Online Learning and Stochastic Optimization
slug: Recurrent-Continuous-Translation-Models-Kalchbrenner-Blunsom
title: Recurrent Continuous Translation Models
url: https://www.semanticscholar.org/paper/Recurrent-Continuous-Translation-Models-Kalchbrenner-Blunsom/944a1cfd79dbfb6fef460360a0765ba790f4027a?sort=total-citations
venue: EMNLP
year: 2013
