authors:
- Prajit Ramachandran
- Peter J. Liu
- Quoc V. Le
badges:
- id: OPEN_ACCESS
corpusId: 3488076
fieldsOfStudy:
- Computer Science
numCitedBy: 249
numCiting: 66
paperAbstract: "This work presents a general unsupervised learning method to improve\
  \ the accuracy of sequence to sequence (seq2seq) models. In our method, the weights\
  \ of the encoder and decoder of a seq2seq model are initialized with the pretrained\
  \ weights of two language models and then fine-tuned with labeled data. We apply\
  \ this method to challenging benchmarks in machine translation and abstractive summarization\
  \ and find that it significantly improves the subsequent supervised models. Our\
  \ main result is that pretraining improves the generalization of seq2seq models.\
  \ We achieve state-of-the-art results on the WMT English\u2192German task, surpassing\
  \ a range of methods using both phrase-based machine translation and neural machine\
  \ translation. Our method achieves a significant improvement of 1.3 BLEU from th\
  \ previous best models on both WMT\u201914 and WMT\u201915 English\u2192German.\
  \ We also conduct human evaluations on abstractive summarization and find that our\
  \ method outperforms a purely supervised learning baseline in a statistically significant\
  \ manner."
ref_count: 66
references:
- pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
- pid: 4aa9f5150b46320f534de4747a2dd0cd7f3fe292
  title: Semi-supervised Sequence Learning
- pid: d76c07211479e233f7c6a6f32d5346c983c5598f
  title: Multi-task Sequence to Sequence Learning
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
- pid: 93499a7c7f699b6630a86fad964536f9423bb6d0
  title: Effective Approaches to Attention-based Neural Machine Translation
- pid: 85315b64a4c73cb86f156ef5b0a085d6ebc8a65d
  title: A Neural Conversational Model
- pid: dbde7dfa6cae81df8ac19ef500c42db96c3d1edd
  title: 'Google''s Neural Machine Translation System: Bridging the Gap between Human
    and Machine Translation'
- pid: f37076f426023241f19cdc2fb0a0fd733a6fa7fa
  title: Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond
- pid: 2f2d8f8072e5cc9b296fad551f65f183bdbff7aa
  title: Exploring the Limits of Language Modeling
- pid: 832fc9327695f7425d8759c6aaeec0fa2d7b0a90
  title: 'WikiReading: A Novel Large-scale Language Understanding Task over Wikipedia'
- pid: 1af68821518f03568f913ab03fc02080247a27ff
  title: Neural Machine Translation of Rare Words with Subword Units
- pid: 944a1cfd79dbfb6fef460360a0765ba790f4027a
  title: Recurrent Continuous Translation Models
- pid: 0b544dfe355a5070b60986319a3f51fb45d1348e
  title: "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical\
    \ Machine Translation"
- pid: 0d2336389dff3031910bd21dd1c44d1b4cd51725
  title: Why Does Unsupervised Pre-training Help Deep Learning?
- pid: 6658bbf68995731b2083195054ff45b4eca38b3a
  title: Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech
    Recognition
- pid: 664ec878de4b7170712baae4a7821fc2602bba25
  title: Learning to Generate Reviews and Discovering Sentiment
- pid: 47570e7f63e296f224a0e7f9a0d08b0de3cbaf40
  title: Grammar as a Foreign Language
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: d1505c6123c102e53eb19dff312cb25cea840b72
  title: Teaching Machines to Read and Comprehend
- pid: dc555e8156c956f823587ebbff018863e6d2a95e
  title: Listen, Attend and Spell
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
- pid: 87f40e6f3022adbc1f1905e3e506abad05a9964f
  title: Distributed Representations of Words and Phrases and their Compositionality
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: 067e07b725ab012c80aa2f87857f6791c1407f6d
  title: Long short-term memory recurrent neural network architectures for large scale
    acoustic modeling
- pid: 355d44f53428b1ac4fb2ab468d593c720640e5bd
  title: Greedy Layer-Wise Training of Deep Networks
- pid: f264e8b33c0d49a692a6ce2c4bcb28588aeb7d97
  title: Recurrent Neural Network Regularization
- pid: 90b63e917d5737b06357d50aa729619e933d9614
  title: Phone Recognition with the Mean-Covariance Restricted Boltzmann Machine
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: d7da009f457917aa381619facfa5ffae9329a6e9
  title: 'Bleu: a Method for Automatic Evaluation of Machine Translation'
- pid: 8978cf7574ceb35f4c3096be768c7547b28a35d0
  title: A Fast Learning Algorithm for Deep Belief Nets
- pid: 60b05f32c32519a809f21642ef1eb3eaf3848008
  title: 'ROUGE: A Package for Automatic Evaluation of Summaries'
- pid: 84069287da0a6b488b8c933f3cb5be759cb6237e
  title: On the difficulty of training recurrent neural networks
- pid: 94e3e7bc3d23276f0ee2d1cb8f9d14aa19668d5f
  title: Under Review as a Conference Paper at Iclr 2017 Delving into Transferable
    Adversarial Ex- Amples and Black-box Attacks
- pid: e74f9b7f8eec6ba4704c206b93bc8079af3da4bd
  title: ImageNet Large Scale Visual Recognition Challenge
- pid: a538b05ebb01a40323997629e171c91aa28b8e2f
  title: Rectified Linear Units Improve Restricted Boltzmann Machines
slug: Unsupervised-Pretraining-for-Sequence-to-Sequence-Ramachandran-Liu
title: Unsupervised Pretraining for Sequence to Sequence Learning
url: https://www.semanticscholar.org/paper/Unsupervised-Pretraining-for-Sequence-to-Sequence-Ramachandran-Liu/85f94d8098322f8130512b4c6c4627548ce4a6cc?sort=total-citations
venue: EMNLP
year: 2017
