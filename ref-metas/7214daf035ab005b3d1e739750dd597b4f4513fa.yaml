authors:
- Ilija Ilievski
- Shuicheng Yan
- Jiashi Feng
badges:
- id: OPEN_ACCESS
corpusId: 1935307
fieldsOfStudy:
- Computer Science
numCitedBy: 105
numCiting: 28
paperAbstract: Visual Question and Answering (VQA) problems are attracting increasing
  interest from multiple research disciplines. Solving VQA problems requires techniques
  from both computer vision for understanding the visual contents of a presented image
  or video, as well as the ones from natural language processing for understanding
  semantics of the question and generating the answers. Regarding visual content modeling,
  most of existing VQA methods adopt the strategy of extracting global features from
  the image or video, which inevitably fails in capturing fine-grained information
  such as spatial configuration of multiple objects. Extracting features from auto-generated
  regions -- as some region-based image recognition methods do -- cannot essentially
  address this problem and may introduce some overwhelming irrelevant features with
  the question. In this work, we propose a novel Focused Dynamic Attention (FDA) model
  to provide better aligned image content representation with proposed questions.
  Being aware of the key words in the question, FDA employs off-the-shelf object detector
  to identify important regions and fuse the information from the regions and global
  features via an LSTM unit. Such question-driven representations are then combined
  with question representation and fed into a reasoning unit for generating the answers.
  Extensive evaluation on a large-scale benchmark dataset, VQA, clearly demonstrate
  the superior performance of FDA over well-established baselines.
ref_count: 28
references:
- pid: 1cf6bc0866226c1f8e282463adc8b75d92fba9bb
  title: 'Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for
    Visual Question Answering'
- pid: 20dbdf02497aa84510970d0f5e8b599073bca1bc
  title: 'Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge
    from External Sources'
- pid: 3d1382fa43c31e594ed2d84dda9984b1db047b0e
  title: Compositional Memory for Visual Question Answering
- pid: b196bc11ad516c8e6ff96f83acfc443fd7161730
  title: 'ABC-CNN: An Attention Based Convolutional Neural Network for Visual Question
    Answering'
- pid: bd7bd1d2945a58cdcc1797ba9698b8810fe68f60
  title: 'Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images'
- pid: 175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22
  title: 'Where to Look: Focus Regions for Visual Question Answering'
- pid: 62a956d7600b10ca455076cd56e604dfd106072a
  title: Exploring Models and Data for Image Question Answering
- pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  title: Stacked Attention Networks for Image Question Answering
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: 2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1
  title: Are You Talking to a Machine? Dataset and Methods for Multilingual Image
    Question
- pid: 98bd5dd1740f585bf25320ba504e2c1ae57f2e5f
  title: Learning to Answer Questions from Image Using Convolutional Neural Network
- pid: 050da5d159fb0dd96143948e1cffeb3dec814673
  title: Visual Turing test for computer vision systems
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: 385c18cc4024a3b3206c508c512e037b9c00b8f3
  title: Image Question Answering Using Convolutional Neural Network with Dynamic
    Parameter Prediction
- pid: 267fb4ac632449dbe84f7acf17c8c7527cb25b0d
  title: Simple Baseline for Visual Question Answering
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: 75ddc7ee15be14013a3462c01b38b0548486fbcb
  title: Learning to Compose Neural Networks for Question Answering
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: b183947ee15718b45546eda6b01e179b9a95421f
  title: 'Edge Boxes: Locating Object Proposals from Edges'
- pid: e15cf50aa89fee8535703b9f9512fca5bfc43327
  title: Going deeper with convolutions
- pid: cb2c4afc60b074d74a1cf5dd0b8b4f768a20626d
  title: Multiscale Combinatorial Grouping for Image Segmentation and Object Proposal
    Generation
- pid: 87f40e6f3022adbc1f1905e3e506abad05a9964f
  title: Distributed Representations of Words and Phrases and their Compositionality
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: a8e8f3c8d4418c8d62e306538c9c1292635e9d27
  title: Backpropagation Applied to Handwritten Zip Code Recognition
slug: A-Focused-Dynamic-Attention-Model-for-Visual-Ilievski-Yan
title: A Focused Dynamic Attention Model for Visual Question Answering
url: https://www.semanticscholar.org/paper/A-Focused-Dynamic-Attention-Model-for-Visual-Ilievski-Yan/7214daf035ab005b3d1e739750dd597b4f4513fa?sort=total-citations
venue: ArXiv
year: 2016
