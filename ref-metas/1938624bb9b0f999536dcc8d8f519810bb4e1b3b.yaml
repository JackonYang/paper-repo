authors:
- "S\xE9bastien Jean"
- Kyunghyun Cho
- R. Memisevic
- Yoshua Bengio
badges:
- id: OPEN_ACCESS
corpusId: 2863491
fieldsOfStudy:
- Computer Science
numCitedBy: 857
numCiting: 26
paperAbstract: Neural machine translation, a recently proposed approach to machine
  translation based purely on neural networks, has shown promising results compared
  to the existing approaches such as phrase-based statistical machine translation.
  Despite its recent success, neural machine translation has its limitation in handling
  a larger vocabulary, as training complexity as well as decoding complexity increase
  proportionally to the number of target words. In this paper, we propose a method
  based on importance sampling that allows us to use a very large target vocabulary
  without increasing training complexity. We show that decoding can be efficiently
  done even with the model having a very large target vocabulary by selecting only
  a small subset of the whole target vocabulary. The models trained by the proposed
  approach are empirically found to outperform the baseline models with a small vocabulary
  as well as the LSTM-based neural machine translation models. Furthermore, when we
  use the ensemble of a few models with very large target vocabularies, we achieve
  the state-of-the-art translation performance (measured by BLEU) on the English!German
  translation and almost as high performance as state-of-the-art English!French translation
  system.
ref_count: 26
references:
- pid: 1956c239b3552e030db1b78951f64781101125ed
  title: Addressing the Rare Word Problem in Neural Machine Translation
- pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
- pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
- pid: 1eb09fecd75eb27825dce4f964b97f4f5cc399d7
  title: "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches"
- pid: 944a1cfd79dbfb6fef460360a0765ba790f4027a
  title: Recurrent Continuous Translation Models
- pid: 53ca064b9f1b92951c1997e90b776e95b0880e52
  title: Learning word embeddings efficiently with noise-contrastive estimation
- pid: a4b828609b60b06e61bea7a4029cc9e1cad5df87
  title: Statistical Phrase-Based Translation
- pid: 0b544dfe355a5070b60986319a3f51fb45d1348e
  title: "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical\
    \ Machine Translation"
- pid: 699d5ab38deee78b1fd17cc8ad233c74196d16e9
  title: Adaptive Importance Sampling to Accelerate Training of a Neural Probabilistic
    Language Model
- pid: b3e89f05876d47b9bd6ece225aaeee457a6824e8
  title: Statistical Machine Translation
- pid: 330da625c15427c6e42ccfa3b747fb29e5835bf0
  title: Efficient Estimation of Word Representations in Vector Space
- pid: 97cedf99252026f58e8154bc61d49cf885d42030
  title: "Edinburgh\u2019s Phrase-based Machine Translation Systems for WMT-14"
- pid: 8e4fb17fff38a7834af5b4eaafcbbde02bf00975
  title: N-gram Counts and Language Models from the Common Crawl
- pid: d7da009f457917aa381619facfa5ffae9329a6e9
  title: 'Bleu: a Method for Automatic Evaluation of Machine Translation'
- pid: 7b5e31257f01aba987f16e175a3e49e00a5bd3bb
  title: A Simple, Fast, and Effective Reparameterization of IBM Model 2
- pid: e3ce36b9deb47aa6bb2aa19c4bfa71283b505025
  title: 'Noise-contrastive estimation: A new estimation principle for unnormalized
    statistical models'
- pid: 855d0f722d75cc56a66a00ede18ace96bafee6bd
  title: 'Theano: new features and speed improvements'
slug: On-Using-Very-Large-Target-Vocabulary-for-Neural-Jean-Cho
title: On Using Very Large Target Vocabulary for Neural Machine Translation
url: https://www.semanticscholar.org/paper/On-Using-Very-Large-Target-Vocabulary-for-Neural-Jean-Cho/1938624bb9b0f999536dcc8d8f519810bb4e1b3b?sort=total-citations
venue: ACL
year: 2015
