authors:
- Makarand Tapaswi
- Yukun Zhu
- R. Stiefelhagen
- A. Torralba
- R. Urtasun
- S. Fidler
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 1017389
fieldsOfStudy:
- Computer Science
numCitedBy: 478
numCiting: 59
paperAbstract: We introduce the MovieQA dataset which aims to evaluate automatic story
  comprehension from both video and text. The dataset consists of 14,944 questions
  about 408 movies with high semantic diversity. The questions range from simpler
  "Who" did "What" to "Whom", to "Why" and "How" certain events occurred. Each question
  comes with a set of five possible answers, a correct one and four deceiving answers
  provided by human annotators. Our dataset is unique in that it contains multiple
  sources of information - video clips, plots, subtitles, scripts, and DVS. We analyze
  our data through various statistics and methods. We further extend existing QA techniques
  to show that question-answering with such open-ended semantics is hard. We make
  this data set public along with an evaluation benchmark to encourage inspiring work
  in this challenging domain.
ref_count: 59
references:
- pid: 0e6824e137847be0599bb0032e37042ed2ef5045
  title: 'Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching
    Movies and Reading Books'
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: 564257469fa44cdb57e4272f85253efb9acfd69d
  title: 'MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of
    Text'
- pid: a5ea0da7b93452bec54b5034706f2255bfb5a8f3
  title: A dataset for Movie Description
- pid: 62a956d7600b10ca455076cd56e604dfd106072a
  title: Exploring Models and Data for Image Question Answering
- pid: eaaed23a2d94feb2f1c3ff22a25777c7a78f3141
  title: 'Every Picture Tells a Story: Generating Sentences from Images'
- pid: 3b9f8101c61b415f946625b69f69fc9e3d0d6fc4
  title: Generating Natural-Language Video Descriptions Using Text-Mined Knowledge
- pid: bd7bd1d2945a58cdcc1797ba9698b8810fe68f60
  title: 'Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images'
- pid: a58a582b95a07932cb248f1b739e4ad739ead6b9
  title: 'Visual Madlibs: Fill in the blank Image Generation and Question Answering'
- pid: 6e795c6e9916174ae12349f5dc3f516570c17ce8
  title: Skip-Thought Vectors
- pid: c980b058f98dc1904ad328c2341a47c31479d076
  title: 'Movie/Script: Alignment and Parsing of Video and Text Transcription'
- pid: abb33d75dc297993fcc3fb75e0f4498f413eb4f6
  title: 'Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks'
- pid: 13549b4e6fffbb7932b7a83a8eb6be27e6a60eca
  title: What Are You Talking About? Text-to-Image Coreference
- pid: e8cd37fbd8bd5e690eef5861cf92af8e002d4533
  title: Translating Video Content to Natural Language Descriptions
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: a23ab0fb7d9e9961e92d704ed71e3dbc15c0d908
  title: 'A Thousand Frames in Just a Few Words: Lingual Description of Videos through
    Latent Topics and Sparse Object Stitching'
- pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
- pid: f4af49a1ead3c81cc5d023878cb67c5646dd8a04
  title: Learning a Recurrent Visual Representation for Image Caption Generation
- pid: 76a1dca3a9c2b0229c1b12c95752dcf40dc95a11
  title: Corpus-Guided Sentence Generation of Natural Images
- pid: 7afd833f484c8032e7fdc5f53188d2ebb0fb9934
  title: 'Visual Semantic Search: Retrieving Videos via Complex Textual Queries'
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: 43795b7bac3d921c4e579964b54187bdbf6c6330
  title: Translating Videos to Natural Language Using Deep Recurrent Neural Networks
- pid: 554a31ce91189cf6022ac677413ef2f8b9b40ca7
  title: Collecting Highly Parallel Data for Paraphrase Evaluation
- pid: 2e36ea91a3c8fbff92be2989325531b4002e2afc
  title: Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
- pid: 0b888196dda951287dddb60bd44798aab16d6fca
  title: Learning Common Sense through Visual Abstraction
- pid: 999f0acfac28215db2e4c69ff42711fd4f56511d
  title: Machine Comprehension with Syntax, Frames, and Semantics
- pid: f8403bf4e3060487cbc8acceb1fb256a4f1cfc76
  title: Adopting Abstract Images for Semantic Scene Understanding
- pid: d1505c6123c102e53eb19dff312cb25cea840b72
  title: Teaching Machines to Read and Comprehend
- pid: 3ecd3e00bbbfd94446c3adc9c6878de27e250f7c
  title: Learning Dependency-Based Compositional Semantics
- pid: dfe448d6297ea0a3d4deba21fbf1006bc35877d7
  title: Inferring the Why in Images
- pid: 4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e
  title: End-To-End Memory Networks
- pid: 793c1c908672ea71aef9e1b41a46272aa27598f7
  title: Video In Sentences Out
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  title: 'Im2Text: Describing Images Using 1 Million Captioned Photographs'
- pid: 169b847e69c35cfd475eb4dcc561a24de11762ca
  title: 'Baby talk: Understanding and generating simple image descriptions'
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: 44040913380206991b1991daf1192942e038fe31
  title: 'From image descriptions to visual denotations: New similarity metrics for
    semantic inference over event descriptions'
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: 330da625c15427c6e42ccfa3b747fb29e5835bf0
  title: Efficient Estimation of Word Representations in Vector Space
- pid: 9667f8264745b626c6173b1310e2ff0298b09cfc
  title: Learning Deep Features for Scene Recognition using Places Database
- pid: e15cf50aa89fee8535703b9f9512fca5bfc43327
  title: Going deeper with convolutions
- pid: 3d2218b17e7898a222e5fc2079a3f1531990708f
  title: I and J
slug: MovieQA:-Understanding-Stories-in-Movies-through-Tapaswi-Zhu
title: 'MovieQA: Understanding Stories in Movies through Question-Answering'
url: https://www.semanticscholar.org/paper/MovieQA:-Understanding-Stories-in-Movies-through-Tapaswi-Zhu/1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7?sort=total-citations
venue: 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2016
