authors:
- Jacob Devlin
- Hao Cheng
- Hao Fang
- Saurabh Gupta
- L. Deng
- Xiaodong He
- G. Zweig
- Margaret Mitchell
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 7988167
fieldsOfStudy:
- Computer Science
numCitedBy: 243
numCiting: 25
paperAbstract: Two recent approaches have achieved state-of-the-art results in image
  captioning. The first uses a pipelined process where a set of candidate words is
  generated by a convolutional neural network (CNN) trained on images, and then a
  maximum entropy (ME) language model is used to arrange these words into a coherent
  sentence. The second uses the penultimate activation layer of the CNN as input to
  a recurrent neural network (RNN) that then generates the caption sequence. In this
  paper, we compare the merits of these different language modeling approaches for
  the first time by using the same state-ofthe-art CNN as input. We examine issues
  in the different approaches, including linguistic irregularities, caption repetition,
  and data set overlap. By combining key aspects of the ME and RNN methods, we achieve
  a new record performance over previously published results on the benchmark COCO
  dataset. However, the gains we see in BLEU do not translate to human judgments.
ref_count: 25
references:
- pid: 54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745
  title: Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: f4af49a1ead3c81cc5d023878cb67c5646dd8a04
  title: Learning a Recurrent Visual Representation for Image Caption Generation
- pid: a72b8bbd039989db39769da836cdb287737deb92
  title: 'Mind''s eye: A recurrent visual representation for image caption generation'
- pid: 82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9
  title: Explain Images with Multimodal Recurrent Neural Networks
- pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
- pid: 2e36ea91a3c8fbff92be2989325531b4002e2afc
  title: Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
- pid: 9814df8bd00ba999c4d1e305a7e9bca579dc7c75
  title: 'Framing Image Description as a Ranking Task: Data, Models and Evaluation
    Metrics (Extended Abstract)'
- pid: d1275b2a2ab53013310e759e5c6878b96df643d4
  title: Context dependent recurrent neural network language model
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: fad611e35b3731740b4d8b754241e77add5a70b9
  title: Multimodal Neural Language Models
- pid: eaaed23a2d94feb2f1c3ff22a25777c7a78f3141
  title: 'Every Picture Tells a Story: Generating Sentences from Images'
- pid: 0b544dfe355a5070b60986319a3f51fb45d1348e
  title: "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical\
    \ Machine Translation"
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: 175468ba0a7242f259a4d7b81f3d82951313de61
  title: An Investigation into the Validity of Some Metrics for Automatically Evaluating
    Natural Language Generation Systems
- pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  title: 'Im2Text: Describing Images Using 1 Million Captioned Photographs'
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: 1f12451245667a85d0ee225a80880fc93c71cc8b
  title: Minimum Error Rate Training in Statistical Machine Translation
- pid: 26adb749fc5d80502a6d889966e50b31391560d3
  title: 'Meteor Universal: Language Specific Translation Evaluation for Any Target
    Language'
- pid: d7da009f457917aa381619facfa5ffae9329a6e9
  title: 'Bleu: a Method for Automatic Evaluation of Machine Translation'
- pid: e74f9b7f8eec6ba4704c206b93bc8079af3da4bd
  title: ImageNet Large Scale Visual Recognition Challenge
- pid: 0a1f4cc5e1d7ccdce98c65545bbcccc23a6c16e7
  title: Re-evaluating the Role of Bleu in Machine Translation Research
slug: Language-Models-for-Image-Captioning:-The-Quirks-Devlin-Cheng
title: 'Language Models for Image Captioning: The Quirks and What Works'
url: https://www.semanticscholar.org/paper/Language-Models-for-Image-Captioning:-The-Quirks-Devlin-Cheng/f142c849ffef66f7520aff4e0b40ac964ccb8cc1?sort=total-citations
venue: ACL
year: 2015
