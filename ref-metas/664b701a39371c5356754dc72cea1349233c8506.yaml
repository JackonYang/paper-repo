authors:
- S. Weiss
- C. Kulikowski
badges: []
corpusId: 12484204
fieldsOfStudy:
- Computer Science
numCitedBy: 1046
numCiting: 0
paperAbstract: 'Preface 1 Overview of Learning Systems 1.1 What is a Learning System?
  1.2 Motivation for Building Learning Systems 1.3 Types of Practical Empirical Learning
  Systems 1.3.1 Common Theme: The Classification Model 1.3.2 Let the Data Speak 1.4
  What''s New in Learning Methods 1.4.1 The Impact of New Technology 1.5 Outline of
  the Book 1.6 Bibliographical and Historical Remarks 2 How to Estimate the True Performance
  of a Learning System 2.1 The Importance of Unbiased Error Rate Estimation 2.2. What
  is an Error? 2.2.1 Costs and Risks 2.3 Apparent Error Rate Estimates 2.4 Too Good
  to Be True: Overspecialization 2.5 True Error Rate Estimation 2.5.1 The Idealized
  Model for Unlimited Samples 2.5.2 Train-and Test Error Rate Estimation 2.5.3 Resampling
  Techniques 2.5.4 Finding the Right Complexity Fit 2.6 Getting the Most Out of the
  Data 2.7 Classifier Complexity and Feature Dimensionality 2.7.1 Expected Patterns
  of Classifier Behavior 2.8 What Can Go Wrong? 2.8.1 Poor Features, Data Errors,
  and Mislabeled Classes 2.8.2 Unrepresentative Samples 2.9 How Close to the Truth?
  2.10 Common Mistakes in Performance Analysis 2.11 Bibliographical and Historical
  Remarks 3 Statistical Pattern Recognition 3.1 Introduction and Overview 3.2 A Few
  Sample Applications 3.3 Bayesian Classifiers 3.3.1 Direct Application of the Bayes
  Rule 3.4 Linear Discriminants 3.4.1 The Normality Assumption and Discriminant Functions
  3.4.2 Logistic Regression 3.5 Nearest Neighbor Methods 3.6 Feature Selection 3.7
  Error Rate Analysis 3.8 Bibliographical and Historical Remarks 4 Neural Nets 4.1
  Introduction and Overview 4.2 Perceptrons 4.2.1 Least Mean Square Learning Systems
  4.2.2 How Good Is a Linear Separation Network? 4.3 Multilayer Neural Networks 4.3.1
  Back-Propagation 4.3.2 The Practical Application of Back-Propagation 4.4 Error Rate
  and Complexity Fit Estimation 4.5 Improving on Standard Back-Propagation 4.6 Bibliographical
  and Historical Remarks 5 Machine Learning: Easily Understood Decision Rules 5.1
  Introduction and Overview 5.2 Decision Trees 5.2.1 Finding the Perfect Tree 5.2.2
  The Incredible Shrinking Tree 5.2.3 Limitations of Tree Induction Methods 5.3 Rule
  Induction 5.3.1 Predictive Value Maximization 5.4 Bibliographical and Historical
  Remarks 6 Which Technique is Best? 6.1 What''s Important in Choosing a Classifier?
  6.1.1 Prediction Accuracy 6.1.2 Speed of Learning and Classification 6.1.3 Explanation
  and Insight 6.2 So, How Do I Choose a Learning System? 6.3 Variations on the Standard
  Problem 6.3.1 Missing Data 6.3.2 Incremental Learning 6.4 Future Prospects for Improved
  Learning Methods 6.5 Bibliographical and Historical Remarks 7 Expert Systems 7.1
  Introduction and Overview 7.1.1 Why Build Expert Systems? New vs. Old Knowledge
  7.2 Estimating Error Rates for Expert Systems 7.3 Complexity of Knowledge Bases
  7.3.1 How Many Rules Are Too Many? 7.4 Knowledge Base Example 7.5 Empirical Analysis
  of Knowledge Bases 7.6 Future: Combined Learning and Expert Systems 7.7 Bibliographical
  and Historical Remarks References Author Index Subject Index'
ref_count: 0
references: []
slug: Computer-Systems-That-Learn:-Classification-and-and-Weiss-Kulikowski
title: 'Computer Systems That Learn: Classification and Prediction Methods from Statistics,
  Neural Nets, Machine Learning and Expert Systems'
url: https://www.semanticscholar.org/paper/Computer-Systems-That-Learn:-Classification-and-and-Weiss-Kulikowski/664b701a39371c5356754dc72cea1349233c8506?sort=total-citations
venue: ''
year: 1990
