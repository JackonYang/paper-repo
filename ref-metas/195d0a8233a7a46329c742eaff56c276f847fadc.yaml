authors:
- S. Rifai
- Pascal Vincent
- X. Muller
- Xavier Glorot
- Yoshua Bengio
badges:
- id: OPEN_ACCESS
corpusId: 8141422
fieldsOfStudy:
- Computer Science
meta_key: contractive-auto-encoders-explicit-invariance-during-feature-extraction
numCitedBy: 1248
numCiting: 25
paperAbstract: We present in this paper a novel approach for training deterministic
  auto-encoders. We show that by adding a well chosen penalty term to the classical
  reconstruction cost function, we can achieve results that equal or surpass those
  attained by other regularized auto-encoders as well as denoising auto-encoders on
  a range of datasets. This penalty term corresponds to the Frobenius norm of the
  Jacobian matrix of the encoder activations with respect to the input. We show that
  this penalty term results in a localized space contraction which in turn yields
  robust features on the activation layer. Furthermore, we show how this penalty term
  is related to both regularized auto-encoders and denoising auto-encoders and how
  it can be seen as a link between deterministic and non-deterministic auto-encoders.
  We find empirically that this penalty helps to carve a representation that better
  captures the local directions of variation dictated by the data, corresponding to
  a lower-dimensional non-linear manifold, while being more invariant to the vast
  majority of directions orthogonal to the manifold. Finally, we show that by using
  the learned features to initialize a MLP, we achieve state of the art classification
  error on a range of datasets, surpassing other methods of pretraining.
ref_count: 25
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: stacked-denoising-autoencoders-learning-useful-representations-in-a-deep-network-with-a-local-denoising-criterion
  numCitedBy: 5611
  pid: e2b7f37cd97a7907b1b8a41138721ed06a0b76cd
  show_ref_link: true
  title: 'Stacked Denoising Autoencoders: Learning Useful Representations in a Deep
    Network with a Local Denoising Criterion'
  year: 2010
- fieldsOfStudy:
  - Mathematics
  meta_key: training-with-noise-is-equivalent-to-tikhonov-regularization
  numCitedBy: 993
  pid: c3ecd8e19e016d15670c8953b4b9afaa5186b0f3
  show_ref_link: false
  title: Training with Noise is Equivalent to Tikhonov Regularization
  year: 1995
- fieldsOfStudy:
  - Computer Science
  meta_key: tangent-prop-a-formalism-for-specifying-selected-invariances-in-an-adaptive-network
  numCitedBy: 286
  pid: ff32cebbdb8a436ccd8ae797647428615ae32d74
  show_ref_link: false
  title: Tangent Prop - A Formalism for Specifying Selected Invariances in an Adaptive
    Network
  year: 1991
- fieldsOfStudy:
  - Biology
  meta_key: sparse-coding-with-an-overcomplete-basis-set-a-strategy-employed-by-v1
  numCitedBy: 3574
  pid: 2805537bec87a6177037b18f9a3a9d3f1038867b
  show_ref_link: false
  title: 'Sparse coding with an overcomplete basis set: A strategy employed by V1?'
  year: 1997
- fieldsOfStudy:
  - Computer Science
  meta_key: neural-networks-and-principal-component-analysis-learning-from-examples-without-local-minima
  numCitedBy: 1336
  pid: 9552ac39a57daacf3d75865a268935b5a0df9bbb
  show_ref_link: false
  title: 'Neural networks and principal component analysis: Learning from examples
    without local minima'
  year: 1989
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-multiple-layers-of-features-from-tiny-images
  numCitedBy: 17113
  pid: 5d90f06bb70a0a3dced62413346235c02b1aa086
  show_ref_link: true
  title: Learning Multiple Layers of Features from Tiny Images
  year: 2009
- fieldsOfStudy:
  - Computer Science
  meta_key: a-fast-learning-algorithm-for-deep-belief-nets
  numCitedBy: 13412
  pid: 8978cf7574ceb35f4c3096be768c7547b28a35d0
  show_ref_link: true
  title: A Fast Learning Algorithm for Deep Belief Nets
  year: 2006
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-invariant-features-through-topographic-filter-maps
  numCitedBy: 312
  pid: 54a9c2553138932426faebcaa67a63a84a56b55d
  show_ref_link: false
  title: Learning invariant features through topographic filter maps
  year: 2009
- fieldsOfStudy:
  - Computer Science
  meta_key: greedy-layer-wise-training-of-deep-networks
  numCitedBy: 3434
  pid: 355d44f53428b1ac4fb2ab468d593c720640e5bd
  show_ref_link: true
  title: Greedy Layer-Wise Training of Deep Networks
  year: 2006
- fieldsOfStudy:
  - Computer Science
  meta_key: convolutional-deep-belief-networks-for-scalable-unsupervised-learning-of-hierarchical-representations
  numCitedBy: 2510
  pid: 1e80f755bcbf10479afd2338cec05211fdbd325c
  show_ref_link: false
  title: Convolutional deep belief networks for scalable unsupervised learning of
    hierarchical representations
  year: 2009
- fieldsOfStudy:
  - Computer Science
  meta_key: what-is-the-best-multi-stage-architecture-for-object-recognition
  numCitedBy: 2085
  pid: 1f88427d7aa8225e47f946ac41a0667d7b69ac52
  show_ref_link: false
  title: What is the best multi-stage architecture for object recognition?
  year: 2009
- fieldsOfStudy:
  - Computer Science
  meta_key: sparse-deep-belief-net-model-for-visual-area-v2
  numCitedBy: 1028
  pid: 202cbbf671743aefd380d2f23987bd46b9caaf97
  show_ref_link: false
  title: Sparse deep belief net model for visual area V2
  year: 2007
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-learning-via-semi-supervised-embedding
  numCitedBy: 612
  pid: 7ee368e60d0b826e78f965aad8d6c7d406127104
  show_ref_link: false
  title: Deep learning via semi-supervised embedding
  year: 2008
- fieldsOfStudy:
  - Computer Science
  meta_key: nonlinear-autoassociation-is-not-equivalent-to-pca
  numCitedBy: 181
  pid: 36473661a17a4b97a92ce9c4324ee669bd0a59d5
  show_ref_link: false
  title: Nonlinear Autoassociation Is Not Equivalent to PCA
  year: 2000
- fieldsOfStudy:
  - Environmental Science
  meta_key: learning-representations-by-backpropagating-errors
  numCitedBy: 1037
  pid: ae3fe34be9230c98b04d68b4621c89b7dbc2d717
  show_ref_link: false
  title: Learning representations by backpropagating errors
  year: 2004
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-representations-by-back-propagating-errors
  numCitedBy: 20334
  pid: 052b1d8ce63b07fec3de9dbb583772d860b7c769
  show_ref_link: false
  title: Learning representations by back-propagating errors
  year: 1986
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-deep-architectures-for-ai
  numCitedBy: 7558
  pid: e60ff004dde5c13ec53087872cfcdd12e85beb57
  show_ref_link: true
  title: Learning Deep Architectures for AI
  year: 2007
- fieldsOfStudy:
  - Computer Science
  meta_key: an-empirical-evaluation-of-deep-architectures-on-problems-with-many-factors-of-variation
  numCitedBy: 973
  pid: b8012351bc5ebce4a4b3039bbbba3ce393bc3315
  show_ref_link: false
  title: An empirical evaluation of deep architectures on problems with many factors
    of variation
  year: 2007
- fieldsOfStudy:
  - Psychology
  meta_key: learning-representations-by-back-propagation-errors-nature
  numCitedBy: 1334
  pid: 749ce8ccd9453d1b34901143cddf5f9bee2977cf
  show_ref_link: false
  title: Learning representations by back-propagation errors, nature
  year: 1986
- fieldsOfStudy:
  - Computer Science
  meta_key: advances-in-neural-information-processing-systems-8-nips-1995
  numCitedBy: 36
  pid: 47edd3b21802836ccc80d3d6e0d84e8cc008fa5b
  show_ref_link: false
  title: Advances in Neural Information Processing Systems 8 (NIPS 1995)
  year: 1991
slug: Contractive-Auto-Encoders:-Explicit-Invariance-Rifai-Vincent
title: 'Contractive Auto-Encoders: Explicit Invariance During Feature Extraction'
url: https://www.semanticscholar.org/paper/Contractive-Auto-Encoders:-Explicit-Invariance-Rifai-Vincent/195d0a8233a7a46329c742eaff56c276f847fadc?sort=total-citations
venue: ICML
year: 2011
