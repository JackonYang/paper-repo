authors:
- Mandar Joshi
- Danqi Chen
- Yinhan Liu
- Daniel S. Weld
- Luke Zettlemoyer
- Omer Levy
badges:
- id: OPEN_ACCESS
corpusId: 198229624
fieldsOfStudy:
- Computer Science
meta_key: spanbert-improving-pre-training-by-representing-and-predicting-spans
numCitedBy: 879
numCiting: 120
paperAbstract: We present SpanBERT, a pre-training method that is designed to better
  represent and predict spans of text. Our approach extends BERT by (1) masking contiguous
  random spans, rather than random tokens, and (2) training the span boundary representations
  to predict the entire content of the masked span, without relying on the individual
  token representations within it. SpanBERT consistently outperforms BERT and our
  better-tuned baselines, with substantial gains on span selection tasks such as question
  answering and coreference resolution. In particular, with the same training data
  and model size as BERTlarge, our single model obtains 94.6% and 88.7% F1 on SQuAD
  1.1 and 2.0 respectively. We also achieve a new state of the art on the OntoNotes
  coreference resolution task (79.6% F1), strong performance on the TACRED relation
  extraction benchmark, and even gains on GLUE.1
ref_count: 68
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: end-to-end-neural-coreference-resolution
  numCitedBy: 602
  pid: 8ae1af4a424f5e464d46903bc3d18fe1cf1434ff
  show_ref_link: false
  title: End-to-end Neural Coreference Resolution
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-recurrent-span-representations-for-extractive-question-answering
  numCitedBy: 139
  pid: 97e6ed1f7e5de0034f71c370c01f59c87aaf9a72
  show_ref_link: false
  title: Learning Recurrent Span Representations for Extractive Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: bert-for-coreference-resolution-baselines-and-analysis
  numCitedBy: 180
  pid: 127ffe6d21b75bd41dd808e3313bc392b9428346
  show_ref_link: false
  title: 'BERT for Coreference Resolution: Baselines and Analysis'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding
  numCitedBy: 33744
  pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  show_ref_link: true
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: ernie-enhanced-language-representation-with-informative-entities
  numCitedBy: 594
  pid: 5f994dc8cae24ca9d1ed629e517fcc652660ddde
  show_ref_link: false
  title: 'ERNIE: Enhanced Language Representation with Informative Entities'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: matching-the-blanks-distributional-similarity-for-relation-learning
  numCitedBy: 343
  pid: 4af09143735210777281b66997ec12994dbb43d4
  show_ref_link: false
  title: 'Matching the Blanks: Distributional Similarity for Relation Learning'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: unified-language-model-pre-training-for-natural-language-understanding-and-generation
  numCitedBy: 732
  pid: 1c71771c701aadfd72c5866170a9f5d71464bb88
  show_ref_link: true
  title: Unified Language Model Pre-training for Natural Language Understanding and
    Generation
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: mass-masked-sequence-to-sequence-pre-training-for-language-generation
  numCitedBy: 599
  pid: 145b8b5d99a2beba6029418ca043585b90138d12
  show_ref_link: true
  title: 'MASS: Masked Sequence to Sequence Pre-training for Language Generation'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: conll-2012-shared-task-modeling-multilingual-unrestricted-coreference-in-ontonotes
  numCitedBy: 595
  pid: f8cdf754fb7c08caf6e2f82b176819230910be5b
  show_ref_link: false
  title: 'CoNLL-2012 Shared Task: Modeling Multilingual Unrestricted Coreference in
    OntoNotes'
  year: 2012
- fieldsOfStudy:
  - Computer Science
  meta_key: transformer-xl-attentive-language-models-beyond-a-fixed-length-context
  numCitedBy: 1771
  pid: c4744a7c2bb298e4a52289a1e085c71cc3d37bc6
  show_ref_link: true
  title: 'Transformer-XL: Attentive Language Models beyond a Fixed-Length Context'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: glue-a-multi-task-benchmark-and-analysis-platform-for-natural-language-understanding
  numCitedBy: 2634
  pid: 93b8da28d006415866bf48f9a6e06b5242129195
  show_ref_link: true
  title: 'GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language
    Understanding'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: roberta-a-robustly-optimized-bert-pretraining-approach
  numCitedBy: 7267
  pid: 077f8329a7b6fa3b7c877a57b81eb6c18b5f87de
  show_ref_link: true
  title: 'RoBERTa: A Robustly Optimized BERT Pretraining Approach'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: higher-order-coreference-resolution-with-coarse-to-fine-inference
  numCitedBy: 283
  pid: e6566ece21f6637c515fe9969f9d1ec6cca6d36c
  show_ref_link: false
  title: Higher-Order Coreference Resolution with Coarse-to-Fine Inference
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: skip-thought-vectors
  numCitedBy: 1928
  pid: 6e795c6e9916174ae12349f5dc3f516570c17ce8
  show_ref_link: true
  title: Skip-Thought Vectors
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: squad-100-000-questions-for-machine-comprehension-of-text
  numCitedBy: 4263
  pid: 05dd7254b632376973f3a1b4d39485da17814df5
  show_ref_link: true
  title: 'SQuAD: 100,000+ Questions for Machine Comprehension of Text'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: jointly-predicting-predicates-and-arguments-in-neural-semantic-role-labeling
  numCitedBy: 154
  pid: 7442a18a55f257a68f21d0cbb8b1395f8915a452
  show_ref_link: false
  title: Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: cross-lingual-language-model-pretraining
  numCitedBy: 1509
  pid: ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc
  show_ref_link: true
  title: Cross-lingual Language Model Pretraining
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: xlnet-generalized-autoregressive-pretraining-for-language-understanding
  numCitedBy: 4226
  pid: e0c6abdbdecf04ffac65c440da77fb9d66bb474c
  show_ref_link: true
  title: 'XLNet: Generalized Autoregressive Pretraining for Language Understanding'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: triviaqa-a-large-scale-distantly-supervised-challenge-dataset-for-reading-comprehension
  numCitedBy: 883
  pid: f010affab57b5fcf1cd6be23df79d8ec98c7289c
  show_ref_link: true
  title: 'TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading
    Comprehension'
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: a-broad-coverage-challenge-corpus-for-sentence-understanding-through-inference
  numCitedBy: 2036
  pid: 5ded2b8c64491b4a67f6d39ce473d4b9347a672e
  show_ref_link: true
  title: A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: position-aware-attention-and-supervised-data-improve-slot-filling
  numCitedBy: 416
  pid: 400e746bc8027c4b5f915cae6123cd1775484b4d
  show_ref_link: false
  title: Position-aware Attention and Supervised Data Improve Slot Filling
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: pair2vec-compositional-word-pair-embeddings-for-cross-sentence-inference
  numCitedBy: 41
  pid: 5f6a87289ef0977073e49aa4460f6018de89e14c
  show_ref_link: false
  title: 'pair2vec: Compositional Word-Pair Embeddings for Cross-Sentence Inference'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: attention-is-all-you-need
  numCitedBy: 35150
  pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  show_ref_link: true
  title: Attention is All you Need
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: huggingface-s-transformers-state-of-the-art-natural-language-processing
  numCitedBy: 2727
  pid: 1fa9ed2bea208511ae698a967875e943049f16b6
  show_ref_link: true
  title: 'HuggingFace''s Transformers: State-of-the-art Natural Language Processing'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: universal-language-model-fine-tuning-for-text-classification
  numCitedBy: 2251
  pid: 1e077413b25c4d34945cc2707e17e46ed4fe784a
  show_ref_link: true
  title: Universal Language Model Fine-tuning for Text Classification
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: context2vec-learning-generic-context-embedding-with-bidirectional-lstm
  numCitedBy: 398
  pid: 59761abc736397539bdd01ad7f9d91c8607c0457
  show_ref_link: false
  title: 'context2vec: Learning Generic Context Embedding with Bidirectional LSTM'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: multi-task-deep-neural-networks-for-natural-language-understanding
  numCitedBy: 732
  pid: 658721bc13b0fa97366d38c05a96bf0a9f4bb0ac
  show_ref_link: true
  title: Multi-Task Deep Neural Networks for Natural Language Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: newsqa-a-machine-comprehension-dataset
  numCitedBy: 585
  pid: 3eda43078ae1f4741f09be08c4ecab6229046a5c
  show_ref_link: true
  title: 'NewsQA: A Machine Comprehension Dataset'
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: searchqa-a-new-q-a-dataset-augmented-with-context-from-a-search-engine
  numCitedBy: 303
  pid: 3adff57fd09965224506a1bacc0579d9d3c8c11e
  show_ref_link: false
  title: 'SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine'
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: natural-questions-a-benchmark-for-question-answering-research
  numCitedBy: 896
  pid: 17dbd7b72029181327732e4d11b52a08ed4630d0
  show_ref_link: true
  title: 'Natural Questions: A Benchmark for Question Answering Research'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: hotpotqa-a-dataset-for-diverse-explainable-multi-hop-question-answering
  numCitedBy: 744
  pid: 22655979df781d222eaf812b0d325fa9adf11594
  show_ref_link: false
  title: 'HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: know-what-you-don-t-know-unanswerable-questions-for-squad
  numCitedBy: 1398
  pid: 4d1c856275744c0284312a3a50efb6ca9dc4cd4c
  show_ref_link: true
  title: 'Know What You Don''t Know: Unanswerable Questions for SQuAD'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank
  numCitedBy: 5366
  pid: 687bac2d3320083eb4530bf18bb8f8f721477600
  show_ref_link: true
  title: Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank
  year: 2013
- fieldsOfStudy:
  - Computer Science
  - Psychology
  meta_key: semeval-2017-task-1-semantic-textual-similarity-multilingual-and-crosslingual-focused-evaluation
  numCitedBy: 934
  pid: a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096
  show_ref_link: true
  title: 'SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual
    Focused Evaluation'
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: an-efficient-framework-for-learning-sentence-representations
  numCitedBy: 346
  pid: bc1d609520290e0460c49b685675eb5a57fa5935
  show_ref_link: true
  title: An efficient framework for learning sentence representations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: the-seventh-pascal-recognizing-textual-entailment-challenge
  numCitedBy: 390
  pid: 0f8468de03ee9f12d693237bec87916311bf1c24
  show_ref_link: false
  title: The Seventh PASCAL Recognizing Textual Entailment Challenge
  year: 2011
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-contextualized-word-representations
  numCitedBy: 7987
  pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  show_ref_link: true
  title: Deep Contextualized Word Representations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: kermit-generative-insertion-based-modeling-for-sequences
  numCitedBy: 54
  pid: 130277ff64c7171c90d98d7e73f4bda8a0b0c1f9
  show_ref_link: false
  title: 'KERMIT: Generative Insertion-Based Modeling for Sequences'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: mrqa-2019-shared-task-evaluating-generalization-in-reading-comprehension
  numCitedBy: 149
  pid: 1be21e96eaac56f626e7b41c1f332b6b46131608
  show_ref_link: false
  title: 'MRQA 2019 Shared Task: Evaluating Generalization in Reading Comprehension'
  year: 2019
- fieldsOfStudy:
  - Linguistics
  meta_key: the-winograd-schema-challenge
  numCitedBy: 691
  pid: 128cb6b891aee1b5df099acb48e2efecfcff689f
  show_ref_link: false
  title: The Winograd Schema Challenge
  year: 2011
- fieldsOfStudy:
  - Computer Science
  meta_key: ernie-enhanced-representation-through-knowledge-integration
  numCitedBy: 389
  pid: 031e4e43aaffd7a479738dcea69a2d5be7957aa3
  show_ref_link: false
  title: 'ERNIE: Enhanced Representation through Knowledge Integration'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: blockwise-parallel-decoding-for-deep-autoregressive-models
  numCitedBy: 45
  pid: 5e04881e91bff952d102d967c4ffb498ec30d4af
  show_ref_link: false
  title: Blockwise Parallel Decoding for Deep Autoregressive Models
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: the-second-pascal-recognising-textual-entailment-challenge
  numCitedBy: 408
  pid: 136326377c122560768db674e35f5bcd6de3bc40
  show_ref_link: false
  title: The Second PASCAL Recognising Textual Entailment Challenge
  year: 2006
- fieldsOfStudy:
  - Computer Science
  meta_key: using-the-output-embedding-to-improve-language-models
  numCitedBy: 568
  pid: 63e39cdf1ad884da6bc69096bb3413b5b1100559
  show_ref_link: true
  title: Using the Output Embedding to Improve Language Models
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: automatically-constructing-a-corpus-of-sentential-paraphrases
  numCitedBy: 834
  pid: 475354f10798f110d34792b6d88f31d6d5cb099e
  show_ref_link: false
  title: Automatically Constructing a Corpus of Sentential Paraphrases
  year: 2005
- fieldsOfStudy:
  - Computer Science
  - Linguistics
  meta_key: neural-network-acceptability-judgments
  numCitedBy: 545
  pid: cb0f3ee1e98faf92429d601cdcd76c69c1e484eb
  show_ref_link: true
  title: Neural Network Acceptability Judgments
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: the-pascal-recognising-textual-entailment-challenge
  numCitedBy: 1762
  pid: de794d50713ea5f91a7c9da3d72041e2f5ef8452
  show_ref_link: false
  title: The PASCAL Recognising Textual Entailment Challenge
  year: 2005
- fieldsOfStudy:
  - Computer Science
  meta_key: a-baseline-for-detecting-misclassified-and-out-of-distribution-examples-in-neural-networks
  numCitedBy: 1323
  pid: 6ff2a434578ff2746b9283e45abf296887f48a2d
  show_ref_link: false
  title: A Baseline for Detecting Misclassified and Out-of-Distribution Examples in
    Neural Networks
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: adam-a-method-for-stochastic-optimization
  numCitedBy: 90054
  pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  show_ref_link: true
  title: 'Adam: A Method for Stochastic Optimization'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: fairseq-a-fast-extensible-toolkit-for-sequence-modeling
  numCitedBy: 1565
  pid: faadd7d081c8d67e8c2567e8a5579e46cd6b2280
  show_ref_link: false
  title: 'fairseq: A Fast, Extensible Toolkit for Sequence Modeling'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: decoupled-weight-decay-regularization
  numCitedBy: 3475
  pid: d07284a6811f1b2745d91bdb06b040b57f226882
  show_ref_link: true
  title: Decoupled Weight Decay Regularization
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: layer-normalization
  numCitedBy: 3049
  pid: 97fb4e3d45bb098e27e0071448b6152217bd35a5
  show_ref_link: true
  title: Layer Normalization
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: gaussian-error-linear-units-gelus
  numCitedBy: 971
  pid: 15f4c35889ccc1ae258b680c2ca2fcbfe1e260f7
  show_ref_link: true
  title: Gaussian Error Linear Units (GELUs)
  year: 2016
slug: SpanBERT:-Improving-Pre-training-by-Representing-Joshi-Chen
title: 'SpanBERT: Improving Pre-training by Representing and Predicting Spans'
url: https://www.semanticscholar.org/paper/SpanBERT:-Improving-Pre-training-by-Representing-Joshi-Chen/81f5810fbbab9b7203b9556f4ce3c741875407bc?sort=total-citations
venue: TACL
year: 2020
