authors:
- L. Logeswaran
- Honglak Lee
badges:
- id: OPEN_ACCESS
corpusId: 3525802
fieldsOfStudy:
- Computer Science
numCitedBy: 346
numCiting: 48
paperAbstract: In this work we propose a simple and efficient framework for learning
  sentence representations from unlabelled data. Drawing inspiration from the distributional
  hypothesis and recent work on learning sentence representations, we reformulate
  the problem of predicting the context in which a sentence appears as a classification
  problem. Given a sentence and its context, a classifier distinguishes context sentences
  from other contrastive sentences based on their vector representations. This allows
  us to efficiently learn different types of encoding functions, and we show that
  the model learns high-quality sentence representations. We demonstrate that our
  sentence representations outperform state-of-the-art unsupervised and supervised
  representation learning methods on several downstream NLP tasks that involve understanding
  sentence semantics while achieving an order of magnitude speedup in training time.
ref_count: 48
references:
- pid: 6e795c6e9916174ae12349f5dc3f516570c17ce8
  title: Skip-Thought Vectors
- pid: 26e743d5bd465f49b9538deaf116c15e61b7951f
  title: Learning Distributed Representations of Sentences from Unlabelled Data
- pid: ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c
  title: Supervised Learning of Universal Sentence Representations from Natural Language
    Inference Data
- pid: f527bcfb09f32e6a4a8afc0b37504941c1ba2cee
  title: Distributed Representations of Sentences and Documents
- pid: 395044a2e3f5624b2471fb28826e7dbb1009356e
  title: Towards Universal Paraphrastic Sentence Embeddings
- pid: d41cfe9b2ada4e09d53262bc75c473d8043936fc
  title: Self-Adaptive Hierarchical Sentence Model
- pid: 330da625c15427c6e42ccfa3b747fb29e5835bf0
  title: Efficient Estimation of Word Representations in Vector Space
- pid: 87f40e6f3022adbc1f1905e3e506abad05a9964f
  title: Distributed Representations of Words and Phrases and their Compositionality
- pid: 687bac2d3320083eb4530bf18bb8f8f721477600
  title: Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank
- pid: 46b8cbcdff87b842c2c1d4a003c831f845096ba7
  title: Order-Embeddings of Images and Language
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
- pid: fc1b1c9364c58ec406f494dd944b609a6a038ba6
  title: Unsupervised Visual Representation Learning by Context Prediction
- pid: c4fd9c86b2b41df51a6fe212406dda81b1997fd4
  title: Linguistic Regularities in Continuous Space Word Representations
- pid: 0e5fa90e28fab414c8ef3ac6ca937c6195c2860e
  title: Discriminative Improvements to Distributional Sentence Similarity
- pid: ae5e6c6f5513613a161b2c85563f9708bf2e9178
  title: Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection
- pid: 32de44f01a96d4473d21099d15e25bc2b9f08e2f
  title: Improved Semantic Representations From Tree-Structured Long Short-Term Memory
    Networks
- pid: 51239b320c73f3f2219286bf62f24d6763379328
  title: Associating neural word embeddings with deep image representations using
    Fisher Vectors
- pid: 1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba
  title: Convolutional Neural Networks for Sentence Classification
- pid: c333778104f648c385b4631f7b4a859787e9d3d3
  title: A SICK cure for the evaluation of compositional distributional semantic models
- pid: 54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745
  title: Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)
- pid: 16084914bc3729f86f46ac6267ea7a42e7951d41
  title: 'SemEval-2014 Task 10: Multilingual Semantic Textual Similarity'
- pid: 2ec8f7e0257a07d3914322b36072d1bbcd58a1e0
  title: Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles
- pid: a9fc84f8abe740cdc7ee82e69444d1d00dbe0ceb
  title: A Scalable Hierarchical Distributed Language Model
- pid: 1af68821518f03568f913ab03fc02080247a27ff
  title: Neural Machine Translation of Rare Words with Subword Units
- pid: 1938624bb9b0f999536dcc8d8f519810bb4e1b3b
  title: On Using Very Large Target Vocabulary for Neural Machine Translation
- pid: 7d0effebfa4bed19b6ba41f3af5b7e5b6890de87
  title: 'Context Encoders: Feature Learning by Inpainting'
- pid: 6af58c061f2e4f130c3b795c21ff0c7e3903278f
  title: 'Seeing Stars: Exploiting Class Relationships for Sentiment Categorization
    with Respect to Rating Scales'
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: 167e1359943b96b9e92ee73db1df69a1f65d731d
  title: 'A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization
    Based on Minimum Cuts'
- pid: d14c7e5f5cace4c925abc74c88baa474e9f31a28
  title: Gated Feedback Recurrent Neural Networks
- pid: 1cff7cc15555c38607016aaba24059e76b160adb
  title: Annotating Expressions of Opinions and Emotions in Language
- pid: cdcf7cb29f37ac0546961ea8a076075b9cc1f992
  title: Mining and summarizing customer reviews
slug: An-efficient-framework-for-learning-sentence-Logeswaran-Lee
title: An efficient framework for learning sentence representations
url: https://www.semanticscholar.org/paper/An-efficient-framework-for-learning-sentence-Logeswaran-Lee/bc1d609520290e0460c49b685675eb5a57fa5935?sort=total-citations
venue: ICLR
year: 2018
