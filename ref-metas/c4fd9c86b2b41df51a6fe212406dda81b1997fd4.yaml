authors:
- Tomas Mikolov
- Wen-tau Yih
- G. Zweig
badges:
- id: OPEN_ACCESS
corpusId: 7478738
fieldsOfStudy:
- Computer Science
numCitedBy: 3051
numCiting: 24
paperAbstract: "Continuous space language models have recently demonstrated outstanding\
  \ results across a variety of tasks. In this paper, we examine the vector-space\
  \ word representations that are implicitly learned by the input-layer weights. We\
  \ find that these representations are surprisingly good at capturing syntactic and\
  \ semantic regularities in language, and that each relationship is characterized\
  \ by a relation-specific vector offset. This allows vector-oriented reasoning based\
  \ on the offsets between words. For example, the male/female relationship is automatically\
  \ learned, and with the induced vector representations, \u201CKing Man + Woman\u201D\
  \ results in a vector very close to \u201CQueen.\u201D We demonstrate that the word\
  \ vectors capture syntactic regularities by means of syntactic analogy questions\
  \ (provided with this paper), and are able to correctly answer almost 40% of the\
  \ questions. We demonstrate that the word vectors capture semantic regularities\
  \ by using the vector offset method to answer SemEval-2012 Task 2 questions. Remarkably,\
  \ this method outperforms the best previous systems."
ref_count: 24
references:
- pid: 6c2b28f9354f667cd5bd07afc0471d8334430da7
  title: A Neural Probabilistic Language Model
- pid: 5eb1a272f9933a11d113cf63fe659e073942bce5
  title: Neural Probabilistic Language Models
- pid: 330da625c15427c6e42ccfa3b747fb29e5835bf0
  title: Efficient Estimation of Word Representations in Vector Space
- pid: f2f72cfb48d15d4d2bd1e91a92e7f3ac8635d433
  title: Joint Learning of Words and Meaning Representations for Open-Text Semantic
    Parsing
- pid: 0fcc184b3b90405ec3ceafd6a4007c749df7c363
  title: Continuous space language models
- pid: dac72f2c509aee67524d3321f77e97e8eff51de6
  title: 'Word Representations: A Simple and General Method for Semi-Supervised Learning'
- pid: 605d738a39df3c5e596613ab0ca6925f0eecdf35
  title: Distributed representations, simple recurrent networks, and grammatical structure
- pid: 3aaa1e4974800767fcbd2c24c2f2af42bf412f97
  title: Structured Output Layer neural network language model
- pid: c19fbefdeead6a4154a22a9c8551a18b1530033a
  title: Hierarchical Probabilistic Neural Network Language Model
- pid: 57458bc1cffe5caa45a885af986d70f723f406b4
  title: 'A unified architecture for natural language processing: deep neural networks
    with multitask learning'
- pid: a9fc84f8abe740cdc7ee82e69444d1d00dbe0ceb
  title: A Scalable Hierarchical Distributed Language Model
- pid: 6a835df43fdc2f79126319f6fa033bb42147c6f6
  title: Recursive Distributed Representations
- pid: 0b44fcbeea9415d400c5f5789d6b892b6f98daff
  title: 'Building a Large Annotated Corpus of English: The Penn Treebank'
- pid: cb45e9217fe323fbc199d820e7735488fca2a9b3
  title: Strategies for training large scale neural network language models
- pid: 9819b600a828a57e1cde047bbe710d3446b30da5
  title: Recurrent neural network based language model
- pid: 20a80a7356859daa4170fb4da6b87b84adbb547f
  title: Indexing by Latent Semantic Analysis
- pid: 46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e
  title: Reducing the Dimensionality of Data with Neural Networks
- pid: 4ade4934db522fe6d634ff6f48887da46eedb4d1
  title: Learning distributed representations of concepts.
slug: Linguistic-Regularities-in-Continuous-Space-Word-Mikolov-Yih
title: Linguistic Regularities in Continuous Space Word Representations
url: https://www.semanticscholar.org/paper/Linguistic-Regularities-in-Continuous-Space-Word-Mikolov-Yih/c4fd9c86b2b41df51a6fe212406dda81b1997fd4?sort=total-citations
venue: NAACL
year: 2013
