authors:
- Licheng Yu
- Eunbyung Park
- A. Berg
- Tamara L. Berg
badges:
- id: OPEN_ACCESS
corpusId: 15431370
fieldsOfStudy:
- Computer Science
numCitedBy: 82
numCiting: 37
paperAbstract: 'In this paper, we introduce a new dataset consisting of 360,001 focused
  natural language descriptions for 10,738 images. This dataset, the Visual Madlibs
  dataset, is collected using automatically produced fill-in-the-blank templates designed
  to gather targeted descriptions about: people and objects, their appearances, activities,
  and interactions, as well as inferences about the general scene or its broader context.
  We provide several analyses of the Visual Madlibs dataset and demonstrate its applicability
  to two new description generation tasks: focused description generation, and multiple-choice
  question-answering for images. Experiments using joint-embedding and deep learning
  methods show promising results on these tasks.'
ref_count: 37
references:
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: f4af49a1ead3c81cc5d023878cb67c5646dd8a04
  title: Learning a Recurrent Visual Representation for Image Caption Generation
- pid: 123b9de009865472c660192f8072493a48352dc2
  title: Phrase-based Image Captioning
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: 43795b7bac3d921c4e579964b54187bdbf6c6330
  title: Translating Videos to Natural Language Using Deep Recurrent Neural Networks
- pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  title: 'Im2Text: Describing Images Using 1 Million Captioned Photographs'
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: eaaed23a2d94feb2f1c3ff22a25777c7a78f3141
  title: 'Every Picture Tells a Story: Generating Sentences from Images'
- pid: 2a0d0f6c5a69b264710df0230696f47c5918e2f2
  title: Collective Generation of Natural Image Descriptions
- pid: 76a1dca3a9c2b0229c1b12c95752dcf40dc95a11
  title: Corpus-Guided Sentence Generation of Natural Images
- pid: 2f4df08d9072fc2ac181b7fced6a245315ce05c8
  title: Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation
- pid: 3b9f8101c61b415f946625b69f69fc9e3d0d6fc4
  title: Generating Natural-Language Video Descriptions Using Text-Mined Knowledge
- pid: 2e36ea91a3c8fbff92be2989325531b4002e2afc
  title: Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd
  title: 'Don''t just listen, use your imagination: Leveraging visual common sense
    for non-visual tasks'
- pid: 5ce04063ecf83a6584813e1a09fb3d81642e5790
  title: Understanding and predicting importance in images
- pid: 9d896605fbf93315b68d4ee03be0770077f84e40
  title: 'Baby Talk : Understanding and Generating Image Descriptions'
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: a583af2696030bcf5f556edc74573fbee902be0b
  title: Weakly Supervised Memory Networks
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: bf60322f83714523e2d7c1d39983151fe9db7146
  title: "Collecting Image Annotations Using Amazon\u2019s Mechanical Turk"
- pid: 355de7460120ddc1150d9ce3756f9848983f7ff4
  title: 'Midge: Generating Image Descriptions From Computer Vision Detections'
- pid: e8dbc756ea246f599250c09e3efd9bba9909a842
  title: Generating Image Descriptions Using Dependency Relational Patterns
- pid: 050da5d159fb0dd96143948e1cffeb3dec814673
  title: Visual Turing test for computer vision systems
- pid: 7fceccc7a1046caa4936b14eeacb71ccf4d6be10
  title: A Multi-View Embedding Space for Modeling Internet Images, Tags, and Their
    Semantics
- pid: 4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e
  title: End-To-End Memory Networks
- pid: 44040913380206991b1991daf1192942e038fe31
  title: 'From image descriptions to visual denotations: New similarity metrics for
    semantic inference over event descriptions'
- pid: bc1022b031dc6c7019696492e8116598097a8c12
  title: Natural Language Processing (Almost) from Scratch
- pid: 33261d252218007147a71e40f8367ed152fa2fe0
  title: Question Answering with Subgraph Embeddings
- pid: 330da625c15427c6e42ccfa3b747fb29e5835bf0
  title: Efficient Estimation of Word Representations in Vector Space
- pid: 3cc228402f31ca749112197720b9ef6af0c16790
  title: Generating Typed Dependency Parses from Phrase Structure Parses
- pid: 10d85561e4aafc516d10064f30dff05b41f70afe
  title: '[Et al].'
slug: Visual-Madlibs:-Fill-in-the-blank-Image-Generation-Yu-Park
title: 'Visual Madlibs: Fill in the blank Image Generation and Question Answering'
url: https://www.semanticscholar.org/paper/Visual-Madlibs:-Fill-in-the-blank-Image-Generation-Yu-Park/a58a582b95a07932cb248f1b739e4ad739ead6b9?sort=total-citations
venue: ArXiv
year: 2015
