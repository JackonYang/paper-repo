authors:
- M. Gherrity
badges: []
corpusId: 28051649
fieldsOfStudy:
- Computer Science
numCitedBy: 78
numCiting: 4
paperAbstract: A learning algorithm for recurrent neural networks is derived. This
  algorithm allows a network to learn specified trajectories in state space in response
  to various input sequences. The network dynamics are described by a system of coupled
  differential equations that specify the continuous change of the unit activities
  and weights over time. The algorithm is nonlocal, in that a change in the connection
  weight between two units may depend on the values for some of the weights between
  different units. However, the operation of a learned network (fixed weights) is
  local. If the network units are specified to behave like electronic amplifiers,
  then an analog implementation of the learned network is straightforward. An example
  demonstrates the use of the algorithm in a completely connected network of four
  units. The network creates a limit cycle attractor in order to perform the specified
  task.<<ETX>>
ref_count: 4
references:
- pid: ce9a21b93ba29d4145a8ef6bf401e77f261848de
  title: A Learning Algorithm for Continually Running Fully Recurrent Neural Networks
- pid: 24b9eebe49cf7e00cf50cf7b7d9243386a23fe7c
  title: Neurons with graded response have collective computational properties like
    those of two-state neurons.
slug: A-learning-algorithm-for-analog,-fully-recurrent-Gherrity
title: A learning algorithm for analog, fully recurrent neural networks
url: https://www.semanticscholar.org/paper/A-learning-algorithm-for-analog,-fully-recurrent-Gherrity/006c42929dcd480490fdb367fd7478b2956dbc99?sort=total-citations
venue: International 1989 Joint Conference on Neural Networks
year: 1989
