authors:
- A. Graves
badges:
- id: OPEN_ACCESS
corpusId: 14885866
fieldsOfStudy:
- Computer Science
numCitedBy: 1074
numCiting: 29
paperAbstract: Variational methods have been previously explored as a tractable approximation
  to Bayesian inference for neural networks. However the approaches proposed so far
  have only been applicable to a few simple network architectures. This paper introduces
  an easy-to-implement stochastic variational method (or equivalently, minimum description
  length loss function) that can be applied to most neural networks. Along the way
  it revisits several common regularisers from a variational perspective. It also
  provides a simple pruning heuristic that can both drastically reduce the number
  of network weights and lead to improved generalisation. Experimental results are
  provided for a hierarchical multidimensional recurrent neural network applied to
  the TIMIT speech corpus.
ref_count: 29
references:
- pid: 3ce9da2d2182a2fbc4b460bdb56d3c34110b3e39
  title: Probable networks and plausible predictions - a review of practical Bayesian
    methods for supervised neural networks
- pid: de75e4e15e22d4376300e5c968e2db44be29ac9e
  title: Simplifying Neural Networks by Soft Weight-Sharing
- pid: 052b1d8ce63b07fec3de9dbb583772d860b7c769
  title: Learning representations by back-propagating errors
- pid: 25c9f33aceac6dcff357727cbe2faf145b01d13c
  title: Keeping the neural networks simple by minimizing the description length of
    the weights
- pid: 030a977bf32e81fb694117d78ac84a3fbe2a1d81
  title: 'An analysis of noise in recurrent neural networks: convergence and generalization'
- pid: e7297db245c3feb1897720b173a59fe7e36babb7
  title: Optimal Brain Damage
- pid: 4a42b2104ca8ff891ae77c40a915d4c94c8f8428
  title: Experiments on Learning by Back Propagation.
- pid: 90b63e917d5737b06357d50aa729619e933d9614
  title: Phone Recognition with the Mean-Covariance Restricted Boltzmann Machine
- pid: 96494e722f58705fa20302fe6179d483f52705b4
  title: 'Connectionist temporal classification: labelling unsegmented sequence data
    with recurrent neural networks'
- pid: 916ceefae4b11dadc3ee754ce590381c568c90de
  title: 'A direct adaptive method for faster backpropagation learning: the RPROP
    algorithm'
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: c08d0525bd42fa1c24f9f5df72f4c8fcf7063b22
  title: Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks
- pid: 3034afcd45fc190ed71982828b77f6e4154bdc5c
  title: Speaker-independent phone recognition using hidden Markov models
- pid: 4f7476037408ac3d993f5088544aab427bc319c1
  title: 'Information processing in dynamical systems: foundations of harmony theory'
- pid: d382b9c11e5c6a8e173fbeb442545e3be8d3e3a5
  title: Modeling By Shortest Data Description*
- pid: 6d12a1d23b21a9b170118a56386552bc5d4727de
  title: A Mathematical Theory of Communication
- pid: 629cc74dcaf655feea40f64cd74617ac884ed0f8
  title: Graphical Models for Machine Learning and Digital Communication
- pid: fd23c9168418324e81881365f297fb6a1caa3a07
  title: Arithmetic coding for data compression
slug: Practical-Variational-Inference-for-Neural-Networks-Graves
title: Practical Variational Inference for Neural Networks
url: https://www.semanticscholar.org/paper/Practical-Variational-Inference-for-Neural-Networks-Graves/5a9ef216bf11f222438fff130c778267d39a9564?sort=total-citations
venue: NIPS
year: 2011
