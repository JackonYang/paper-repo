authors:
- William Chan
- Navdeep Jaitly
- Quoc V. Le
- Oriol Vinyals
badges:
- id: OPEN_ACCESS
corpusId: 14177763
fieldsOfStudy:
- Computer Science
numCitedBy: 365
numCiting: 51
paperAbstract: 'We present Listen, Attend and Spell (LAS), a neural network that learns
  to transcribe speech utterances to characters. Unlike traditional DNN-HMM models,
  this model learns all the components of a speech recognizer jointly. Our system
  has two components: a listener and a speller. The listener is a pyramidal recurrent
  network encoder that accepts filter bank spectra as inputs. The speller is an attention-based
  recurrent network decoder that emits characters as outputs. The network produces
  character sequences without making any independence assumptions between the characters.
  This is the key improvement of LAS over previous end-to-end CTC models. On a subset
  of the Google voice search task, LAS achieves a word error rate (WER) of 14.1% without
  a dictionary or a language model, and 10.3% with language model rescoring over the
  top 32 beams. By comparison, the state-of-the-art CLDNN-HMM model achieves a WER
  of 8.0%.'
ref_count: 51
references:
- pid: b624504240fa52ab76167acfe3156150ca01cf3b
  title: Attention-Based Models for Speech Recognition
- pid: 0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f
  title: Towards End-To-End Speech Recognition with Recurrent Neural Networks
- pid: 1149888d75af4ed5dffc25731b875651c3ccdeb2
  title: Hybrid speech recognition with Deep Bidirectional LSTM
- pid: 24741d280869ad9c60321f5ab6e5f01b7852507d
  title: 'Deep Speech: Scaling up end-to-end speech recognition'
- pid: a4eb9f4fad5c5a1935c6d0532e2c765ee29b0b37
  title: Application of Pretrained Deep Neural Networks to Large Vocabulary Speech
    Recognition
- pid: 47d2dc34e1d02a8109f5c04bb6939725de23716d
  title: 'End-to-end Continuous Speech Recognition using Attention-based Recurrent
    NN: First Results'
- pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
- pid: 9819b600a828a57e1cde047bbe710d3446b30da5
  title: Recurrent neural network based language model
- pid: f37cfdc4520c56c1eaf87cee5ec2a4028ceaa9c5
  title: Deep Belief Networks for phone recognition
- pid: 85315b64a4c73cb86f156ef5b0a085d6ebc8a65d
  title: A Neural Conversational Model
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 5522764282c85aea422f1c4dc92ff7e0ca6987bc
  title: A Clockwork RNN
- pid: 7b4f3d0e4e2486a8d5d3f8e00549cf9a117bf88f
  title: Sequence Transduction with Recurrent Neural Networks
- pid: 0b544dfe355a5070b60986319a3f51fb45d1348e
  title: "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical\
    \ Machine Translation"
- pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
- pid: 3a1a2cff2b70fb84a7ca7d97f8adcc5855851795
  title: The Kaldi Speech Recognition Toolkit
- pid: 96494e722f58705fa20302fe6179d483f52705b4
  title: 'Connectionist temporal classification: labelling unsegmented sequence data
    with recurrent neural networks'
- pid: 1956c239b3552e030db1b78951f64781101125ed
  title: Addressing the Rare Word Problem in Neural Machine Translation
- pid: cd0568b4faa03910ae3c07d00c627666f404305d
  title: Continuous speech recognition using multilayer perceptrons with hidden Markov
    models
- pid: df137487e20ba7c6e1e2b9a1e749f2a578b5ad99
  title: Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks
- pid: d2b62f77cb2864e465aa60bca6c26bb1d2f84963
  title: Acoustic Modeling Using Deep Belief Networks
- pid: 1938624bb9b0f999536dcc8d8f519810bb4e1b3b
  title: On Using Very Large Target Vocabulary for Neural Machine Translation
- pid: b13813b49f160e1a2010c44bd4fb3d09a28446e3
  title: Hierarchical Recurrent Neural Networks for Long-Term Dependencies
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 47570e7f63e296f224a0e7f9a0d08b0de3cbaf40
  title: Grammar as a Foreign Language
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: 87f40e6f3022adbc1f1905e3e506abad05a9964f
  title: Distributed Representations of Words and Phrases and their Compositionality
- pid: 3127190433230b3dc1abd0680bb58dced4bcd90e
  title: Large Scale Distributed Deep Networks
- pid: f4ba954b0412773d047dc41231c733de0c1f4926
  title: 'Conditional Random Fields: Probabilistic Models for Segmenting and Labeling
    Sequence Data'
- pid: 603bdbb17ba1f909280405a076455ac4f878fbf3
  title: Statistical Inference for Probabilistic Functions of Finite State Markov
    Chains
slug: Listen,-Attend-and-Spell-Chan-Jaitly
title: Listen, Attend and Spell
url: https://www.semanticscholar.org/paper/Listen,-Attend-and-Spell-Chan-Jaitly/dc555e8156c956f823587ebbff018863e6d2a95e?sort=total-citations
venue: ArXiv
year: 2015
