authors:
- Chen Zhu
- Yanpeng Zhao
- Shuaiyi Huang
- Kewei Tu
- Yi Ma
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 11117517
fieldsOfStudy:
- Computer Science
numCitedBy: 86
numCiting: 43
paperAbstract: Visual attention, which assigns weights to image regions according
  to their relevance to a question, is considered as an indispensable part by most
  Visual Question Answering models. Although the questions may involve complex rela-
  tions among multiple regions, few attention models can ef- fectively encode such
  cross-region relations. In this paper, we demonstrate the importance of encoding
  such relations by showing the limited effective receptive field of ResNet on two
  datasets, and propose to model the visual attention as a multivariate distribution
  over a grid-structured Con- ditional Random Field on image regions. We demonstrate
  how to convert the iterative inference algorithms, Mean Field and Loopy Belief Propagation,
  as recurrent layers of an end-to-end neural network. We empirically evalu- ated
  our model on 3 datasets, in which it surpasses the best baseline model of the newly
  released CLEVR dataset [13] by 9.5%, and the best published model on the VQA dataset
  [3] by 1.25%. Source code is available at https://github.com/zhuchen03/vqa-sva.
ref_count: 43
references:
- pid: fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b
  title: Hierarchical Question-Image Co-Attention for Visual Question Answering
- pid: 1cf6bc0866226c1f8e282463adc8b75d92fba9bb
  title: 'Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for
    Visual Question Answering'
- pid: 7214daf035ab005b3d1e739750dd597b4f4513fa
  title: A Focused Dynamic Attention Model for Visual Question Answering
- pid: b58e08741fb9803fa2a870eee139137d3bade332
  title: Training Recurrent Answering Units with Joint Loss Minimization for VQA
- pid: 20dbdf02497aa84510970d0f5e8b599073bca1bc
  title: 'Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge
    from External Sources'
- pid: 58cb0c24c936b8a14ca7b2d56ba80de733c545b3
  title: 'Human Attention in Visual Question Answering: Do Humans and Deep Networks
    look at the same regions?'
- pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  title: Stacked Attention Networks for Image Question Answering
- pid: fddc15480d086629b960be5bff96232f967f2252
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
- pid: f96898d15a1bf1fa8925b1280d0e07a7a8e72194
  title: Dynamic Memory Networks for Visual and Textual Question Answering
- pid: 6d92ce1c4f7f0ccfe068e663903e4dd614a15ede
  title: 'Visual question answering: Datasets, algorithms, and future challenges'
- pid: 21c99706bb26e9012bfb4d8d48009a3d45af59b2
  title: Neural Module Networks
- pid: ebe5081b8a24b4740db929b6eae75f28f8edbc58
  title: Answer-Type Prediction for Visual Question Answering
- pid: f651593fa6c83d717fc961482696a53b6fca5ab5
  title: Dual Attention Networks for Multimodal Reasoning and Matching
- pid: 175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22
  title: 'Where to Look: Focus Regions for Visual Question Answering'
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: 1afb710a5b35a2352a6495e4bf6eef66808daf1b
  title: Multimodal Residual Learning for Visual QA
- pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: ca5c766b2d31a1f5ce8896a0a42b40a2bff9323a
  title: Conditional Random Fields as Recurrent Neural Networks
- pid: 21da448e7c31e1ff6cc3b7155a9c9c49a0138060
  title: Deep Structured Output Learning for Unconstrained Text Recognition
- pid: 6e795c6e9916174ae12349f5dc3f516570c17ce8
  title: Skip-Thought Vectors
- pid: 75ddc7ee15be14013a3462c01b38b0548486fbcb
  title: Learning to Compose Neural Networks for Question Answering
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: 916ad37eb897b3858141874e290e20eae5076f5b
  title: Structured Learning and Prediction in Computer Vision
- pid: c66758c1029a463489f26aeb3955f333b37f727a
  title: Learning Deep Structured Models
- pid: 03eb382e04cca8cca743f7799070869954f1402a
  title: 'CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual
    Reasoning'
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: 2935d8071583e46c5a895730c65d2bd213757c07
  title: Joint Video and Text Parsing for Understanding Events and Answering Queries
- pid: 34f25a8704614163c4095b3ee2fc969b60de4698
  title: 'Dropout: a simple way to prevent neural networks from overfitting'
- pid: 0c1f9ca23f4f09ecfc44bcc8ca1c2736624f4652
  title: A Theoretically Grounded Application of Dropout in Recurrent Neural Networks
- pid: b183947ee15718b45546eda6b01e179b9a95421f
  title: 'Edge Boxes: Locating Object Proposals from Edges'
- pid: 62df84d6a4d26f95e4714796c2337c9848cc13b5
  title: 'MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous
    Distributed Systems'
slug: Structured-Attentions-for-Visual-Question-Answering-Zhu-Zhao
title: Structured Attentions for Visual Question Answering
url: https://www.semanticscholar.org/paper/Structured-Attentions-for-Visual-Question-Answering-Zhu-Zhao/5823d18cd378898b12de537862d996443ce9c9e8?sort=total-citations
venue: 2017 IEEE International Conference on Computer Vision (ICCV)
year: 2017
