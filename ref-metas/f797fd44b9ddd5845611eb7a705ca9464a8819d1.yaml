authors:
- Holger Schwenk
- "Lo\xEFc Barrault"
- A. Conneau
- Yann LeCun
badges:
- id: OPEN_ACCESS
corpusId: 5079983
fieldsOfStudy:
- Computer Science
numCitedBy: 729
numCiting: 30
paperAbstract: 'The dominant approach for many NLP tasks are recurrent neural networks,
  in particular LSTMs, and convolutional neural networks. However, these architectures
  are rather shallow in comparison to the deep convolutional networks which have pushed
  the state-of-the-art in computer vision. We present a new architecture (VDCNN) for
  text processing which operates directly at the character level and uses only small
  convolutions and pooling operations. We are able to show that the performance of
  this model increases with the depth: using up to 29 convolutional layers, we report
  improvements over the state-of-the-art on several public text classification tasks.
  To the best of our knowledge, this is the first time that very deep convolutional
  nets have been applied to text processing.'
ref_count: 30
references:
- pid: 51a55df1f023571a7e07e338ee45a3e3d66ef73e
  title: Character-level Convolutional Networks for Text Classification
- pid: 27725a2d2a8cee9bf9fffc6c2167017103aba0fa
  title: A Convolutional Neural Network for Modelling Sentences
- pid: eb42cf88027de515750f230b23b1a057dc782108
  title: Very Deep Convolutional Networks for Large-Scale Image Recognition
- pid: 1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba
  title: Convolutional Neural Networks for Sentence Classification
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: f9a1b3850dfd837793743565a8af95973d395a4e
  title: LSTM Neural Networks for Language Modeling
- pid: 57458bc1cffe5caa45a885af986d70f723f406b4
  title: 'A unified architecture for natural language processing: deep neural networks
    with multitask learning'
- pid: 1a9658c0b7bea22075c0ea3c229b8c70c1790153
  title: Recurrent Convolutional Neural Networks for Scene Labeling
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
- pid: bc1022b031dc6c7019696492e8116598097a8c12
  title: Natural Language Processing (Almost) from Scratch
- pid: d6f2f611da110b5b5061731be3fc4c7f45d8ee23
  title: 'Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet
    Classification'
- pid: 1a2a770d23b4a171fa81de62a78a3deb0588f238
  title: Visualizing and Understanding Convolutional Networks
- pid: 162d958ff885f1462aeda91cd72582323fd6a1f4
  title: Gradient-based learning applied to document recognition
- pid: 4d376d6978dad0374edfa6709c9556b42d3594d3
  title: 'Batch Normalization: Accelerating Deep Network Training by Reducing Internal
    Covariate Shift'
- pid: cfa2646776405d50533055ceb1b7f050e9014dcb
  title: Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions
- pid: 455afd748e8834ef521e4b67c7c056d3c33429e2
  title: Hierarchical Attention Networks for Document Classification
- pid: 77f0a39b8e02686fd85b01971f8feb7f60971f80
  title: Identity Mappings in Deep Residual Networks
- pid: 944a1cfd79dbfb6fef460360a0765ba790f4027a
  title: Recurrent Continuous Translation Models
- pid: 1af68821518f03568f913ab03fc02080247a27ff
  title: Neural Machine Translation of Rare Words with Subword Units
- pid: 6c2b28f9354f667cd5bd07afc0471d8334430da7
  title: A Neural Probabilistic Language Model
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: bcae70dce393c1796d4f15c7b8bbf0ed6f468be1
  title: Distinctive Image Features from Scale-Invariant Keypoints
- pid: 4cab9c4b571761203ed4c3a4c5a07dd615f57a91
  title: Distinctive Image Features from Scale-Invariant Keypoints
slug: Very-Deep-Convolutional-Networks-for-Text-Schwenk-Barrault
title: Very Deep Convolutional Networks for Text Classification
url: https://www.semanticscholar.org/paper/Very-Deep-Convolutional-Networks-for-Text-Schwenk-Barrault/f797fd44b9ddd5845611eb7a705ca9464a8819d1?sort=total-citations
venue: EACL
year: 2017
