authors:
- D. Wolpert
badges:
- id: OPEN_ACCESS
corpusId: 7748868
fieldsOfStudy:
- Computer Science
numCitedBy: 48
numCiting: 20
paperAbstract: The Bayesian "evidence" approximation has recently been employed to
  determine the noise and weight-penalty terms used in back-propagation. This paper
  shows that for neural nets it is far easier to use the exact result than it is to
  use the evidence approximation. Moreover, unlike the evidence approximation, the
  exact result neither has to be re-calculated for every new data set, nor requires
  the running of computer code (the exact result is closed form). In addition, it
  turns out that the evidence procedure's MAP estimate for neural nets is, in toto,
  approximation error. Another advantage of the exact analysis is that it does not
  lead one to incorrect intuition, like the claim that using evidence one can "evaluate
  different priors in light of the data". This paper also discusses sufficiency conditions
  for the evidence approximation to hold, why it can sometimes give "reasonable" results,
  etc.
ref_count: 20
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 3960
  pid: 8e68c54f39e87daf3a8bdc0ee005aece3c652d11
  title: Bayesian Interpolation
  year: 1992
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2590
  pid: b959164d1efca4b73986ba5d21e664aadbbc0457
  title: A Practical Bayesian Framework for Backpropagation Networks
  year: 1992
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 376
  pid: c83684f6207697c12850db423fd9747572cf1784
  title: Bayesian Back-Propagation
  year: 1991
- fieldsOfStudy:
  - Mathematics
  numCitedBy: 316
  pid: 82fa37d5be8e747131a5857992cc33bb95469ce3
  title: Developments in Maximum Entropy Data Analysis
  year: 1989
slug: On-the-Use-of-Evidence-in-Neural-Networks-Wolpert
title: On the Use of Evidence in Neural Networks
url: https://www.semanticscholar.org/paper/On-the-Use-of-Evidence-in-Neural-Networks-Wolpert/3d565fb42892f20c52b9fc615cc537835f30d094?sort=total-citations
venue: NIPS
year: 1992
