authors:
- Andrew M. Saxe
- James L. McClelland
- S. Ganguli
badges:
- id: OPEN_ACCESS
corpusId: 17272965
fieldsOfStudy:
- Computer Science
meta_key: exact-solutions-to-the-nonlinear-dynamics-of-learning-in-deep-linear-neural-networks
numCitedBy: 1265
numCiting: 27
paperAbstract: 'Despite the widespread practical success of deep learning methods,
  our theoretical understanding of the dynamics of learning in deep neural networks
  remains quite sparse. We attempt to bridge the gap between the theory and practice
  of deep learning by systematically analyzing learning dynamics for the restricted
  case of deep linear neural networks. Despite the linearity of their input-output
  map, such networks have nonlinear gradient descent dynamics on weights that change
  with the addition of each new hidden layer. We show that deep linear networks exhibit
  nonlinear learning phenomena similar to those seen in simulations of nonlinear networks,
  including long plateaus followed by rapid transitions to lower error solutions,
  and faster convergence from greedy unsupervised pretraining initial conditions than
  from random initial conditions. We provide an analytical description of these phenomena
  by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical
  analysis also reveals the surprising finding that as the depth of a network approaches
  infinity, learning speed can nevertheless remain finite: for a special class of
  initial conditions on the weights, very deep networks incur only a finite, depth
  independent, delay in learning speed relative to shallow networks. We show that,
  under certain conditions on the training data, unsupervised pretraining can find
  this special class of initial conditions, while scaled random Gaussian initializations
  cannot. We further exhibit a new class of random orthogonal initial conditions on
  weights that, like unsupervised pre-training, enjoys depth independent learning
  times. We further show that these initial conditions also lead to faithful propagation
  of gradients even in deep nonlinear networks, as long as they operate in a special
  regime known as the edge of chaos.'
ref_count: 27
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: understanding-the-difficulty-of-training-deep-feedforward-neural-networks
  numCitedBy: 12426
  pid: b71ac1e9fb49420d13e084ac67254a0bbd40f83f
  show_ref_link: true
  title: Understanding the difficulty of training deep feedforward neural networks
  year: 2010
- fieldsOfStudy:
  - Computer Science
  meta_key: greedy-layer-wise-training-of-deep-networks
  numCitedBy: 3427
  pid: 355d44f53428b1ac4fb2ab468d593c720640e5bd
  show_ref_link: true
  title: Greedy Layer-Wise Training of Deep Networks
  year: 2006
- fieldsOfStudy:
  - Computer Science
  meta_key: on-the-importance-of-initialization-and-momentum-in-deep-learning
  numCitedBy: 3555
  pid: aa7bfd2304201afbb19971ebde87b17e40242e91
  show_ref_link: true
  title: On the importance of initialization and momentum in deep learning
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-hierarchical-category-structure-in-deep-neural-networks
  numCitedBy: 47
  pid: 4c9934b49ed65407b848c490d2156f08d6998945
  show_ref_link: false
  title: Learning hierarchical category structure in deep neural networks
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: the-difficulty-of-training-deep-architectures-and-the-effect-of-unsupervised-pre-training
  numCitedBy: 395
  pid: ccf415df5a83b343dae261286d29a40e8b80e6c6
  show_ref_link: false
  title: The Difficulty of Training Deep Architectures and the Effect of Unsupervised
    Pre-Training
  year: 2009
- fieldsOfStudy:
  - Computer Science
  meta_key: why-does-unsupervised-pre-training-help-deep-learning
  numCitedBy: 1724
  pid: 0d2336389dff3031910bd21dd1c44d1b4cd51725
  show_ref_link: false
  title: Why Does Unsupervised Pre-training Help Deep Learning?
  year: 2010
- fieldsOfStudy:
  - Computer Science
  meta_key: neural-networks-tricks-of-the-trade
  numCitedBy: 1302
  pid: b1a5961609c623fc816aaa77565ba38b25531a8e
  show_ref_link: false
  title: 'Neural Networks: Tricks of the Trade'
  year: 2002
- fieldsOfStudy:
  - Computer Science
  meta_key: neural-networks-and-principal-component-analysis-learning-from-examples-without-local-minima
  numCitedBy: 1336
  pid: 9552ac39a57daacf3d75865a268935b5a0df9bbb
  show_ref_link: false
  title: 'Neural networks and principal component analysis: Learning from examples
    without local minima'
  year: 1989
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-deep-architectures-for-ai
  numCitedBy: 7558
  pid: e60ff004dde5c13ec53087872cfcdd12e85beb57
  show_ref_link: true
  title: Learning Deep Architectures for AI
  year: 2007
- fieldsOfStudy:
  - Computer Science
  meta_key: effect-of-batch-learning-in-multilayer-neural-networks
  numCitedBy: 19
  pid: 9505f8c9e320fc51417ea5acbe6fad5afdcb37ec
  show_ref_link: false
  title: Effect of Batch Learning in Multilayer Neural Networks
  year: 1998
- fieldsOfStudy:
  - Computer Science
  meta_key: on-the-difficulty-of-training-recurrent-neural-networks
  numCitedBy: 3800
  pid: 84069287da0a6b488b8c933f3cb5be759cb6237e
  show_ref_link: true
  title: On the difficulty of training recurrent neural networks
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: scaling-learning-algorithms-towards-ai
  numCitedBy: 1116
  pid: 6fdb77260fc83dff91c44fea0f31a2cb8ed13d04
  show_ref_link: false
  title: Scaling learning algorithms towards AI
  year: 2007
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-long-term-dependencies-with-gradient-descent-is-difficult
  numCitedBy: 6142
  pid: d0be39ee052d246ae99c082a565aba25b811be2d
  show_ref_link: false
  title: Learning long-term dependencies with gradient descent is difficult
  year: 1994
- fieldsOfStudy:
  - Computer Science
  meta_key: reducing-the-dimensionality-of-data-with-neural-networks
  numCitedBy: 14638
  pid: 46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e
  show_ref_link: true
  title: Reducing the Dimensionality of Data with Neural Networks
  year: 2006
- fieldsOfStudy:
  - Computer Science
  meta_key: imagenet-classification-with-deep-convolutional-neural-networks
  numCitedBy: 80897
  pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  show_ref_link: true
  title: ImageNet classification with deep convolutional neural networks
  year: 2012
- fieldsOfStudy:
  - Computer Science
  meta_key: big-neural-networks-waste-capacity
  numCitedBy: 68
  pid: 306c7cd74beda5a09662b5f289bba50a2b5ea308
  show_ref_link: false
  title: Big Neural Networks Waste Capacity
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: acoustic-modeling-using-deep-belief-networks
  numCitedBy: 1641
  pid: d2b62f77cb2864e465aa60bca6c26bb1d2f84963
  show_ref_link: true
  title: Acoustic Modeling Using Deep Belief Networks
  year: 2012
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-learning-via-hessian-free-optimization
  numCitedBy: 844
  pid: 4c46347fbc272b21468efe3d9af34b4b2bad6684
  show_ref_link: false
  title: Deep learning via Hessian-free optimization
  year: 2010
- fieldsOfStudy:
  - Computer Science
  meta_key: building-high-level-features-using-large-scale-unsupervised-learning
  numCitedBy: 2100
  pid: 72e93aa6767ee683de7f001fa72f1314e40a8f35
  show_ref_link: true
  title: Building high-level features using large scale unsupervised learning
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: multi-column-deep-neural-networks-for-image-classification
  numCitedBy: 3369
  pid: 398c296d0cc7f9d180f84969f8937e6d3a413796
  show_ref_link: true
  title: Multi-column deep neural networks for image classification
  year: 2012
- fieldsOfStudy:
  - Computer Science
  meta_key: a-unified-architecture-for-natural-language-processing-deep-neural-networks-with-multitask-learning
  numCitedBy: 5023
  pid: 57458bc1cffe5caa45a885af986d70f723f406b4
  show_ref_link: true
  title: 'A unified architecture for natural language processing: deep neural networks
    with multitask learning'
  year: 2008
- fieldsOfStudy:
  - Computer Science
  meta_key: parsing-with-compositional-vector-grammars
  numCitedBy: 900
  pid: acc4e56c44771ebf69302a06af51498aeb0a6ac8
  show_ref_link: false
  title: Parsing with Compositional Vector Grammars
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: improved-preconditioner-for-hessian-free-optimization
  numCitedBy: 39
  pid: b0ced8ba22674b3b948c22deb0f43df93c82f87f
  show_ref_link: false
  title: Improved Preconditioner for Hessian Free Optimization
  year: 2011
- fieldsOfStudy:
  - Computer Science
  meta_key: untersuchungen-zu-dynamischen-neuronalen-netzen
  numCitedBy: 603
  pid: 3f3d13e95c25a8f6a753e38dfce88885097cbd43
  show_ref_link: false
  title: Untersuchungen zu dynamischen neuronalen Netzen
  year: 1991
- fieldsOfStudy:
  - Computer Science
  meta_key: efficient-backprop
  numCitedBy: 2630
  pid: b87274e6d9aa4e6ba5148898aa92941617d2b6ed
  show_ref_link: true
  title: Efficient BackProp
  year: 2012
slug: Exact-solutions-to-the-nonlinear-dynamics-of-in-Saxe-McClelland
title: Exact solutions to the nonlinear dynamics of learning in deep linear neural
  networks
url: https://www.semanticscholar.org/paper/Exact-solutions-to-the-nonlinear-dynamics-of-in-Saxe-McClelland/99c970348b8f70ce23d6641e201904ea49266b6e?sort=total-citations
venue: ICLR
year: 2014
