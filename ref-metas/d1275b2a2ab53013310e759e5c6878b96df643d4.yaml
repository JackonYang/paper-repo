authors:
- Tomas Mikolov
- G. Zweig
badges:
- id: OPEN_ACCESS
corpusId: 11383176
fieldsOfStudy:
- Computer Science
numCitedBy: 548
numCiting: 42
paperAbstract: Recurrent neural network language models (RNNLMs) have recently demonstrated
  state-of-the-art performance across a variety of tasks. In this paper, we improve
  their performance by providing a contextual real-valued input vector in association
  with each word. This vector is used to convey contextual information about the sentence
  being modeled. By performing Latent Dirichlet Allocation using a block of preceding
  text, we achieve a topic-conditioned RNNLM. This approach has the key advantage
  of avoiding the data fragmentation associated with building multiple topic models
  on different data subsets. We report perplexity results on the Penn Treebank data,
  where we achieve a new state-of-the-art. We further apply the model to the Wall
  Street Journal speech recognition task, where we observe improvements in word-error-rate.
ref_count: 42
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 4902
  pid: 9819b600a828a57e1cde047bbe710d3446b30da5
  title: Recurrent neural network based language model
  year: 2010
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 157
  pid: 3aaa1e4974800767fcbd2c24c2f2af42bf412f97
  title: Structured Output Layer neural network language model
  year: 2011
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 554
  pid: 0fcc184b3b90405ec3ceafd6a4007c749df7c363
  title: Continuous space language models
  year: 2007
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1423
  pid: 07ca885cb5cc4328895bfaec9ab752d5801b14cd
  title: Extensions of recurrent neural network language model
  year: 2011
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 26
  pid: 9319ca5a532462f9f3515ac3d317668aa9650d5b
  title: Exact training of a neural syntactic language model
  year: 2004
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 575
  pid: 96364af2d208ea75ca3aeb71892d2f7ce7326b55
  title: Statistical Language Models Based on Neural Networks
  year: 2012
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 580
  pid: be1fed9544830df1137e72b1d2396c40d3e18365
  title: A Cache-Based Natural Language Model for Speech Recognition
  year: 1990
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 104
  pid: b888cae7e6e288b108f9d119fc23b84b4d447029
  title: Towards better integration of semantic predictors in statistical language
    modeling
  year: 1998
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 474
  pid: cb45e9217fe323fbc199d820e7735488fca2a9b3
  title: Strategies for training large scale neural network language models
  year: 2011
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 69
  pid: f72084efcae8b2007e590b0c5a8f1decb61ef935
  title: A whole sentence maximum entropy language model
  year: 1997
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 6011
  pid: 6c2b28f9354f667cd5bd07afc0471d8334430da7
  title: A Neural Probabilistic Language Model
  year: 2000
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 606
  pid: bd7d93193aad6c4b71cc8942e808753019e87706
  title: Three new graphical models for statistical language modelling
  year: 2007
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 6144
  pid: d0be39ee052d246ae99c082a565aba25b811be2d
  title: Learning long-term dependencies with gradient descent is difficult
  year: 1994
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 585
  pid: 0d6203718c15f137fda2f295c96269bc2b254644
  title: Learning Recurrent Neural Networks with Hessian-Free Optimization
  year: 2011
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 51704
  pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
  year: 1997
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 30947
  pid: f198043a866e9187925a8d8db9a55e3bfdd47f2c
  title: Latent Dirichlet Allocation
  year: 2003
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 314
  pid: 77dfe038a9bdab27c4505444931eaa976e9ec667
  title: Empirical Evaluation and Combination of Advanced Language Modeling Techniques
  year: 2011
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 5127
  pid: 3a1a2cff2b70fb84a7ca7d97f8adcc5855851795
  title: The Kaldi Speech Recognition Toolkit
  year: 2011
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 223
  pid: 6e58b5f825df9fb0b00465a66598f302c30b080a
  title: 'Trigger-based language models: a maximum entropy approach'
  year: 1993
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 8177
  pid: 0b44fcbeea9415d400c5f5789d6b892b6f98daff
  title: 'Building a Large Annotated Corpus of English: The Penn Treebank'
  year: 1993
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2861
  pid: d4e8bed3b50a035e1eabad614fe4218a34b3b178
  title: An empirical study of smoothing techniques for language modeling
  year: 1999
slug: Context-dependent-recurrent-neural-network-language-Mikolov-Zweig
title: Context dependent recurrent neural network language model
url: https://www.semanticscholar.org/paper/Context-dependent-recurrent-neural-network-language-Mikolov-Zweig/d1275b2a2ab53013310e759e5c6878b96df643d4?sort=total-citations
venue: 2012 IEEE Spoken Language Technology Workshop (SLT)
year: 2012
