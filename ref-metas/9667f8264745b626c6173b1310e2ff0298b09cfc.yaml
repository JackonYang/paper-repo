authors:
- Bolei Zhou
- "\xC0. Lapedriza"
- Jianxiong Xiao
- A. Torralba
- A. Oliva
badges:
- id: OPEN_ACCESS
corpusId: 1849990
fieldsOfStudy:
- Computer Science
numCitedBy: 2610
numCiting: 29
paperAbstract: Scene recognition is one of the hallmark tasks of computer vision,
  allowing definition of a context for object recognition. Whereas the tremendous
  recent progress in object recognition tasks is due to the availability of large
  datasets like ImageNet and the rise of Convolutional Neural Networks (CNNs) for
  learning high-level features, performance at scene recognition has not attained
  the same level of success. This may be because current deep features trained from
  ImageNet are not competitive enough for such tasks. Here, we introduce a new scene-centric
  database called Places with over 7 million labeled pictures of scenes. We propose
  new methods to compare the density and diversity of image datasets and show that
  Places is as dense as other scene datasets and has more diversity. Using CNN, we
  learn deep features for scene recognition tasks, and establish new state-of-the-art
  results on several scene-centric datasets. A visualization of the CNN layers' responses
  allows us to show differences in the internal representations of object-centric
  and scene-centric networks.
ref_count: 29
references:
- pid: 6270baedeba28001cd1b563a199335720d6e0fe0
  title: 'CNN Features Off-the-Shelf: An Astounding Baseline for Recognition'
- pid: b8de958fead0d8a9619b55c7299df3257c624a96
  title: 'DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition'
- pid: 908091b4a8757c3b2f7d9cfa2c4f616ee12c5157
  title: 'SUN database: Large-scale scene recognition from abbey to zoo'
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: c82d90336ba365c7914fe4bd6c292a8c6916a801
  title: Recognizing indoor scenes
- pid: dcbf587642c39f495117552ca453a4f955ffa76a
  title: Analyzing the Performance of Multilayer Neural Networks for Object Recognition
- pid: 6dbaff29d3898cf60f63f5a34cb9610ebb75220c
  title: 'Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural
    Scene Categories'
- pid: 0302bb2d5476540cfb21467473f5eca843caf90b
  title: Unbiased look at dataset bias
- pid: 5a5effa909cdeafaddbbb7855037e02f8e25d632
  title: Caltech-256 Object Category Dataset
- pid: ef4209ed288ef38fecdfae2409bce78633386c10
  title: What, where and who? Classifying events by scene and object recognition
- pid: d4cede3acfd94fccc927519e04384a8debfec705
  title: 'Image Classification with the Fisher Vector: Theory and Practice'
- pid: 6bdb186ec4726e00a8051119636d4df3b94043b5
  title: 'Caffe: Convolutional Architecture for Fast Feature Embedding'
- pid: add89dbbd15b82d8275d712f7f969f1b511f96fd
  title: 'SUN attribute database: Discovering, annotating, and recognizing scene attributes'
- pid: b222b3b05d8d313420dbde8b163e4336a85dcde9
  title: Mid-level Visual Element Discovery as Discriminative Mode Seeking
- pid: 1b47265245e8db53a553049dcb27ed3e495fd625
  title: 'ImageNet: A large-scale hierarchical image database'
- pid: 869171b2f56cfeaa9b81b2626cb4956fea590a57
  title: 'Modeling the Shape of the Scene: A Holistic Representation of the Spatial
    Envelope'
- pid: aedb8df8f953429ec5a6df99fda5c5d71dbee4ff
  title: 'Learning Generative Visual Models from Few Training Examples: An Incremental
    Bayesian Approach Tested on 101 Object Categories'
- pid: e60ff004dde5c13ec53087872cfcdd12e85beb57
  title: Learning Deep Architectures for AI
- pid: a8e8f3c8d4418c8d62e306538c9c1292635e9d27
  title: Backpropagation Applied to Handwritten Zip Code Recognition
- pid: 268a4f8da15a42f3e0e71691f760ff5edbf9cec8
  title: 'LIBLINEAR: A Library for Large Linear Classification'
slug: Learning-Deep-Features-for-Scene-Recognition-using-Zhou-Lapedriza
title: Learning Deep Features for Scene Recognition using Places Database
url: https://www.semanticscholar.org/paper/Learning-Deep-Features-for-Scene-Recognition-using-Zhou-Lapedriza/9667f8264745b626c6173b1310e2ff0298b09cfc?sort=total-citations
venue: NIPS
year: 2014
