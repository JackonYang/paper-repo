authors:
- M. Collins
- Terry Koo
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 405878
fieldsOfStudy:
- Computer Science
numCitedBy: 776
numCiting: 65
paperAbstract: This article considers approaches which rerank the output of an existing
  probabilistic parser. The base parser produces a set of candidate parses for each
  input sentence, with associated probabilities that define an initial ranking of
  these parses. A second model then attempts to improve upon this initial ranking,
  using additional features of the tree as evidence. The strength of our approach
  is that it allows a tree to be represented as an arbitrary set of features, without
  concerns about how these features interact or overlap and without the need to define
  a derivation or a generative model which takes these features into account. We introduce
  a new method for the reranking task, based on the boosting approach to ranking problems
  described in Freund et al. (1998). We apply the boosting method to parsing the Wall
  Street Journal treebank. The method combined the log-likelihood under a baseline
  model (that of Collins [1999]) with evidence from an additional 500,000 features
  over parse trees that were not included in the original model. The new model achieved
  89.75 F-measure, a 13 relative decrease in F-measure error over the baseline model's
  score of 88.2. The article also introduces a new algorithm for the boosting approach
  which takes advantage of the sparsity of the feature space in the parsing data.
  Experiments show significant efficiency gains for the new algorithm over the obvious
  implementation of the boosting approach. We argue that the method is an appealing
  alternative-in terms of both simplicity and efficiency-to work on feature selection
  methods within log-linear (maximum-entropy) models. Although the experiments in
  this article are on natural language parsing (NLP), the approach should be applicable
  to many other NLP problems which are naturally framed as ranking tasks, for example,
  speech recognition, machine translation, or natural language generation.
ref_count: 66
references:
- pid: 3fc44ff7f37ec5585310666c183c65e0a0bb2446
  title: Head-Driven Statistical Models for Natural Language Parsing
- pid: d0ccae6c9f33e41de9c00053aac0bc6c615c7b4a
  title: 'Towards History-based Grammars: Using Richer Models for Probabilistic Parsing'
- pid: 76d5e3fa888bee872b7adb7fa810089aa8ab1d58
  title: A Maximum-Entropy-Inspired Parser
- pid: 7f8f8f33187e20768ae0177780ac5ef78b77feca
  title: Parsing the Wall Street Journal using a Lexical-Functional Grammar and Discriminative
    Estimation Techniques
- pid: b49db3ac26d96b6c5c081dc6c2cc24da93e633f1
  title: Maximum entropy models for natural language ambiguity resolution
- pid: fe638b5610475d4524684fb2c2b7b08c119c8700
  title: 'New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete Structures,
    and the Voted Perceptron'
- pid: 2a5e619f2c5f4220438b1357e596db5b1578398d
  title: Statistical Parsing with a Context-Free Grammar and Word Statistics
- pid: 54c846ee00c6132d70429cc279e8577f63ed05e4
  title: A Linear Observed Time Statistical Parser Based on Maximum Entropy Models
- pid: 897249c93f55ef1c0d2aa1e799eb67b414c6d4a6
  title: Shallow Parsing with Conditional Random Fields
- pid: f72084efcae8b2007e590b0c5a8f1decb61ef935
  title: A whole sentence maximum entropy language model
- pid: 0ffa423a5283396c88ff3d4033d541796bd039cc
  title: Three Generative, Lexicalised Models for Statistical Parsing
- pid: 34dc22dcbdf1e09fb48691ee1fc6fe4bb8f834c3
  title: Efficiently Inducing Features of Conditional Random Fields
- pid: b951b9f78b98a186ba259027996a48e4189d37e5
  title: Inducing Features of Random Fields
- pid: 0b44fcbeea9415d400c5f5789d6b892b6f98daff
  title: 'Building a Large Annotated Corpus of English: The Penn Treebank'
- pid: 75e85c2e90b0abb17ae6445516a49ac05c1dbf0f
  title: An Efficient Boosting Algorithm for Combining Preferences
- pid: 9a9309e056272ff2076f447df8dbc536f46fc466
  title: Improved Boosting Algorithms Using Confidence-rated Predictions
- pid: e6c7adc28e20d361d5c35aa9808094b10f6a34d1
  title: Convolution Kernels for Natural Language
- pid: 61dffff2116f3543e71d536a18308fa4fc5e53c3
  title: Stochastic Attribute-Value Grammars
- pid: 39fb0b6873c58ec182357721eaed75801505a9df
  title: 'Ranking Algorithms for Named Entity Extraction: Boosting and the VotedPerceptron'
- pid: 1a6cda5c73b3da91ce4260b2b70ca5c226b39edf
  title: 'Parameter Estimation for Statistical Parsing Models: Theory and Practice
    of'
- pid: 37fadfb6d60e83e24c72d8a90da5644b39d6e8f0
  title: Discriminative Training and Maximum Entropy Models for Statistical Machine
    Translation
- pid: f4ba954b0412773d047dc41231c733de0c1f4926
  title: 'Conditional Random Fields: Probabilistic Models for Segmenting and Labeling
    Sequence Data'
- pid: b54c9359e8858842d1b1b744ac5ca573b8031dcc
  title: Logistic Regression, AdaBoost and Bregman Distances
- pid: 5a7958b418bceb48a315384568091ab1898b1640
  title: 'Discriminative Training Methods for Hidden Markov Models: Theory and Experiments
    with Perceptron Algorithms'
- pid: 6f4493eff2531536a7aeb3fc11d62c30a8f487f6
  title: 'Special Invited Paper-Additive logistic regression: A statistical view of
    boosting'
- pid: b03f43c5620bfc8993ea25dee20ce52a203ebcf7
  title: Additive models, boosting, and inference for generalized divergences
- pid: 463dbd690d912b23d29b7581fb6b253b36f50394
  title: Estimators for Stochastic "Unification-Based" Grammars
- pid: e7a07c3aaef303850e5a1fcc81bb44f6d2db6696
  title: 'BoosTexter: A Boosting-based System for Text Categorization'
- pid: 878783964ab23c97052ea82685368099d85c500d
  title: A Comparison of Algorithms for Maximum Entropy Parameter Estimation
- pid: fb486e03369a64de2d5b0df86ec0a7b55d3907db
  title: A Maximum Entropy Approach to Natural Language Processing
- pid: 0043ccb045bc7d07ea6c9b719a72a6a01df1ab0a
  title: A Gaussian Prior for Smoothing Maximum Entropy Models
- pid: 5ed4e1dbe10c0ac9fa00b30d1882cae1249a5a6a
  title: Toward Optimal Feature Selection
- pid: 70ef29e6f0ce082bb8a47fd85b9bfb7cc0f20c93
  title: Probabilistic reasoning in intelligent systems - networks of plausible inference
- pid: 4d19272112b50547614479a0c409fca66e3b05f7
  title: 'Boosting the margin: A new explanation for the effectiveness of voting methods'
- pid: 10ddb646feddc12337b5a755c72e153e37088c02
  title: A theory of the learnable
- pid: 5bf6f01402e1648b7d1e6c9200ede6cb1af30123
  title: Probabilistic reasoning in intelligent systems
- pid: f374db77b414bfdd142616434162a0aa88d5a551
  title: A maximum entropy model for parsing
- pid: 23645d7e433009061d8dd6c81f8556166f97acdd
  title: Feature-based language understanding
slug: Discriminative-Reranking-for-Natural-Language-Collins-Koo
title: Discriminative Reranking for Natural Language Parsing
url: https://www.semanticscholar.org/paper/Discriminative-Reranking-for-Natural-Language-Collins-Koo/844db702be4bc149b06b822b47247e15f5894cc3?sort=total-citations
venue: Computational Linguistics
year: 2005
