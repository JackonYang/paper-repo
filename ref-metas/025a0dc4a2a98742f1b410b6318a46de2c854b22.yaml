authors:
- Chen Sun
- Fabien Baradel
- K. Murphy
- C. Schmid
badges: []
corpusId: 203594078
fieldsOfStudy:
- Computer Science
numCitedBy: 170
numCiting: 65
paperAbstract: This paper proposes a self-supervised learning approach for video features
  that results in significantly improved performance on downstream tasks (such as
  video classification, captioning and segmentation) compared to existing methods.
  Our method extends the BERT model for text sequences to the case of sequences of
  real-valued feature vectors, by replacing the softmax loss with noise contrastive
  estimation (NCE). We also show how to learn representations from sequences of visual
  features and sequences of words derived from ASR (automatic speech recognition),
  and show that such cross-modal training (when possible) helps even more.
ref_count: 65
references:
- pid: c41a11c0e9b8b92b4faaf97749841170b760760a
  title: 'VideoBERT: A Joint Model for Video and Language Representation Learning'
- pid: 6d4e3616d0b27957c4107ae877dc0dd4504b69ab
  title: 'Shuffle and Learn: Unsupervised Learning Using Temporal Order Verification'
- pid: 67dccc9a856b60bdc4d058d83657a089b8ad4486
  title: Two-Stream Convolutional Networks for Action Recognition in Videos
- pid: ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1
  title: Generating Videos with Scene Dynamics
- pid: bd243d77076b3b8fe046bd3dc6e8a02aa9b38d62
  title: 'C3D: Generic Features for Video Analysis'
- pid: 35ed258aede3df17ee20a6635364cb5fd2461049
  title: End-to-End Dense Video Captioning with Masked Transformer
- pid: 6d4ff172c2d1820f33c0c72286d52b846ab5a216
  title: Unsupervised Learning of Visual Representations Using Videos
- pid: 2bc1c8bd00bbf7401afcb5460277840fd8bab029
  title: 'Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal
    Pre-training'
- pid: d25c65d261ea0e6a458be4c50c40ffe5bc508f77
  title: Learning Spatiotemporal Features with 3D Convolutional Networks
- pid: 93a87dfa72f22fba14ef243a62c7d0a6906dfed7
  title: Ambient Sound Provides Supervision for Visual Learning
- pid: cc0bb8f933e514dd9441e3082a34a9f129e35500
  title: 'Patch to the Future: Unsupervised Visual Prediction'
- pid: 5aec474c31a2f4b74703c6f786c0a8ff85c450da
  title: 'VisualBERT: A Simple and Performant Baseline for Vision and Language'
- pid: da9e411fcf740569b6b356f330a1d0fc077c8d7c
  title: 'UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild'
- pid: 79c93274429d6355959f1e4374c2147bb81ea649
  title: 'LXMERT: Learning Cross-Modality Encoder Representations from Transformers'
- pid: 65a9c7b0800c86a196bc14e7621ff895cc6ab287
  title: 'ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language
    Tasks'
- pid: 8b3b8848a311c501e704c45c6d50430ab7068956
  title: 'HMDB: A large video database for human motion recognition'
- pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  title: Attention is All you Need
- pid: 0e6824e137847be0599bb0032e37042ed2ef5045
  title: 'Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching
    Movies and Reading Books'
- pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
- pid: 2527626c11a84f15709e943fbfa2356e19930e3b
  title: 'VL-BERT: Pre-training of Generic Visual-Linguistic Representations'
- pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  title: Deep Contextualized Word Representations
- pid: ac640c2d0f33fb3ab49f37b26982948fc31e3191
  title: Visually Indicated Sounds
- pid: e3ce36b9deb47aa6bb2aa19c4bfa71283b505025
  title: 'Noise-contrastive estimation: A new estimation principle for unnormalized
    statistical models'
- pid: 2f2d8f8072e5cc9b296fad551f65f183bdbff7aa
  title: Exploring the Limits of Language Modeling
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: d79ac7a7bafdc9a782fb8c53285ca11c7f2e3f18
  title: 'BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language
    Model'
slug: Learning-Video-Representations-using-Contrastive-Sun-Baradel
title: Learning Video Representations using Contrastive Bidirectional Transformer
url: https://www.semanticscholar.org/paper/Learning-Video-Representations-using-Contrastive-Sun-Baradel/025a0dc4a2a98742f1b410b6318a46de2c854b22?sort=total-citations
venue: ''
year: 2019
