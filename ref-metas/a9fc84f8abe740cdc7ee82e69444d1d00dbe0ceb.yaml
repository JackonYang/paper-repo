authors:
- A. Mnih
- Geoffrey E. Hinton
badges:
- id: OPEN_ACCESS
corpusId: 10097073
fieldsOfStudy:
- Computer Science
numCitedBy: 938
numCiting: 14
paperAbstract: Neural probabilistic language models (NPLMs) have been shown to be
  competitive with and occasionally superior to the widely-used n-gram language models.
  The main drawback of NPLMs is their extremely long training and testing times. Morin
  and Bengio have proposed a hierarchical language model built around a binary tree
  of words, which was two orders of magnitude faster than the non-hierarchical model
  it was based on. However, it performed considerably worse than its non-hierarchical
  counterpart in spite of using a word tree created using expert knowledge. We introduce
  a fast hierarchical language model along with a simple feature-based algorithm for
  automatic construction of word trees from the data. We then show that the resulting
  models can outperform non-hierarchical neural models as well as the best n-gram
  models.
ref_count: 14
references:
- pid: c19fbefdeead6a4154a22a9c8551a18b1530033a
  title: Hierarchical Probabilistic Neural Network Language Model
- pid: 3d6036af971c1f11ab712cc41487376a94e63673
  title: Using a connectionist model in a syntactical based language model
- pid: bd7d93193aad6c4b71cc8942e808753019e87706
  title: Three new graphical models for statistical language modelling
- pid: 6c2b28f9354f667cd5bd07afc0471d8334430da7
  title: A Neural Probabilistic Language Model
- pid: 09c76da2361d46689825c4efc37ad862347ca577
  title: A bit of progress in language modeling
- pid: e41498c05d4c68e4750fb84a380317a112d97b01
  title: Connectionist language modeling for large vocabulary continuous speech recognition
- pid: 3de5d40b60742e3dfa86b19e7f660962298492af
  title: Class-Based n-gram Models of Natural Language
- pid: 5eb328cf7e94995199e4c82a1f4d0696430a80b5
  title: Distributional Clustering of English Words
- pid: d87ceda3042f781c341ac17109d1e94a717f5f60
  title: 'WordNet : an electronic lexical database'
- pid: d4e8bed3b50a035e1eabad614fe4218a34b3b178
  title: An empirical study of smoothing techniques for language modeling
- pid: 6b388f0151ab37adb3d57738b8f52a3f943f86c8
  title: Quick Training of Probabilistic Neural Nets by Importance Sampling
slug: A-Scalable-Hierarchical-Distributed-Language-Model-Mnih-Hinton
title: A Scalable Hierarchical Distributed Language Model
url: https://www.semanticscholar.org/paper/A-Scalable-Hierarchical-Distributed-Language-Model-Mnih-Hinton/a9fc84f8abe740cdc7ee82e69444d1d00dbe0ceb?sort=total-citations
venue: NIPS
year: 2008
