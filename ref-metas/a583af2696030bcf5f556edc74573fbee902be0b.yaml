authors:
- Sainbayar Sukhbaatar
- Arthur D. Szlam
- J. Weston
- R. Fergus
badges:
- id: OPEN_ACCESS
corpusId: 195345948
fieldsOfStudy:
- Computer Science
numCitedBy: 99
numCiting: 21
paperAbstract: In this paper we introduce a variant of Memory Networks (Weston et
  al., 2015b) that needs significantly less supervision to perform question and answering
  tasks. The original model requires that the sentences supporting the answer be explicitly
  indicated during training. In contrast, our approach only requires the answer to
  the question during training. We apply the model to the synthetic bAbI tasks, showing
  that our approach is competitive with the supervised approach, particularly when
  trained on a sufficiently large amount of data. Furthermore, it decisively beats
  other weakly supervised approaches based on LSTMs. The approach is quite general
  and can potentially be applied to many other tasks that require capturing long-term
  dependencies.
ref_count: 21
references:
- pid: 71ae756c75ac89e2d731c9c79649562b5768ff39
  title: Memory Networks
- pid: abb33d75dc297993fcc3fb75e0f4498f413eb4f6
  title: 'Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks'
- pid: adfcf065e15fd3bc9badf6145034c84dfb08f204
  title: Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling
- pid: d38e8631bba0720becdaf7b89f79d9f9dca45d82
  title: Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets
- pid: 5522764282c85aea422f1c4dc92ff7e0ca6987bc
  title: A Clockwork RNN
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: 9665247ea3421929f9b6ad721f139f11edb1dbb8
  title: Learning Longer Memory in Recurrent Neural Networks
- pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 30110856f45fde473f1903f686aa365cf70ed4c7
  title: 'Learning Context-free Grammars: Capabilities and Limitations of a Recurrent
    Neural Network with an External Stack Memory'
- pid: 89b1f4740ae37fd04f6ac007577bdd34621f0861
  title: Generating Sequences With Recurrent Neural Networks
- pid: c3823aacea60bc1f2cabb9283144690a3d015db5
  title: Neural Turing Machines
slug: Weakly-Supervised-Memory-Networks-Sukhbaatar-Szlam
title: Weakly Supervised Memory Networks
url: https://www.semanticscholar.org/paper/Weakly-Supervised-Memory-Networks-Sukhbaatar-Szlam/a583af2696030bcf5f556edc74573fbee902be0b?sort=total-citations
venue: ArXiv
year: 2015
