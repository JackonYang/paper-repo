authors:
- Zhou Yu
- Jun Yu
- Jianping Fan
- D. Tao
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 3005731
fieldsOfStudy:
- Computer Science
numCitedBy: 368
numCiting: 40
paperAbstract: "Visual question answering (VQA) is challenging because it requires\
  \ a simultaneous understanding of both the visual content of images and the textual\
  \ content of questions. The approaches used to represent the images and questions\
  \ in a fine-grained manner and questions and to fuse these multimodal features play\
  \ key roles in performance. Bilinear pooling based models have been shown to outperform\
  \ traditional linear models for VQA, but their high-dimensional representations\
  \ and high computational complexity may seriously limit their applicability in practice.\
  \ For multimodal feature fusion, here we develop a Multi-modal Factorized Bilinear\
  \ (MFB) pooling approach to efficiently and effectively combine multi-modal features,\
  \ which results in superior performance for VQA compared with other bilinear pooling\
  \ approaches. For fine-grained image and question representation, we develop a \u2018\
  co-attention\u2019 mechanism using an end-to-end deep network architecture to jointly\
  \ learn both the image and question attentions. Combining the proposed MFB approach\
  \ with co-attention learning in a new network architecture provides a unified model\
  \ for VQA. Our experimental results demonstrate that the single MFB with co-attention\
  \ model achieves new state-of-theart performance on the real-world VQA dataset.\
  \ Code available at https://github.com/yuzcccc/mfb."
ref_count: 40
references:
- pid: fddc15480d086629b960be5bff96232f967f2252
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
- pid: fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b
  title: Hierarchical Question-Image Co-Attention for Visual Question Answering
- pid: 7214daf035ab005b3d1e739750dd597b4f4513fa
  title: A Focused Dynamic Attention Model for Visual Question Answering
- pid: 1afb710a5b35a2352a6495e4bf6eef66808daf1b
  title: Multimodal Residual Learning for Visual QA
- pid: b196bc11ad516c8e6ff96f83acfc443fd7161730
  title: 'ABC-CNN: An Attention Based Convolutional Neural Network for Visual Question
    Answering'
- pid: 1cf6bc0866226c1f8e282463adc8b75d92fba9bb
  title: 'Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for
    Visual Question Answering'
- pid: f651593fa6c83d717fc961482696a53b6fca5ab5
  title: Dual Attention Networks for Multimodal Reasoning and Matching
- pid: bd7bd1d2945a58cdcc1797ba9698b8810fe68f60
  title: 'Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images'
- pid: 121a9a160f1f2819a01edbe522024b58dbfee798
  title: 'DualNet: Domain-invariant network for visual question answering'
- pid: 3d3f789a56dca288b2c8e23ef047a2b342184950
  title: Bilinear CNN Models for Fine-Grained Visual Recognition
- pid: b58e08741fb9803fa2a870eee139137d3bade332
  title: Training Recurrent Answering Units with Joint Loss Minimization for VQA
- pid: 21c99706bb26e9012bfb4d8d48009a3d45af59b2
  title: Neural Module Networks
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: 267fb4ac632449dbe84f7acf17c8c7527cb25b0d
  title: Simple Baseline for Visual Question Answering
- pid: 20dbdf02497aa84510970d0f5e8b599073bca1bc
  title: 'Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge
    from External Sources'
- pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  title: Stacked Attention Networks for Image Question Answering
- pid: 385c18cc4024a3b3206c508c512e037b9c00b8f3
  title: Image Question Answering Using Convolutional Neural Network with Dynamic
    Parameter Prediction
- pid: f96898d15a1bf1fa8925b1280d0e07a7a8e72194
  title: Dynamic Memory Networks for Visual and Textual Question Answering
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
- pid: 175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22
  title: 'Where to Look: Focus Regions for Visual Question Answering'
- pid: 6bdb186ec4726e00a8051119636d4df3b94043b5
  title: 'Caffe: Convolutional Architecture for Fast Feature Embedding'
- pid: 6e795c6e9916174ae12349f5dc3f516570c17ce8
  title: Skip-Thought Vectors
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: 75ddc7ee15be14013a3462c01b38b0548486fbcb
  title: Learning to Compose Neural Networks for Question Answering
- pid: 0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a
  title: Explicit Knowledge-based Reasoning for Visual Question Answering
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
slug: Multi-modal-Factorized-Bilinear-Pooling-with-for-Yu-Yu
title: Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual
  Question Answering
url: https://www.semanticscholar.org/paper/Multi-modal-Factorized-Bilinear-Pooling-with-for-Yu-Yu/8e9ad6f8b2bc97f0412fa0cc243ac6975864534a?sort=total-citations
venue: 2017 IEEE International Conference on Computer Vision (ICCV)
year: 2017
