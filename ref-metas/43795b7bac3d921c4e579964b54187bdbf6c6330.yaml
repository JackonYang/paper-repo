authors:
- U. Austin
- Austin
- UMass Lowell
- Lowell
badges: []
corpusId: 52316421
fieldsOfStudy:
- Computer Science
numCitedBy: 650
numCiting: 50
paperAbstract: Solving the visual symbol grounding problem has long been a goal of
  artificial intelligence. The field appears to be advancing closer to this goal with
  recent breakthroughs in deep learning for natural language grounding in static images.
  In this paper, we propose to translate videos directly to sentences using a unified
  deep neural network with both convolutional and recurrent structure. Described video
  datasets are scarce, and most existing methods have been applied to toy domains
  with a small vocabulary of possible words. By transferring knowledge from 1.2M+
  images with category labels and 100,000+ images with captions, our method is able
  to create sentence descriptions of open-domain videos with large vocabularies. We
  compare our approach with recent work using language generation metrics, subject,
  verb, and object prediction accuracy, and a human evaluation.
ref_count: 50
references:
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 2e36ea91a3c8fbff92be2989325531b4002e2afc
  title: Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
- pid: cea967b59209c6be22829699f05b8b1ac4dc092d
  title: Sequence to Sequence Learning with Neural Networks
- pid: 20ab42c9b93b6e41f6e1d7b546f87c5a871db020
  title: Integrating Language and Vision to Generate Natural Language Descriptions
    of Videos in the Wild
- pid: e8cd37fbd8bd5e690eef5861cf92af8e002d4533
  title: Translating Video Content to Natural Language Descriptions
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: 82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9
  title: Explain Images with Multimodal Recurrent Neural Networks
- pid: a23ab0fb7d9e9961e92d704ed71e3dbc15c0d908
  title: 'A Thousand Frames in Just a Few Words: Lingual Description of Videos through
    Latent Topics and Sparse Object Stitching'
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: b8de958fead0d8a9619b55c7299df3257c624a96
  title: 'DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition'
- pid: 3b9f8101c61b415f946625b69f69fc9e3d0d6fc4
  title: Generating Natural-Language Video Descriptions Using Text-Mined Knowledge
- pid: 0d0b3ff23fbf1ec7a0dfebd923a3ef224306491a
  title: Learning to Execute
- pid: d6a7a563640bf53953c4fda0997e4db176488510
  title: 'YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic
    Hierarchies and Zero-Shot Recognition'
- pid: 7f1b111f0bb703b0bd97aba505728a9b0d9b2a54
  title: Deep Fragment Embeddings for Bidirectional Image Sentence Mapping
- pid: 1eb09fecd75eb27825dce4f964b97f4f5cc399d7
  title: "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches"
- pid: 0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f
  title: Towards End-To-End Speech Recognition with Recurrent Neural Networks
- pid: 96a0320ef14877038906947b684011cf7378c440
  title: Grounded Language Learning from Video Described with Sentences
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: 6bdb186ec4726e00a8051119636d4df3b94043b5
  title: 'Caffe: Convolutional Architecture for Fast Feature Embedding'
- pid: d53a97a3dd7760b193c0d9a5293b60feff239059
  title: Natural Language Description of Human Activities from Video Images Based
    on Concept Hierarchy of Actions
- pid: 1a2a770d23b4a171fa81de62a78a3deb0588f238
  title: Visualizing and Understanding Convolutional Networks
- pid: 889e723cd6d581e120ee6776b231fdf69707ab50
  title: Coherent Multi-sentence Video Description with Variable Level of Detail
- pid: eaaed23a2d94feb2f1c3ff22a25777c7a78f3141
  title: 'Every Picture Tells a Story: Generating Sentences from Images'
- pid: 554a31ce91189cf6022ac677413ef2f8b9b40ca7
  title: Collecting Highly Parallel Data for Paraphrase Evaluation
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 05e074abddd3fe987b9bebd46f6cf4bf8465c37e
  title: 'I2T: Image Parsing to Text Description'
- pid: 169b847e69c35cfd475eb4dcc561a24de11762ca
  title: 'Baby talk: Understanding and generating simple image descriptions'
- pid: 52f86811b57034ba5c0478b37cab101d9a84024a
  title: Comparing Automatic Evaluation Measures for Image Description
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: e74f9b7f8eec6ba4704c206b93bc8079af3da4bd
  title: ImageNet Large Scale Visual Recognition Challenge
- pid: 59927ded86ab4f7253fc32efb351e5a13e746ead
  title: 'TreeTalk: Composition and Compression of Trees for Image Descriptions'
- pid: aed054834e2c696807cc8b227ac7a4197196e211
  title: 'Gradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term Dependencies'
- pid: e8dbc756ea246f599250c09e3efd9bba9909a842
  title: Generating Image Descriptions Using Dependency Relational Patterns
- pid: 0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7
  title: 'METEOR: An Automatic Metric for MT Evaluation with Improved Correlation
    with Human Judgments'
- pid: 44040913380206991b1991daf1192942e038fe31
  title: 'From image descriptions to visual denotations: New similarity metrics for
    semantic inference over event descriptions'
- pid: d7da009f457917aa381619facfa5ffae9329a6e9
  title: 'Bleu: a Method for Automatic Evaluation of Machine Translation'
slug: Translating-Videos-to-Natural-Language-Using-Deep-Austin-Austin
title: Translating Videos to Natural Language Using Deep Recurrent Neural Networks
url: https://www.semanticscholar.org/paper/Translating-Videos-to-Natural-Language-Using-Deep-Austin-Austin/43795b7bac3d921c4e579964b54187bdbf6c6330?sort=total-citations
venue: ''
year: 2017
