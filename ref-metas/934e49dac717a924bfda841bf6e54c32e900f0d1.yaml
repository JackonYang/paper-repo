authors:
- Raymond L. Watrous
badges: []
corpusId: 15329984
fieldsOfStudy:
- Computer Science
numCitedBy: 294
numCiting: 28
paperAbstract: "The problem of learning using connectionist networks, in which network\
  \ connection strengths are modified systematically so that the response of the network\
  \ increasingly approximates the desired response can be structured as an optimization\
  \ problem. The widely used back propagation method of connectionist learning [19,\
  \ 21, 18] is set in the context of nonlinear optimization. In this framework, the\
  \ issues of stability, convergence and parallelism are considered. As a form of\
  \ gradient descent with fixed step size, back propagation is known to be unstable,\
  \ which is illustrated using Rosenbrock's function. This is contrasted with stable\
  \ methods which involve a line search in the gradient direction. The convergence\
  \ criterion for connectionist problems involving binary functions is discussed relative\
  \ to the behavior of gradient descent in the vicinity of local minima. A minimax\
  \ criterion is compared with the least squares criterion. The contribution of the\
  \ momentum term [19, 18] to more rapid convergence is interpreted relative to the\
  \ geometry of the weight space. It is shown that in plateau regions of relatively\
  \ constant gradient, the momentum term acts to increase the step size by a factor\
  \ of 1/1-\u03BC, where \u03BC is the momentum term. In valley regions with steep\
  \ sides, the momentum constant acts to focus the search direction toward the local\
  \ minimum by averaging oscillations in the gradient. Comments University of Pennsylvania\
  \ Department of Computer and Information Science Technical Report No. MSCIS-88-62.\
  \ This technical report is available at ScholarlyCommons: http://repository.upenn.edu/cis_reports/597\
  \ LEARNING ALGORITHMS FOR CONNECTIONIST NETWORKS: APPLIED GRADIENT METHODS OF NONLINEAR\
  \ OPTIMIZATION"
ref_count: 28
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 390
  pid: 4a42b2104ca8ff891ae77c40a915d4c94c8f8428
  title: Experiments on Learning by Back Propagation.
  year: 1986
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 81
  pid: f1e40283ecd4633c36c70fbc8dbb14e9a4afb37f
  title: Learning Phonetic Features Using Connectionist Networks
  year: 1987
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 16694
  pid: 98b4d4e24aab57ab4e1124ff8106909050645cfa
  title: Neural networks and physical systems with emergent collective computational
    abilities.
  year: 1982
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 288
  pid: c86590e947c28e8791d1e8bab8fc8ab53302341f
  title: Learning the hidden structure of speech.
  year: 1988
- fieldsOfStudy:
  - Mathematics
  numCitedBy: 25604
  pid: 017ddb7e815236defd0566bc46f6ed8401cc6ba6
  title: A Simplex Method for Function Minimization
  year: 1965
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 9912
  pid: 1b84b383ad59f79e607ad0f08a8a10876631a0cd
  title: Practical Methods of Optimization
  year: 1988
- fieldsOfStudy:
  - Biology
  numCitedBy: 19356
  pid: 111fd833a4ae576cfdbb27d87d2f8fc0640af355
  title: Learning internal representations by error propagation
  year: 1986
slug: Learning-Algorithms-for-Connectionist-Networks:-of-Watrous
title: 'Learning Algorithms for Connectionist Networks: Applied Gradient Methods of
  Nonlinear Optimization'
url: https://www.semanticscholar.org/paper/Learning-Algorithms-for-Connectionist-Networks:-of-Watrous/934e49dac717a924bfda841bf6e54c32e900f0d1?sort=total-citations
venue: ''
year: 1988
