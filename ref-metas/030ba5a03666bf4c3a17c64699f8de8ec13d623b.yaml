authors:
- Corso Elvezia
badges: []
corpusId: 17866647
fieldsOfStudy:
- Computer Science
numCitedBy: 35
numCiting: 39
paperAbstract: 'Numerous recent papers (including many NIPS papers) focus on standard
  recurrent nets'' inability to deal with long time lags between relevant input signals
  and teacher signals. Rather sophisticated, alternative methods were proposed. We
  rst show: problems used to promote certain algorithms in numerous previous papers
  can be solved more quickly by random weight guessing than by the proposed algorithms.
  This does not mean that guessing is a good algorithm. It just casts doubt on whether
  the other algorithms are, or whether the chosen problems are meaningful. We then
  use long short term memory (LSTM), our own recent algorithm, to solve hard problems
  that can neither be quickly solved by random weight guessing nor by any other recurrent
  net algorithm we are aware of.'
ref_count: 39
references:
- pid: b158a006bebb619e2ea7bf0a22c27d45c5d19004
  title: LSTM can Solve Hard Long Time Lag Problems
- pid: 762031682309e0124b2811ee05a798860dde82d1
  title: Guessing can Outperform Many Long Time Lag Algorithms
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: d0be39ee052d246ae99c082a565aba25b811be2d
  title: Learning long-term dependencies with gradient descent is difficult
- pid: 13369d124474b5f8dcbc70d12296a185832192b2
  title: 'Credit Assignment through Time: Alternatives to Backpropagation'
- pid: 50c770b425a5bb25c77387f687a9910a9d130722
  title: Learning Complex, Extended Sequences Using the Principle of History Compression
- pid: b13813b49f160e1a2010c44bd4fb3d09a28446e3
  title: Hierarchical Recurrent Neural Networks for Long-Term Dependencies
- pid: 32e97eef94beacace020e79322cef0e1e5a76ee0
  title: 'Gradient calculations for dynamic recurrent neural networks: a survey'
- pid: e141d68065ce638f9fc4f006eab2f66711e89768
  title: Induction of Multiscale Temporal Structure
- pid: d0dd604b2b29bbc0adee2b71bbabca5d5ad3cd54
  title: Learning Sequential Tasks by Incrementally Adding Higher Orders
- pid: 86dee86ea1b2eb5651e9ef9a4962460718d2ebd4
  title: Learning Sequential Structure with the Real-Time Recurrent Learning Algorithm
- pid: 668087f0ae7ce1de6e0bd0965dbb480c08103260
  title: Finding Structure in Time
- pid: b1ae0fb208fd389d2ff723e5442f9ca7896cb0a4
  title: Time Warping Invariant Neural Networks
- pid: bd46c1b5948abe04e565a8bae6454da63a1b021e
  title: Finite State Automata and Simple Recurrent Networks
- pid: 415dca031402b5186c0c8bf00ca7bb60bfedb986
  title: Language Induction by Phase Transition in Dynamical Recognizers
- pid: 26bc0449360d7016f684eafae5b5d2feded32041
  title: An Efficient Gradient-Based Algorithm for On-Line Training of Recurrent Network
    Trajectories
- pid: e08d090d1e586610d636a46004876e9f3ded8209
  title: A time-delay neural network architecture for isolated word recognition
- pid: c115f0d793225c515ebce6be91521fcb8374ad6b
  title: A Theory for Neural Networks with Time Delays
- pid: a64ca771a733d58dcbf8f7a3fe65a09310424bf8
  title: Induction of Finite-State Languages Using Second-Order Recurrent Networks
- pid: ebf62950d733a4a8f9ecd8d3752dee8d13fc8e6d
  title: Holographic Recurrent Networks
- pid: 29085cdffb3277c1c8fd10ac09e0d89452c8db83
  title: An Input Output HMM Architecture
- pid: 063fe6ed19c0204d55bde174483c5a93eb4819c0
  title: Learning long-term dependencies is not as difficult with NARX recurrent neural
    networks
- pid: 3f3d13e95c25a8f6a753e38dfce88885097cbd43
  title: Untersuchungen zu dynamischen neuronalen Netzen
slug: Bridging-Long-Time-Lags-by-Weight-Guessing-and-Term-Elvezia
title: Bridging Long Time Lags by Weight Guessing and \long Short Term Memory"
url: https://www.semanticscholar.org/paper/Bridging-Long-Time-Lags-by-Weight-Guessing-and-Term-Elvezia/030ba5a03666bf4c3a17c64699f8de8ec13d623b?sort=total-citations
venue: ''
year: 1996
