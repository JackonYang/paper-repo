authors:
- H. Ben-younes
- "R\xE9mi Cad\xE8ne"
- M. Cord
- Nicolas Thome
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 12913776
fieldsOfStudy:
- Computer Science
numCitedBy: 387
numCiting: 36
paperAbstract: Bilinear models provide an appealing framework for mixing and merging
  information in Visual Question Answering (VQA) tasks. They help to learn high level
  associations between question meaning and visual concepts in the image, but they
  suffer from huge dimensionality issues.,,We introduce MUTAN, a multimodal tensor-based
  Tucker decomposition to efficiently parametrize bilinear interactions between visual
  and textual representations. Additionally to the Tucker framework, we design a low-rank
  matrix-based decomposition to explicitly constrain the interaction rank. With MUTAN,
  we control the complexity of the merging scheme while keeping nice interpretable
  fusion relations. We show how the Tucker decomposition framework generalizes some
  of the latest VQA architectures, providing state-of-the-art results.
ref_count: 37
references:
- pid: fddc15480d086629b960be5bff96232f967f2252
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
- pid: 62a956d7600b10ca455076cd56e604dfd106072a
  title: Exploring Models and Data for Image Question Answering
- pid: def584565d05d6a8ba94de6621adab9e301d375d
  title: 'Visual7W: Grounded Question Answering in Images'
- pid: fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b
  title: Hierarchical Question-Image Co-Attention for Visual Question Answering
- pid: 175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22
  title: 'Where to Look: Focus Regions for Visual Question Answering'
- pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  title: Stacked Attention Networks for Image Question Answering
- pid: 1afb710a5b35a2352a6495e4bf6eef66808daf1b
  title: Multimodal Residual Learning for Visual QA
- pid: 20dbdf02497aa84510970d0f5e8b599073bca1bc
  title: 'Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge
    from External Sources'
- pid: 1cf6bc0866226c1f8e282463adc8b75d92fba9bb
  title: 'Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for
    Visual Question Answering'
- pid: 75ddc7ee15be14013a3462c01b38b0548486fbcb
  title: Learning to Compose Neural Networks for Question Answering
- pid: 3d29e1c4f1c2b079cf6b5dd458fa6cee246955f9
  title: Towards a Visual Turing Challenge
- pid: 6e795c6e9916174ae12349f5dc3f516570c17ce8
  title: Skip-Thought Vectors
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
- pid: 3d3f789a56dca288b2c8e23ef047a2b342184950
  title: Bilinear CNN Models for Fine-Grained Visual Recognition
- pid: 0ca7d208ff8d81377e0eaa9723820aeae7a7322d
  title: Grounded Compositional Semantics for Finding and Describing Images with Sentences
- pid: efb0e69bc640171d1f115bb286d865bec6f21a7f
  title: Deep correlation for matching images and text
- pid: fad611e35b3731740b4d8b754241e77add5a70b9
  title: Multimodal Neural Language Models
- pid: 153d6feb7149e063b33e8ee437b74e4a2def8057
  title: Multimodal Convolutional Neural Networks for Matching Image and Sentence
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: 1eb09fecd75eb27825dce4f964b97f4f5cc399d7
  title: "On the Properties of Neural Machine Translation: Encoder\u2013Decoder Approaches"
- pid: 0da353e79f666a3ae7dd0a5d28c75b852a7f60bf
  title: SHOW
- pid: 032db195efd97fe2bcd20c4ad04628c70ff4e79c
  title: and a at
- pid: 45fd483402290ad4cae059a4e20cd586c019c3da
  title: (b)
slug: "MUTAN:-Multimodal-Tucker-Fusion-for-Visual-Question-Ben-younes-Cad\xE8ne"
title: 'MUTAN: Multimodal Tucker Fusion for Visual Question Answering'
url: "https://www.semanticscholar.org/paper/MUTAN:-Multimodal-Tucker-Fusion-for-Visual-Question-Ben-younes-Cad\xE8\
  ne/fe466e84fa2e838adc3c37ee327cd68004ae08fe?sort=total-citations"
venue: 2017 IEEE International Conference on Computer Vision (ICCV)
year: 2017
