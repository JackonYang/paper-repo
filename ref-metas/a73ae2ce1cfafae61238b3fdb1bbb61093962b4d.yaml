authors:
- Andrei Alexandrescu
- Katrin Kirchhoff
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 937826
fieldsOfStudy:
- Computer Science
numCitedBy: 98
numCiting: 11
paperAbstract: We present a new type of neural probabilistic language model that learns
  a mapping from both words and explicit word features into a continuous space that
  is then used for word prediction. Additionally, we investigate several ways of deriving
  continuous word representations for unknown words from those of known words. The
  resulting model significantly reduces perplexity on sparse-data tasks when compared
  to standard backoff models, standard neural language models, and factored language
  models.
ref_count: 11
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 942
  pid: c19fbefdeead6a4154a22a9c8551a18b1530033a
  title: Hierarchical Probabilistic Neural Network Language Model
  year: 2005
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 6011
  pid: 6c2b28f9354f667cd5bd07afc0471d8334430da7
  title: A Neural Probabilistic Language Model
  year: 2000
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 3318
  pid: 3de5d40b60742e3dfa86b19e7f660962298492af
  title: Class-Based n-gram Models of Natural Language
  year: 1992
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 26
  pid: 9319ca5a532462f9f3515ac3d317668aa9650d5b
  title: Exact training of a neural syntactic language model
  year: 2004
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 128
  pid: 8b395470a57c48d174c4216ea21a7a58bc046917
  title: Training Neural Network Language Models on Very Large Corpora
  year: 2005
slug: Factored-Neural-Language-Models-Alexandrescu-Kirchhoff
title: Factored Neural Language Models
url: https://www.semanticscholar.org/paper/Factored-Neural-Language-Models-Alexandrescu-Kirchhoff/a73ae2ce1cfafae61238b3fdb1bbb61093962b4d?sort=total-citations
venue: NAACL
year: 2006
