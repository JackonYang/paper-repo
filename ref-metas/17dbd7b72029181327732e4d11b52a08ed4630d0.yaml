authors:
- T. Kwiatkowski
- Jennimaria Palomaki
- Olivia Redfield
- Michael Collins
- Ankur P. Parikh
- Chris Alberti
- D. Epstein
- Illia Polosukhin
- Jacob Devlin
- Kenton Lee
- Kristina Toutanova
- Llion Jones
- Matthew Kelcey
- Ming-Wei Chang
- Andrew M. Dai
- Jakob Uszkoreit
- Quoc V. Le
- Slav Petrov
badges:
- id: OPEN_ACCESS
corpusId: 86611921
fieldsOfStudy:
- Computer Science
numCitedBy: 896
numCiting: 44
paperAbstract: We present the Natural Questions corpus, a question answering data
  set. Questions consist of real anonymized, aggregated queries issued to the Google
  search engine. An annotator is presented with a question along with a Wikipedia
  page from the top 5 search results, and annotates a long answer (typically a paragraph)
  and a short answer (one or more entities) if present on the page, or marks null
  if no long/short answer is present. The public release consists of 307,373 training
  examples with single annotations; 7,830 examples with 5-way annotations for development
  data; and a further 7,842 examples with 5-way annotated sequestered as test data.
  We present experiments validating quality of the data. We also describe analysis
  of 25-way annotations on 302 examples, giving insights into human variability on
  the annotation task. We introduce robust metrics for the purposes of evaluating
  question answering systems; demonstrate high human upper bounds on these metrics;
  and establish baseline results using competitive methods drawn from related literature.
ref_count: 44
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 623
  pid: f53e2ae46470b89cd1ce6e3bf1d60d9c59722ce1
  title: 'WikiQA: A Challenge Dataset for Open-Domain Question Answering'
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 4269
  pid: 05dd7254b632376973f3a1b4d39485da17814df5
  title: 'SQuAD: 100,000+ Questions for Machine Comprehension of Text'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1057
  pid: a69cf45d44a9d806d2487a1ffb9eca71ee73c2ee
  title: 'MS MARCO: A Human Generated MAchine Reading COmprehension Dataset'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1403
  pid: 4d1c856275744c0284312a3a50efb6ca9dc4cd4c
  title: "Know What You Don\u2019t Know: Unanswerable Questions for SQuAD"
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 886
  pid: f010affab57b5fcf1cd6be23df79d8ec98c7289c
  title: 'TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading
    Comprehension'
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 596
  pid: 564257469fa44cdb57e4272f85253efb9acfd69d
  title: 'MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of
    Text'
  year: 2013
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2045
  pid: 5ded2b8c64491b4a67f6d39ce473d4b9347a672e
  title: A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 341
  pid: 3c78c6df5eb1695b6a399e346dde880af27d1016
  title: Simple and Effective Multi-Paragraph Reading Comprehension
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 493
  pid: b1e20420982a4f923c08652941666b189b11b7fe
  title: A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2525
  pid: f04df4e20a18358ea2f689b4c129781628ef7fc1
  title: A large annotated corpus for learning natural language inference
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1078
  pid: ffb949d3493c3b2f3c9acf9c75cb03938933ddf0
  title: Adversarial Examples for Evaluating Reading Comprehension Systems
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 699
  pid: 636a79420d838eabe4af7fb25d6437de45ab64e8
  title: 'RACE: Large-scale ReAding Comprehension Dataset From Examinations'
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2435
  pid: d1505c6123c102e53eb19dff312cb25cea840b72
  title: Teaching Machines to Read and Comprehend
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 532
  pid: 35b91b365ceb016fb3e022577cec96fb9b445dc5
  title: 'The Goldilocks Principle: Reading Children''s Books with Explicit Memory
    Representations'
  year: 2016
- fieldsOfStudy:
  - Linguistics
  - Computer Science
  numCitedBy: 3648
  pid: dbfd191afbbc8317577cbc44afe7156df546e143
  title: Automatic Acquisition of Hyponyms from Large Text Corpora
  year: 1992
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1061
  pid: 2cd8e8f510c89c7c18268e8ad51c061e459ad321
  title: A Decomposable Attention Model for Natural Language Inference
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 16633
  pid: d7da009f457917aa381619facfa5ffae9329a6e9
  title: 'Bleu: a Method for Automatic Evaluation of Machine Translation'
  year: 2002
- fieldsOfStudy:
  - Geology
  numCitedBy: 2177
  pid: 566eb7be43b8a2b2daff82b03711098a84859b2a
  title: Association for Computational Linguistics
  year: 2001
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 3565
  pid: 43fcdee6c6d885ac2bd32e122dbf282f93720c22
  title: A Probabilistic Theory of Pattern Recognition
  year: 1996
slug: Natural-Questions:-A-Benchmark-for-Question-Kwiatkowski-Palomaki
title: 'Natural Questions: A Benchmark for Question Answering Research'
url: https://www.semanticscholar.org/paper/Natural-Questions:-A-Benchmark-for-Question-Kwiatkowski-Palomaki/17dbd7b72029181327732e4d11b52a08ed4630d0?sort=total-citations
venue: TACL
year: 2019
