authors:
- Yen-Chun Chen
- Linjie Li
- Licheng Yu
- Ahmed El Kholy
- Faisal Ahmed
- Zhe Gan
- Yu Cheng
- Jingjing Liu
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 216080982
fieldsOfStudy:
- Computer Science
numCitedBy: 577
numCiting: 60
paperAbstract: 'Joint image-text embedding is the bedrock for most Vision-and-Language
  (V+L) tasks, where multimodality inputs are simultaneously processed for joint visual
  and textual understanding. In this paper, we introduce UNITER, a UNiversal Image-TExt
  Representation, learned through large-scale pre-training over four image-text datasets
  (COCO, Visual Genome, Conceptual Captions, and SBU Captions), which can power heterogeneous
  downstream V+L tasks with joint multimodal embeddings. We design four pre-training
  tasks: Masked Language Modeling (MLM), Masked Region Modeling (MRM, with three variants),
  Image-Text Matching (ITM), and Word-Region Alignment (WRA). Different from previous
  work that applies joint random masking to both modalities, we use conditional masking
  on pre-training tasks (i.e., masked language/region modeling is conditioned on full
  observation of image/text). In addition to ITM for global image-text alignment,
  we also propose WRA via the use of Optimal Transport (OT) to explicitly encourage
  fine-grained alignment between words and image regions during pre-training. Comprehensive
  analysis shows that both conditional masking and OT-based WRA contribute to better
  pre-training. We also conduct a thorough ablation study to find an optimal combination
  of pre-training tasks. Extensive experiments show that UNITER achieves new state
  of the art across six V+L tasks (over nine datasets), including Visual Question
  Answering, Image-Text Retrieval, Referring Expression Comprehension, Visual Commonsense
  Reasoning, Visual Entailment, and NLVR$^2$. Code is available at this https URL.'
ref_count: 60
references:
- pid: 6648b4db5f12c30941ea78c695e77aded19672bb
  title: Unified Vision-Language Pre-Training for Image Captioning and VQA
- pid: 45dd2a3cd7c27f2e9509b023d702408f5ac11c9d
  title: Stacked Cross Attention for Image-Text Matching
- pid: 26cfb57a9722599b361858d454ec816420723e36
  title: 'Behind the Scene: Revealing the Secrets of Pre-trained Vision-and-Language
    Models'
- pid: 2bc1c8bd00bbf7401afcb5460277840fd8bab029
  title: 'Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal
    Pre-training'
- pid: b27e791e843c924ef052981b79490ab59fc0433d
  title: Learning Deep Structure-Preserving Image-Text Embeddings
- pid: fdce9cbe5c726201575b3c8a8c1af0752f1af53f
  title: 'MAttNet: Modular Attention Network for Referring Expression Comprehension'
- pid: 65a9c7b0800c86a196bc14e7621ff895cc6ab287
  title: 'ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language
    Tasks'
- pid: 2f5f81bc516a6d085d39479378af1fc27104f91e
  title: Large-Scale Adversarial Training for Vision-and-Language Representation Learning
- pid: fddc15480d086629b960be5bff96232f967f2252
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
- pid: c41a11c0e9b8b92b4faaf97749841170b760760a
  title: 'VideoBERT: A Joint Model for Video and Language Representation Learning'
- pid: b4df354db88a70183a64dbc9e56cf14e7669a6c0
  title: 'Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic
    Image Captioning'
- pid: 7d0effebfa4bed19b6ba41f3af5b7e5b6890de87
  title: 'Context Encoders: Feature Learning by Inpainting'
- pid: 5466ee5f16fc3c776fd1da667917592e5fd06720
  title: 'Selfie: Self-supervised Pretraining for Image Embedding'
- pid: 6548a60a6bcdf6c402d9de1c05ba7afe4f49fee9
  title: '12-in-1: Multi-Task Vision and Language Representation Learning'
- pid: 79c93274429d6355959f1e4374c2147bb81ea649
  title: 'LXMERT: Learning Cross-Modality Encoder Representations from Transformers'
- pid: 5aec474c31a2f4b74703c6f786c0a8ff85c450da
  title: 'VisualBERT: A Simple and Performant Baseline for Vision and Language'
- pid: 3c54b796cc10cb530f77caa4d18e1c80ac863822
  title: 'Visual Entailment: A Novel Task for Fine-Grained Image Understanding'
- pid: 2527626c11a84f15709e943fbfa2356e19930e3b
  title: 'VL-BERT: Pre-training of Generic Visual-Linguistic Representations'
- pid: 784da2a7b53a16d2243f747e14946cc5e3476af0
  title: 'VQA: Visual Question Answering'
- pid: b82153bf85d5d1edd3f170aace830e5328ca9ed0
  title: Fusion of Detected Objects in Text for Visual Question Answering
- pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
- pid: aab368284210c1bb917ec2d31b84588e3d2d7eb4
  title: Unsupervised Representation Learning by Predicting Image Rotations
- pid: 9405cc0d6169988371b2755e573cc28650d14dfe
  title: Language Models are Unsupervised Multitask Learners
- pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  title: Attention is All you Need
- pid: 2ec8f7e0257a07d3914322b36072d1bbcd58a1e0
  title: Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles
- pid: f259bc7ef31c4ec7dd041c94bfd6b2f93b99b47c
  title: Contrastive Bidirectional Transformer for Temporal Representation Learning
- pid: 784da2a7b53a16d2243f747e14946cc5e3476af0
  title: 'VQA: Visual Question Answering'
- pid: 8201e6e687f2de477258e9be53ba7b73ee30d7de
  title: Colorful Image Colorization
- pid: 7a064df1aeada7e69e5173f7d4c8606f4470365b
  title: 'ALBERT: A Lite BERT for Self-supervised Learning of Language Representations'
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: 025a0dc4a2a98742f1b410b6318a46de2c854b22
  title: Learning Video Representations using Contrastive Bidirectional Transformer
- pid: a5d10341717c0519cf63151b496a6d2ed67aa05f
  title: Bilinear Attention Networks
- pid: 6dfc2ff03534a4325d06c6f88c3144831996629b
  title: 'From Recognition to Cognition: Visual Commonsense Reasoning'
- pid: e0c6abdbdecf04ffac65c440da77fb9d66bb474c
  title: 'XLNet: Generalized Autoregressive Pretraining for Language Understanding'
- pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  title: Deep Contextualized Word Representations
- pid: 784da2a7b53a16d2243f747e14946cc5e3476af0
  title: 'VQA: Visual Question Answering'
- pid: e9b13731027418ed38103d1dfc8a70f6881bc684
  title: Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question
    Answering
- pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  title: 'Im2Text: Describing Images Using 1 Million Captioned Photographs'
- pid: dbde7dfa6cae81df8ac19ef500c42db96c3d1edd
  title: 'Google''s Neural Machine Translation System: Bridging the Gap between Human
    and Machine Translation'
- pid: 8e86dd59429e8b7fd34b6893c2dea3921974c328
  title: NLVR2 Visual Bias Analysis
- pid: a1bc7d90564c342beb75cedf36fd921de89d94ad
  title: Learning Generative Models with Sinkhorn Divergences
- pid: bf8fe437f779f2098f9af82b534aa51dc9edb06f
  title: Scaling Neural Machine Translation
- pid: cf336d272a30d6ad6141db67faa64deb8791cd61
  title: A Corpus for Reasoning about Natural Language Grounded in Photographs
- pid: 0c908739fbff75f03469d13d4a1a07de3414ee19
  title: Distilling the Knowledge in a Neural Network
- pid: 784da2a7b53a16d2243f747e14946cc5e3476af0
  title: 'VQA: Visual Question Answering'
- pid: b36a5bb1707bb9c70025294b3a310138aae8327a
  title: Automatic differentiation in PyTorch
- pid: 7b54a851675cc73367cd28c296d393564ebe55f5
  title: A Fast Proximal Point Method for Wasserstein Distance
- pid: d07284a6811f1b2745d91bdb06b040b57f226882
  title: Decoupled Weight Decay Regularization
- pid: 69902406e7d08f8865f02185699978db499d25e7
  title: Improving GANs Using Optimal Transport
- pid: d78aed1dac6656affa4a04cbf225ced11a83d103
  title: Revealing the Dark Secrets of BERT
- pid: acd87843a451d18b4dc6474ddce1ae946429eaf1
  title: Wasserstein Generative Adversarial Networks
- pid: 0080118b0eb02af581ff32b85a1bb6aed7081f45
  title: 'Sinkhorn Distances: Lightspeed Computation of Optimal Transport'
- pid: 8e51d68250db5637cd6bc1de98a99396441399b2
  title: Computational Optimal Transport
- pid: 784da2a7b53a16d2243f747e14946cc5e3476af0
  title: 'VQA: Visual Question Answering'
slug: UNITER:-UNiversal-Image-TExt-Representation-Chen-Li
title: 'UNITER: UNiversal Image-TExt Representation Learning'
url: https://www.semanticscholar.org/paper/UNITER:-UNiversal-Image-TExt-Representation-Chen-Li/d8a305b9366608d54452ac30459ee57b4f5cf1c9?sort=total-citations
venue: ECCV
year: 2020
