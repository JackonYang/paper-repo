authors:
- Yen-Chun Chen
- Linjie Li
- Licheng Yu
- Ahmed El Kholy
- Faisal Ahmed
- Zhe Gan
- Yu Cheng
- Jingjing Liu
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 216080982
fieldsOfStudy:
- Computer Science
meta_key: uniter-universal-image-text-representation-learning
numCitedBy: 577
numCiting: 60
paperAbstract: 'Joint image-text embedding is the bedrock for most Vision-and-Language
  (V+L) tasks, where multimodality inputs are simultaneously processed for joint visual
  and textual understanding. In this paper, we introduce UNITER, a UNiversal Image-TExt
  Representation, learned through large-scale pre-training over four image-text datasets
  (COCO, Visual Genome, Conceptual Captions, and SBU Captions), which can power heterogeneous
  downstream V+L tasks with joint multimodal embeddings. We design four pre-training
  tasks: Masked Language Modeling (MLM), Masked Region Modeling (MRM, with three variants),
  Image-Text Matching (ITM), and Word-Region Alignment (WRA). Different from previous
  work that applies joint random masking to both modalities, we use conditional masking
  on pre-training tasks (i.e., masked language/region modeling is conditioned on full
  observation of image/text). In addition to ITM for global image-text alignment,
  we also propose WRA via the use of Optimal Transport (OT) to explicitly encourage
  fine-grained alignment between words and image regions during pre-training. Comprehensive
  analysis shows that both conditional masking and OT-based WRA contribute to better
  pre-training. We also conduct a thorough ablation study to find an optimal combination
  of pre-training tasks. Extensive experiments show that UNITER achieves new state
  of the art across six V+L tasks (over nine datasets), including Visual Question
  Answering, Image-Text Retrieval, Referring Expression Comprehension, Visual Commonsense
  Reasoning, Visual Entailment, and NLVR$^2$. Code is available at this https URL.'
ref_count: 60
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: unified-vision-language-pre-training-for-image-captioning-and-vqa
  numCitedBy: 355
  pid: 6648b4db5f12c30941ea78c695e77aded19672bb
  show_ref_link: true
  title: Unified Vision-Language Pre-Training for Image Captioning and VQA
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: stacked-cross-attention-for-image-text-matching
  numCitedBy: 481
  pid: 45dd2a3cd7c27f2e9509b023d702408f5ac11c9d
  show_ref_link: true
  title: Stacked Cross Attention for Image-Text Matching
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: behind-the-scene-revealing-the-secrets-of-pre-trained-vision-and-language-models
  numCitedBy: 64
  pid: 26cfb57a9722599b361858d454ec816420723e36
  show_ref_link: false
  title: Behind the Scene - Revealing the Secrets of Pre-trained Vision-and-Language
    Models
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: unicoder-vl-a-universal-encoder-for-vision-and-language-by-cross-modal-pre-training
  numCitedBy: 382
  pid: 2bc1c8bd00bbf7401afcb5460277840fd8bab029
  show_ref_link: true
  title: Unicoder-VL - A Universal Encoder for Vision and Language by Cross-modal
    Pre-training
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-deep-structure-preserving-image-text-embeddings
  numCitedBy: 582
  pid: b27e791e843c924ef052981b79490ab59fc0433d
  show_ref_link: true
  title: Learning Deep Structure-Preserving Image-Text Embeddings
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: mattnet-modular-attention-network-for-referring-expression-comprehension
  numCitedBy: 369
  pid: fdce9cbe5c726201575b3c8a8c1af0752f1af53f
  show_ref_link: true
  title: MAttNet - Modular Attention Network for Referring Expression Comprehension
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks
  numCitedBy: 1266
  pid: 65a9c7b0800c86a196bc14e7621ff895cc6ab287
  show_ref_link: true
  title: ViLBERT - Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language
    Tasks
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: large-scale-adversarial-training-for-vision-and-language-representation-learning
  numCitedBy: 169
  pid: 2f5f81bc516a6d085d39479378af1fc27104f91e
  show_ref_link: true
  title: Large-Scale Adversarial Training for Vision-and-Language Representation Learning
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: multimodal-compact-bilinear-pooling-for-visual-question-answering-and-visual-grounding
  numCitedBy: 1086
  pid: fddc15480d086629b960be5bff96232f967f2252
  show_ref_link: true
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: videobert-a-joint-model-for-video-and-language-representation-learning
  numCitedBy: 569
  pid: c41a11c0e9b8b92b4faaf97749841170b760760a
  show_ref_link: true
  title: VideoBERT - A Joint Model for Video and Language Representation Learning
  year: 2019
- fieldsOfStudy:
  - Computer Science
  - Environmental Science
  meta_key: conceptual-captions-a-cleaned-hypernymed-image-alt-text-dataset-for-automatic-image-captioning
  numCitedBy: 632
  pid: b4df354db88a70183a64dbc9e56cf14e7669a6c0
  show_ref_link: true
  title: Conceptual Captions - A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic
    Image Captioning
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: context-encoders-feature-learning-by-inpainting
  numCitedBy: 3342
  pid: 7d0effebfa4bed19b6ba41f3af5b7e5b6890de87
  show_ref_link: true
  title: Context Encoders - Feature Learning by Inpainting
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: selfie-self-supervised-pretraining-for-image-embedding
  numCitedBy: 68
  pid: 5466ee5f16fc3c776fd1da667917592e5fd06720
  show_ref_link: false
  title: Selfie - Self-supervised Pretraining for Image Embedding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: 12-in-1-multi-task-vision-and-language-representation-learning
  numCitedBy: 227
  pid: 6548a60a6bcdf6c402d9de1c05ba7afe4f49fee9
  show_ref_link: true
  title: 12-in-1 - Multi-Task Vision and Language Representation Learning
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: lxmert-learning-cross-modality-encoder-representations-from-transformers
  numCitedBy: 916
  pid: 79c93274429d6355959f1e4374c2147bb81ea649
  show_ref_link: true
  title: LXMERT - Learning Cross-Modality Encoder Representations from Transformers
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: visualbert-a-simple-and-performant-baseline-for-vision-and-language
  numCitedBy: 630
  pid: 5aec474c31a2f4b74703c6f786c0a8ff85c450da
  show_ref_link: true
  title: VisualBERT - A Simple and Performant Baseline for Vision and Language
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: visual-entailment-a-novel-task-for-fine-grained-image-understanding
  numCitedBy: 99
  pid: 3c54b796cc10cb530f77caa4d18e1c80ac863822
  show_ref_link: false
  title: Visual Entailment - A Novel Task for Fine-Grained Image Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: vl-bert-pre-training-of-generic-visual-linguistic-representations
  numCitedBy: 707
  pid: 2527626c11a84f15709e943fbfa2356e19930e3b
  show_ref_link: true
  title: VL-BERT - Pre-training of Generic Visual-Linguistic Representations
  year: 2020
- fieldsOfStudy: []
  meta_key: vqa-visual-question-answering
  numCitedBy: 0
  pid: 784da2a7b53a16d2243f747e14946cc5e3476af0
  show_ref_link: false
  title: VQA - Visual Question Answering
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: fusion-of-detected-objects-in-text-for-visual-question-answering
  numCitedBy: 111
  pid: b82153bf85d5d1edd3f170aace830e5328ca9ed0
  show_ref_link: true
  title: Fusion of Detected Objects in Text for Visual Question Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: graph-optimal-transport-for-cross-domain-alignment
  numCitedBy: 44
  pid: 2a81f6bf76bcb70244aa40217ff316025971bd0f
  show_ref_link: false
  title: Graph Optimal Transport for Cross-Domain Alignment
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: bottom-up-and-top-down-attention-for-image-captioning-and-visual-question-answering
  numCitedBy: 2275
  pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  show_ref_link: true
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: unsupervised-representation-learning-by-predicting-image-rotations
  numCitedBy: 1664
  pid: aab368284210c1bb917ec2d31b84588e3d2d7eb4
  show_ref_link: true
  title: Unsupervised Representation Learning by Predicting Image Rotations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: language-models-are-unsupervised-multitask-learners
  numCitedBy: 6284
  pid: 9405cc0d6169988371b2755e573cc28650d14dfe
  show_ref_link: true
  title: Language Models are Unsupervised Multitask Learners
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: attention-is-all-you-need
  numCitedBy: 35148
  pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  show_ref_link: true
  title: Attention is All you Need
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: unsupervised-learning-of-visual-representations-by-solving-jigsaw-puzzles
  numCitedBy: 1664
  pid: 2ec8f7e0257a07d3914322b36072d1bbcd58a1e0
  show_ref_link: true
  title: Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: contrastive-bidirectional-transformer-for-temporal-representation-learning
  numCitedBy: 117
  pid: f259bc7ef31c4ec7dd041c94bfd6b2f93b99b47c
  show_ref_link: true
  title: Contrastive Bidirectional Transformer for Temporal Representation Learning
  year: 2019
- fieldsOfStudy: []
  meta_key: vqa-visual-question-answering
  numCitedBy: 0
  pid: 784da2a7b53a16d2243f747e14946cc5e3476af0
  show_ref_link: false
  title: VQA - Visual Question Answering
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: colorful-image-colorization
  numCitedBy: 2297
  pid: 8201e6e687f2de477258e9be53ba7b73ee30d7de
  show_ref_link: true
  title: Colorful Image Colorization
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: albert-a-lite-bert-for-self-supervised-learning-of-language-representations
  numCitedBy: 2706
  pid: 7a064df1aeada7e69e5173f7d4c8606f4470365b
  show_ref_link: true
  title: ALBERT - A Lite BERT for Self-supervised Learning of Language Representations
  year: 2020
- fieldsOfStudy:
  - Computer Science
  meta_key: vqa-visual-question-answering
  numCitedBy: 2887
  pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  show_ref_link: true
  title: VQA - Visual Question Answering
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-video-representations-using-contrastive-bidirectional-transformer
  numCitedBy: 170
  pid: 025a0dc4a2a98742f1b410b6318a46de2c854b22
  show_ref_link: true
  title: Learning Video Representations using Contrastive Bidirectional Transformer
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: bilinear-attention-networks
  numCitedBy: 408
  pid: a5d10341717c0519cf63151b496a6d2ed67aa05f
  show_ref_link: true
  title: Bilinear Attention Networks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: from-recognition-to-cognition-visual-commonsense-reasoning
  numCitedBy: 372
  pid: 6dfc2ff03534a4325d06c6f88c3144831996629b
  show_ref_link: true
  title: From Recognition to Cognition - Visual Commonsense Reasoning
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: xlnet-generalized-autoregressive-pretraining-for-language-understanding
  numCitedBy: 4226
  pid: e0c6abdbdecf04ffac65c440da77fb9d66bb474c
  show_ref_link: true
  title: XLNet - Generalized Autoregressive Pretraining for Language Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-contextualized-word-representations
  numCitedBy: 7987
  pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  show_ref_link: true
  title: Deep Contextualized Word Representations
  year: 2018
- fieldsOfStudy: []
  meta_key: vqa-visual-question-answering
  numCitedBy: 0
  pid: 784da2a7b53a16d2243f747e14946cc5e3476af0
  show_ref_link: false
  title: VQA - Visual Question Answering
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: dynamic-fusion-with-intra-and-inter-modality-attention-flow-for-visual-question-answering
  numCitedBy: 192
  pid: e9b13731027418ed38103d1dfc8a70f6881bc684
  show_ref_link: true
  title: Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question
    Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: im2text-describing-images-using-1-million-captioned-photographs
  numCitedBy: 734
  pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  show_ref_link: false
  title: Im2Text - Describing Images Using 1 Million Captioned Photographs
  year: 2011
- fieldsOfStudy:
  - Computer Science
  meta_key: google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation
  numCitedBy: 4645
  pid: dbde7dfa6cae81df8ac19ef500c42db96c3d1edd
  show_ref_link: true
  title: Google's Neural Machine Translation System - Bridging the Gap between Human
    and Machine Translation
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: nlvr2-visual-bias-analysis
  numCitedBy: 5
  pid: 8e86dd59429e8b7fd34b6893c2dea3921974c328
  show_ref_link: false
  title: NLVR2 Visual Bias Analysis
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-generative-models-with-sinkhorn-divergences
  numCitedBy: 393
  pid: a1bc7d90564c342beb75cedf36fd921de89d94ad
  show_ref_link: true
  title: Learning Generative Models with Sinkhorn Divergences
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: scaling-neural-machine-translation
  numCitedBy: 474
  pid: bf8fe437f779f2098f9af82b534aa51dc9edb06f
  show_ref_link: true
  title: Scaling Neural Machine Translation
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: a-corpus-for-reasoning-about-natural-language-grounded-in-photographs
  numCitedBy: 211
  pid: cf336d272a30d6ad6141db67faa64deb8791cd61
  show_ref_link: true
  title: A Corpus for Reasoning about Natural Language Grounded in Photographs
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: distilling-the-knowledge-in-a-neural-network
  numCitedBy: 8699
  pid: 0c908739fbff75f03469d13d4a1a07de3414ee19
  show_ref_link: true
  title: Distilling the Knowledge in a Neural Network
  year: 2015
- fieldsOfStudy: []
  meta_key: vqa-visual-question-answering
  numCitedBy: 0
  pid: 784da2a7b53a16d2243f747e14946cc5e3476af0
  show_ref_link: false
  title: VQA - Visual Question Answering
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: automatic-differentiation-in-pytorch
  numCitedBy: 10324
  pid: b36a5bb1707bb9c70025294b3a310138aae8327a
  show_ref_link: true
  title: Automatic differentiation in PyTorch
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: a-fast-proximal-point-method-for-wasserstein-distance
  numCitedBy: 37
  pid: 7b54a851675cc73367cd28c296d393564ebe55f5
  show_ref_link: false
  title: A Fast Proximal Point Method for Wasserstein Distance
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: decoupled-weight-decay-regularization
  numCitedBy: 3475
  pid: d07284a6811f1b2745d91bdb06b040b57f226882
  show_ref_link: true
  title: Decoupled Weight Decay Regularization
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: improving-gans-using-optimal-transport
  numCitedBy: 207
  pid: 69902406e7d08f8865f02185699978db499d25e7
  show_ref_link: true
  title: Improving GANs Using Optimal Transport
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: revealing-the-dark-secrets-of-bert
  numCitedBy: 290
  pid: d78aed1dac6656affa4a04cbf225ced11a83d103
  show_ref_link: true
  title: Revealing the Dark Secrets of BERT
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: wasserstein-generative-adversarial-networks
  numCitedBy: 3929
  pid: acd87843a451d18b4dc6474ddce1ae946429eaf1
  show_ref_link: true
  title: Wasserstein Generative Adversarial Networks
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: sinkhorn-distances-lightspeed-computation-of-optimal-transport
  numCitedBy: 1873
  pid: 0080118b0eb02af581ff32b85a1bb6aed7081f45
  show_ref_link: true
  title: Sinkhorn Distances - Lightspeed Computation of Optimal Transport
  year: 2013
- fieldsOfStudy:
  - Geology
  meta_key: computational-optimal-transport
  numCitedBy: 960
  pid: 8e51d68250db5637cd6bc1de98a99396441399b2
  show_ref_link: true
  title: Computational Optimal Transport
  year: 2019
- fieldsOfStudy: []
  meta_key: vqa-visual-question-answering
  numCitedBy: 0
  pid: 784da2a7b53a16d2243f747e14946cc5e3476af0
  show_ref_link: false
  title: VQA - Visual Question Answering
  year: 2015
slug: UNITER:-UNiversal-Image-TExt-Representation-Chen-Li
title: UNITER - UNiversal Image-TExt Representation Learning
url: https://www.semanticscholar.org/paper/UNITER:-UNiversal-Image-TExt-Representation-Chen-Li/d8a305b9366608d54452ac30459ee57b4f5cf1c9?sort=total-citations
venue: ECCV
year: 2020
