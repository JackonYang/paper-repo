authors:
- F. Jelinek
- "B. M\xE9rialdo"
- S. Roukos
- M. Strauss
badges:
- id: OPEN_ACCESS
corpusId: 11601499
fieldsOfStudy:
- Computer Science
numCitedBy: 146
numCiting: 3
paperAbstract: In the case of a trigram language model, the probability of the next
  word conditioned on the previous two words is estimated from a large corpus of text.
  The resulting static trigram language model (STLM) has fixed probabilities that
  are independent of the document being dictated. To improve the language model (LM),
  one can adapt the probabilities of the trigram language model to match the current
  document more closely. The partially dictated document provides significant clues
  about what words are more likely to be used next. Of many methods that can be used
  to adapt the LM, we describe in this paper a simple model based on the trigram frequencies
  estimated from the partially dictated document. We call this model a cache trigram
  language model (CTLM) since we are caching the recent history of words. We have
  found that the CTLM reduces the perplexity of a dictated document by 23%. The error
  rate of a 20,000-word isolated word recognizer decreases by about 5% at the beginning
  of a document and by about 24% after a few hundred words.
ref_count: 3
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 56
  pid: 491566891addc26134c617ab026f5548de39401a
  title: 'Speech Recognition and the Frequency of Recently Used Words: A Modified
    Markov Model for Natural Language'
  year: 1988
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 48
  pid: 343c8af478f7703459b0e390e888efe723f15e31
  title: Probabilistic Models of Short and Long Distance Word Dependencies in Running
    Text
  year: 1989
slug: "A-Dynamic-Language-Model-for-Speech-Recognition-Jelinek-M\xE9rialdo"
title: A Dynamic Language Model for Speech Recognition
url: "https://www.semanticscholar.org/paper/A-Dynamic-Language-Model-for-Speech-Recognition-Jelinek-M\xE9\
  rialdo/0687165a9f0360bde0469fd401d966540e0897c3?sort=total-citations"
venue: HLT
year: 1991
