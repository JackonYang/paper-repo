ref_count: 45
references:
- pid: 65a9c7b0800c86a196bc14e7621ff895cc6ab287
  title: 'ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language
    Tasks'
- pid: 6648b4db5f12c30941ea78c695e77aded19672bb
  title: Unified Vision-Language Pre-Training for Image Captioning and VQA
- pid: 5aec474c31a2f4b74703c6f786c0a8ff85c450da
  title: 'VisualBERT: A Simple and Performant Baseline for Vision and Language'
- pid: 2527626c11a84f15709e943fbfa2356e19930e3b
  title: 'VL-BERT: Pre-training of Generic Visual-Linguistic Representations'
- pid: 6548a60a6bcdf6c402d9de1c05ba7afe4f49fee9
  title: '12-in-1: Multi-Task Vision and Language Representation Learning'
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: 818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57
  title: 'Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks'
- pid: bc996a4dbf9d4234eacdd0b930a94de1d158e256
  title: 'ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through Scene
    Graph'
- pid: 2bc1c8bd00bbf7401afcb5460277840fd8bab029
  title: 'Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal
    Pre-training'
- pid: 3e92f6ad7b1a0d59d5ffa30fc6e617e885f7be1a
  title: In Defense of Grid Features for Visual Question Answering
- pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
- pid: f147279c9d1edddda57f1f21f23b3b58998bad74
  title: 'VIVO: Surpassing Human Performance in Novel Object Captioning with Visual
    Vocabulary Pre-Training'
- pid: 79c93274429d6355959f1e4374c2147bb81ea649
  title: 'LXMERT: Learning Cross-Modality Encoder Representations from Transformers'
- pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
- pid: 54416048772b921720f19869ed11c2a360589d03
  title: 'UNITER: Learning UNiversal Image-TExt Representations'
- pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
- pid: faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1
  title: 'VSE++: Improved Visual-Semantic Embeddings'
- pid: 48a7873681c6aa88b9e0e22a25c2a8245eaeb45f
  title: Position Focused Attention Network for Image-Text Matching
- pid: b9b4e05faa194e5022edd9eb9dd07e3d675c2b36
  title: Feature Pyramid Networks for Object Detection
- pid: 554363727a07d39b23ad5b4e32f556685afd332a
  title: 'FCOS: A Simple and Strong Anchor-Free Object Detector'
- pid: b9779ddeb6a8a9de0f7e104d8742728aa14578d6
  title: 'InterBERT: Vision-and-Language Interaction for Multi-modal Pretraining'
- pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  title: 'Making the V in VQA Matter: Elevating the Role of Image Understanding in
    Visual Question Answering'
- pid: 4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0
  title: X-Linear Attention Networks for Image Captioning
- pid: 2f5f81bc516a6d085d39479378af1fc27104f91e
  title: Large-Scale Adversarial Training for Vision-and-Language Representation Learning
- pid: 8b55402ffee2734bfc7d5d7595500916e1ef04e8
  title: 'nocaps: novel object captioning at scale'
- pid: 45dd2a3cd7c27f2e9509b023d702408f5ac11c9d
  title: Stacked Cross Attention for Image-Text Matching
- pid: 4c163d4942117179d3e97182e1b280027d7d60a9
  title: Attention on Attention for Image Captioning
- pid: c5ff974a69fd0c760b4855b819e61e89f31cfffe
  title: 'Objects365: A Large-Scale, High-Quality Dataset for Object Detection'
- pid: 58555c7d168d1f50422ed9435d31ecd28d66eaa8
  title: Dual-path Convolutional Image-Text Embeddings with Instance Loss
- pid: 136c05cb8dd359fb8e0dc7947172a9ecb74ccbec
  title: 'Learning by Abstraction: The Neural State Machine'
- pid: 19c630ad5a9de227f6357479fc95c62667be17f6
  title: 'CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval'
- pid: 1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1
  title: 'GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question
    Answering'
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: ad748d1772f893b3c8a3857a19292375be259daf
  title: Knowledge Aware Semantic Concept Expansion for Image-Text Matching
- pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  title: Stacked Attention Networks for Image Question Answering
- pid: 72564a69bf339ff1d16a639c86a764db2321caab
  title: Focal Loss for Dense Object Detection
- pid: 79cfb51a51fc093f66aac8e858afe2e14d4a1f20
  title: Focal Loss for Dense Object Detection
- pid: b4df354db88a70183a64dbc9e56cf14e7669a6c0
  title: 'Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic
    Image Captioning'
- pid: 320464aa0231bc728c7d9ab7e71e552c12a7486b
  title: Meta Module Network for Compositional Visual Reasoning
- pid: cf336d272a30d6ad6141db67faa64deb8791cd61
  title: A Corpus for Reasoning about Natural Language Grounded in Photographs
- pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  title: 'Im2Text: Describing Images Using 1 Million Captioned Photographs'
- pid: 6c8353697cdbb98dfba4f493875778c4286d3e3a
  title: Self-Critical Sequence Training for Image Captioning
- pid: 44040913380206991b1991daf1192942e038fe31
  title: 'From image descriptions to visual denotations: New similarity metrics for
    semantic inference over event descriptions'
url: https://www.semanticscholar.org/paper/VinVL%3A-Revisiting-Visual-Representations-in-Models-Zhang-Li/63c74d15940af1af9b386b5762e4445e54c73719
