authors:
- George E. Dahl
- Dong Yu
- L. Deng
- A. Acero
badges:
- id: OPEN_ACCESS
corpusId: 14862572
fieldsOfStudy:
- Computer Science
numCitedBy: 2677
numCiting: 93
paperAbstract: We propose a novel context-dependent (CD) model for large-vocabulary
  speech recognition (LVSR) that leverages recent advances in using deep belief networks
  for phone recognition. We describe a pre-trained deep neural network hidden Markov
  model (DNN-HMM) hybrid architecture that trains the DNN to produce a distribution
  over senones (tied triphone states) as its output. The deep belief network pre-training
  algorithm is a robust and often helpful way to initialize deep neural networks generatively
  that can aid in optimization and reduce generalization error. We illustrate the
  key components of our model, describe the procedure for applying CD-DNN-HMMs to
  LVSR, and analyze the effects of various modeling choices on performance. Experiments
  on a challenging business search dataset demonstrate that CD-DNN-HMMs can significantly
  outperform the conventional context-dependent Gaussian mixture model (GMM)-HMMs,
  with an absolute sentence accuracy improvement of 5.8% and 9.2% (or relative error
  reduction of 16.0% and 23.2%) over the CD-GMM-HMMs trained using the minimum phone
  error rate (MPE) and maximum-likelihood (ML) criteria, respectively.
ref_count: 93
references:
- pid: d0191c9b53a99942a9b4ec39dc30489e41c7aaa1
  title: Investigation of full-sequence training of deep belief networks for speech
    recognition
- pid: 90b63e917d5737b06357d50aa729619e933d9614
  title: Phone Recognition with the Mean-Covariance Restricted Boltzmann Machine
- pid: df5b82595a29724467a98eed4d7e2a45e804579e
  title: Speech Recognition Using Augmented Conditional Random Fields
- pid: f37cfdc4520c56c1eaf87cee5ec2a4028ceaa9c5
  title: Deep Belief Networks for phone recognition
- pid: d2b62f77cb2864e465aa60bca6c26bb1d2f84963
  title: Acoustic Modeling Using Deep Belief Networks
- pid: 3d82e058a5c40954b8f5db170a298a889a254c37
  title: 'Connectionist Speech Recognition: A Hybrid Approach'
- pid: 5e9082caea65c76bfd23b8763872804473ee7872
  title: Tandem connectionist feature extraction for conventional HMM systems
- pid: 62c87f843ae5c1ce7972d7cdcd227e3ec3fe5417
  title: Structured speech modeling
- pid: 57458bc1cffe5caa45a885af986d70f723f406b4
  title: 'A unified architecture for natural language processing: deep neural networks
    with multitask learning'
- pid: cd0568b4faa03910ae3c07d00c627666f404305d
  title: Continuous speech recognition using multilayer perceptrons with hidden Markov
    models
- pid: 0d2336389dff3031910bd21dd1c44d1b4cd51725
  title: Why Does Unsupervised Pre-training Help Deep Learning?
- pid: 8978cf7574ceb35f4c3096be768c7547b28a35d0
  title: A Fast Learning Algorithm for Deep Belief Nets
- pid: ccf415df5a83b343dae261286d29a40e8b80e6c6
  title: The Difficulty of Training Deep Architectures and the Effect of Unsupervised
    Pre-Training
- pid: b71ac1e9fb49420d13e084ac67254a0bbd40f83f
  title: Understanding the difficulty of training deep feedforward neural networks
- pid: a08c99425ad94eed67d059813511fe9ca55e73eb
  title: Connectionist probability estimators in HMM speech recognition
- pid: 5a2668bf420d8509a4dfa28e1cdcdac14c649975
  title: 3D Object Recognition with Deep Belief Nets
- pid: d9d2ba2003d7324ae3d5ff7423a13f13efc79ca5
  title: Pushing the envelope - aside [speech recognition]
- pid: e60ff004dde5c13ec53087872cfcdd12e85beb57
  title: Learning Deep Architectures for AI
- pid: 843959ffdccf31c6694d135fad07425924f785b1
  title: Extracting and composing robust features with denoising autoencoders
- pid: 0228810a988f6b8f06337e14f564e2fd3f6e1056
  title: The Recurrent Temporal Restricted Boltzmann Machine
- pid: cd5af41a81e7fc9588dc74f3831fb14daf2f8e2a
  title: Semantic hashing
- pid: e2c04849a3802715d5a9d89179c9f161014d6c2a
  title: Modeling pixel means and covariances using factorized third-order boltzmann
    machines
- pid: 6fdb77260fc83dff91c44fea0f31a2cb8ed13d04
  title: Scaling learning algorithms towards AI
- pid: d63cdc1d1f023c63f8aa3b64cd5e853670680c3e
  title: Discriminative learning in sequential pattern recognition
- pid: 1f88427d7aa8225e47f946ac41a0667d7b69ac52
  title: What is the best multi-stage architecture for object recognition?
- pid: 46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e
  title: Reducing the Dimensionality of Data with Neural Networks
- pid: 052b1d8ce63b07fec3de9dbb583772d860b7c769
  title: Learning representations by back-propagating errors
- pid: 9360e5ce9c98166bb179ad479a9d2919ff13d022
  title: Training Products of Experts by Minimizing Contrastive Divergence
- pid: b7d471970467a99bec4bce34c7dba5ef6745ad06
  title: The Curse of Highly Variable Functions for Local Kernel Machines
- pid: 4c46347fbc272b21468efe3d9af34b4b2bad6684
  title: Deep learning via Hessian-free optimization
- pid: 2184fb6d32bc46f252b940035029273563c4fc82
  title: Exponential Family Harmoniums with an Application to Information Retrieval
- pid: 0ea90fac0958d84bcf4a2875c2b169478358b480
  title: 'CUDAMat: a CUDA-based matrix class for Python'
- pid: 4f7476037408ac3d993f5088544aab427bc319c1
  title: 'Information processing in dynamical systems: foundations of harmony theory'
slug: Context-Dependent-Pre-Trained-Deep-Neural-Networks-Dahl-Yu
title: Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech
  Recognition
url: https://www.semanticscholar.org/paper/Context-Dependent-Pre-Trained-Deep-Neural-Networks-Dahl-Yu/6658bbf68995731b2083195054ff45b4eca38b3a?sort=total-citations
venue: IEEE Transactions on Audio, Speech, and Language Processing
year: 2012
