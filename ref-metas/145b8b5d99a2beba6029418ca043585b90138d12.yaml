authors:
- Kaitao Song
- Xu Tan
- Tao Qin
- Jianfeng Lu
- Tie-Yan Liu
badges:
- id: OPEN_ACCESS
corpusId: 146808476
fieldsOfStudy:
- Computer Science
meta_key: mass-masked-sequence-to-sequence-pre-training-for-language-generation
numCitedBy: 599
numCiting: 59
paperAbstract: 'Pre-training and fine-tuning, e.g., BERT, have achieved great success
  in language understanding by transferring knowledge from rich-resource pre-training
  task to the low/zero-resource downstream tasks. Inspired by the success of BERT,
  we propose MAsked Sequence to Sequence pre-training (MASS) for the encoder-decoder
  based language generation tasks. MASS adopts the encoder-decoder framework to reconstruct
  a sentence fragment given the remaining part of the sentence: its encoder takes
  a sentence with randomly masked fragment (several consecutive tokens) as input,
  and its decoder tries to predict this masked fragment. In this way, MASS can jointly
  train the encoder and decoder to develop the capability of representation extraction
  and language modeling. By further fine-tuning on a variety of zero/low-resource
  language generation tasks, including neural machine translation, text summarization
  and conversational response generation (3 tasks and totally 8 datasets), MASS achieves
  significant improvements over the baselines without pre-training or with other pre-training
  methods. Specially, we achieve the state-of-the-art accuracy (37.5 in terms of BLEU
  score) on the unsupervised English-French translation, even beating the early attention-based
  supervised model.'
ref_count: 59
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding
  numCitedBy: 33777
  pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  show_ref_link: true
  title: BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: transfer-learning-for-low-resource-neural-machine-translation
  numCitedBy: 561
  pid: 1cd7f2c74bd7ffb3a8b1527bec8795d0876a40b6
  show_ref_link: false
  title: Transfer Learning for Low-Resource Neural Machine Translation
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: unsupervised-pretraining-for-sequence-to-sequence-learning
  numCitedBy: 249
  pid: 85f94d8098322f8130512b4c6c4627548ce4a6cc
  show_ref_link: true
  title: Unsupervised Pretraining for Sequence to Sequence Learning
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: improving-language-understanding-by-generative-pre-training
  numCitedBy: 3536
  pid: cd18800a0fe0b668a1cc19f2ec95b5003d0a5035
  show_ref_link: true
  title: Improving Language Understanding by Generative Pre-Training
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: maskgan-better-text-generation-via-filling-in-the-______
  numCitedBy: 352
  pid: 7f4afc1bf3272ae6ec00b46e27efc4a4f6b0826d
  show_ref_link: false
  title: MaskGAN - Better Text Generation via Filling in the ______
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: attention-is-all-you-need
  numCitedBy: 35186
  pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  show_ref_link: true
  title: Attention is All you Need
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: neural-machine-translation-by-jointly-learning-to-align-and-translate
  numCitedBy: 19346
  pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  show_ref_link: true
  title: Neural Machine Translation by Jointly Learning to Align and Translate
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: unsupervised-neural-machine-translation-with-weight-sharing
  numCitedBy: 100
  pid: f3035aa7da6b7772b3f036cb405a4b128b2a00ef
  show_ref_link: false
  title: Unsupervised Neural Machine Translation with Weight Sharing
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: phrase-based-neural-unsupervised-machine-translation
  numCitedBy: 541
  pid: 48925fef94500cf19ee220ed74217816f1ab5e60
  show_ref_link: false
  title: Phrase-Based & Neural Unsupervised Machine Translation
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: google-s-neural-machine-translation-system-bridging-the-gap-between-human-and-machine-translation
  numCitedBy: 4645
  pid: dbde7dfa6cae81df8ac19ef500c42db96c3d1edd
  show_ref_link: true
  title: Google's Neural Machine Translation System - Bridging the Gap between Human
    and Machine Translation
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: skip-thought-vectors
  numCitedBy: 1928
  pid: 6e795c6e9916174ae12349f5dc3f516570c17ce8
  show_ref_link: true
  title: Skip-Thought Vectors
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: exploiting-source-side-monolingual-data-in-neural-machine-translation
  numCitedBy: 214
  pid: d9b03cd97db6255081d1e57983fa673d1f8f2d0e
  show_ref_link: false
  title: Exploiting Source-side Monolingual Data in Neural Machine Translation
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: universal-language-model-fine-tuning-for-text-classification
  numCitedBy: 2251
  pid: 1e077413b25c4d34945cc2707e17e46ed4fe784a
  show_ref_link: true
  title: Universal Language Model Fine-tuning for Text Classification
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: glue-a-multi-task-benchmark-and-analysis-platform-for-natural-language-understanding
  numCitedBy: 2637
  pid: 93b8da28d006415866bf48f9a6e06b5242129195
  show_ref_link: true
  title: GLUE - A Multi-Task Benchmark and Analysis Platform for Natural Language
    Understanding
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: layer-wise-coordination-between-encoder-and-decoder-for-neural-machine-translation
  numCitedBy: 93
  pid: b12ccd118974839db290f15c989649b2b5188636
  show_ref_link: false
  title: Layer-Wise Coordination between Encoder and Decoder for Neural Machine Translation
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: learned-in-translation-contextualized-word-vectors
  numCitedBy: 710
  pid: bc8fa64625d9189f5801837e7b133e7fe3c581f7
  show_ref_link: true
  title: Learned in Translation - Contextualized Word Vectors
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: neural-headline-generation-with-minimum-risk-training
  numCitedBy: 49
  pid: 2aacacb684ea755702c034bca794f35518b471c5
  show_ref_link: false
  title: Neural Headline Generation with Minimum Risk Training
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: neural-machine-translation-of-rare-words-with-subword-units
  numCitedBy: 4795
  pid: 1af68821518f03568f913ab03fc02080247a27ff
  show_ref_link: true
  title: Neural Machine Translation of Rare Words with Subword Units
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: unsupervised-machine-translation-using-monolingual-corpora-only
  numCitedBy: 797
  pid: e3d772986d176057aca2f5e3eb783da53b559134
  show_ref_link: false
  title: Unsupervised Machine Translation Using Monolingual Corpora Only
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: unsupervised-machine-translation-using-monolingual-corpora-only
  numCitedBy: 65
  pid: 57ea3bc5ad8d67909b086a92a801a5e5f2d17035
  show_ref_link: false
  title: UNSUPERVISED MACHINE TRANSLATION USING MONOLINGUAL CORPORA ONLY
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: unsupervised-neural-machine-translation
  numCitedBy: 599
  pid: c2a7afbb5609a723f8eea91bfde4b02579b048d6
  show_ref_link: false
  title: Unsupervised Neural Machine Translation
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: double-path-networks-for-sequence-to-sequence-learning
  numCitedBy: 14
  pid: a4ba799bd373b2923ab67eb0679bf1fe56c25d51
  show_ref_link: false
  title: Double Path Networks for Sequence to Sequence Learning
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: semi-supervised-sequence-learning
  numCitedBy: 881
  pid: 4aa9f5150b46320f534de4747a2dd0cd7f3fe292
  show_ref_link: false
  title: Semi-supervised Sequence Learning
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: multilingual-neural-machine-translation-with-knowledge-distillation
  numCitedBy: 155
  pid: 1b24b7b4ac2427d20ab60c8451563eb8d99caf9c
  show_ref_link: false
  title: Multilingual Neural Machine Translation with Knowledge Distillation
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: unsupervised-pivot-translation-for-distant-languages
  numCitedBy: 19
  pid: 85318466c38f91f21192da24f0ff747b75a39c21
  show_ref_link: false
  title: Unsupervised Pivot Translation for Distant Languages
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: almost-unsupervised-text-to-speech-and-automatic-speech-recognition
  numCitedBy: 59
  pid: a65aaa6bfa182baf06fe2504f0b7098b9ed95618
  show_ref_link: false
  title: Almost Unsupervised Text to Speech and Automatic Speech Recognition
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: a-unified-architecture-for-natural-language-processing-deep-neural-networks-with-multitask-learning
  numCitedBy: 5024
  pid: 57458bc1cffe5caa45a885af986d70f723f406b4
  show_ref_link: true
  title: A unified architecture for natural language processing - deep neural networks
    with multitask learning
  year: 2008
- fieldsOfStudy:
  - Computer Science
  meta_key: unsupervised-statistical-machine-translation
  numCitedBy: 188
  pid: 776b4f1d6ed07f1623831eae2849562cf4381394
  show_ref_link: false
  title: Unsupervised Statistical Machine Translation
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: zero-resource-translation-with-multi-lingual-neural-machine-translation
  numCitedBy: 229
  pid: 198ac64703e83d00eb0f51a4c4a7c77cb08a7e5c
  show_ref_link: false
  title: Zero-Resource Translation with Multi-Lingual Neural Machine Translation
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: cross-lingual-language-model-pretraining
  numCitedBy: 1512
  pid: ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc
  show_ref_link: true
  title: Cross-lingual Language Model Pretraining
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: machine-comprehension-by-text-to-text-neural-question-generation
  numCitedBy: 135
  pid: bc6ad001c395e92920839e45dfd7e05ce69405d2
  show_ref_link: false
  title: Machine Comprehension by Text-to-Text Neural Question Generation
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: convolutional-sequence-to-sequence-learning
  numCitedBy: 2423
  pid: 43428880d75b3a14257c3ee9bda054e61eb869c0
  show_ref_link: true
  title: Convolutional Sequence to Sequence Learning
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation
  numCitedBy: 15052
  pid: 0b544dfe355a5070b60986319a3f51fb45d1348e
  show_ref_link: true
  title: Learning Phrase Representations using RNN Encoder-Decoder for Statistical
    Machine Translation
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: neural-responding-machine-for-short-text-conversation
  numCitedBy: 997
  pid: ba49d3823d43515e447296ca4e1e55d3f1fd8c4d
  show_ref_link: false
  title: Neural Responding Machine for Short-Text Conversation
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank
  numCitedBy: 5367
  pid: 687bac2d3320083eb4530bf18bb8f8f721477600
  show_ref_link: true
  title: Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: dense-information-flow-for-neural-machine-translation
  numCitedBy: 28
  pid: 636280d54ea08cbe37cb4aba3efcec59349eaefa
  show_ref_link: false
  title: Dense Information Flow for Neural Machine Translation
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-contextualized-word-representations
  numCitedBy: 7988
  pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  show_ref_link: true
  title: Deep Contextualized Word Representations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: domain-adaptation-with-structural-correspondence-learning
  numCitedBy: 1518
  pid: 9fa8d73e572c3ca824a04a5f551b602a17831bc5
  show_ref_link: false
  title: Domain Adaptation with Structural Correspondence Learning
  year: 2006
- fieldsOfStudy:
  - Computer Science
  meta_key: cutting-off-redundant-repeating-generations-for-neural-abstractive-summarization
  numCitedBy: 55
  pid: 364f7f7bac907ce326dce84b26eb857f186d3dc2
  show_ref_link: false
  title: Cutting-off Redundant Repeating Generations for Neural Abstractive Summarization
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: achieving-human-parity-on-automatic-chinese-to-english-news-translation
  numCitedBy: 459
  pid: d7dded37a976ebc05103a4f3785969005c37af5b
  show_ref_link: false
  title: Achieving Human Parity on Automatic Chinese to English News Translation
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: distributed-representations-of-sentences-and-documents
  numCitedBy: 7044
  pid: f527bcfb09f32e6a4a8afc0b37504941c1ba2cee
  show_ref_link: true
  title: Distributed Representations of Sentences and Documents
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: a-large-annotated-corpus-for-learning-natural-language-inference
  numCitedBy: 2518
  pid: f04df4e20a18358ea2f689b4c129781628ef7fc1
  show_ref_link: true
  title: A large annotated corpus for learning natural language inference
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: an-efficient-framework-for-learning-sentence-representations
  numCitedBy: 347
  pid: bc1d609520290e0460c49b685675eb5a57fa5935
  show_ref_link: true
  title: An efficient framework for learning sentence representations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: a-neural-probabilistic-language-model
  numCitedBy: 6011
  pid: 6c2b28f9354f667cd5bd07afc0471d8334430da7
  show_ref_link: false
  title: A Neural Probabilistic Language Model
  year: 2000
- fieldsOfStudy:
  - Computer Science
  meta_key: glove-global-vectors-for-word-representation
  numCitedBy: 22538
  pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  show_ref_link: true
  title: GloVe - Global Vectors for Word Representation
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: squad-100-000-questions-for-machine-comprehension-of-text
  numCitedBy: 4266
  pid: 05dd7254b632376973f3a1b4d39485da17814df5
  show_ref_link: true
  title: SQuAD - 100,000+ Questions for Machine Comprehension of Text
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: distributed-representations-of-words-and-phrases-and-their-compositionality
  numCitedBy: 26054
  pid: 87f40e6f3022adbc1f1905e3e506abad05a9964f
  show_ref_link: true
  title: Distributed Representations of Words and Phrases and their Compositionality
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-residual-learning-for-image-recognition
  numCitedBy: 95351
  pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  show_ref_link: true
  title: Deep Residual Learning for Image Recognition
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: recurrent-neural-network-based-language-model
  numCitedBy: 4902
  pid: 9819b600a828a57e1cde047bbe710d3446b30da5
  show_ref_link: true
  title: Recurrent neural network based language model
  year: 2010
- fieldsOfStudy:
  - Computer Science
  meta_key: rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation
  numCitedBy: 17089
  pid: 2f4df08d9072fc2ac181b7fced6a245315ce05c8
  show_ref_link: true
  title: Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: a-framework-for-learning-predictive-structures-from-multiple-tasks-and-unlabeled-data
  numCitedBy: 1414
  pid: 944e1a7b2c5c62e952418d7684e3cade89c76f87
  show_ref_link: false
  title: A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled
    Data
  year: 2005
- fieldsOfStudy:
  - Psychology
  meta_key: chameleons-in-imagined-conversations-a-new-approach-to-understanding-coordination-of-linguistic-style-in-dialogs
  numCitedBy: 321
  pid: ea45438193cd724445d08cf3a1fa9137ffed54f6
  show_ref_link: false
  title: Chameleons in Imagined Conversations - A New Approach to Understanding Coordination
    of Linguistic Style in Dialogs
  year: 2011
- fieldsOfStudy:
  - Computer Science
  meta_key: adam-a-method-for-stochastic-optimization
  numCitedBy: 90091
  pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  show_ref_link: true
  title: Adam - A Method for Stochastic Optimization
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: extracting-and-composing-robust-features-with-denoising-autoencoders
  numCitedBy: 5471
  pid: 843959ffdccf31c6694d135fad07425924f785b1
  show_ref_link: true
  title: Extracting and composing robust features with denoising autoencoders
  year: 2008
- fieldsOfStudy:
  - Computer Science
  meta_key: going-deeper-with-convolutions
  numCitedBy: 29484
  pid: e15cf50aa89fee8535703b9f9512fca5bfc43327
  show_ref_link: true
  title: Going deeper with convolutions
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: learning-deep-representation-with-large-scale-attributes
  numCitedBy: 21
  pid: b55da293699ddea02fc4a6c8bb197375e4cfa195
  show_ref_link: false
  title: Learning Deep Representation with Large-Scale Attributes
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: class-based-n-gram-models-of-natural-language
  numCitedBy: 3318
  pid: 3de5d40b60742e3dfa86b19e7f660962298492af
  show_ref_link: false
  title: Class-Based n-gram Models of Natural Language
  year: 1992
- fieldsOfStudy:
  - Computer Science
  meta_key: introduction-to-the-conll-2003-shared-task-language-independent-named-entity-recognition
  numCitedBy: 2960
  pid: 10f97f1fb4f5c2c8e6c44d4a33da46d331dd4aeb
  show_ref_link: false
  title: Introduction to the CoNLL-2003 Shared Task - Language-Independent Named Entity
    Recognition
  year: 2003
slug: MASS:-Masked-Sequence-to-Sequence-Pre-training-for-Song-Tan
title: MASS - Masked Sequence to Sequence Pre-training for Language Generation
url: https://www.semanticscholar.org/paper/MASS:-Masked-Sequence-to-Sequence-Pre-training-for-Song-Tan/145b8b5d99a2beba6029418ca043585b90138d12?sort=total-citations
venue: ICML
year: 2019
