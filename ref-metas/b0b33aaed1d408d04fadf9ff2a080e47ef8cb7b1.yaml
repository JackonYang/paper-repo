authors:
- Michiel Hermans
- B. Schrauwen
badges: []
corpusId: 20071973
fieldsOfStudy:
- Computer Science
numCitedBy: 397
numCiting: 18
paperAbstract: Time series often have a temporal hierarchy, with information that
  is spread out over multiple time scales. Common recurrent neural networks, however,
  do not explicitly accommodate such a hierarchy, and most research on them has been
  focusing on training algorithms rather than on their basic architecture. In this
  pa- per we study the effect of a hierarchy of recurrent neural networks on processing
  time series. Here, each layer is a recurrent network which receives the hidden state
  of the previous layer as input. This architecture allows us to perform hi- erarchical
  processing on difficult temporal tasks, and more naturally capture the structure
  of time series. We show that they reach state-of-the-art performance for recurrent
  networks in character-level language modelling when trained with sim- ple stochastic
  gradient descent. We also offer an analysis of the different emergent time scales.
ref_count: 18
references:
- pid: b13813b49f160e1a2010c44bd4fb3d09a28446e3
  title: Hierarchical Recurrent Neural Networks for Long-Term Dependencies
- pid: e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de
  title: Generating Text with Recurrent Neural Networks
- pid: 0d6203718c15f137fda2f295c96269bc2b254644
  title: Learning Recurrent Neural Networks with Hessian-Free Optimization
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 4177ec52d1b80ed57f2e72b0f9a42365f1a8598d
  title: Speech recognition with deep recurrent neural networks
- pid: 8978cf7574ceb35f4c3096be768c7547b28a35d0
  title: A Fast Learning Algorithm for Deep Belief Nets
- pid: d2b62f77cb2864e465aa60bca6c26bb1d2f84963
  title: Acoustic Modeling Using Deep Belief Networks
- pid: 843959ffdccf31c6694d135fad07425924f785b1
  title: Extracting and composing robust features with denoising autoencoders
- pid: 46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e
  title: Reducing the Dimensionality of Data with Neural Networks
- pid: 4c46347fbc272b21468efe3d9af34b4b2bad6684
  title: Deep learning via Hessian-free optimization
- pid: b98cd08b75ebf2bd1d1ec47c51ef75777a7e64bd
  title: Deep, Big, Simple Neural Nets for Handwritten Digit Recognition
- pid: 5936754b5762260bf102ac95d7b26cfc9d31956a
  title: The Tradeoffs of Large Scale Learning
- pid: c1e3f2d537e50e0d5263e4731ab6c7983acd6687
  title: Prediction and entropy of printed English
- pid: 47128bb3ce4ed00691c0d7d58c02791c3e963ab7
  title: Darpa Timit Acoustic-Phonetic Continuous Speech Corpus CD-ROM {TIMIT} | NIST
slug: Training-and-Analysing-Deep-Recurrent-Neural-Hermans-Schrauwen
title: Training and Analysing Deep Recurrent Neural Networks
url: https://www.semanticscholar.org/paper/Training-and-Analysing-Deep-Recurrent-Neural-Hermans-Schrauwen/b0b33aaed1d408d04fadf9ff2a080e47ef8cb7b1?sort=total-citations
venue: NIPS
year: 2013
