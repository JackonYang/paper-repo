authors:
- Ahmad Emami
- P. Xu
- F. Jelinek
badges:
- id: OPEN_ACCESS
corpusId: 6529491
fieldsOfStudy:
- Computer Science
numCitedBy: 34
numCiting: 9
paperAbstract: We investigate the performance of the Structured Language Model when
  one of its components is modeled by a connectionist model. Using a connectionist
  model and a distributed representation of the items in the history makes the component
  able to use much longer contexts than possible with currently used interpolated
  or backoff models, both because of the inherent capability of the connectionist
  model to fight the data sparseness problem, and because of the only sub-linear growth
  in the model size when increasing the context length. Experiments show significant
  improvement in perplexity and moderate reduction in word error rate over the baseline
  SLM results on the UPENN treebank and Wall Street Journal (WSJ) corpora respectively.
  The results also show that the probability distribution obtained by our model is
  much less correlated to regular N-grams than the baseline SLM model.
ref_count: 9
references:
- pid: a1c3748820d6b5ab4e7334524815df9bb6d20aed
  title: Structured language modeling
- pid: 6c2b28f9354f667cd5bd07afc0471d8334430da7
  title: A Neural Probabilistic Language Model
- pid: e41498c05d4c68e4750fb84a380317a112d97b01
  title: Connectionist language modeling for large vocabulary continuous speech recognition
- pid: fb486e03369a64de2d5b0df86ec0a7b55d3907db
  title: A Maximum Entropy Approach to Natural Language Processing
slug: Using-a-connectionist-model-in-a-syntactical-based-Emami-Xu
title: Using a connectionist model in a syntactical based language model
url: https://www.semanticscholar.org/paper/Using-a-connectionist-model-in-a-syntactical-based-Emami-Xu/3d6036af971c1f11ab712cc41487376a94e63673?sort=total-citations
venue: 2003 IEEE International Conference on Acoustics, Speech, and Signal Processing,
  2003. Proceedings. (ICASSP '03).
year: 2003
