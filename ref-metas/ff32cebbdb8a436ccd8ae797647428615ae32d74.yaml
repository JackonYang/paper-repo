authors:
- P. Simard
- B. Victorri
- Yann LeCun
- J. Denker
badges:
- id: OPEN_ACCESS
corpusId: 2184474
fieldsOfStudy:
- Computer Science
numCitedBy: 286
numCiting: 2
paperAbstract: "In many machine learning applications, one has access, not only to\
  \ training data, but also to some high-level a priori knowledge about the desired\
  \ behavior of the system. For example, it is known in advance that the output of\
  \ a character recognizer should be invariant with respect to small spatial distortions\
  \ of the input images (translations, rotations, scale changes, etcetera). \n \n\
  We have implemented a scheme that allows a network to learn the derivative of its\
  \ outputs with respect to distortion operators of our choosing. This not only reduces\
  \ the learning time and the amount of training data, but also provides a powerful\
  \ language for specifying what generalizations we wish the network to perform."
ref_count: 2
references:
- pid: 01b6affe3ea4eae1978aec54e87087feb76d9215
  title: Generalization and network design strategies
slug: Tangent-Prop-A-Formalism-for-Specifying-Selected-in-Simard-Victorri
title: Tangent Prop - A Formalism for Specifying Selected Invariances in an Adaptive
  Network
url: https://www.semanticscholar.org/paper/Tangent-Prop-A-Formalism-for-Specifying-Selected-in-Simard-Victorri/ff32cebbdb8a436ccd8ae797647428615ae32d74?sort=total-citations
venue: NIPS
year: 1991
