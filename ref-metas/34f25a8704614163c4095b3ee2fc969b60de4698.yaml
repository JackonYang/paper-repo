authors:
- Nitish Srivastava
- Geoffrey E. Hinton
- A. Krizhevsky
- Ilya Sutskever
- R. Salakhutdinov
badges:
- id: OPEN_ACCESS
corpusId: 6844431
fieldsOfStudy:
- Computer Science
numCitedBy: 28149
numCiting: 43
paperAbstract: Deep neural nets with a large number of parameters are very powerful
  machine learning systems. However, overfitting is a serious problem in such networks.
  Large networks are also slow to use, making it difficult to deal with overfitting
  by combining the predictions of many different large neural nets at test time. Dropout
  is a technique for addressing this problem. The key idea is to randomly drop units
  (along with their connections) from the neural network during training. This prevents
  units from co-adapting too much. During training, dropout samples from an exponential
  number of different "thinned" networks. At test time, it is easy to approximate
  the effect of averaging the predictions of all these thinned networks by simply
  using a single unthinned network that has smaller weights. This significantly reduces
  overfitting and gives major improvements over other regularization methods. We show
  that dropout improves the performance of neural networks on supervised learning
  tasks in vision, speech recognition, document classification and computational biology,
  obtaining state-of-the-art results on many benchmark data sets.
ref_count: 43
references:
- pid: 5d5d4f49d6443c8529a6f5ebef5c499d47a869da
  title: Improving Neural Networks with Dropout
- pid: 5d90f06bb70a0a3dced62413346235c02b1aa086
  title: Learning Multiple Layers of Features from Tiny Images
- pid: ec92efde21707ddf4b81f301cd58e2051c1a2443
  title: Fast dropout training
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: 8978cf7574ceb35f4c3096be768c7547b28a35d0
  title: A Fast Learning Algorithm for Deep Belief Nets
- pid: de75e4e15e22d4376300e5c968e2db44be29ac9e
  title: Simplifying Neural Networks by Soft Weight-Sharing
- pid: 85021c84383d18a7a4434d76dc8135fc6bdc0aa6
  title: Deep Boltzmann Machines
- pid: db869fa192a3222ae4f2d766674a378e47013b1b
  title: Bayesian Learning for Neural Networks
- pid: e2b7f37cd97a7907b1b8a41138721ed06a0b76cd
  title: 'Stacked Denoising Autoencoders: Learning Useful Representations in a Deep
    Network with a Local Denoising Criterion'
- pid: 90b63e917d5737b06357d50aa729619e933d9614
  title: Phone Recognition with the Mean-Covariance Restricted Boltzmann Machine
- pid: d2b62f77cb2864e465aa60bca6c26bb1d2f84963
  title: Acoustic Modeling Using Deep Belief Networks
- pid: 2e2089ae76fe914706e6fa90081a79c8fe01611e
  title: Practical Bayesian Optimization of Machine Learning Algorithms
- pid: 0abb49fe138e8fb7332c26b148a48d0db39724fc
  title: Stochastic Pooling for Regularization of Deep Convolutional Neural Networks
- pid: 5562a56da3a96dae82add7de705e2bd841eb00fc
  title: Best practices for convolutional neural networks applied to visual document
    analysis
- pid: 46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e
  title: Reducing the Dimensionality of Data with Neural Networks
- pid: b7b915d508987b73b61eccd2b237e7ed099a2d29
  title: Maxout Networks
- pid: 02227c94dd41fe0b439e050d377b0beb5d427cda
  title: Reading Digits in Natural Images with Unsupervised Feature Learning
- pid: 843959ffdccf31c6694d135fad07425924f785b1
  title: Extracting and composing robust features with denoising autoencoders
- pid: 9f7f9aba0a6a966ce04e29e401ea28f9eae82f02
  title: Convolutional neural networks applied to house numbers digit classification
- pid: 1f88427d7aa8225e47f946ac41a0667d7b69ac52
  title: What is the best multi-stage architecture for object recognition?
- pid: a8e8f3c8d4418c8d62e306538c9c1292635e9d27
  title: Backpropagation Applied to Handwritten Zip Code Recognition
- pid: 3a1a2cff2b70fb84a7ca7d97f8adcc5855851795
  title: The Kaldi Speech Recognition Toolkit
- pid: b365b8e45b7d81f081de44ac8f9eadf9144f3ca5
  title: Regression Shrinkage and Selection via the Lasso
- pid: eefcc7bcc05436dac9881acb4ff4e4a0b730e175
  title: High-dimensional signature compression for large-scale image classification
- pid: 0ea90fac0958d84bcf4a2875c2b169478358b480
  title: 'CUDAMat: a CUDA-based matrix class for Python'
- pid: 8423a5782a1acda21a6f68c307ce5376ebef13c7
  title: Rank, Trace-Norm and Max-Norm
slug: Dropout:-a-simple-way-to-prevent-neural-networks-Srivastava-Hinton
title: 'Dropout: a simple way to prevent neural networks from overfitting'
url: https://www.semanticscholar.org/paper/Dropout:-a-simple-way-to-prevent-neural-networks-Srivastava-Hinton/34f25a8704614163c4095b3ee2fc969b60de4698?sort=total-citations
venue: J. Mach. Learn. Res.
year: 2014
