authors:
- Zhe Gan
- Yen-Chun Chen
- Linjie Li
- Chen Zhu
- Yu Cheng
- Jingjing Liu
badges:
- id: OPEN_ACCESS
corpusId: 219573512
fieldsOfStudy:
- Computer Science
numCitedBy: 169
numCiting: 93
paperAbstract: 'We present VILLA, the first known effort on large-scale adversarial
  training for vision-and-language (V+L) representation learning. VILLA consists of
  two training stages: (i) task-agnostic adversarial pre-training; followed by (ii)
  task-specific adversarial finetuning. Instead of adding adversarial perturbations
  on image pixels and textual tokens, we propose to perform adversarial training in
  the embedding space of each modality. To enable large-scale training, we adopt the
  "free" adversarial training strategy, and combine it with KL-divergence-based regularization
  to promote higher invariance in the embedding space. We apply VILLA to current best-performing
  V+L models, and achieve new state of the art on a wide range of tasks, including
  Visual Question Answering, Visual Commonsense Reasoning, Image-Text Retrieval, Referring
  Expression Comprehension, Visual Entailment, and NLVR2.'
ref_count: 94
references:
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 63
  pid: d2038ced371e45aee3651c7a595c4566f4826b9f
  title: 'FreeLB: Enhanced Adversarial Training for Language Understanding'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 64
  pid: 26cfb57a9722599b361858d454ec816420723e36
  title: 'Behind the Scene: Revealing the Secrets of Pre-trained Vision-and-Language
    Models'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 580
  pid: 2cd55ded95d5d13430edfa223ba591b514ebe8a5
  title: Adversarial Training Methods for Semi-Supervised Text Classification
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 282
  pid: 54416048772b921720f19869ed11c2a360589d03
  title: 'UNITER: Learning UNiversal Image-TExt Representations'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 382
  pid: 2bc1c8bd00bbf7401afcb5460277840fd8bab029
  title: 'Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal
    Pre-training'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1266
  pid: 65a9c7b0800c86a196bc14e7621ff895cc6ab287
  title: 'ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language
    Tasks'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 355
  pid: 6648b4db5f12c30941ea78c695e77aded19672bb
  title: Unified Vision-Language Pre-Training for Image Captioning and VQA
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 569
  pid: c41a11c0e9b8b92b4faaf97749841170b760760a
  title: 'VideoBERT: A Joint Model for Video and Language Representation Learning'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 916
  pid: 79c93274429d6355959f1e4374c2147bb81ea649
  title: 'LXMERT: Learning Cross-Modality Encoder Representations from Transformers'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 227
  pid: 6548a60a6bcdf6c402d9de1c05ba7afe4f49fee9
  title: '12-in-1: Multi-Task Vision and Language Representation Learning'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 534
  pid: 41071dbbbcbb27af3fec70de045f19c28535f5b7
  title: Feature Denoising for Improving Adversarial Robustness
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 534
  pid: 818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57
  title: 'Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 33744
  pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 368
  pid: 8e9ad6f8b2bc97f0412fa0cc243ac6975864534a
  title: Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual
    Question Answering
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 95
  pid: 6fa25c94e41a0c90e3aabe80cf60f59ec9ff0a52
  title: Towards Learning a Generic Agent for Vision-and-Language Navigation via Pre-Training
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 10104
  pid: bee044c8e8903fb67523c1f8c105ab4718600cdb
  title: Explaining and Harnessing Adversarial Examples
  year: 2015
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 372
  pid: 6dfc2ff03534a4325d06c6f88c3144831996629b
  title: 'From Recognition to Cognition: Visual Commonsense Reasoning'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 630
  pid: 5aec474c31a2f4b74703c6f786c0a8ff85c450da
  title: 'VisualBERT: A Simple and Performant Baseline for Vision and Language'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1162
  pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  title: 'Making the V in VQA Matter: Elevating the Role of Image Understanding in
    Visual Question Answering'
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 707
  pid: 2527626c11a84f15709e943fbfa2356e19930e3b
  title: 'VL-BERT: Pre-training of Generic Visual-Linguistic Representations'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 99
  pid: 3c54b796cc10cb530f77caa4d18e1c80ac863822
  title: 'Visual Entailment: A Novel Task for Fine-Grained Image Understanding'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1086
  pid: fddc15480d086629b960be5bff96232f967f2252
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 323
  pid: 8a1744da011375d711ed75fc2d160c6fdca2cf89
  title: Deep Modular Co-Attention Networks for Visual Question Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 149
  pid: 6ac33d3dcecbed17580509a34bccdff2425f7ed8
  title: Learning Conditioned Graph Structures for Interpretable Visual Question Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 35148
  pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  title: Attention is All you Need
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 733
  pid: 21c99706bb26e9012bfb4d8d48009a3d45af59b2
  title: Neural Module Networks
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 117
  pid: f259bc7ef31c4ec7dd041c94bfd6b2f93b99b47c
  title: Contrastive Bidirectional Transformer for Temporal Representation Learning
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 148
  pid: 598a2ee223e2949c3b28389e922c1892b4717d2a
  title: 'Pixel-BERT: Aligning Image Pixels with Text by Deep Multi-Modal Transformers'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1121
  pid: fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b
  title: Hierarchical Question-Image Co-Attention for Visual Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 168
  pid: 0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3
  title: 'MUREL: Multimodal Relational Reasoning for Visual Question Answering'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 111
  pid: b82153bf85d5d1edd3f170aace830e5328ca9ed0
  title: Fusion of Detected Objects in Text for Visual Question Answering
  year: 2019
- fieldsOfStudy:
  - Psychology
  numCitedBy: 1035
  pid: 43f2ad297941db230c089ba353efc3f281ab678c
  title: "5\u5206\u3067\u5206\u304B\u308B!? \u6709\u540D\u8AD6\u6587\u30CA\u30CA\u30E1\
    \u8AAD\u307F\uFF1AJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional\
    \ Transformers for Language Understanding"
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 448
  pid: 1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1
  title: 'GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question
    Answering'
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 408
  pid: a5d10341717c0519cf63151b496a6d2ed67aa05f
  title: Bilinear Attention Networks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 430
  pid: a396a6febdacb84340d139096455e67049ac1e22
  title: 'Learning to Reason: End-to-End Module Networks for Visual Question Answering'
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 2772
  pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 146
  pid: d379ba96b8f400b23b2cd72c428af67e578959ea
  title: Relation-Aware Graph Attention Network for Visual Question Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 8881
  pid: d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad
  title: Intriguing properties of neural networks
  year: 2014
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 401
  pid: 289fb3709475f5c87df8d97f129af54029d27fee
  title: Compositional Attention Networks for Machine Reasoning
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 664
  pid: 0612745dbd292fc0a548a16d39cd73e127faedde
  title: 'Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer
    Image-to-Sentence Models'
  year: 2015
- fieldsOfStudy:
  - Psychology
  numCitedBy: 1035
  pid: 43f2ad297941db230c089ba353efc3f281ab678c
  title: "5\u5206\u3067\u5206\u304B\u308B!? \u6709\u540D\u8AD6\u6587\u30CA\u30CA\u30E1\
    \u8AAD\u307F\uFF1AJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional\
    \ Transformers for Language Understanding"
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1197
  pid: 007112213ece771be72cbecfd59f048209facabd
  title: A simple neural network module for relational reasoning
  year: 2017
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 481
  pid: 45dd2a3cd7c27f2e9509b023d702408f5ac11c9d
  title: Stacked Cross Attention for Image-Text Matching
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 192
  pid: e9b13731027418ed38103d1dfc8a70f6881bc684
  title: Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question
    Answering
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 1474
  pid: 2c1890864c1c2b750f48316dc8b650ba4772adc5
  title: Stacked Attention Networks for Image Question Answering
  year: 2016
- fieldsOfStudy:
  - Computer Science
  - Environmental Science
  numCitedBy: 632
  pid: b4df354db88a70183a64dbc9e56cf14e7669a6c0
  title: 'Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic
    Image Captioning'
  year: 2018
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 378
  pid: 29efbe391950ae438c63d86ad5c82b2942efb0b4
  title: Modeling Context in Referring Expressions
  year: 2016
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 32
  pid: 320464aa0231bc728c7d9ab7e71e552c12a7486b
  title: Meta Module Network for Compositional Visual Reasoning
  year: 2021
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 19778
  pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
  year: 2014
- fieldsOfStudy:
  - Psychology
  numCitedBy: 1035
  pid: 43f2ad297941db230c089ba353efc3f281ab678c
  title: "5\u5206\u3067\u5206\u304B\u308B!? \u6709\u540D\u8AD6\u6587\u30CA\u30CA\u30E1\
    \u8AAD\u307F\uFF1AJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional\
    \ Transformers for Language Understanding"
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 734
  pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  title: 'Im2Text: Describing Images Using 1 Million Captioned Photographs'
  year: 2011
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 413
  pid: 2e17cf6a339fd071ad222062f868e882ef4120a4
  title: Inferring and Executing Programs for Visual Reasoning
  year: 2017
- fieldsOfStudy:
  - Psychology
  numCitedBy: 1035
  pid: 43f2ad297941db230c089ba353efc3f281ab678c
  title: "5\u5206\u3067\u5206\u304B\u308B!? \u6709\u540D\u8AD6\u6587\u30CA\u30CA\u30E1\
    \u8AAD\u307F\uFF1AJacob Devlin et al. : BERT : Pre-training of Deep Bidirectional\
    \ Transformers for Language Understanding"
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 577
  pid: d8a305b9366608d54452ac30459ee57b4f5cf1c9
  title: 'UNITER: UNiversal Image-TExt Representation Learning'
  year: 2020
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 170
  pid: 025a0dc4a2a98742f1b410b6318a46de2c854b22
  title: Learning Video Representations using Contrastive Bidirectional Transformer
  year: 2019
- fieldsOfStudy:
  - Computer Science
  numCitedBy: 93
  pid: 735a63b58349e07b84c2e31927ce1b1cfaf09980
  title: Cycle-Consistency for Robust Visual Question Answering
  year: 2019
- fieldsOfStudy: []
  numCitedBy: 0
  pid: 784da2a7b53a16d2243f747e14946cc5e3476af0
  title: 'VQA: Visual Question Answering'
  year: 2015
slug: Large-Scale-Adversarial-Training-for-Representation-Gan-Chen
title: Large-Scale Adversarial Training for Vision-and-Language Representation Learning
url: https://www.semanticscholar.org/paper/Large-Scale-Adversarial-Training-for-Representation-Gan-Chen/2f5f81bc516a6d085d39479378af1fc27104f91e?sort=total-citations
venue: NeurIPS
year: 2020
