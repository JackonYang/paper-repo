authors:
- J. Lafferty
- A. McCallum
- Fernando Pereira
badges:
- id: OPEN_ACCESS
corpusId: 219683473
fieldsOfStudy:
- Computer Science
numCitedBy: 13409
numCiting: 75
paperAbstract: We present conditional random fields , a framework for building probabilistic
  models to segment and label sequence data. Conditional random fields offer several
  advantages over hidden Markov models and stochastic grammars for such tasks, including
  the ability to relax strong independence assumptions made in those models. Conditional
  random fields also avoid a fundamental limitation of maximum entropy Markov models
  (MEMMs) and other discriminative Markov models based on directed graphical models,
  which can be biased towards states with few successor states. We present iterative
  parameter estimation algorithms for conditional random fields and compare the performance
  of the resulting models to HMMs and MEMMs on synthetic and natural-language data.
ref_count: 76
references:
- pid: bece46ed303f8eaef2affae2cba4e0aef51fe636
  title: Maximum Entropy Markov Models for Information Extraction and Segmentation
- pid: 02c8a0bc8bab9920e6615cfacf1df2ab3f2b1f68
  title: Information Extraction with HMM Structures Learned by Stochastic Optimization
- pid: b951b9f78b98a186ba259027996a48e4189d37e5
  title: Inducing Features of Random Fields
- pid: f72084efcae8b2007e590b0c5a8f1decb61ef935
  title: A whole sentence maximum entropy language model
- pid: 2dc4d6d7d55f9f0f1de53bb7f6816502f8f38892
  title: Boltzmann Chains and Hidden Markov Models
- pid: 3fab92869cfab684b3ffb1c16a771e9c3b774acd
  title: The Use of Classifiers in Sequential Inference
- pid: 571f5bbecd3a083a2bb6844f59a3f8cea237252e
  title: 'Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic
    Acids'
- pid: 3ed17a1114e2dc48597ab17cc8d5234006f525c9
  title: 'Learning to Resolve Natural Language Ambiguities: A Unified Approach'
- pid: fb486e03369a64de2d5b0df86ec0a7b55d3907db
  title: A Maximum Entropy Approach to Natural Language Processing
- pid: a574e320d899e7e82e341eb64baef7dfe8a24642
  title: A Maximum Entropy Model for Part-Of-Speech Tagging
- pid: 084c55d6432265785e3ff86a2e900a49d501c00a
  title: Foundations of statistical natural language processing
- pid: f4cc5563c694355ddcf746ff9a55ccdb22d86a98
  title: Finite-State Transducers in Language and Speech Processing
- pid: ccf5208521cb8c35f50ee8873df89294b8ed7292
  title: A decision-theoretic generalization of on-line learning and an application
    to boosting
- pid: 162d958ff885f1462aeda91cd72582323fd6a1f4
  title: Gradient-based learning applied to document recognition
- pid: f42b865e20e61a954239f421b42007236e671f19
  title: GradientBased Learning Applied to Document Recognition
- pid: 2b2eb4a9bb146e3ffaa0b025fba0ed14240c683f
  title: 'Transformation-Based Error-Driven Learning and Natural Language Processing:
    A Case Study in Part-of-Speech Tagging'
- pid: 37c931cbaa9217b829596dd196520a838562a109
  title: Generalized Iterative Scaling for Log-Linear Models
- pid: ec75e3ca906681bd900218a348a4a35dfed3d6fd
  title: Markov fields on finite graphs and lattices
- pid: 4ba566223e426677d12a9a18418c023a4deec77e
  title: A Decision-Theoretic Generalization of On-Line Learning and an Application
    to Boosting
slug: Conditional-Random-Fields:-Probabilistic-Models-for-Lafferty-McCallum
title: 'Conditional Random Fields: Probabilistic Models for Segmenting and Labeling
  Sequence Data'
url: https://www.semanticscholar.org/paper/Conditional-Random-Fields:-Probabilistic-Models-for-Lafferty-McCallum/f4ba954b0412773d047dc41231c733de0c1f4926?sort=total-citations
venue: ICML
year: 2001
