authors:
- Kushal Kafle
- Christopher Kanan
badges:
- id: OPEN_ACCESS
corpusId: 8409675
fieldsOfStudy:
- Computer Science
numCitedBy: 89
numCiting: 22
paperAbstract: 'Recently, algorithms for object recognition and related tasks have
  become sufficiently proficient that new vision tasks can now be pursued. In this
  paper, we build a system capable of answering open-ended text-based questions about
  images, which is known as Visual Question Answering (VQA). Our approach''s key insight
  is that we can predict the form of the answer from the question. We formulate our
  solution in a Bayesian framework. When our approach is combined with a discriminative
  model, the combined model achieves state-of-the-art results on four benchmark datasets
  for open-ended VQA: DAQUAR, COCO-QA, The VQA Dataset, and Visual7W.'
ref_count: 22
references:
- pid: 62a956d7600b10ca455076cd56e604dfd106072a
  title: Exploring Models and Data for Image Question Answering
- pid: def584565d05d6a8ba94de6621adab9e301d375d
  title: 'Visual7W: Grounded Question Answering in Images'
- pid: bd7bd1d2945a58cdcc1797ba9698b8810fe68f60
  title: 'Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images'
- pid: ac64fb7e6d2ddf236332ec9f371fe85d308c114d
  title: A Multi-World Approach to Question Answering about Real-World Scenes based
    on Uncertain Input
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: 2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1
  title: Are You Talking to a Machine? Dataset and Methods for Multilingual Image
    Question
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: 6e795c6e9916174ae12349f5dc3f516570c17ce8
  title: Skip-Thought Vectors
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: e74f9b7f8eec6ba4704c206b93bc8079af3da4bd
  title: ImageNet Large Scale Visual Recognition Challenge
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: b35e4d00d9a9bfae83a8b0914eb1073a77a11d78
  title: 'Contextual guidance of eye movements and attention in real-world scenes:
    the role of global features in object search.'
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: 90929a6aa901ba958eb4960aeeb594c752e08369
  title: 'On Discriminative vs. Generative Classifiers: A comparison of logistic regression
    and naive Bayes'
- pid: c1994ba5946456fc70948c549daf62363f13fa2d
  title: Indoor Segmentation and Support Inference from RGBD Images
- pid: 0e3e3c3d8ae5cb7c4636870d69967c197484d3bb
  title: Verb Semantics and Lexical Selection
slug: Answer-Type-Prediction-for-Visual-Question-Kafle-Kanan
title: Answer-Type Prediction for Visual Question Answering
url: https://www.semanticscholar.org/paper/Answer-Type-Prediction-for-Visual-Question-Kafle-Kanan/ebe5081b8a24b4740db929b6eae75f28f8edbc58?sort=total-citations
venue: 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2016
