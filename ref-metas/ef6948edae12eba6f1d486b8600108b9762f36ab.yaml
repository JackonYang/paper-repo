authors:
- Kevin Clark
- Minh-Thang Luong
- Urvashi Khandelwal
- Christopher D. Manning
- Quoc V. Le
badges:
- id: OPEN_ACCESS
corpusId: 85464175
fieldsOfStudy:
- Computer Science
meta_key: bam-born-again-multi-task-networks-for-natural-language-understanding
numCitedBy: 139
numCiting: 48
paperAbstract: It can be challenging to train multi-task neural networks that outperform
  or even match their single-task counterparts. To help address this, we propose using
  knowledge distillation where single-task models teach a multi-task model. We enhance
  this training with teacher annealing, a novel method that gradually transitions
  the model from distillation to supervised learning, helping the multi-task model
  surpass its single-task teachers. We evaluate our approach by multi-task fine-tuning
  BERT on the GLUE benchmark. Our method consistently improves over standard single-task
  and multi-task training.
ref_count: 48
references:
- fieldsOfStudy:
  - Computer Science
  meta_key: a-joint-many-task-model-growing-a-neural-network-for-multiple-nlp-tasks
  numCitedBy: 461
  pid: ade0c116120b54b57a91da51235108b75c28375a
  show_ref_link: true
  title: A Joint Many-Task Model - Growing a Neural Network for Multiple NLP Tasks
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: improving-multi-task-deep-neural-networks-via-knowledge-distillation-for-natural-language-understanding
  numCitedBy: 103
  pid: 7ebed46b7f3ec913e508e6468304fcaea832eda1
  show_ref_link: false
  title: Improving Multi-Task Deep Neural Networks via Knowledge Distillation for
    Natural Language Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: multi-task-deep-neural-networks-for-natural-language-understanding
  numCitedBy: 732
  pid: 658721bc13b0fa97366d38c05a96bf0a9f4bb0ac
  show_ref_link: true
  title: Multi-Task Deep Neural Networks for Natural Language Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: identifying-beneficial-task-relations-for-multi-task-learning-in-deep-neural-networks
  numCitedBy: 199
  pid: 1b02204b210f822dabf8d68b7e3ea7ac14ee1268
  show_ref_link: false
  title: Identifying beneficial task relations for multi-task learning in deep neural
    networks
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: latent-multi-task-architecture-learning
  numCitedBy: 157
  pid: ebf7b916cf84f9e43d5948395a48e18688c5464d
  show_ref_link: false
  title: Latent Multi-Task Architecture Learning
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: a-hierarchical-multi-task-approach-for-learning-embeddings-from-semantic-tasks
  numCitedBy: 145
  pid: c3d8d98847bd33fa48bc6448316f78ed7f131afe
  show_ref_link: false
  title: A Hierarchical Multi-task Approach for Learning Embeddings from Semantic
    Tasks
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-multi-task-learning-with-low-level-tasks-supervised-at-lower-layers
  numCitedBy: 392
  pid: 03ad06583c9721855ccd82c3d969a01360218d86
  show_ref_link: true
  title: Deep multi-task learning with low level tasks supervised at lower layers
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: a-unified-architecture-for-natural-language-processing-deep-neural-networks-with-multitask-learning
  numCitedBy: 5024
  pid: 57458bc1cffe5caa45a885af986d70f723f406b4
  show_ref_link: true
  title: A unified architecture for natural language processing - deep neural networks
    with multitask learning
  year: 2008
- fieldsOfStudy:
  - Computer Science
  meta_key: can-you-tell-me-how-to-get-past-sesame-street-sentence-level-pretraining-beyond-language-modeling
  numCitedBy: 71
  pid: 06a1bf4a7333bbc78dbd7470666b33bd9e26882b
  show_ref_link: false
  title: Can You Tell Me How to Get Past Sesame Street? Sentence-Level Pretraining
    Beyond Language Modeling
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: an-overview-of-multi-task-learning-in-deep-neural-networks
  numCitedBy: 1534
  pid: 6d431f835c06afdea45dff6b24486bf301ebdef0
  show_ref_link: true
  title: An Overview of Multi-Task Learning in Deep Neural Networks
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding
  numCitedBy: 33781
  pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  show_ref_link: true
  title: BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: multi-task-sequence-to-sequence-learning
  numCitedBy: 683
  pid: d76c07211479e233f7c6a6f32d5346c983c5598f
  show_ref_link: true
  title: Multi-task Sequence to Sequence Learning
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: glue-a-multi-task-benchmark-and-analysis-platform-for-natural-language-understanding
  numCitedBy: 2638
  pid: 93b8da28d006415866bf48f9a6e06b5242129195
  show_ref_link: true
  title: GLUE - A Multi-Task Benchmark and Analysis Platform for Natural Language
    Understanding
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: distilling-word-embeddings-an-encoding-approach
  numCitedBy: 20
  pid: 7613d67c7348f746ecaf71c6fd034fd577154050
  show_ref_link: false
  title: Distilling Word Embeddings - An Encoding Approach
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: looking-for-elmo-s-friends-sentence-level-pretraining-beyond-language-modeling
  numCitedBy: 28
  pid: 256623ff025f36d343588bcd0b966c1fd26afcf8
  show_ref_link: false
  title: Looking for ELMo's friends - Sentence-Level Pretraining Beyond Language Modeling
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: sentence-encoders-on-stilts-supplementary-training-on-intermediate-labeled-data-tasks
  numCitedBy: 264
  pid: b47381e04739ea3f392ba6c8faaf64105493c196
  show_ref_link: true
  title: Sentence Encoders on STILTs - Supplementary Training on Intermediate Labeled-data
    Tasks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: attention-is-all-you-need
  numCitedBy: 35186
  pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  show_ref_link: true
  title: Attention is All you Need
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: distral-robust-multitask-reinforcement-learning
  numCitedBy: 357
  pid: cf90552b5d2e992e93ab838fd615e1c36618e31c
  show_ref_link: false
  title: Distral - Robust multitask reinforcement learning
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: universal-language-model-fine-tuning-for-text-classification
  numCitedBy: 2252
  pid: 1e077413b25c4d34945cc2707e17e46ed4fe784a
  show_ref_link: true
  title: Universal Language Model Fine-tuning for Text Classification
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: actor-mimic-deep-multitask-and-transfer-reinforcement-learning
  numCitedBy: 440
  pid: 1def5d3711ebd1d86787b1ed57c91832c5ddc90b
  show_ref_link: true
  title: Actor-Mimic - Deep Multitask and Transfer Reinforcement Learning
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: when-is-multitask-learning-effective-semantic-sequence-prediction-under-varying-data-conditions
  numCitedBy: 134
  pid: 9405d0388f90ba1432ef13c21309d8363860e22e
  show_ref_link: false
  title: When is multitask learning effective? Semantic sequence prediction under
    varying data conditions
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: born-again-neural-networks
  numCitedBy: 517
  pid: 2444be7584d1f5a7e2aa9f65078de09154f14ea1
  show_ref_link: false
  title: Born Again Neural Networks
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: semi-supervised-sequence-learning
  numCitedBy: 881
  pid: 4aa9f5150b46320f534de4747a2dd0cd7f3fe292
  show_ref_link: false
  title: Semi-supervised Sequence Learning
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: multilingual-neural-machine-translation-with-knowledge-distillation
  numCitedBy: 155
  pid: 1b24b7b4ac2427d20ab60c8451563eb8d99caf9c
  show_ref_link: false
  title: Multilingual Neural Machine Translation with Knowledge Distillation
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: distilling-the-knowledge-in-a-neural-network
  numCitedBy: 8706
  pid: 0c908739fbff75f03469d13d4a1a07de3414ee19
  show_ref_link: true
  title: Distilling the Knowledge in a Neural Network
  year: 2015
- fieldsOfStudy:
  - Computer Science
  meta_key: multitask-learning
  numCitedBy: 3258
  pid: 47aaeb6dc682162dfe5659c2cad64e5d825ad910
  show_ref_link: false
  title: Multitask Learning
  year: 1998
- fieldsOfStudy:
  - Computer Science
  meta_key: unifying-question-answering-and-text-classification-via-span-extraction
  numCitedBy: 16
  pid: 9e10e2cae05b2906330eb7dde2f27042966413b1
  show_ref_link: false
  title: Unifying Question Answering and Text Classification via Span Extraction
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: adversarial-multi-task-learning-for-text-classification
  numCitedBy: 434
  pid: 9151f229e7b4e318b0b12afe99993da0ee5e0e34
  show_ref_link: false
  title: Adversarial Multi-task Learning for Text Classification
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: unifying-question-answering-text-classification-and-regression-via-span-extraction
  numCitedBy: 19
  pid: 36bc673153aa08c228db9fe5193b546e8d79cd36
  show_ref_link: false
  title: Unifying Question Answering, Text Classification, and Regression via Span
    Extraction
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: squad-100-000-questions-for-machine-comprehension-of-text
  numCitedBy: 4266
  pid: 05dd7254b632376973f3a1b4d39485da17814df5
  show_ref_link: true
  title: SQuAD - 100,000+ Questions for Machine Comprehension of Text
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: a-broad-coverage-challenge-corpus-for-sentence-understanding-through-inference
  numCitedBy: 2037
  pid: 5ded2b8c64491b4a67f6d39ce473d4b9347a672e
  show_ref_link: true
  title: A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: deep-contextualized-word-representations
  numCitedBy: 7988
  pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  show_ref_link: true
  title: Deep Contextualized Word Representations
  year: 2018
- fieldsOfStudy:
  - Computer Science
  - Psychology
  meta_key: semeval-2017-task-1-semantic-textual-similarity-multilingual-and-crosslingual-focused-evaluation
  numCitedBy: 935
  pid: a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096
  show_ref_link: true
  title: SemEval-2017 Task 1 - Semantic Textual Similarity Multilingual and Crosslingual
    Focused Evaluation
  year: 2017
- fieldsOfStudy:
  - Computer Science
  meta_key: distilling-an-ensemble-of-greedy-dependency-parsers-into-one-mst-parser
  numCitedBy: 71
  pid: d43b4801ea469a71b346698bf41197ef97e97d53
  show_ref_link: false
  title: Distilling an Ensemble of Greedy Dependency Parsers into One MST Parser
  year: 2016
- fieldsOfStudy:
  - Computer Science
  meta_key: recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank
  numCitedBy: 5367
  pid: 687bac2d3320083eb4530bf18bb8f8f721477600
  show_ref_link: true
  title: Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank
  year: 2013
- fieldsOfStudy:
  - Computer Science
  meta_key: neural-machine-translation-of-rare-words-with-subword-units
  numCitedBy: 4795
  pid: 1af68821518f03568f913ab03fc02080247a27ff
  show_ref_link: true
  title: Neural Machine Translation of Rare Words with Subword Units
  year: 2016
- fieldsOfStudy:
  - Computer Science
  - Linguistics
  meta_key: neural-network-acceptability-judgments
  numCitedBy: 546
  pid: cb0f3ee1e98faf92429d601cdcd76c69c1e484eb
  show_ref_link: true
  title: Neural Network Acceptability Judgments
  year: 2019
- fieldsOfStudy:
  - Computer Science
  meta_key: do-deep-nets-really-need-to-be-deep
  numCitedBy: 1528
  pid: d770060812fb646b3846a7d398a3066145b5e3c8
  show_ref_link: false
  title: Do Deep Nets Really Need to be Deep?
  year: 2014
- fieldsOfStudy:
  - Computer Science
  meta_key: model-compression
  numCitedBy: 1452
  pid: 30c9bb327b7f2b9f1d1e5b69b9d0c97b410948d9
  show_ref_link: false
  title: Model compression
  year: 2006
- fieldsOfStudy:
  - Education
  meta_key: the-natural-language-decathlon-multitask-learning-as-question-answering
  numCitedBy: 410
  pid: 9784fbf77295860b2e412137b86356d70b25e3c0
  show_ref_link: true
  title: The Natural Language Decathlon - Multitask Learning as Question Answering
  year: 2018
- fieldsOfStudy:
  - Computer Science
  meta_key: automatically-constructing-a-corpus-of-sentential-paraphrases
  numCitedBy: 834
  pid: 475354f10798f110d34792b6d88f31d6d5cb099e
  show_ref_link: false
  title: Automatically Constructing a Corpus of Sentential Paraphrases
  year: 2005
- fieldsOfStudy:
  - Mathematics
  meta_key: a-simple-sequentially-rejective-multiple-test-procedure
  numCitedBy: 19485
  pid: b0ebbcf713b3ddf3f94325bc58dc39ff76fdc412
  show_ref_link: false
  title: A Simple Sequentially Rejective Multiple Test Procedure
  year: 1979
- fieldsOfStudy:
  - Philosophy
  meta_key: the-third-pascal-recognizing-textual-entailment-challenge
  numCitedBy: 474
  pid: b2815bc4c9e4260227cd7ca0c9d68d41c4c2f58b
  show_ref_link: false
  title: The Third PASCAL Recognizing Textual Entailment Challenge
  year: 2007
slug: BAM!-Born-Again-Multi-Task-Networks-for-Natural-Clark-Luong
title: BAM! Born-Again Multi-Task Networks for Natural Language Understanding
url: https://www.semanticscholar.org/paper/BAM!-Born-Again-Multi-Task-Networks-for-Natural-Clark-Luong/ef6948edae12eba6f1d486b8600108b9762f36ab?sort=total-citations
venue: ACL
year: 2019
