authors:
- Kevin Clark
- Minh-Thang Luong
- Urvashi Khandelwal
- Christopher D. Manning
- Quoc V. Le
badges:
- id: OPEN_ACCESS
corpusId: 85464175
fieldsOfStudy:
- Computer Science
numCitedBy: 139
numCiting: 48
paperAbstract: It can be challenging to train multi-task neural networks that outperform
  or even match their single-task counterparts. To help address this, we propose using
  knowledge distillation where single-task models teach a multi-task model. We enhance
  this training with teacher annealing, a novel method that gradually transitions
  the model from distillation to supervised learning, helping the multi-task model
  surpass its single-task teachers. We evaluate our approach by multi-task fine-tuning
  BERT on the GLUE benchmark. Our method consistently improves over standard single-task
  and multi-task training.
ref_count: 48
references:
- pid: ade0c116120b54b57a91da51235108b75c28375a
  title: 'A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks'
- pid: 658721bc13b0fa97366d38c05a96bf0a9f4bb0ac
  title: Multi-Task Deep Neural Networks for Natural Language Understanding
- pid: 03ad06583c9721855ccd82c3d969a01360218d86
  title: Deep multi-task learning with low level tasks supervised at lower layers
- pid: 57458bc1cffe5caa45a885af986d70f723f406b4
  title: 'A unified architecture for natural language processing: deep neural networks
    with multitask learning'
- pid: 6d431f835c06afdea45dff6b24486bf301ebdef0
  title: An Overview of Multi-Task Learning in Deep Neural Networks
- pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
- pid: d76c07211479e233f7c6a6f32d5346c983c5598f
  title: Multi-task Sequence to Sequence Learning
- pid: 93b8da28d006415866bf48f9a6e06b5242129195
  title: 'GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language
    Understanding'
- pid: b47381e04739ea3f392ba6c8faaf64105493c196
  title: 'Sentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data
    Tasks'
- pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  title: Attention is All you Need
- pid: 1e077413b25c4d34945cc2707e17e46ed4fe784a
  title: Universal Language Model Fine-tuning for Text Classification
- pid: 1def5d3711ebd1d86787b1ed57c91832c5ddc90b
  title: 'Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning'
- pid: 4aa9f5150b46320f534de4747a2dd0cd7f3fe292
  title: Semi-supervised Sequence Learning
- pid: 0c908739fbff75f03469d13d4a1a07de3414ee19
  title: Distilling the Knowledge in a Neural Network
- pid: 47aaeb6dc682162dfe5659c2cad64e5d825ad910
  title: Multitask Learning
- pid: 9e10e2cae05b2906330eb7dde2f27042966413b1
  title: Unifying Question Answering and Text Classification via Span Extraction
- pid: 05dd7254b632376973f3a1b4d39485da17814df5
  title: 'SQuAD: 100,000+ Questions for Machine Comprehension of Text'
- pid: 5ded2b8c64491b4a67f6d39ce473d4b9347a672e
  title: A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference
- pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  title: Deep Contextualized Word Representations
- pid: a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096
  title: 'SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual
    Focused Evaluation'
- pid: 687bac2d3320083eb4530bf18bb8f8f721477600
  title: Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank
- pid: 1af68821518f03568f913ab03fc02080247a27ff
  title: Neural Machine Translation of Rare Words with Subword Units
- pid: cb0f3ee1e98faf92429d601cdcd76c69c1e484eb
  title: Neural Network Acceptability Judgments
- pid: 30c9bb327b7f2b9f1d1e5b69b9d0c97b410948d9
  title: Model compression
- pid: 9784fbf77295860b2e412137b86356d70b25e3c0
  title: 'The Natural Language Decathlon: Multitask Learning as Question Answering'
- pid: 475354f10798f110d34792b6d88f31d6d5cb099e
  title: Automatically Constructing a Corpus of Sentential Paraphrases
- pid: b2815bc4c9e4260227cd7ca0c9d68d41c4c2f58b
  title: The Third PASCAL Recognizing Textual Entailment Challenge
slug: BAM!-Born-Again-Multi-Task-Networks-for-Natural-Clark-Luong
title: BAM! Born-Again Multi-Task Networks for Natural Language Understanding
url: https://www.semanticscholar.org/paper/BAM!-Born-Again-Multi-Task-Networks-for-Natural-Clark-Luong/ef6948edae12eba6f1d486b8600108b9762f36ab?sort=total-citations
venue: ACL
year: 2019
