authors:
- Xu Yang
- Kaihua Tang
- Hanwang Zhang
- Jianfei Cai
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 54460890
fieldsOfStudy:
- Computer Science
numCitedBy: 325
numCiting: 67
paperAbstract: 'We propose Scene Graph Auto-Encoder (SGAE) that incorporates the language
  inductive bias into the encoder-decoder image captioning framework for more human-like
  captions. Intuitively, we humans use the inductive bias to compose collocations
  and contextual inference in discourse. For example, when we see the relation ``person
  on bike'''', it is natural to replace ``on'''' with ``ride'''' and infer ``person
  riding bike on a road'''' even the ``road'''' is not evident. Therefore, exploiting
  such bias as a language prior is expected to help the conventional encoder-decoder
  models less likely to overfit to the dataset bias and focus on reasoning. Specifically,
  we use the scene graph --- a directed graph (G) where an object node is connected
  by adjective nodes and relationship nodes --- to represent the complex structural
  layout of both image (I) and sentence (S). In the textual domain, we use SGAE to
  learn a dictionary (D) that helps to reconstruct sentences in the S -> G -> D ->
  S pipeline, where D encodes the desired language prior; in the vision-language domain,
  we use the shared D to guide the encoder-decoder in the I -> G -> D -> S pipeline.
  Thanks to the scene graph representation and shared dictionary, the inductive bias
  is transferred across domains in principle. We validate the effectiveness of SGAE
  on the challenging MS-COCO image captioning benchmark, \eg, our SGAE-based single-model
  achieves a new state-of-the-art 127.8 CIDEr-D on the Karpathy split, and a competitive
  125.5 CIDEr-D (c40) on the official server even compared to other ensemble models.
  Code has been made available at: https://github.com/yangxuntu/SGAE.'
ref_count: 67
references:
- pid: 0000fcfd467a19cf0e59169c2f07d730a0f3a8b9
  title: Exploring Visual Relationship for Image Captioning
- pid: c7d007ba376faddf0046930ea7375ed59600cee9
  title: Graph-Structured Representations for Visual Question Answering
- pid: 3bf09b2e2639add154a9fe6ff98cc373d3e90e4e
  title: Neural Baby Talk
- pid: 996901b08a6b6f401146204f2db0d54aaf8749c8
  title: Visual Translation Embedding Network for Visual Relation Detection
- pid: 9f4d7d622d1f7319cc511bfef661cd973e881a4c
  title: 'Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image
    Captioning'
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: 5785466bc14529e94e54baa4ed051f7037f3b1d3
  title: Boosting Image Captioning with Attributes
- pid: 46b5d408d950287637dd21ce04772d9b2bacfd14
  title: Image Generation from Scene Graphs
- pid: 1c54acd7d9ed8017acdc5674c9b7faac738fd651
  title: 'SPICE: Semantic Propositional Image Caption Evaluation'
- pid: 0da8af8d81e84381ffe656a0bbf2f3937ffac618
  title: 'Neural Motifs: Scene Graph Parsing with Global Context'
- pid: 34b73c1aa158b892bbe41705b4ae5bf01ecaea86
  title: Scene Graph Generation by Iterative Message Passing
- pid: c3a3c163f25b9181f1fb7e71a32482a7393d2088
  title: Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling
- pid: 2606e6a5759c030e259ebf3f4261b9c04a36a609
  title: Generating Semantically Precise Scene Graphs from Textual Descriptions for
    Improved Image Retrieval
- pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
- pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
- pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
- pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
- pid: 85ae705ef4353c6854f5be4a4664269d6317c66b
  title: Image retrieval using scene graphs
- pid: 2a0d0f6c5a69b264710df0230696f47c5918e2f2
  title: Collective Generation of Natural Image Descriptions
- pid: 4d8f2d14af5991d4f0d050d22216825cac3157bd
  title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
- pid: 19b7769dab4e6092aa4b7eeb8aa078a7b725c9b4
  title: Relational inductive biases, deep learning, and graph networks
- pid: 258986132bf17755fe8263e42429fe73218c1534
  title: 'CIDEr: Consensus-based image description evaluation'
- pid: fbdbe747c6aa8b35b981d21e475ff1506a1bae66
  title: Composing Simple Image Descriptions using Web-scale N-grams
- pid: f96898d15a1bf1fa8925b1280d0e07a7a8e72194
  title: Dynamic Memory Networks for Visual and Textual Question Answering
- pid: 5cb6700d94c6118ee13f4f4fecac99f111189812
  title: 'BabyTalk: Understanding and Generating Simple Image Descriptions'
- pid: be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6
  title: Matching Networks for One Shot Learning
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: 30a3eee5e9302108416f6234d739373dde68d373
  title: Learning to Count Objects in Natural Images for Visual Question Answering
- pid: 6c8353697cdbb98dfba4f493875778c4286d3e3a
  title: Self-Critical Sequence Training for Image Captioning
- pid: 4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e
  title: End-To-End Memory Networks
- pid: 492f57ee9ceb61fb5a47ad7aebfec1121887a175
  title: Gated Graph Sequence Neural Networks
- pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
- pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  title: 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks'
- pid: 03eb382e04cca8cca743f7799070869954f1402a
  title: 'CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual
    Reasoning'
- pid: 35c1668dc64d24a28c6041978e5fcca754eb2f4b
  title: Sequence Level Training with Recurrent Neural Networks
- pid: 169b847e69c35cfd475eb4dcc561a24de11762ca
  title: 'Baby talk: Understanding and generating simple image descriptions'
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: 7260c0692f8d265e11c4e9c4c8ef4c185bd587ad
  title: Building machines that learn and think like people
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: 0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7
  title: 'METEOR: An Automatic Metric for MT Evaluation with Improved Correlation
    with Human Judgments'
- pid: 081651b38ff7533550a3adfc1c00da333a8fe86c
  title: How transferable are features in deep neural networks?
- pid: 60b05f32c32519a809f21642ef1eb3eaf3848008
  title: 'ROUGE: A Package for Automatic Evaluation of Summaries'
- pid: 355de7460120ddc1150d9ce3756f9848983f7ff4
  title: 'Midge: Generating Image Descriptions From Computer Vision Detections'
- pid: 7d39d69b23424446f0400ef603b2e3e22d0309d6
  title: 'YOLO9000: Better, Faster, Stronger'
- pid: a600850ac0120cb09a0b7de7da80bb6a7a76de06
  title: Accurate Unlexicalized Parsing
- pid: d7da009f457917aa381619facfa5ffae9329a6e9
  title: 'Bleu: a Method for Automatic Evaluation of Machine Translation'
- pid: 0da353e79f666a3ae7dd0a5d28c75b852a7f60bf
  title: SHOW
- pid: 10d85561e4aafc516d10064f30dff05b41f70afe
  title: '[Et al].'
slug: Auto-Encoding-Scene-Graphs-for-Image-Captioning-Yang-Tang
title: Auto-Encoding Scene Graphs for Image Captioning
url: https://www.semanticscholar.org/paper/Auto-Encoding-Scene-Graphs-for-Image-Captioning-Yang-Tang/f6feb1af1809dfd872d868dfcc13021cc42f496c?sort=total-citations
venue: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2019
