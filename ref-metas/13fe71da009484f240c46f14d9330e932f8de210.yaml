authors:
- Jianpeng Cheng
- Li Dong
- Mirella Lapata
badges:
- id: OPEN_ACCESS
corpusId: 6506243
fieldsOfStudy:
- Computer Science
numCitedBy: 765
numCiting: 94
paperAbstract: In this paper we address the question of how to render sequence-level
  networks better at handling structured input. We propose a machine reading simulator
  which processes text incrementally from left to right and performs shallow reasoning
  with memory and attention. The reader extends the Long Short-Term Memory architecture
  with a memory network in place of a single memory cell. This enables adaptive memory
  usage during recurrence with neural attention, offering a way to weakly induce relations
  among tokens. The system is initially designed to process a single sequence but
  we also demonstrate how to integrate it with an encoder-decoder architecture. Experiments
  on language modeling, sentiment analysis, and natural language inference show that
  our model matches or outperforms the state of the art.
ref_count: 94
references:
- pid: 71ae756c75ac89e2d731c9c79649562b5768ff39
  title: Memory Networks
- pid: 452059171226626718eb677358836328f884298e
  title: 'Ask Me Anything: Dynamic Memory Networks for Natural Language Processing'
- pid: 4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e
  title: End-To-End Memory Networks
- pid: 32de44f01a96d4473d21099d15e25bc2b9f08e2f
  title: Improved Semantic Representations From Tree-Structured Long Short-Term Memory
    Networks
- pid: 27725a2d2a8cee9bf9fffc6c2167017103aba0fa
  title: A Convolutional Neural Network for Modelling Sentences
- pid: f96898d15a1bf1fa8925b1280d0e07a7a8e72194
  title: Dynamic Memory Networks for Visual and Textual Question Answering
- pid: 5b791cd374c7109693aaddee2c12d659ae4e3ec0
  title: Grid Long Short-Term Memory
- pid: 60dda7f5efd67758bde1ee7f45e6d3ef86445495
  title: Deep Recursive Neural Networks for Compositionality in Language
- pid: 596c882de006e4bb4a93f1fa08a5dd467bee060a
  title: Learning Natural Language Inference with LSTM
- pid: 89b1f4740ae37fd04f6ac007577bdd34621f0861
  title: Generating Sequences With Recurrent Neural Networks
- pid: d1505c6123c102e53eb19dff312cb25cea840b72
  title: Teaching Machines to Read and Comprehend
- pid: 0d0b3ff23fbf1ec7a0dfebd923a3ef224306491a
  title: Learning to Execute
- pid: 36c097a225a95735271960e2b63a2cb9e98bff83
  title: A Fast Unified Model for Parsing and Sentence Understanding
- pid: 9665247ea3421929f9b6ad721f139f11edb1dbb8
  title: Learning Longer Memory in Recurrent Neural Networks
- pid: 5522764282c85aea422f1c4dc92ff7e0ca6987bc
  title: A Clockwork RNN
- pid: 0b544dfe355a5070b60986319a3f51fb45d1348e
  title: "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical\
    \ Machine Translation"
- pid: 30110856f45fde473f1903f686aa365cf70ed4c7
  title: 'Learning Context-free Grammars: Capabilities and Limitations of a Recurrent
    Neural Network with an External Stack Memory'
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: 75ddc7ee15be14013a3462c01b38b0548486fbcb
  title: Learning to Compose Neural Networks for Question Answering
- pid: 687bac2d3320083eb4530bf18bb8f8f721477600
  title: Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank
- pid: 2846e83d405cbe3bf2f0f3b5f635dd8b3c680c45
  title: Reasoning about Entailment with Neural Attention
- pid: f04df4e20a18358ea2f689b4c129781628ef7fc1
  title: A large annotated corpus for learning natural language inference
- pid: ae5e6c6f5513613a161b2c85563f9708bf2e9178
  title: Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection
- pid: e837b79de602c69395498c1fbbe39bbb4e6f75ad
  title: Learning to Transduce with Unbounded Memory
- pid: fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5
  title: Neural Machine Translation by Jointly Learning to Align and Translate
- pid: 1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba
  title: Convolutional Neural Networks for Sentence Classification
- pid: 9819b600a828a57e1cde047bbe710d3446b30da5
  title: Recurrent neural network based language model
- pid: 5082a1a13daea5c7026706738f8528391a1e6d59
  title: A Neural Attention Model for Abstractive Sentence Summarization
- pid: 1f4a4769e4d2fb846e59c2f185e0377190739f18
  title: Learning Structured Embeddings of Knowledge Bases
- pid: d0be39ee052d246ae99c082a565aba25b811be2d
  title: Learning long-term dependencies with gradient descent is difficult
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
- pid: d14c7e5f5cace4c925abc74c88baa474e9f31a28
  title: Gated Feedback Recurrent Neural Networks
- pid: f7312b8568d63bbbb239583ed282f46cdc40978d
  title: Toward an Architecture for Never-Ending Language Learning
- pid: f527bcfb09f32e6a4a8afc0b37504941c1ba2cee
  title: Distributed Representations of Sentences and Documents
- pid: b36b7f7c68923d14ba2859b5d28a1124616a8c89
  title: Transition-Based Dependency Parsing with Stack Long Short-Term Memory
- pid: d4b651d6a904f69f8fa1dcad4ebe972296af3a9a
  title: Identifying Relations for Open Information Extraction
- pid: 84069287da0a6b488b8c933f3cb5be759cb6237e
  title: On the difficulty of training recurrent neural networks
- pid: a49498e51840165d55b6badd4b52e34d17860bc0
  title: On the Computational Power of Neural Nets
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: de794d50713ea5f91a7c9da3d72041e2f5ef8452
  title: The PASCAL Recognising Textual Entailment Challenge
- pid: 3f3d13e95c25a8f6a753e38dfce88885097cbd43
  title: Untersuchungen zu dynamischen neuronalen Netzen
slug: Long-Short-Term-Memory-Networks-for-Machine-Reading-Cheng-Dong
title: Long Short-Term Memory-Networks for Machine Reading
url: https://www.semanticscholar.org/paper/Long-Short-Term-Memory-Networks-for-Machine-Reading-Cheng-Dong/13fe71da009484f240c46f14d9330e932f8de210?sort=total-citations
venue: EMNLP
year: 2016
