authors:
- H. Ney
- U. Essen
- Reinhard Kneser
badges: []
corpusId: 206560877
fieldsOfStudy:
- Computer Science
numCitedBy: 599
numCiting: 0
paperAbstract: 'Abstract In this paper, we study the problem of stochastic language
  modelling from the viewpoint of introducing suitable structures into the conditional
  probability distributions. The task of these distributions is to predict the probability
  of a new word by looking at M or even all predecessor words. The conventional approach
  is to limit M to 1 or 2 and to interpolate the resulting bigram and trigram models
  with a unigram model in a linear fashion. However, there are many other structures
  that can be used to model the probabilistic dependences between the predecessor
  word and the word to be predicted. The structures considered in this paper are:
  nonlinear interpolation as an alternative to linear interpolation; equivalence classes
  for word histories and single words; cache memory and word associations. For the
  optimal estimation of nonlinear and linear interpolation parameters, the leaving-one-out
  method is systematically used. For the determination of word equivalence classes
  in a bigram model, an automatic clustering procedure has been adapted. To capture
  long-distance dependences, we consider various models for word-by-word dependences;
  the cache model may be viewed as a special type of self-association. Experimental
  results are presented for two text databases, a Germany database and an English
  database.'
ref_count: 0
references: []
slug: On-structuring-probabilistic-dependences-in-Ney-Essen
title: On structuring probabilistic dependences in stochastic language modelling
url: https://www.semanticscholar.org/paper/On-structuring-probabilistic-dependences-in-Ney-Essen/b3e53b9c0e3a7a60e7a5295e9b08af74d6fb3dbf?sort=total-citations
venue: Comput. Speech Lang.
year: 1994
