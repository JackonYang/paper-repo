authors:
- Vasin Punyakanok
- D. Roth
badges:
- id: OPEN_ACCESS
corpusId: 14509422
fieldsOfStudy:
- Computer Science
numCitedBy: 220
numCiting: 38
paperAbstract: We study the problem of combining the outcomes of several different
  classifiers in a way that provides a coherent inference that satisfies some constraints.
  In particular, we develop two general approaches for an important subproblem - identifying
  phrase structure. The first is a Markovian approach that extends standard HMMs to
  allow the use of a rich observation structure and of general classifiers to model
  state-observation dependencies. The second is an extension of constraint satisfaction
  formalisms. We develop efficient combination algorithms under both models and study
  them experimentally in the context of shallow parsing.
ref_count: 38
references:
- pid: 3ed17a1114e2dc48597ab17cc8d5234006f525c9
  title: 'Learning to Resolve Natural Language Ambiguities: A Unified Approach'
- pid: bece46ed303f8eaef2affae2cba4e0aef51fe636
  title: Maximum Entropy Markov Models for Information Extraction and Segmentation
- pid: a7e084fe51a40eeaaf79bf0b78e837d5bc4a8e10
  title: A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text
- pid: 0b44fcbeea9415d400c5f5789d6b892b6f98daff
  title: 'Building a Large Annotated Corpus of English: The Penn Treebank'
- pid: 56d7826f3afaa374077f87ca3529709b1ca7e044
  title: Parsing By Chunks
- pid: d9c71db75046473f0e3d3229950d7c84c09afd5e
  title: Text Chunking using Transformation-Based Learning
- pid: 8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5
  title: A Tutorial on Hidden Markov Models and Selected Applications
- pid: 81d734347d5d6732be09493180387bd640d3490f
  title: A tutorial on Hidden Markov Models
slug: The-Use-of-Classifiers-in-Sequential-Inference-Punyakanok-Roth
title: The Use of Classifiers in Sequential Inference
url: https://www.semanticscholar.org/paper/The-Use-of-Classifiers-in-Sequential-Inference-Punyakanok-Roth/3fab92869cfab684b3ffb1c16a771e9c3b774acd?sort=total-citations
venue: NIPS
year: 2000
