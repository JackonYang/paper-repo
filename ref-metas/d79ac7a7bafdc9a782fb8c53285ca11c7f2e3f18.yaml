authors:
- Alex Wang
- Kyunghyun Cho
badges:
- id: OPEN_ACCESS
corpusId: 60441316
fieldsOfStudy:
- Computer Science
numCitedBy: 194
numCiting: 24
paperAbstract: We show that BERT (Devlin et al., 2018) is a Markov random field language
  model. This formulation gives way to a natural procedure to sample sentences from
  BERT. We generate from BERT and find that it can produce high quality, fluent generations.
  Compared to the generations of a traditional left-to-right language model, BERT
  generates sentences that are more diverse but of slightly worse quality.
ref_count: 24
references:
- pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
- pid: 88caa4a0253a8b0076176745ebc072864eab66e1
  title: Language Modeling with Gated Convolutional Networks
- pid: efbd381493bb9636f489b965a2034d529cd56bcd
  title: Pointer Sentinel Mixture Models
- pid: cd18800a0fe0b668a1cc19f2ec95b5003d0a5035
  title: Improving Language Understanding by Generative Pre-Training
- pid: ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc
  title: Cross-lingual Language Model Pretraining
- pid: 872bae24c109f7c30e052ac218b17a8b028d08a0
  title: A Connection Between Score Matching and Denoising Autoencoders
- pid: 0e6824e137847be0599bb0032e37042ed2ef5045
  title: 'Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching
    Movies and Reading Books'
- pid: 330da625c15427c6e42ccfa3b747fb29e5835bf0
  title: Efficient Estimation of Word Representations in Vector Space
- pid: e2b7f37cd97a7907b1b8a41138721ed06a0b76cd
  title: 'Stacked Denoising Autoencoders: Learning Useful Representations in a Deep
    Network with a Local Denoising Criterion'
- pid: d7da009f457917aa381619facfa5ffae9329a6e9
  title: 'Bleu: a Method for Automatic Evaluation of Machine Translation'
- pid: 1f462943c8d0af69c12a09058251848324135e5a
  title: Probabilistic Interpretation of Feedforward Classification Network Outputs,
    with Relationships to Statistical Pattern Recognition
- pid: ed91ce023b6500c586802de7d23d8f8f01e5aa1b
  title: Efficiency of pseudolikelihood estimation for simple Gaussian fields
slug: BERT-has-a-Mouth,-and-It-Must-Speak:-BERT-as-a-Wang-Cho
title: 'BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language
  Model'
url: https://www.semanticscholar.org/paper/BERT-has-a-Mouth,-and-It-Must-Speak:-BERT-as-a-Wang-Cho/d79ac7a7bafdc9a782fb8c53285ca11c7f2e3f18?sort=total-citations
venue: Proceedings of the Workshop on Methods for Optimizing and Evaluating Neural
  Language Generation
year: 2019
