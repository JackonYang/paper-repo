authors: []
badges: []
corpusId: 236923196
fieldsOfStudy:
- Computer Science
numCitedBy: 21
numCiting: 25
paperAbstract: 'Understanding document from their visual snapshots is an emerging
  and challenging problem that requires both advanced computer vision and NLP methods.
  Although the recent advance in OCR enables the accurate extraction of text segments,
  it is still challenging to extract key information from documents due to the diversity
  of layouts. To compensate for the difficulties, this paper introduces a pre-trained
  language model, BERT Relying On Spatiality (BROS), that represents and understands
  the semantics of spatially distributed texts. Different from previous pre-training
  methods on 1D text, BROS is pre-trained on large-scale semistructured documents
  with a novel area-masking strategy while efficiently including the spatial layout
  information of input documents. Also, to generate structured outputs in various
  document understanding tasks, BROS utilizes a powerful graphbased decoder that can
  capture the relation between text segments. BROS achieves state-of-the-art results
  on four benchmark tasks: FUNSD, SROIE*, CORD, and SciTSR. Our experimental settings
  and implementation codes will be publicly available.'
ref_count: 25
references:
- pid: 3465c06c872d8c48d628c5fc2d484087719351b6
  title: 'LayoutLM: Pre-training of Text and Layout for Document Image Understanding'
- pid: ba5ed98c4546fada5c732bced4a1c1615f1a4c16
  title: 'PICK: Processing Key Information Extraction from Documents using Improved
    Graph Learning-Convolutional Networks'
- pid: d56c1fc337fb07ec004dc846f80582c327af717c
  title: 'StructBERT: Incorporating Language Structures into Pre-training for Deep
    Language Understanding'
- pid: 04df8c70257b5280b9d303502c9d7ddf946f181b
  title: Graph Convolution for Multimodal Information Extraction from Visually Rich
    Documents
- pid: 756810258e3419af76aff38c895c20343b0602d0
  title: 'ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators'
- pid: 58c793e278cdbf669a615b2c2479cd69ff785d63
  title: 'FUNSD: A Dataset for Form Understanding in Noisy Scanned Documents'
- pid: 15aae08159856cdbf0ce539357d473a04dcbb7f3
  title: 'Chargrid: Towards Understanding 2D Documents'
- pid: 2fbda89395f993040b7665730c64182ade3be195
  title: 'BERTgrid: Contextualized Embedding for 2D Document Representation and Understanding'
- pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
- pid: f8bead3ae810cd3f7427d3004e45b4158da9b744
  title: 'DeepDeSRT: Deep Learning for Detection and Structure Recognition of Tables
    in Document Images'
- pid: bd86b4b551b9d3fb498f62008b037e7599365018
  title: Evaluation of deep convolutional nets for document image classification and
    retrieval
- pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  title: Attention is All you Need
- pid: 81f5810fbbab9b7203b9556f4ce3c741875407bc
  title: 'SpanBERT: Improving Pre-training by Representing and Predicting Spans'
- pid: e0c6abdbdecf04ffac65c440da77fb9d66bb474c
  title: 'XLNet: Generalized Autoregressive Pretraining for Language Understanding'
- pid: 1da8e1ad1814d81f69433ac877ef70caa950e4e6
  title: 'GraphIE: A Graph-Based Framework for Information Extraction'
- pid: c69942bf1b4f75e53cb62d0c5126c1cb4a5aa7bc
  title: 'CORD: A Consolidated Receipt Dataset for Post-OCR Parsing'
- pid: 53a69f1de96a66f0a1b335dfa34895c6d3792354
  title: Configurable Table Structure Recognition in Untagged PDF documents
- pid: d00cbb0c05c1dc922126fe72c1078b773d01c688
  title: ICDAR2019 Competition on Scanned Receipt OCR and Information Extraction
- pid: 87dee6b4a5fcbab541b45a967c24030df6cee29b
  title: Intellix -- End-User Trained Information Extraction for Document Archiving
- pid: da5d93e2931c12b81774a6857db0175875fdf71a
  title: 'Post-OCR parsing: building simple and robust parser via BIO tagging'
- pid: 47c6d10fe8a29fcd1727e805a2b9f804c12e0d4d
  title: Building a test collection for complex document information processing
- pid: d07284a6811f1b2745d91bdb06b040b57f226882
  title: Decoupled Weight Decay Regularization
slug: BROS:-A-PRE-TRAINED-LANGUAGE-MODEL
title: 'BROS: A PRE-TRAINED LANGUAGE MODEL'
url: https://www.semanticscholar.org/paper/BROS:-A-PRE-TRAINED-LANGUAGE-MODEL/aa111c8920e963195968360f59c9de271ae470c2?sort=total-citations
venue: ''
year: 2020
