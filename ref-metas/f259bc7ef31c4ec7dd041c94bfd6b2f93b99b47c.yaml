authors:
- Chen Sun
- Fabien Baradel
- K. Murphy
- C. Schmid
badges:
- id: OPEN_ACCESS
corpusId: 189762371
fieldsOfStudy:
- Computer Science
numCitedBy: 117
numCiting: 41
paperAbstract: This paper aims at learning representations for long sequences of continuous
  signals. Recently, the BERT model has demonstrated the effectiveness of stacked
  transformers for representing sequences of discrete signals (i.e. word tokens).
  Inspired by its success, we adopt the stacked transformer architecture, but generalize
  its training objective to maximize the mutual information between the masked signals,
  and the bidirectional context, via contrastive loss. This enables the model to handle
  continuous signals, such as visual features. We further consider the case when there
  are multiple sequences that are semantically aligned at the sequencelevel but not
  at the element-level (e.g. video and ASR), where we propose to use a Transformer
  to estimate the mutual information between the two sequences, which is again maximized
  via contrastive loss. We demonstrate the effectiveness of the learned representations
  on modeling long video sequences for action anticipation and video captioning. The
  results show that our method, referred to by Contrastive Bidirectional Transformer
  (CBT), outperforms various baselines significantly. Furthermore, we improve over
  the state of the art.
ref_count: 41
references:
- pid: c41a11c0e9b8b92b4faaf97749841170b760760a
  title: 'VideoBERT: A Joint Model for Video and Language Representation Learning'
- pid: df2b0e26d0599ce3e70df8a9da02e51594e0e992
  title: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'
- pid: 6d4e3616d0b27957c4107ae877dc0dd4504b69ab
  title: 'Shuffle and Learn: Unsupervised Learning Using Temporal Order Verification'
- pid: 204e3073870fae3d05bcbc2f6a8e263d9b72e776
  title: Attention is All you Need
- pid: 35ed258aede3df17ee20a6635364cb5fd2461049
  title: End-to-End Dense Video Captioning with Masked Transformer
- pid: 67dccc9a856b60bdc4d058d83657a089b8ad4486
  title: Two-Stream Convolutional Networks for Action Recognition in Videos
- pid: ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1
  title: Generating Videos with Scene Dynamics
- pid: 9405cc0d6169988371b2755e573cc28650d14dfe
  title: Language Models are Unsupervised Multitask Learners
- pid: 3febb2bed8865945e7fddc99efd791887bb7e14f
  title: Deep Contextualized Word Representations
- pid: bd243d77076b3b8fe046bd3dc6e8a02aa9b38d62
  title: 'C3D: Generic Features for Video Analysis'
- pid: 93a87dfa72f22fba14ef243a62c7d0a6906dfed7
  title: Ambient Sound Provides Supervision for Visual Learning
- pid: 0e6824e137847be0599bb0032e37042ed2ef5045
  title: 'Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching
    Movies and Reading Books'
- pid: 2f2d8f8072e5cc9b296fad551f65f183bdbff7aa
  title: Exploring the Limits of Language Modeling
- pid: cc0bb8f933e514dd9441e3082a34a9f129e35500
  title: 'Patch to the Future: Unsupervised Visual Prediction'
- pid: 8b3b8848a311c501e704c45c6d50430ab7068956
  title: 'HMDB: A large video database for human motion recognition'
- pid: da9e411fcf740569b6b356f330a1d0fc077c8d7c
  title: 'UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild'
- pid: e3ce36b9deb47aa6bb2aa19c4bfa71283b505025
  title: 'Noise-contrastive estimation: A new estimation principle for unnormalized
    statistical models'
- pid: d79ac7a7bafdc9a782fb8c53285ca11c7f2e3f18
  title: 'BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language
    Model'
- pid: ac640c2d0f33fb3ab49f37b26982948fc31e3191
  title: Visually Indicated Sounds
slug: Contrastive-Bidirectional-Transformer-for-Temporal-Sun-Baradel
title: Contrastive Bidirectional Transformer for Temporal Representation Learning
url: https://www.semanticscholar.org/paper/Contrastive-Bidirectional-Transformer-for-Temporal-Sun-Baradel/f259bc7ef31c4ec7dd041c94bfd6b2f93b99b47c?sort=total-citations
venue: ArXiv
year: 2019
