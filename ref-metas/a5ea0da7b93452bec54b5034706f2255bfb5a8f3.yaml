authors:
- Anna Rohrbach
- Marcus Rohrbach
- Niket Tandon
- B. Schiele
badges:
- id: UNPAYWALL
- id: OPEN_ACCESS
corpusId: 15184723
fieldsOfStudy:
- Computer Science
numCitedBy: 322
numCiting: 79
paperAbstract: Audio Description (AD) provides linguistic descriptions of movies and
  allows visually impaired people to follow a movie along with their peers. Such descriptions
  are by design mainly visual and thus naturally form an interesting data source for
  computer vision and computational linguistics. In this work we propose a novel dataset
  which contains transcribed ADs, which are temporally aligned to full length HD movies.
  In addition we also collected the aligned movie scripts which have been used in
  prior work and compare the two different sources of descriptions. In total the MPII
  Movie Description dataset (MPII-MD) contains a parallel corpus of over 68K sentences
  and video snippets from 94 HD movies. We characterize the dataset by benchmarking
  different approaches for generating video descriptions. Comparing ADs to scripts,
  we find that ADs are far more visual and describe precisely what is shown rather
  than what should happen according to the scripts created prior to movie production.
ref_count: 79
references:
- pid: c980b058f98dc1904ad328c2341a47c31479d076
  title: 'Movie/Script: Alignment and Parsing of Video and Text Transcription'
- pid: e8cd37fbd8bd5e690eef5861cf92af8e002d4533
  title: Translating Video Content to Natural Language Descriptions
- pid: a23ab0fb7d9e9961e92d704ed71e3dbc15c0d908
  title: 'A Thousand Frames in Just a Few Words: Lingual Description of Videos through
    Latent Topics and Sparse Object Stitching'
- pid: eaaed23a2d94feb2f1c3ff22a25777c7a78f3141
  title: 'Every Picture Tells a Story: Generating Sentences from Images'
- pid: 889e723cd6d581e120ee6776b231fdf69707ab50
  title: Coherent Multi-sentence Video Description with Variable Level of Detail
- pid: 55e022fb7581bb9e1fce678d21fb25ffbb3fbb88
  title: Deep Visual-Semantic Alignments for Generating Image Descriptions
- pid: f4af49a1ead3c81cc5d023878cb67c5646dd8a04
  title: Learning a Recurrent Visual Representation for Image Caption Generation
- pid: 21b3007f967d39e1346bc91e0fc8b3f16121300c
  title: Grounding Action Descriptions in Videos
- pid: 15f102c3c9f4d4fe6ba105e221df48c6e8902b3b
  title: From captions to visual concepts and back
- pid: d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0
  title: 'Show and tell: A neural image caption generator'
- pid: 20ab42c9b93b6e41f6e1d7b546f87c5a871db020
  title: Integrating Language and Vision to Generate Natural Language Descriptions
    of Videos in the Wild
- pid: 0f86767732f76f478d5845f2e59f99ba106e9265
  title: Learning realistic human actions from movies
- pid: fbdbe747c6aa8b35b981d21e475ff1506a1bae66
  title: Composing Simple Image Descriptions using Web-scale N-grams
- pid: 0ca7d208ff8d81377e0eaa9723820aeae7a7322d
  title: Grounded Compositional Semantics for Finding and Describing Images with Sentences
- pid: 2a0d0f6c5a69b264710df0230696f47c5918e2f2
  title: Collective Generation of Natural Image Descriptions
- pid: 8e080b98efbe65c02a116439205ca2344b9f7cd4
  title: 'Im2Text: Describing Images Using 1 Million Captioned Photographs'
- pid: 2e36ea91a3c8fbff92be2989325531b4002e2afc
  title: Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models
- pid: 59927ded86ab4f7253fc32efb351e5a13e746ead
  title: 'TreeTalk: Composition and Compression of Trees for Image Descriptions'
- pid: 49927656ede0c75af22ca73dcf4abba028839650
  title: Understanding videos, constructing plots learning a visually grounded storyline
    model from annotated videos
- pid: b705317a618911b5f6e611181eeeece0a7079f80
  title: Actions in context
- pid: 169b847e69c35cfd475eb4dcc561a24de11762ca
  title: 'Baby talk: Understanding and generating simple image descriptions'
- pid: d6a7a563640bf53953c4fda0997e4db176488510
  title: 'YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic
    Hierarchies and Zero-Shot Recognition'
- pid: a4aba56927d7841c0aaedf5c73d42ccfadd75124
  title: Hello! My name is... Buffy'' -- Automatic Naming of Characters in TV Video
- pid: f01fc808592ea7c473a69a6e7484040a435f36d9
  title: Long-term recurrent convolutional networks for visual recognition and description
- pid: 43795b7bac3d921c4e579964b54187bdbf6c6330
  title: Translating Videos to Natural Language Using Deep Recurrent Neural Networks
- pid: fad611e35b3731740b4d8b754241e77add5a70b9
  title: Multimodal Neural Language Models
- pid: d53a97a3dd7760b193c0d9a5293b60feff239059
  title: Natural Language Description of Human Activities from Video Images Based
    on Concept Hierarchy of Actions
- pid: 71b7178df5d2b112d07e45038cb5637208659ff7
  title: 'Microsoft COCO: Common Objects in Context'
- pid: 54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745
  title: Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)
- pid: 1b47265245e8db53a553049dcb27ed3e495fd625
  title: 'ImageNet: A large-scale hierarchical image database'
- pid: 793c1c908672ea71aef9e1b41a46272aa27598f7
  title: Video In Sentences Out
- pid: 44040913380206991b1991daf1192942e038fe31
  title: 'From image descriptions to visual denotations: New similarity metrics for
    semantic inference over event descriptions'
- pid: bbe0819a47a9f3f11dd34bb3ab44a997ef111088
  title: Dense Trajectories and Motion Boundary Descriptors for Action Recognition
- pid: 554a31ce91189cf6022ac677413ef2f8b9b40ca7
  title: Collecting Highly Parallel Data for Paraphrase Evaluation
- pid: d721f4d64b8e722222c876f0a0f226ed49476347
  title: Action Recognition with Improved Trajectories
- pid: 9667f8264745b626c6173b1310e2ff0298b09cfc
  title: Learning Deep Features for Scene Recognition using Places Database
- pid: 547f23597f9ec8a93f66cedaa6fbfb73960426b1
  title: The Berkeley FrameNet Project
- pid: 908091b4a8757c3b2f7d9cfa2c4f616ee12c5157
  title: 'SUN database: Large-scale scene recognition from abbey to zoo'
- pid: 355de7460120ddc1150d9ce3756f9848983f7ff4
  title: 'Midge: Generating Image Descriptions From Computer Vision Detections'
- pid: 40eac6e6bb54e0da7885989f220f4d3f70249950
  title: 'LSDA: Large Scale Detection through Adaptation'
- pid: b29447ba499507a259ae9d8f685d60cc1597d7d3
  title: Semantic Parsing on Freebase from Question-Answer Pairs
- pid: e74f9b7f8eec6ba4704c206b93bc8079af3da4bd
  title: ImageNet Large Scale Visual Recognition Challenge
- pid: f86ec155cce6259e5230aaad3b762343757feb1d
  title: Open question answering over curated and extracted knowledge bases
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: d87ceda3042f781c341ac17109d1e94a717f5f60
  title: 'WordNet : an electronic lexical database'
- pid: 4ee2eab4c298c1824a9fb8799ad8eed21be38d21
  title: 'Moses: Open Source Toolkit for Statistical Machine Translation'
- pid: 495f3405da229b903797472c64d09d83659fdb34
  title: 'WordNet: : Similarity - Measuring the Relatedness of Concepts'
- pid: 99e8d34817ae10d7304521e89c5fbf908b9d856b
  title: 'Open Source Toolkit for Statistical Machine Translation: Factored Translation
    Models and Lattice Decoding'
slug: A-dataset-for-Movie-Description-Rohrbach-Rohrbach
title: A dataset for Movie Description
url: https://www.semanticscholar.org/paper/A-dataset-for-Movie-Description-Rohrbach-Rohrbach/a5ea0da7b93452bec54b5034706f2255bfb5a8f3?sort=total-citations
venue: 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2015
