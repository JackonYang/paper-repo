authors:
- D. Plaut
- S. Nowlan
- Geoffrey E. Hinton
badges:
- id: OPEN_ACCESS
corpusId: 15150815
fieldsOfStudy:
- Computer Science
numCitedBy: 390
numCiting: 9
paperAbstract: 'Abstract : Rumelhart, Hinton and Williams (Rumelhart 86) describe
  a learning procedure for layered networks of deterministic, neuron-like units. This
  paper describes further research on the learning procedure. We start by describing
  the units, the way they are connected, the learning procedure, and the extension
  to iterative nets. We then give an example in which a network learns a set of filters
  that enable it to discriminate formant-like patterns in the presence of noise. The
  speed of learning is strongly dependent on the shape of the surface formed by the
  error measure in weight space . We give examples of the shape of the error surface
  for a typical task and illustrate how an acceleration method speeds up descent in
  weight space. The main drawback of the learning procedure is the way it scales as
  the size of the task and the network increases. We give some preliminary results
  on scaling and show how the magnitude of the optimal weight changes depends on the
  fan-in of the units. Additional results illustrate the effects on learning speed
  of the amount of interaction between the weights. A variation of the learning procedure
  that back-propagates desired state information rather than error gradients is developed
  and compared with the standard procedure. Finally, we discuss the relationship between
  our iterative networks and the analog networks described by Hopefield and Tank (Hopfield
  85). The learning procedure can discover appropriate weights in their kind of network,
  as well as determine an optimal schedule for varying the nonlinearity of the units
  during a search.'
ref_count: 9
references:
- pid: 44f2679f8169e7f6449c52e058ebe6a45838b3c0
  title: Learning Process in an Asymmetric Threshold Network
- pid: a0d16f0e99f7ce5e6fb70b1a68c685e9ad610657
  title: A Learning Algorithm for Boltzmann Machines
- pid: 98b4d4e24aab57ab4e1124ff8106909050645cfa
  title: Neural networks and physical systems with emergent collective computational
    abilities.
- pid: 1718965f492d4e9fe1d98a3fb83efe671a4aed2c
  title: OPTIMAL PERCEPTUAL INFERENCE
- pid: a8059c598e4f9643eb040685af0d6e7055391048
  title: On Edge Detection
- pid: 111fd833a4ae576cfdbb27d87d2f8fc0640af355
  title: Learning internal representations by error propagation
- pid: dd5061631a4d11fa394f4421700ebf7e78dcbc59
  title: Optimization by Simulated Annealing
- pid: d007ed936c51a700d8c65d1bbfae7acc83783c31
  title: Une procedure d'apprentissage pour reseau a seuil asymmetrique (A learning
    scheme for asymmetric threshold networks)
slug: Experiments-on-Learning-by-Back-Propagation.-Plaut-Nowlan
title: Experiments on Learning by Back Propagation.
url: https://www.semanticscholar.org/paper/Experiments-on-Learning-by-Back-Propagation.-Plaut-Nowlan/4a42b2104ca8ff891ae77c40a915d4c94c8f8428?sort=total-citations
venue: ''
year: 1986
