authors:
- Yu Jiang
- Vivek Natarajan
- Xinlei Chen
- Marcus Rohrbach
- Dhruv Batra
- Devi Parikh
badges:
- id: OPEN_ACCESS
corpusId: 50787139
fieldsOfStudy:
- Computer Science
numCitedBy: 140
numCiting: 17
paperAbstract: "This document describes Pythia v0.1, the winning entry from Facebook\
  \ AI Research (FAIR)'s A-STAR team to the VQA Challenge 2018. \nOur starting point\
  \ is a modular re-implementation of the bottom-up top-down (up-down) model. We demonstrate\
  \ that by making subtle but important changes to the model architecture and the\
  \ learning rate schedule, fine-tuning image features, and adding data augmentation,\
  \ we can significantly improve the performance of the up-down model on VQA v2.0\
  \ dataset -- from 65.67% to 70.22%. \nFurthermore, by using a diverse ensemble of\
  \ models trained with different features and on different datasets, we are able\
  \ to significantly improve over the 'standard' way of ensembling (i.e. same model\
  \ with different random seeds) by 1.31%. Overall, we achieve 72.27% on the test-std\
  \ split of the VQA v2.0 dataset. Our code in its entirety (training, evaluation,\
  \ data-augmentation, ensembling) and pre-trained models are publicly available at:\
  \ this https URL"
ref_count: 17
references:
- pid: b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81
  title: 'Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge'
- pid: a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c
  title: 'Making the V in VQA Matter: Elevating the Role of Image Understanding in
    Visual Question Answering'
- pid: 0d57ba12a6d958e178d83be4c84513f7e42b24e5
  title: 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'
- pid: a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8
  title: Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
    Answering
- pid: f6e0856b4a9199fa968ac00da612a9407b5cb85c
  title: Aggregated Residual Transformations for Deep Neural Networks
- pid: 3d2c6941a9b4608ba52b328369a3352db2092ae0
  title: 'Weight Normalization: A Simple Reparameterization to Accelerate Training
    of Deep Neural Networks'
- pid: 0c0f41d3162e76500d4639557ff4463bd246e395
  title: 'Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for
    Visual Question Answering'
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: 2c03df8b48bf3fa39054345bafabfeff15bfd11d
  title: Deep Residual Learning for Image Recognition
- pid: 97ad70a9fa3f99adf18030e5e38ebe3d90daa2db
  title: 'VQA: Visual Question Answering'
- pid: fddc15480d086629b960be5bff96232f967f2252
  title: Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual
    Grounding
- pid: b9b4e05faa194e5022edd9eb9dd07e3d675c2b36
  title: Feature Pyramid Networks for Object Detection
- pid: 2231f44be9a8472a46d8e8a628b4e52b9a8f44e0
  title: Visual Dialog
- pid: 424561d8585ff8ebce7d5d07de8dbf7aae5e7270
  title: 'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks'
- pid: afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d
  title: 'Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image
    Annotations'
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
slug: Pythia-v0.1:-the-Winning-Entry-to-the-VQA-Challenge-Jiang-Natarajan
title: 'Pythia v0.1: the Winning Entry to the VQA Challenge 2018'
url: https://www.semanticscholar.org/paper/Pythia-v0.1:-the-Winning-Entry-to-the-VQA-Challenge-Jiang-Natarajan/36c3972569a6949ecca90bfa6f8e99883e092845?sort=total-citations
venue: ArXiv
year: 2018
