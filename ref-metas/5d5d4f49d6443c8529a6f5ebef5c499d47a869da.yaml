authors:
- Nitish Srivastava
badges:
- id: OPEN_ACCESS
corpusId: 17084851
fieldsOfStudy:
- Computer Science
numCitedBy: 236
numCiting: 32
paperAbstract: Improving Neural Networks with Dropout Nitish Srivastava Master of
  Science Graduate Department of Computer Science University of Toronto 2013 Deep
  neural nets with a huge number of parameters are very powerful machine learning
  systems. However, overfitting is a serious problem in such networks. Large networks
  are also slow to use, making it difficult to deal with overfitting by combining
  many different large neural nets at test time. Dropout is a technique for addressing
  this problem. The key idea is to randomly drop units (along with their connections)
  from a neural network during training. This prevents the units from co-adapting
  too much. Dropping units creates thinned networks during training. The number of
  possible thinned networks is exponential in the number of units in the network.
  At test time all possible thinned networks are combined using an approximate model
  averaging procedure. Dropout training followed by this approximate model combination
  significantly reduces overfitting and gives major improvements over other regularization
  methods. In this work, we describe models that improve the performance of neural
  networks using dropout, often obtaining state-of-the-art results on benchmark datasets.
ref_count: 32
references:
- pid: 1366de5bb112746a555e9c0cd00de3ad8628aea8
  title: Improving neural networks by preventing co-adaptation of feature detectors
- pid: abd1c342495432171beb7ca8fd9551ef13cbd0ff
  title: ImageNet classification with deep convolutional neural networks
- pid: 8978cf7574ceb35f4c3096be768c7547b28a35d0
  title: A Fast Learning Algorithm for Deep Belief Nets
- pid: e2b7f37cd97a7907b1b8a41138721ed06a0b76cd
  title: 'Stacked Denoising Autoencoders: Learning Useful Representations in a Deep
    Network with a Local Denoising Criterion'
- pid: 85021c84383d18a7a4434d76dc8135fc6bdc0aa6
  title: Deep Boltzmann Machines
- pid: 5562a56da3a96dae82add7de705e2bd841eb00fc
  title: Best practices for convolutional neural networks applied to visual document
    analysis
- pid: d2b62f77cb2864e465aa60bca6c26bb1d2f84963
  title: Acoustic Modeling Using Deep Belief Networks
- pid: db869fa192a3222ae4f2d766674a378e47013b1b
  title: Bayesian Learning for Neural Networks
- pid: 46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e
  title: Reducing the Dimensionality of Data with Neural Networks
- pid: 843959ffdccf31c6694d135fad07425924f785b1
  title: Extracting and composing robust features with denoising autoencoders
- pid: 90b63e917d5737b06357d50aa729619e933d9614
  title: Phone Recognition with the Mean-Covariance Restricted Boltzmann Machine
- pid: 9f7f9aba0a6a966ce04e29e401ea28f9eae82f02
  title: Convolutional neural networks applied to house numbers digit classification
- pid: 5726c7b40fcc454b77d989656c085520bf6c15fa
  title: Multimodal learning with deep Boltzmann machines
- pid: 80e9e3fc3670482c1fee16b2542061b779f47c4f
  title: Multimodal Deep Learning
- pid: 02227c94dd41fe0b439e050d377b0beb5d427cda
  title: Reading Digits in Natural Images with Unsupervised Feature Learning
- pid: e0f49caabbf79ffda35432219bb0ec9b41753dff
  title: Multimodal semi-supervised learning for image classification
- pid: 3a1a2cff2b70fb84a7ca7d97f8adcc5855851795
  title: The Kaldi Speech Recognition Toolkit
- pid: b365b8e45b7d81f081de44ac8f9eadf9144f3ca5
  title: Regression Shrinkage and Selection via the Lasso
- pid: 0ea90fac0958d84bcf4a2875c2b169478358b480
  title: 'CUDAMat: a CUDA-based matrix class for Python'
- pid: 8423a5782a1acda21a6f68c307ce5376ebef13c7
  title: Rank, Trace-Norm and Max-Norm
slug: Improving-Neural-Networks-with-Dropout-Srivastava
title: Improving Neural Networks with Dropout
url: https://www.semanticscholar.org/paper/Improving-Neural-Networks-with-Dropout-Srivastava/5d5d4f49d6443c8529a6f5ebef5c499d47a869da?sort=total-citations
venue: ''
year: 2013
