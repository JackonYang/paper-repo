authors:
- Shuohang Wang
- Jing Jiang
badges:
- id: OPEN_ACCESS
corpusId: 5592690
fieldsOfStudy:
- Computer Science
numCitedBy: 541
numCiting: 23
paperAbstract: Machine comprehension of text is an important problem in natural language
  processing. A recently released dataset, the Stanford Question Answering Dataset
  (SQuAD), offers a large number of real questions and their answers created by humans
  through crowdsourcing. SQuAD provides a challenging testbed for evaluating machine
  comprehension algorithms, partly because compared with previous datasets, in SQuAD
  the answers do not come from a small set of candidate answers and they have variable
  lengths. We propose an end-to-end neural architecture for the task. The architecture
  is based on match-LSTM, a model we proposed previously for textual entailment, and
  Pointer Net, a sequence-to-sequence model proposed by Vinyals et al.(2015) to constrain
  the output tokens to be from the input sequences. We propose two ways of using Pointer
  Net for our task. Our experiments show that both of our two models substantially
  outperform the best results obtained by Rajpurkar et al.(2016) using logistic regression
  and manually crafted features.
ref_count: 23
references:
- pid: 05dd7254b632376973f3a1b4d39485da17814df5
  title: 'SQuAD: 100,000+ Questions for Machine Comprehension of Text'
- pid: b1e20420982a4f923c08652941666b189b11b7fe
  title: A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task
- pid: 564257469fa44cdb57e4272f85253efb9acfd69d
  title: 'MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of
    Text'
- pid: abb33d75dc297993fcc3fb75e0f4498f413eb4f6
  title: 'Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks'
- pid: 832fc9327695f7425d8759c6aaeec0fa2d7b0a90
  title: 'WikiReading: A Novel Large-scale Language Understanding Task over Wikipedia'
- pid: 596c882de006e4bb4a93f1fa08a5dd467bee060a
  title: Learning Natural Language Inference with LSTM
- pid: 452059171226626718eb677358836328f884298e
  title: 'Ask Me Anything: Dynamic Memory Networks for Natural Language Processing'
- pid: f2e50e2ee4021f199877c8920f1f984481c723aa
  title: Text Understanding with the Attention Sum Reader Network
- pid: 1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7
  title: 'MovieQA: Understanding Stories in Movies through Question-Answering'
- pid: d1505c6123c102e53eb19dff312cb25cea840b72
  title: Teaching Machines to Read and Comprehend
- pid: ba30df190664193514d1d309cb673728ed48f449
  title: Incorporating Copying Mechanism in Sequence-to-Sequence Learning
- pid: 4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e
  title: End-To-End Memory Networks
- pid: 35b91b365ceb016fb3e022577cec96fb9b445dc5
  title: 'The Goldilocks Principle: Reading Children''s Books with Explicit Memory
    Representations'
- pid: 9653d5c2c7844347343d073bbedd96e05d52f69b
  title: Pointer Networks
- pid: 71ae756c75ac89e2d731c9c79649562b5768ff39
  title: Memory Networks
- pid: f37e1b62a767a307c046404ca96bc140b3e68cb5
  title: 'GloVe: Global Vectors for Word Representation'
- pid: 44d2abe2175df8153f465f6c39b68b76a0d40ab9
  title: Long Short-Term Memory
- pid: a6cb366736791bcccc5c8639de5a8f9636bf87e8
  title: 'Adam: A Method for Stochastic Optimization'
- pid: 94e3e7bc3d23276f0ee2d1cb8f9d14aa19668d5f
  title: Under Review as a Conference Paper at Iclr 2017 Delving into Transferable
    Adversarial Ex- Amples and Black-box Attacks
slug: Machine-Comprehension-Using-Match-LSTM-and-Answer-Wang-Jiang
title: Machine Comprehension Using Match-LSTM and Answer Pointer
url: https://www.semanticscholar.org/paper/Machine-Comprehension-Using-Match-LSTM-and-Answer-Wang-Jiang/ff1861b71eaedba46cb679bbe2c585dbe18f9b19?sort=total-citations
venue: ICLR
year: 2017
