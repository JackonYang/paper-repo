authors:
- Yezhou Yang
- C. L. Teo
- "Hal Daum\xE9"
- Y. Aloimonos
badges:
- id: OPEN_ACCESS
corpusId: 1539668
fieldsOfStudy:
- Computer Science
numCitedBy: 356
numCiting: 30
paperAbstract: We propose a sentence generation strategy that describes images by
  predicting the most likely nouns, verbs, scenes and prepositions that make up the
  core sentence structure. The input are initial noisy estimates of the objects and
  scenes detected in the image using state of the art trained detectors. As predicting
  actions from still images directly is unreliable, we use a language model trained
  from the English Gigaword corpus to obtain their estimates; together with probabilities
  of co-located nouns, scenes and prepositions. We use these estimates as parameters
  on a HMM that models the sentence generation process, with hidden nodes as sentence
  components and image detections as the emissions. Experimental results show that
  our strategy of combining vision and language produces readable and descriptive
  sentences compared to naive strategies that use vision alone.
ref_count: 30
references:
- pid: eaaed23a2d94feb2f1c3ff22a25777c7a78f3141
  title: 'Every Picture Tells a Story: Generating Sentences from Images'
- pid: 05e074abddd3fe987b9bebd46f6cf4bf8465c37e
  title: 'I2T: Image Parsing to Text Description'
- pid: 50499aa9af9b4be0f5ef3ffbdd24299f3c402586
  title: 'Grouplet: A structured image representation for recognizing human and object
    interactions'
- pid: 869171b2f56cfeaa9b81b2626cb4956fea590a57
  title: 'Modeling the Shape of the Scene: A Holistic Representation of the Spatial
    Envelope'
- pid: c93fcbc5512a4634a557f420bcfad4caa313c470
  title: Recognizing human actions from still images with latent poses
- pid: 860a9d55d87663ca88e74b3ca357396cd51733d0
  title: A discriminatively trained, multiscale, deformable part model
- pid: e79272fe3d65197100eae8be9fec6469107969ae
  title: Object Detection with Discriminatively Trained Part Based Models
- pid: 37684bb33f21dc70619597498f1b95fb44fbb139
  title: Context-based vision system for place and object recognition
- pid: c63bb976dc0d3a897f3b0920170a4c573ef904c6
  title: Automatic Evaluation of Summaries Using N-gram Co-occurrence Statistics
- pid: efc0cb142588a6dd571e52b30217c4a7905f254d
  title: Human detection using partial least squares analysis
- pid: 6a2ed19ac684022aa3186887cd4893484ab8f80c
  title: The PASCAL visual object classes challenge 2006 (VOC2006) results
- pid: 2788d0f1f7fbd44ebb5185e59c4aaf09aad97013
  title: What's in a picture?
- pid: 0ec48ac86456cea3d6d6172ca81ef68e98b21a61
  title: The PASCAL Visual Object Classes Challenge
slug: Corpus-Guided-Sentence-Generation-of-Natural-Images-Yang-Teo
title: Corpus-Guided Sentence Generation of Natural Images
url: https://www.semanticscholar.org/paper/Corpus-Guided-Sentence-Generation-of-Natural-Images-Yang-Teo/76a1dca3a9c2b0229c1b12c95752dcf40dc95a11?sort=total-citations
venue: EMNLP
year: 2011
